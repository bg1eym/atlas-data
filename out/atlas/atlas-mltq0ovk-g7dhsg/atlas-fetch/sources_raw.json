{
  "run_id": "atlas-mltq0ovk-g7dhsg",
  "item_count": 985,
  "item_count_after_policy": 118,
  "by_source": {
    "techcrunch-alt-tech-breakthrough-ovr": [
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-klhxon",
        "title": "Meta is shutting down Messenger’s standalone website",
        "link": "https://techcrunch.com/2026/02/19/meta-is-shutting-down-messengers-standalone-website/",
        "url": "https://techcrunch.com/2026/02/19/meta-is-shutting-down-messengers-standalone-website/",
        "content": "The move comes a few months after Meta shut down Messenger’s stand-alone desktop apps for Windows and Mac.",
        "contentSnippet": "The move comes a few months after Meta shut down Messenger’s stand-alone desktop apps for Windows and Mac.",
        "pubDate": "Thu, 19 Feb 2026 17:01:29 +0000",
        "isoDate": "2026-02-19T17:01:29.000Z",
        "creator": "Aisha Malik",
        "source": "https://techcrunch.com/2026/02/19/meta-is-shutting-down-messengers-standalone-website/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-i0cey7",
        "title": "New York hits the brakes on robotaxi expansion plan",
        "link": "https://techcrunch.com/2026/02/19/new-york-hits-the-brakes-on-robotaxi-expansion-plan/",
        "url": "https://techcrunch.com/2026/02/19/new-york-hits-the-brakes-on-robotaxi-expansion-plan/",
        "content": "The governor of New York pulled a robotaxi expansion proposal that was viewed as a win for Waymo. ",
        "contentSnippet": "The governor of New York pulled a robotaxi expansion proposal that was viewed as a win for Waymo.",
        "pubDate": "Thu, 19 Feb 2026 16:53:05 +0000",
        "isoDate": "2026-02-19T16:53:05.000Z",
        "creator": "Kirsten Korosec",
        "source": "https://techcrunch.com/2026/02/19/new-york-hits-the-brakes-on-robotaxi-expansion-plan/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-98gbw",
        "title": "Zuckerberg grilled in court over social media harms on teens",
        "link": "https://techcrunch.com/2026/02/19/zuckerberg-grilled-in-court-over-social-media-harms-on-teens/",
        "url": "https://techcrunch.com/2026/02/19/zuckerberg-grilled-in-court-over-social-media-harms-on-teens/",
        "content": "Meta's CEO was questioned over the addictive nature of its social media apps like Instagram, and other teen harms. ",
        "contentSnippet": "Meta's CEO was questioned over the addictive nature of its social media apps like Instagram, and other teen harms.",
        "pubDate": "Thu, 19 Feb 2026 16:41:59 +0000",
        "isoDate": "2026-02-19T16:41:59.000Z",
        "creator": "Sarah Perez",
        "source": "https://techcrunch.com/2026/02/19/zuckerberg-grilled-in-court-over-social-media-harms-on-teens/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-vve5ib",
        "title": "SoftBank to spend an eye-popping $33B to build huge U.S. gas power plant",
        "link": "https://techcrunch.com/2026/02/19/softbank-to-spend-an-eye-popping-33b-to-build-huge-u-s-gas-power-plant/",
        "url": "https://techcrunch.com/2026/02/19/softbank-to-spend-an-eye-popping-33b-to-build-huge-u-s-gas-power-plant/",
        "content": "If completed, the project would be among the largest and most expensive natural gas power plants.",
        "contentSnippet": "If completed, the project would be among the largest and most expensive natural gas power plants.",
        "pubDate": "Thu, 19 Feb 2026 16:27:58 +0000",
        "isoDate": "2026-02-19T16:27:58.000Z",
        "creator": "Tim De Chant",
        "source": "https://techcrunch.com/2026/02/19/softbank-to-spend-an-eye-popping-33b-to-build-huge-u-s-gas-power-plant/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-d8okhy",
        "title": "OpenAI reportedly finalizing $100B deal at more than $850B valuation",
        "link": "https://techcrunch.com/2026/02/19/openai-reportedly-finalizing-100b-deal-at-more-than-850b-valuation/",
        "url": "https://techcrunch.com/2026/02/19/openai-reportedly-finalizing-100b-deal-at-more-than-850b-valuation/",
        "content": "OpenAI is reportedly getting close to closing a $100 billion deal, with backers including Amazon, Nvidia, SoftBank, and Microsoft. The deal would value the ChatGPT-maker at $850 billion.",
        "contentSnippet": "OpenAI is reportedly getting close to closing a $100 billion deal, with backers including Amazon, Nvidia, SoftBank, and Microsoft. The deal would value the ChatGPT-maker at $850 billion.",
        "pubDate": "Thu, 19 Feb 2026 15:35:58 +0000",
        "isoDate": "2026-02-19T15:35:58.000Z",
        "creator": "Rebecca Bellan",
        "source": "https://techcrunch.com/2026/02/19/openai-reportedly-finalizing-100b-deal-at-more-than-850b-valuation/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-j3lqyb",
        "title": "Current is a new RSS reader that’s more like a river than an inbox",
        "link": "https://techcrunch.com/2026/02/19/current-is-a-new-rss-reader-thats-more-like-a-river-than-an-inbox/",
        "url": "https://techcrunch.com/2026/02/19/current-is-a-new-rss-reader-thats-more-like-a-river-than-an-inbox/",
        "content": "Current introduces a stress-free, totally reimagined RSS news reading app as a one-time paid download. ",
        "contentSnippet": "Current introduces a stress-free, totally reimagined RSS news reading app as a one-time paid download.",
        "pubDate": "Thu, 19 Feb 2026 15:33:29 +0000",
        "isoDate": "2026-02-19T15:33:29.000Z",
        "creator": "Sarah Perez",
        "source": "https://techcrunch.com/2026/02/19/current-is-a-new-rss-reader-thats-more-like-a-river-than-an-inbox/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-rysvtt",
        "title": "Sex toys maker Tenga says hacker stole customer information",
        "link": "https://techcrunch.com/2026/02/19/sex-toys-maker-tenga-says-hacker-stole-customer-information/",
        "url": "https://techcrunch.com/2026/02/19/sex-toys-maker-tenga-says-hacker-stole-customer-information/",
        "content": "The Japanese sex toy maker said a hacker broke into an employee's inbox and stole customer names, email addresses, and correspondence, including order details and customer service inquiries.",
        "contentSnippet": "The Japanese sex toy maker said a hacker broke into an employee's inbox and stole customer names, email addresses, and correspondence, including order details and customer service inquiries.",
        "pubDate": "Thu, 19 Feb 2026 15:25:00 +0000",
        "isoDate": "2026-02-19T15:25:00.000Z",
        "creator": "Lorenzo Franceschi-Bicchierai",
        "source": "https://techcrunch.com/2026/02/19/sex-toys-maker-tenga-says-hacker-stole-customer-information/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-duuexl",
        "title": "Bug in student admissions website exposed children’s personal information",
        "link": "https://techcrunch.com/2026/02/19/bug-in-student-admissions-website-exposed-childrens-personal-information/",
        "url": "https://techcrunch.com/2026/02/19/bug-in-student-admissions-website-exposed-childrens-personal-information/",
        "content": "Ravenna Hub, which lets parents apply and track the status of their kids' applications across thousands of schools, allowed any logged-in user to access the personally identifiable data associated with any other user, including their children.",
        "contentSnippet": "Ravenna Hub, which lets parents apply and track the status of their kids' applications across thousands of schools, allowed any logged-in user to access the personally identifiable data associated with any other user, including their children.",
        "pubDate": "Thu, 19 Feb 2026 15:05:35 +0000",
        "isoDate": "2026-02-19T15:05:35.000Z",
        "creator": "Zack Whittaker",
        "source": "https://techcrunch.com/2026/02/19/bug-in-student-admissions-website-exposed-childrens-personal-information/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-i5211s",
        "title": "Reload wants to give your AI agents a shared memory",
        "link": "https://techcrunch.com/2026/02/19/reload-an-ai-employee-agent-management-platform-raises-2-275m-and-launches-an-ai-employee/",
        "url": "https://techcrunch.com/2026/02/19/reload-an-ai-employee-agent-management-platform-raises-2-275m-and-launches-an-ai-employee/",
        "content": "Reload announces a $2.275 million raise in a round led by Anthemis and the launch of its first AI employee, Epic. ",
        "contentSnippet": "Reload announces a $2.275 million raise in a round led by Anthemis and the launch of its first AI employee, Epic.",
        "pubDate": "Thu, 19 Feb 2026 15:00:00 +0000",
        "isoDate": "2026-02-19T15:00:00.000Z",
        "creator": "Dominic-Madori Davis",
        "source": "https://techcrunch.com/2026/02/19/reload-an-ai-employee-agent-management-platform-raises-2-275m-and-launches-an-ai-employee/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-mbtisd",
        "title": "Rivian owners will soon be able to access vehicle controls using their Apple Watch",
        "link": "https://techcrunch.com/2026/02/19/rivian-owners-will-be-able-to-access-vehicle-controls-through-their-apple-watch/",
        "url": "https://techcrunch.com/2026/02/19/rivian-owners-will-be-able-to-access-vehicle-controls-through-their-apple-watch/",
        "content": "Rivian is launching a companion app that pairs with Apple Watch in the coming week. ",
        "contentSnippet": "Rivian is launching a companion app that pairs with Apple Watch in the coming week.",
        "pubDate": "Thu, 19 Feb 2026 15:00:00 +0000",
        "isoDate": "2026-02-19T15:00:00.000Z",
        "creator": "Kirsten Korosec",
        "source": "https://techcrunch.com/2026/02/19/rivian-owners-will-be-able-to-access-vehicle-controls-through-their-apple-watch/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-bmhlux",
        "title": "OpenAI, Reliance partner to add AI search to JioHotstar",
        "link": "https://techcrunch.com/2026/02/19/openai-reliance-partner-to-add-ai-search-to-jiohotstar/",
        "url": "https://techcrunch.com/2026/02/19/openai-reliance-partner-to-add-ai-search-to-jiohotstar/",
        "content": "The rollout includes two-way integration that surfaces streaming links directly inside ChatGPT.",
        "contentSnippet": "The rollout includes two-way integration that surfaces streaming links directly inside ChatGPT.",
        "pubDate": "Thu, 19 Feb 2026 14:45:29 +0000",
        "isoDate": "2026-02-19T14:45:29.000Z",
        "creator": "Jagmeet Singh",
        "source": "https://techcrunch.com/2026/02/19/openai-reliance-partner-to-add-ai-search-to-jiohotstar/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-80l3kc",
        "title": "Co-founders behind Reface and Prisma join hands to improve on-device model inference with Mirai",
        "link": "https://techcrunch.com/2026/02/19/co-founders-behind-reface-and-prisma-join-hands-to-improve-on-device-model-inference-with-mirai/",
        "url": "https://techcrunch.com/2026/02/19/co-founders-behind-reface-and-prisma-join-hands-to-improve-on-device-model-inference-with-mirai/",
        "content": "Mirai raised a $10 million seed to improve how AI models run on devices like smartphones and laptops.",
        "contentSnippet": "Mirai raised a $10 million seed to improve how AI models run on devices like smartphones and laptops.",
        "pubDate": "Thu, 19 Feb 2026 14:43:58 +0000",
        "isoDate": "2026-02-19T14:43:58.000Z",
        "creator": "Ivan Mehta",
        "source": "https://techcrunch.com/2026/02/19/co-founders-behind-reface-and-prisma-join-hands-to-improve-on-device-model-inference-with-mirai/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-8mg1zs",
        "title": "These former Big Tech engineers are using AI to navigate Trump’s trade chaos",
        "link": "https://techcrunch.com/2026/02/19/this-former-big-tech-engineers-are-using-ai-to-navigate-trumps-trade-chaos/",
        "url": "https://techcrunch.com/2026/02/19/this-former-big-tech-engineers-are-using-ai-to-navigate-trumps-trade-chaos/",
        "content": "Amari AI is making custom AI-powered software that helps customs brokers modernize and minimize constantly shifting trade policies.",
        "contentSnippet": "Amari AI is making custom AI-powered software that helps customs brokers modernize and minimize constantly shifting trade policies.",
        "pubDate": "Thu, 19 Feb 2026 14:00:00 +0000",
        "isoDate": "2026-02-19T14:00:00.000Z",
        "creator": "Sean O'Kane",
        "source": "https://techcrunch.com/2026/02/19/this-former-big-tech-engineers-are-using-ai-to-navigate-trumps-trade-chaos/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-iwn23x",
        "title": "For open-source programs, AI coding tools are a mixed blessing",
        "link": "https://techcrunch.com/2026/02/19/for-open-source-programs-ai-coding-tools-are-a-mixed-blessing/",
        "url": "https://techcrunch.com/2026/02/19/for-open-source-programs-ai-coding-tools-are-a-mixed-blessing/",
        "content": "AI coding tools have enabled a flood of bad code that threatens to overwhelm many projects. Building new features is easier but maintaining them is just as hard.",
        "contentSnippet": "AI coding tools have enabled a flood of bad code that threatens to overwhelm many projects. Building new features is easier but maintaining them is just as hard.",
        "pubDate": "Thu, 19 Feb 2026 14:00:00 +0000",
        "isoDate": "2026-02-19T14:00:00.000Z",
        "creator": "Russell Brandom",
        "source": "https://techcrunch.com/2026/02/19/for-open-source-programs-ai-coding-tools-are-a-mixed-blessing/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-69wjic",
        "title": "Altman and Amodei share a moment of awkwardness at India’s big AI summit",
        "link": "https://techcrunch.com/2026/02/19/altman-and-amodei-share-a-moment-of-awkwardness-at-indias-big-ai-summit/",
        "url": "https://techcrunch.com/2026/02/19/altman-and-amodei-share-a-moment-of-awkwardness-at-indias-big-ai-summit/",
        "content": " When Prime Minister Narendra Modi prompted speakers at the event to join hands and raise them in a show of unity, all executives on stage obliged, except OpenAI's Sam Altman and Anthropic's Dario Amodei, who held their hands conspicuously apart.",
        "contentSnippet": "When Prime Minister Narendra Modi prompted speakers at the event to join hands and raise them in a show of unity, all executives on stage obliged, except OpenAI's Sam Altman and Anthropic's Dario Amodei, who held their hands conspicuously apart.",
        "pubDate": "Thu, 19 Feb 2026 13:49:06 +0000",
        "isoDate": "2026-02-19T13:49:06.000Z",
        "creator": "Ivan Mehta",
        "source": "https://techcrunch.com/2026/02/19/altman-and-amodei-share-a-moment-of-awkwardness-at-indias-big-ai-summit/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-8tg1xf",
        "title": "Freeform raises $67M Series B to scale up laser AI manufacturing ",
        "link": "https://techcrunch.com/2026/02/19/freeform-raises-67m-series-b-to-scale-up-laser-ai-manufacturing/",
        "url": "https://techcrunch.com/2026/02/19/freeform-raises-67m-series-b-to-scale-up-laser-ai-manufacturing/",
        "content": "“I think we're the only quote-unquote manufacturing company out there that has H200 clusters in a data center on site.\" ",
        "contentSnippet": "“I think we're the only quote-unquote manufacturing company out there that has H200 clusters in a data center on site.\"",
        "pubDate": "Thu, 19 Feb 2026 13:00:00 +0000",
        "isoDate": "2026-02-19T13:00:00.000Z",
        "creator": "Tim Fernholz",
        "source": "https://techcrunch.com/2026/02/19/freeform-raises-67m-series-b-to-scale-up-laser-ai-manufacturing/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-q6z9kx",
        "title": "This VC’s best advice for building a founding team",
        "link": "https://techcrunch.com/2026/02/19/this-vcs-best-advice-for-building-a-founding-team/",
        "url": "https://techcrunch.com/2026/02/19/this-vcs-best-advice-for-building-a-founding-team/",
        "content": "One of the most consequential decisions early-stage founders have to make is who they will bring on as their founding team. That’s why this season on Build Mode, we’re diving into what it takes to build a world-class founding team. ",
        "contentSnippet": "One of the most consequential decisions early-stage founders have to make is who they will bring on as their founding team. That’s why this season on Build Mode, we’re diving into what it takes to build a world-class founding team.",
        "pubDate": "Thu, 19 Feb 2026 12:30:00 +0000",
        "isoDate": "2026-02-19T12:30:00.000Z",
        "creator": "Maggie Nye",
        "source": "https://techcrunch.com/2026/02/19/this-vcs-best-advice-for-building-a-founding-team/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-kbx4md",
        "title": "Reliance unveils $110B AI investment plan as India ramps up tech ambitions",
        "link": "https://techcrunch.com/2026/02/19/reliance-unveils-110b-ai-investment-plan-as-india-ramps-up-tech-ambitions/",
        "url": "https://techcrunch.com/2026/02/19/reliance-unveils-110b-ai-investment-plan-as-india-ramps-up-tech-ambitions/",
        "content": "Reliance has begun building multi-gigawatt AI data centers in Jamnagar, with more than 120 MW of capacity expected to come online in 2026.",
        "contentSnippet": "Reliance has begun building multi-gigawatt AI data centers in Jamnagar, with more than 120 MW of capacity expected to come online in 2026.",
        "pubDate": "Thu, 19 Feb 2026 11:39:17 +0000",
        "isoDate": "2026-02-19T11:39:17.000Z",
        "creator": "Jagmeet Singh",
        "source": "https://techcrunch.com/2026/02/19/reliance-unveils-110b-ai-investment-plan-as-india-ramps-up-tech-ambitions/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-ms2nmr",
        "title": "OpenAI taps Tata for 100MW AI data center capacity in India, eyes 1GW",
        "link": "https://techcrunch.com/2026/02/18/openai-taps-tata-for-100mw-ai-data-center-capacity-in-india-eyes-1gw/",
        "url": "https://techcrunch.com/2026/02/18/openai-taps-tata-for-100mw-ai-data-center-capacity-in-india-eyes-1gw/",
        "content": "OpenAI also plans to expand its presence in India with new offices in Mumbai and Bengaluru later this year.",
        "contentSnippet": "OpenAI also plans to expand its presence in India with new offices in Mumbai and Bengaluru later this year.",
        "pubDate": "Thu, 19 Feb 2026 05:34:25 +0000",
        "isoDate": "2026-02-19T05:34:25.000Z",
        "creator": "Jagmeet Singh",
        "source": "https://techcrunch.com/2026/02/18/openai-taps-tata-for-100mw-ai-data-center-capacity-in-india-eyes-1gw/"
      },
      {
        "id": "rss-techcrunch-alt-tech-breakthrough-ovr-3nl0y1",
        "title": "OpenAI deepens India push with Pine Labs fintech partnership",
        "link": "https://techcrunch.com/2026/02/18/openai-deepens-india-push-with-pine-labs-fintech-partnership/",
        "url": "https://techcrunch.com/2026/02/18/openai-deepens-india-push-with-pine-labs-fintech-partnership/",
        "content": "OpenAI moves beyond ChatGPT in India with a Pine Labs deal targeting enterprise payments and AI-driven commerce.",
        "contentSnippet": "OpenAI moves beyond ChatGPT in India with a Pine Labs deal targeting enterprise payments and AI-driven commerce.",
        "pubDate": "Thu, 19 Feb 2026 03:30:00 +0000",
        "isoDate": "2026-02-19T03:30:00.000Z",
        "creator": "Jagmeet Singh",
        "source": "https://techcrunch.com/2026/02/18/openai-deepens-india-push-with-pine-labs-fintech-partnership/"
      }
    ],
    "openai-blog-tech-breakthrough-1": [
      {
        "id": "rss-openai-blog-tech-breakthrough-1-lizqeo",
        "title": "Introducing OpenAI for India",
        "link": "https://openai.com/index/openai-for-india",
        "url": "https://openai.com/index/openai-for-india",
        "content": "OpenAI for India expands AI access across the country—building local infrastructure, powering enterprises, and advancing workforce skills.",
        "contentSnippet": "OpenAI for India expands AI access across the country—building local infrastructure, powering enterprises, and advancing workforce skills.",
        "pubDate": "Wed, 18 Feb 2026 21:00:00 GMT",
        "isoDate": "2026-02-18T21:00:00.000Z",
        "source": "https://openai.com/index/openai-for-india"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-rofop",
        "title": "GPT-5.2 derives a new result in theoretical physics",
        "link": "https://openai.com/index/new-result-theoretical-physics",
        "url": "https://openai.com/index/new-result-theoretical-physics",
        "content": "A new preprint shows GPT-5.2 proposing a new formula for a gluon amplitude, later formally proved and verified by OpenAI and academic collaborators.",
        "contentSnippet": "A new preprint shows GPT-5.2 proposing a new formula for a gluon amplitude, later formally proved and verified by OpenAI and academic collaborators.",
        "pubDate": "Fri, 13 Feb 2026 11:00:00 GMT",
        "isoDate": "2026-02-13T11:00:00.000Z",
        "source": "https://openai.com/index/new-result-theoretical-physics"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-nzjgr",
        "title": "Introducing Lockdown Mode and Elevated Risk labels in ChatGPT",
        "link": "https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt",
        "url": "https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt",
        "content": "Introducing Lockdown Mode and Elevated Risk labels in ChatGPT to help organizations defend against prompt injection and AI-driven data exfiltration.",
        "contentSnippet": "Introducing Lockdown Mode and Elevated Risk labels in ChatGPT to help organizations defend against prompt injection and AI-driven data exfiltration.",
        "pubDate": "Fri, 13 Feb 2026 10:00:00 GMT",
        "isoDate": "2026-02-13T10:00:00.000Z",
        "source": "https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xhucmy",
        "title": "Scaling social science research",
        "link": "https://openai.com/index/scaling-social-science-research",
        "url": "https://openai.com/index/scaling-social-science-research",
        "content": "GABRIEL is a new open-source toolkit from OpenAI that uses GPT to turn qualitative text and images into quantitative data, helping social scientists analyze research at scale.",
        "contentSnippet": "GABRIEL is a new open-source toolkit from OpenAI that uses GPT to turn qualitative text and images into quantitative data, helping social scientists analyze research at scale.",
        "pubDate": "Fri, 13 Feb 2026 09:00:00 GMT",
        "isoDate": "2026-02-13T09:00:00.000Z",
        "source": "https://openai.com/index/scaling-social-science-research"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-cf76fz",
        "title": "Beyond rate limits: scaling access to Codex and Sora",
        "link": "https://openai.com/index/beyond-rate-limits",
        "url": "https://openai.com/index/beyond-rate-limits",
        "content": "How OpenAI built a real-time access system combining rate limits, usage tracking, and credits to power continuous access to Sora and Codex.",
        "contentSnippet": "How OpenAI built a real-time access system combining rate limits, usage tracking, and credits to power continuous access to Sora and Codex.",
        "pubDate": "Fri, 13 Feb 2026 09:00:00 GMT",
        "isoDate": "2026-02-13T09:00:00.000Z",
        "source": "https://openai.com/index/beyond-rate-limits"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9xedha",
        "title": "Introducing GPT-5.3-Codex-Spark",
        "link": "https://openai.com/index/introducing-gpt-5-3-codex-spark",
        "url": "https://openai.com/index/introducing-gpt-5-3-codex-spark",
        "content": "Introducing GPT-5.3-Codex-Spark—our first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.",
        "contentSnippet": "Introducing GPT-5.3-Codex-Spark—our first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.",
        "pubDate": "Thu, 12 Feb 2026 10:00:00 GMT",
        "isoDate": "2026-02-12T10:00:00.000Z",
        "source": "https://openai.com/index/introducing-gpt-5-3-codex-spark"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-em760y",
        "title": "Harness engineering: leveraging Codex in an agent-first world",
        "link": "https://openai.com/index/harness-engineering",
        "url": "https://openai.com/index/harness-engineering",
        "content": "By Ryan Lopopolo, Member of the Technical Staff",
        "contentSnippet": "By Ryan Lopopolo, Member of the Technical Staff",
        "pubDate": "Wed, 11 Feb 2026 09:00:00 GMT",
        "isoDate": "2026-02-11T09:00:00.000Z",
        "source": "https://openai.com/index/harness-engineering"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-1tyvgd",
        "title": "Testing ads in ChatGPT",
        "link": "https://openai.com/index/testing-ads-in-chatgpt",
        "url": "https://openai.com/index/testing-ads-in-chatgpt",
        "content": "OpenAI begins testing ads in ChatGPT to support free access, with clear labeling, answer independence, strong privacy protections, and user control.",
        "contentSnippet": "OpenAI begins testing ads in ChatGPT to support free access, with clear labeling, answer independence, strong privacy protections, and user control.",
        "pubDate": "Mon, 09 Feb 2026 11:00:00 GMT",
        "isoDate": "2026-02-09T11:00:00.000Z",
        "source": "https://openai.com/index/testing-ads-in-chatgpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-fefwkr",
        "title": "Bringing ChatGPT to GenAI.mil",
        "link": "https://openai.com/index/bringing-chatgpt-to-genaimil",
        "url": "https://openai.com/index/bringing-chatgpt-to-genaimil",
        "content": "OpenAI for Government announces the deployment of a custom ChatGPT on GenAI.mil, bringing secure, safety-forward AI to U.S. defense teams.",
        "contentSnippet": "OpenAI for Government announces the deployment of a custom ChatGPT on GenAI.mil, bringing secure, safety-forward AI to U.S. defense teams.",
        "pubDate": "Mon, 09 Feb 2026 11:00:00 GMT",
        "isoDate": "2026-02-09T11:00:00.000Z",
        "source": "https://openai.com/index/bringing-chatgpt-to-genaimil"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-q5hkdb",
        "title": "Making AI work for everyone, everywhere: our approach to localization",
        "link": "https://openai.com/index/our-approach-to-localization",
        "url": "https://openai.com/index/our-approach-to-localization",
        "content": "OpenAI shares its approach to AI localization, showing how globally shared frontier models can be adapted to local languages, laws, and cultures without compromising safety.",
        "contentSnippet": "OpenAI shares its approach to AI localization, showing how globally shared frontier models can be adapted to local languages, laws, and cultures without compromising safety.",
        "pubDate": "Fri, 06 Feb 2026 10:00:00 GMT",
        "isoDate": "2026-02-06T10:00:00.000Z",
        "source": "https://openai.com/index/our-approach-to-localization"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-3r9l0n",
        "title": "GPT-5 lowers the cost of cell-free protein synthesis",
        "link": "https://openai.com/index/gpt-5-lowers-protein-synthesis-cost",
        "url": "https://openai.com/index/gpt-5-lowers-protein-synthesis-cost",
        "content": "An autonomous lab combining OpenAI’s GPT-5 with Ginkgo Bioworks’ cloud automation cut cell-free protein synthesis costs by 40% through closed-loop experimentation.",
        "contentSnippet": "An autonomous lab combining OpenAI’s GPT-5 with Ginkgo Bioworks’ cloud automation cut cell-free protein synthesis costs by 40% through closed-loop experimentation.",
        "pubDate": "Thu, 05 Feb 2026 11:00:00 GMT",
        "isoDate": "2026-02-05T11:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-lowers-protein-synthesis-cost"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ymim2u",
        "title": "Introducing Trusted Access for Cyber",
        "link": "https://openai.com/index/trusted-access-for-cyber",
        "url": "https://openai.com/index/trusted-access-for-cyber",
        "content": "OpenAI introduces Trusted Access for Cyber, a trust-based framework that expands access to frontier cyber capabilities while strengthening safeguards against misuse.",
        "contentSnippet": "OpenAI introduces Trusted Access for Cyber, a trust-based framework that expands access to frontier cyber capabilities while strengthening safeguards against misuse.",
        "pubDate": "Thu, 05 Feb 2026 10:00:00 GMT",
        "isoDate": "2026-02-05T10:00:00.000Z",
        "source": "https://openai.com/index/trusted-access-for-cyber"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-frdyn5",
        "title": "Introducing OpenAI Frontier",
        "link": "https://openai.com/index/introducing-openai-frontier",
        "url": "https://openai.com/index/introducing-openai-frontier",
        "content": "OpenAI Frontier is an enterprise platform for building, deploying, and managing AI agents with shared context, onboarding, permissions, and governance.",
        "contentSnippet": "OpenAI Frontier is an enterprise platform for building, deploying, and managing AI agents with shared context, onboarding, permissions, and governance.",
        "pubDate": "Thu, 05 Feb 2026 06:00:00 GMT",
        "isoDate": "2026-02-05T06:00:00.000Z",
        "source": "https://openai.com/index/introducing-openai-frontier"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-shdqcj",
        "title": "Navigating health questions with ChatGPT",
        "link": "https://openai.com/index/navigating-health-questions",
        "url": "https://openai.com/index/navigating-health-questions",
        "content": "A family shares how ChatGPT helped them prepare for critical cancer treatment decisions for their son alongside expert guidance from his doctors.",
        "contentSnippet": "A family shares how ChatGPT helped them prepare for critical cancer treatment decisions for their son alongside expert guidance from his doctors.",
        "pubDate": "Thu, 05 Feb 2026 00:00:00 GMT",
        "isoDate": "2026-02-05T00:00:00.000Z",
        "source": "https://openai.com/index/navigating-health-questions"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vtszgy",
        "title": "Introducing GPT-5.3-Codex",
        "link": "https://openai.com/index/introducing-gpt-5-3-codex",
        "url": "https://openai.com/index/introducing-gpt-5-3-codex",
        "content": "GPT-5.3-Codex is a Codex-native agent that pairs frontier coding performance with general reasoning to support long-horizon, real-world technical work.",
        "contentSnippet": "GPT-5.3-Codex is a Codex-native agent that pairs frontier coding performance with general reasoning to support long-horizon, real-world technical work.",
        "pubDate": "Thu, 05 Feb 2026 00:00:00 GMT",
        "isoDate": "2026-02-05T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-gpt-5-3-codex"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-l6ypa8",
        "title": "GPT-5.3-Codex System Card",
        "link": "https://openai.com/index/gpt-5-3-codex-system-card",
        "url": "https://openai.com/index/gpt-5-3-codex-system-card",
        "content": "GPT‑5.3-Codex is the most capable agentic coding model to date, combining the frontier coding performance of GPT‑5.2-Codex with the reasoning and professional knowledge capabilities of GPT‑5.2. ",
        "contentSnippet": "GPT‑5.3-Codex is the most capable agentic coding model to date, combining the frontier coding performance of GPT‑5.2-Codex with the reasoning and professional knowledge capabilities of GPT‑5.2.",
        "pubDate": "Thu, 05 Feb 2026 00:00:00 GMT",
        "isoDate": "2026-02-05T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-3-codex-system-card"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-98fpxn",
        "title": "Unlocking the Codex harness: how we built the App Server",
        "link": "https://openai.com/index/unlocking-the-codex-harness",
        "url": "https://openai.com/index/unlocking-the-codex-harness",
        "content": "Learn how to embed the Codex agent using the Codex App Server, a bidirectional JSON-RPC API powering streaming progress, tool use, approvals, and diffs.",
        "contentSnippet": "Learn how to embed the Codex agent using the Codex App Server, a bidirectional JSON-RPC API powering streaming progress, tool use, approvals, and diffs.",
        "pubDate": "Wed, 04 Feb 2026 13:00:00 GMT",
        "isoDate": "2026-02-04T13:00:00.000Z",
        "source": "https://openai.com/index/unlocking-the-codex-harness"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-llqxsw",
        "title": "VfL Wolfsburg turns ChatGPT into a club-wide capability",
        "link": "https://openai.com/index/vfl-wolfsburg",
        "url": "https://openai.com/index/vfl-wolfsburg",
        "content": "By focusing on people, not pilots, the Bundesliga club is scaling efficiency, creativity, and knowledge—without losing its football identity.",
        "contentSnippet": "By focusing on people, not pilots, the Bundesliga club is scaling efficiency, creativity, and knowledge—without losing its football identity.",
        "pubDate": "Wed, 04 Feb 2026 00:00:00 GMT",
        "isoDate": "2026-02-04T00:00:00.000Z",
        "source": "https://openai.com/index/vfl-wolfsburg"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-l9ml2u",
        "title": "The Sora feed philosophy",
        "link": "https://openai.com/index/sora-feed-philosophy",
        "url": "https://openai.com/index/sora-feed-philosophy",
        "content": "Discover the Sora feed philosophy—built to spark creativity, foster connections, and keep experiences safe with personalized recommendations, parental controls, and strong guardrails.",
        "contentSnippet": "Discover the Sora feed philosophy—built to spark creativity, foster connections, and keep experiences safe with personalized recommendations, parental controls, and strong guardrails.",
        "pubDate": "Tue, 03 Feb 2026 00:00:00 GMT",
        "isoDate": "2026-02-03T00:00:00.000Z",
        "source": "https://openai.com/index/sora-feed-philosophy"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-syj2j5",
        "title": "Snowflake and OpenAI partner to bring frontier intelligence to enterprise data",
        "link": "https://openai.com/index/snowflake-partnership",
        "url": "https://openai.com/index/snowflake-partnership",
        "content": "OpenAI and Snowflake partner in a $200M agreement to bring frontier intelligence into enterprise data, enabling AI agents and insights directly in Snowflake.",
        "contentSnippet": "OpenAI and Snowflake partner in a $200M agreement to bring frontier intelligence into enterprise data, enabling AI agents and insights directly in Snowflake.",
        "pubDate": "Mon, 02 Feb 2026 06:00:00 GMT",
        "isoDate": "2026-02-02T06:00:00.000Z",
        "source": "https://openai.com/index/snowflake-partnership"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-qmu3ba",
        "title": "Introducing the Codex app",
        "link": "https://openai.com/index/introducing-the-codex-app",
        "url": "https://openai.com/index/introducing-the-codex-app",
        "content": "Introducing the Codex app for macOS—a command center for AI coding and software development with multiple agents, parallel workflows, and long-running tasks.",
        "contentSnippet": "Introducing the Codex app for macOS—a command center for AI coding and software development with multiple agents, parallel workflows, and long-running tasks.",
        "pubDate": "Mon, 02 Feb 2026 00:00:00 GMT",
        "isoDate": "2026-02-02T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-the-codex-app"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-op17i5",
        "title": "Inside OpenAI’s in-house data agent",
        "link": "https://openai.com/index/inside-our-in-house-data-agent",
        "url": "https://openai.com/index/inside-our-in-house-data-agent",
        "content": "How OpenAI built an in-house AI data agent that uses GPT-5, Codex, and memory to reason over massive datasets and deliver reliable insights in minutes.",
        "contentSnippet": "How OpenAI built an in-house AI data agent that uses GPT-5, Codex, and memory to reason over massive datasets and deliver reliable insights in minutes.",
        "pubDate": "Thu, 29 Jan 2026 10:00:00 GMT",
        "isoDate": "2026-01-29T10:00:00.000Z",
        "source": "https://openai.com/index/inside-our-in-house-data-agent"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wgq8z0",
        "title": "Retiring GPT-4o, GPT-4.1, GPT-4.1 mini, and OpenAI o4-mini in ChatGPT",
        "link": "https://openai.com/index/retiring-gpt-4o-and-older-models",
        "url": "https://openai.com/index/retiring-gpt-4o-and-older-models",
        "content": "On February 13, 2026, alongside the previously announced retirement⁠ of GPT‑5 (Instant, Thinking, and Pro), we will retire GPT‑4o, GPT‑4.1, GPT‑4.1 mini, and OpenAI o4-mini from ChatGPT. In the API, there are no changes at this time.",
        "contentSnippet": "On February 13, 2026, alongside the previously announced retirement⁠ of GPT‑5 (Instant, Thinking, and Pro), we will retire GPT‑4o, GPT‑4.1, GPT‑4.1 mini, and OpenAI o4-mini from ChatGPT. In the API, there are no changes at this time.",
        "pubDate": "Thu, 29 Jan 2026 00:00:00 GMT",
        "isoDate": "2026-01-29T00:00:00.000Z",
        "source": "https://openai.com/index/retiring-gpt-4o-and-older-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vkcz0t",
        "title": "Taisei Corporation shapes the next generation of talent with ChatGPT",
        "link": "https://openai.com/index/taisei",
        "url": "https://openai.com/index/taisei",
        "content": "Taisei Corporation uses ChatGPT Enterprise to support HR-led talent development and scale generative AI across its global construction business.",
        "contentSnippet": "Taisei Corporation uses ChatGPT Enterprise to support HR-led talent development and scale generative AI across its global construction business.",
        "pubDate": "Thu, 29 Jan 2026 00:00:00 GMT",
        "isoDate": "2026-01-29T00:00:00.000Z",
        "source": "https://openai.com/index/taisei"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-p1elof",
        "title": "EMEA Youth & Wellbeing Grant",
        "link": "https://openai.com/index/emea-youth-and-wellbeing-grant",
        "url": "https://openai.com/index/emea-youth-and-wellbeing-grant",
        "content": "Apply for the EMEA Youth & Wellbeing Grant, a €500,000 program funding NGOs and researchers advancing youth safety and wellbeing in the age of AI.",
        "contentSnippet": "Apply for the EMEA Youth & Wellbeing Grant, a €500,000 program funding NGOs and researchers advancing youth safety and wellbeing in the age of AI.",
        "pubDate": "Wed, 28 Jan 2026 01:00:00 GMT",
        "isoDate": "2026-01-28T01:00:00.000Z",
        "source": "https://openai.com/index/emea-youth-and-wellbeing-grant"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-92wyah",
        "title": "The next chapter for AI in the EU",
        "link": "https://openai.com/index/the-next-chapter-for-ai-in-the-eu",
        "url": "https://openai.com/index/the-next-chapter-for-ai-in-the-eu",
        "content": "OpenAI launches the EU Economic Blueprint 2.0 with new data, partnerships, and initiatives to accelerate AI adoption, skills, and growth across Europe.",
        "contentSnippet": "OpenAI launches the EU Economic Blueprint 2.0 with new data, partnerships, and initiatives to accelerate AI adoption, skills, and growth across Europe.",
        "pubDate": "Wed, 28 Jan 2026 01:00:00 GMT",
        "isoDate": "2026-01-28T01:00:00.000Z",
        "source": "https://openai.com/index/the-next-chapter-for-ai-in-the-eu"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-y74k0g",
        "title": "Keeping your data safe when an AI agent clicks a link",
        "link": "https://openai.com/index/ai-agent-link-safety",
        "url": "https://openai.com/index/ai-agent-link-safety",
        "content": "Learn how OpenAI protects user data when AI agents open links, preventing URL-based data exfiltration and prompt injection with built-in safeguards.",
        "contentSnippet": "Learn how OpenAI protects user data when AI agents open links, preventing URL-based data exfiltration and prompt injection with built-in safeguards.",
        "pubDate": "Wed, 28 Jan 2026 00:00:00 GMT",
        "isoDate": "2026-01-28T00:00:00.000Z",
        "source": "https://openai.com/index/ai-agent-link-safety"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-fsihex",
        "title": "PVH reimagines the future of fashion with OpenAI",
        "link": "https://openai.com/index/pvh-future-of-fashion",
        "url": "https://openai.com/index/pvh-future-of-fashion",
        "content": "PVH Corp., parent company of Calvin Klein and Tommy Hilfiger, is adopting ChatGPT Enterprise to bring AI into fashion design, supply chain, and consumer engagement.",
        "contentSnippet": "PVH Corp., parent company of Calvin Klein and Tommy Hilfiger, is adopting ChatGPT Enterprise to bring AI into fashion design, supply chain, and consumer engagement.",
        "pubDate": "Tue, 27 Jan 2026 06:00:00 GMT",
        "isoDate": "2026-01-27T06:00:00.000Z",
        "source": "https://openai.com/index/pvh-future-of-fashion"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-zhbx24",
        "title": "Powering tax donations with AI powered personalized recommendations",
        "link": "https://openai.com/index/trustbank",
        "url": "https://openai.com/index/trustbank",
        "content": "TRUSTBANK partnered with Recursive to build Choice AI using OpenAI models, delivering personalized, conversational recommendations that simplify Furusato Nozei gift discovery. A multi-agent system helps donors navigate thousands of options and find gifts that match their preferences.",
        "contentSnippet": "TRUSTBANK partnered with Recursive to build Choice AI using OpenAI models, delivering personalized, conversational recommendations that simplify Furusato Nozei gift discovery. A multi-agent system helps donors navigate thousands of options and find gifts that match their preferences.",
        "pubDate": "Tue, 27 Jan 2026 00:00:00 GMT",
        "isoDate": "2026-01-27T00:00:00.000Z",
        "source": "https://openai.com/index/trustbank"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9z5p08",
        "title": "Introducing Prism",
        "link": "https://openai.com/index/introducing-prism",
        "url": "https://openai.com/index/introducing-prism",
        "content": "Prism is a free LaTeX-native workspace with GPT-5.2 built in, helping researchers write, collaborate, and reason in one place.",
        "contentSnippet": "Prism is a free LaTeX-native workspace with GPT-5.2 built in, helping researchers write, collaborate, and reason in one place.",
        "pubDate": "Tue, 27 Jan 2026 00:00:00 GMT",
        "isoDate": "2026-01-27T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-prism"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xfn75g",
        "title": "How Indeed uses AI to help evolve the job search",
        "link": "https://openai.com/index/indeed-maggie-hulce",
        "url": "https://openai.com/index/indeed-maggie-hulce",
        "content": "Indeed’s CRO Maggie Hulce shares how AI is transforming job search, recruiting, and talent acquisition for employers and job seekers.",
        "contentSnippet": "Indeed’s CRO Maggie Hulce shares how AI is transforming job search, recruiting, and talent acquisition for employers and job seekers.",
        "pubDate": "Mon, 26 Jan 2026 00:00:00 GMT",
        "isoDate": "2026-01-26T00:00:00.000Z",
        "source": "https://openai.com/index/indeed-maggie-hulce"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-e5ewfx",
        "title": "Unrolling the Codex agent loop",
        "link": "https://openai.com/index/unrolling-the-codex-agent-loop",
        "url": "https://openai.com/index/unrolling-the-codex-agent-loop",
        "content": "A technical deep dive into the Codex agent loop, explaining how Codex CLI orchestrates models, tools, prompts, and performance using the Responses API.",
        "contentSnippet": "A technical deep dive into the Codex agent loop, explaining how Codex CLI orchestrates models, tools, prompts, and performance using the Responses API.",
        "pubDate": "Fri, 23 Jan 2026 12:00:00 GMT",
        "isoDate": "2026-01-23T12:00:00.000Z",
        "source": "https://openai.com/index/unrolling-the-codex-agent-loop"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-oldwdq",
        "title": "Scaling PostgreSQL to power 800 million ChatGPT users",
        "link": "https://openai.com/index/scaling-postgresql",
        "url": "https://openai.com/index/scaling-postgresql",
        "content": "An inside look at how OpenAI scaled PostgreSQL to millions of queries per second using replicas, caching, rate limiting, and workload isolation.",
        "contentSnippet": "An inside look at how OpenAI scaled PostgreSQL to millions of queries per second using replicas, caching, rate limiting, and workload isolation.",
        "pubDate": "Thu, 22 Jan 2026 12:00:00 GMT",
        "isoDate": "2026-01-22T12:00:00.000Z",
        "source": "https://openai.com/index/scaling-postgresql"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-g1obwx",
        "title": "Inside Praktika's conversational approach to language learning",
        "link": "https://openai.com/index/praktika",
        "url": "https://openai.com/index/praktika",
        "content": "How Praktika uses GPT-4.1 and GPT-5.2 to build adaptive AI tutors that personalize lessons, track progress, and help learners achieve real-world language fluency",
        "contentSnippet": "How Praktika uses GPT-4.1 and GPT-5.2 to build adaptive AI tutors that personalize lessons, track progress, and help learners achieve real-world language fluency",
        "pubDate": "Thu, 22 Jan 2026 05:00:00 GMT",
        "isoDate": "2026-01-22T05:00:00.000Z",
        "source": "https://openai.com/index/praktika"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-z7aa0o",
        "title": "Inside GPT-5 for Work: How Businesses Use GPT-5",
        "link": "https://openai.com/business/guides-and-resources/chatgpt-usage-and-adoption-patterns-at-work",
        "url": "https://openai.com/business/guides-and-resources/chatgpt-usage-and-adoption-patterns-at-work",
        "content": "A data-driven report on how workers across industries use ChatGPT—covering adoption trends, top tasks, departmental patterns, and the future of AI at work.",
        "contentSnippet": "A data-driven report on how workers across industries use ChatGPT—covering adoption trends, top tasks, departmental patterns, and the future of AI at work.",
        "pubDate": "Thu, 22 Jan 2026 00:00:00 GMT",
        "isoDate": "2026-01-22T00:00:00.000Z",
        "source": "https://openai.com/business/guides-and-resources/chatgpt-usage-and-adoption-patterns-at-work"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ohayio",
        "title": "How Higgsfield turns simple ideas into cinematic social videos",
        "link": "https://openai.com/index/higgsfield",
        "url": "https://openai.com/index/higgsfield",
        "content": "Discover how Higgsfield gives creators cinematic, social-first video output from simple inputs using OpenAI GPT-4.1, GPT-5, and Sora 2.",
        "contentSnippet": "Discover how Higgsfield gives creators cinematic, social-first video output from simple inputs using OpenAI GPT-4.1, GPT-5, and Sora 2.",
        "pubDate": "Wed, 21 Jan 2026 10:00:00 GMT",
        "isoDate": "2026-01-21T10:00:00.000Z",
        "source": "https://openai.com/index/higgsfield"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-dzph36",
        "title": "How countries can end the capability overhang",
        "link": "https://openai.com/index/how-countries-can-end-the-capability-overhang",
        "url": "https://openai.com/index/how-countries-can-end-the-capability-overhang",
        "content": "Our latest report reveals stark differences in advanced AI adoption across countries and outlines new initiatives to help nations capture productivity gains from AI.",
        "contentSnippet": "Our latest report reveals stark differences in advanced AI adoption across countries and outlines new initiatives to help nations capture productivity gains from AI.",
        "pubDate": "Wed, 21 Jan 2026 01:00:00 GMT",
        "isoDate": "2026-01-21T01:00:00.000Z",
        "source": "https://openai.com/index/how-countries-can-end-the-capability-overhang"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xg2c0x",
        "title": "Introducing Edu for Countries",
        "link": "https://openai.com/index/edu-for-countries",
        "url": "https://openai.com/index/edu-for-countries",
        "content": "Edu for Countries is a new OpenAI initiative helping governments use AI to modernize education systems and build future-ready workforces.",
        "contentSnippet": "Edu for Countries is a new OpenAI initiative helping governments use AI to modernize education systems and build future-ready workforces.",
        "pubDate": "Wed, 21 Jan 2026 01:00:00 GMT",
        "isoDate": "2026-01-21T01:00:00.000Z",
        "source": "https://openai.com/index/edu-for-countries"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-o8fnef",
        "title": "Horizon 1000: Advancing AI for primary healthcare",
        "link": "https://openai.com/index/horizon-1000",
        "url": "https://openai.com/index/horizon-1000",
        "content": "OpenAI and the Gates Foundation launch Horizon 1000, a $50M pilot advancing AI capabilities for healthcare in Africa. The initiative aims to reach 1,000 clinics by 2028.",
        "contentSnippet": "OpenAI and the Gates Foundation launch Horizon 1000, a $50M pilot advancing AI capabilities for healthcare in Africa. The initiative aims to reach 1,000 clinics by 2028.",
        "pubDate": "Tue, 20 Jan 2026 21:00:00 GMT",
        "isoDate": "2026-01-20T21:00:00.000Z",
        "source": "https://openai.com/index/horizon-1000"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-kfefg1",
        "title": "Stargate Community",
        "link": "https://openai.com/index/stargate-community",
        "url": "https://openai.com/index/stargate-community",
        "content": "Stargate Community plans detail a community-first approach to AI infrastructure, using locally tailored plans shaped by community input, energy needs, and workforce priorities.",
        "contentSnippet": "Stargate Community plans detail a community-first approach to AI infrastructure, using locally tailored plans shaped by community input, energy needs, and workforce priorities.",
        "pubDate": "Tue, 20 Jan 2026 19:00:00 GMT",
        "isoDate": "2026-01-20T19:00:00.000Z",
        "source": "https://openai.com/index/stargate-community"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jcj3wh",
        "title": "Cisco and OpenAI redefine enterprise engineering with AI agents",
        "link": "https://openai.com/index/cisco",
        "url": "https://openai.com/index/cisco",
        "content": "Cisco and OpenAI redefine enterprise engineering with Codex, an AI software agent embedded in workflows to speed builds, automate defect fixes, and enable AI-native development.",
        "contentSnippet": "Cisco and OpenAI redefine enterprise engineering with Codex, an AI software agent embedded in workflows to speed builds, automate defect fixes, and enable AI-native development.",
        "pubDate": "Tue, 20 Jan 2026 11:00:00 GMT",
        "isoDate": "2026-01-20T11:00:00.000Z",
        "source": "https://openai.com/index/cisco"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-l9dahe",
        "title": "ServiceNow powers actionable enterprise AI with OpenAI",
        "link": "https://openai.com/index/servicenow-powers-actionable-enterprise-ai-with-openai",
        "url": "https://openai.com/index/servicenow-powers-actionable-enterprise-ai-with-openai",
        "content": "ServiceNow expands access to OpenAI frontier models to power AI-driven enterprise workflows, summarization, search, and voice across the ServiceNow Platform.",
        "contentSnippet": "ServiceNow expands access to OpenAI frontier models to power AI-driven enterprise workflows, summarization, search, and voice across the ServiceNow Platform.",
        "pubDate": "Tue, 20 Jan 2026 05:45:00 GMT",
        "isoDate": "2026-01-20T05:45:00.000Z",
        "source": "https://openai.com/index/servicenow-powers-actionable-enterprise-ai-with-openai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wz5r4t",
        "title": "Our approach to age prediction",
        "link": "https://openai.com/index/our-approach-to-age-prediction",
        "url": "https://openai.com/index/our-approach-to-age-prediction",
        "content": "ChatGPT is rolling out age prediction to estimate if accounts are under or over 18, applying safeguards for teens and refining accuracy over time.",
        "contentSnippet": "ChatGPT is rolling out age prediction to estimate if accounts are under or over 18, applying safeguards for teens and refining accuracy over time.",
        "pubDate": "Tue, 20 Jan 2026 00:00:00 GMT",
        "isoDate": "2026-01-20T00:00:00.000Z",
        "source": "https://openai.com/index/our-approach-to-age-prediction"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vtdadn",
        "title": "AI for self empowerment",
        "link": "https://openai.com/index/ai-for-self-empowerment",
        "url": "https://openai.com/index/ai-for-self-empowerment",
        "content": "How AI can expand human agency by closing the capability overhang—helping people, businesses, and countries unlock real productivity, growth, and opportunity.",
        "contentSnippet": "How AI can expand human agency by closing the capability overhang—helping people, businesses, and countries unlock real productivity, growth, and opportunity.",
        "pubDate": "Sun, 18 Jan 2026 12:00:00 GMT",
        "isoDate": "2026-01-18T12:00:00.000Z",
        "source": "https://openai.com/index/ai-for-self-empowerment"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vgia9v",
        "title": "A business that scales with the value of intelligence",
        "link": "https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence",
        "url": "https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence",
        "content": "OpenAI’s business model scales with intelligence—spanning subscriptions, API, ads, commerce, and compute—driven by deepening ChatGPT adoption.",
        "contentSnippet": "OpenAI’s business model scales with intelligence—spanning subscriptions, API, ads, commerce, and compute—driven by deepening ChatGPT adoption.",
        "pubDate": "Sun, 18 Jan 2026 10:00:00 GMT",
        "isoDate": "2026-01-18T10:00:00.000Z",
        "source": "https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-o1ygw7",
        "title": "The truth left out from Elon Musk’s recent court filing",
        "link": "https://openai.com/index/the-truth-elon-left-out",
        "url": "https://openai.com/index/the-truth-elon-left-out",
        "content": "The truth left out from Elon Musk’s recent court filing.",
        "contentSnippet": "The truth left out from Elon Musk’s recent court filing.",
        "pubDate": "Fri, 16 Jan 2026 12:00:00 GMT",
        "isoDate": "2026-01-16T12:00:00.000Z",
        "source": "https://openai.com/index/the-truth-elon-left-out"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-b4r2wb",
        "title": "Introducing ChatGPT Go, now available worldwide",
        "link": "https://openai.com/index/introducing-chatgpt-go",
        "url": "https://openai.com/index/introducing-chatgpt-go",
        "content": "ChatGPT Go is now available worldwide, offering expanded access to GPT-5.2 Instant, higher usage limits, and longer memory—making advanced AI more affordable globally.",
        "contentSnippet": "ChatGPT Go is now available worldwide, offering expanded access to GPT-5.2 Instant, higher usage limits, and longer memory—making advanced AI more affordable globally.",
        "pubDate": "Fri, 16 Jan 2026 00:00:00 GMT",
        "isoDate": "2026-01-16T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-chatgpt-go"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-2ds0mq",
        "title": "Our approach to advertising and expanding access to ChatGPT",
        "link": "https://openai.com/index/our-approach-to-advertising-and-expanding-access",
        "url": "https://openai.com/index/our-approach-to-advertising-and-expanding-access",
        "content": "OpenAI plans to test advertising in the U.S. for ChatGPT’s free and Go tiers to expand affordable access to AI worldwide, while protecting privacy, trust, and answer quality.",
        "contentSnippet": "OpenAI plans to test advertising in the U.S. for ChatGPT’s free and Go tiers to expand affordable access to AI worldwide, while protecting privacy, trust, and answer quality.",
        "pubDate": "Fri, 16 Jan 2026 00:00:00 GMT",
        "isoDate": "2026-01-16T00:00:00.000Z",
        "source": "https://openai.com/index/our-approach-to-advertising-and-expanding-access"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-arwi7f",
        "title": "Investing in Merge Labs",
        "link": "https://openai.com/index/investing-in-merge-labs",
        "url": "https://openai.com/index/investing-in-merge-labs",
        "content": "OpenAI is investing in Merge Labs to support new brain computer interfaces that bridge biological and artificial intelligence to maximize human ability, agency, and experience.",
        "contentSnippet": "OpenAI is investing in Merge Labs to support new brain computer interfaces that bridge biological and artificial intelligence to maximize human ability, agency, and experience.",
        "pubDate": "Thu, 15 Jan 2026 07:00:00 GMT",
        "isoDate": "2026-01-15T07:00:00.000Z",
        "source": "https://openai.com/index/investing-in-merge-labs"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-fkos5e",
        "title": "Strengthening the U.S. AI supply chain through domestic manufacturing",
        "link": "https://openai.com/index/strengthening-the-us-ai-supply-chain",
        "url": "https://openai.com/index/strengthening-the-us-ai-supply-chain",
        "content": "OpenAI launches a new RFP to strengthen the U.S. AI supply chain by accelerating domestic manufacturing, creating jobs, and scaling AI infrastructure.",
        "contentSnippet": "OpenAI launches a new RFP to strengthen the U.S. AI supply chain by accelerating domestic manufacturing, creating jobs, and scaling AI infrastructure.",
        "pubDate": "Thu, 15 Jan 2026 00:00:00 GMT",
        "isoDate": "2026-01-15T00:00:00.000Z",
        "source": "https://openai.com/index/strengthening-the-us-ai-supply-chain"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-5l54ue",
        "title": "OpenAI partners with Cerebras  ",
        "link": "https://openai.com/index/cerebras-partnership",
        "url": "https://openai.com/index/cerebras-partnership",
        "content": "OpenAI partners with Cerebras to add 750MW of high-speed AI compute, reducing inference latency and making ChatGPT faster for real-time AI workloads.",
        "contentSnippet": "OpenAI partners with Cerebras to add 750MW of high-speed AI compute, reducing inference latency and making ChatGPT faster for real-time AI workloads.",
        "pubDate": "Wed, 14 Jan 2026 14:00:00 GMT",
        "isoDate": "2026-01-14T14:00:00.000Z",
        "source": "https://openai.com/index/cerebras-partnership"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-snt19z",
        "title": "Zenken boosts a lean sales team with ChatGPT Enterprise",
        "link": "https://openai.com/index/zenken",
        "url": "https://openai.com/index/zenken",
        "content": "By rolling out ChatGPT Enterprise company-wide, Zenken has boosted sales performance, cut preparation time, and increased proposal success rates. AI-supported workflows are helping a lean team deliver more personalized, effective customer engagement.",
        "contentSnippet": "By rolling out ChatGPT Enterprise company-wide, Zenken has boosted sales performance, cut preparation time, and increased proposal success rates. AI-supported workflows are helping a lean team deliver more personalized, effective customer engagement.",
        "pubDate": "Tue, 13 Jan 2026 16:00:00 GMT",
        "isoDate": "2026-01-13T16:00:00.000Z",
        "source": "https://openai.com/index/zenken"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-hcn0gr",
        "title": "OpenAI’s Raising Concerns Policy",
        "link": "https://openai.com/index/openai-raising-concerns-policy",
        "url": "https://openai.com/index/openai-raising-concerns-policy",
        "content": "We’re publishing our Raising Concerns Policy, which protects employees’ rights to make protected disclosures.",
        "contentSnippet": "We’re publishing our Raising Concerns Policy, which protects employees’ rights to make protected disclosures.",
        "pubDate": "Mon, 12 Jan 2026 00:00:00 GMT",
        "isoDate": "2026-01-12T00:00:00.000Z",
        "source": "https://openai.com/index/openai-raising-concerns-policy"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7okmnv",
        "title": "OpenAI and SoftBank Group partner with SB Energy",
        "link": "https://openai.com/index/stargate-sb-energy-partnership",
        "url": "https://openai.com/index/stargate-sb-energy-partnership",
        "content": "OpenAI and SoftBank Group partner with SB Energy to develop multi-gigawatt AI data center campuses, including a 1.2 GW Texas facility supporting the Stargate initiative.",
        "contentSnippet": "OpenAI and SoftBank Group partner with SB Energy to develop multi-gigawatt AI data center campuses, including a 1.2 GW Texas facility supporting the Stargate initiative.",
        "pubDate": "Fri, 09 Jan 2026 11:00:00 GMT",
        "isoDate": "2026-01-09T11:00:00.000Z",
        "source": "https://openai.com/index/stargate-sb-energy-partnership"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-5ovjfq",
        "title": "Datadog uses Codex for system-level code review",
        "link": "https://openai.com/index/datadog",
        "url": "https://openai.com/index/datadog",
        "content": "OpenAI and Datadog brand graphic with the OpenAI wordmark on the left, the Datadog logo on the right, and a central abstract brown fur-like texture panel on a white background.",
        "contentSnippet": "OpenAI and Datadog brand graphic with the OpenAI wordmark on the left, the Datadog logo on the right, and a central abstract brown fur-like texture panel on a white background.",
        "pubDate": "Fri, 09 Jan 2026 00:00:00 GMT",
        "isoDate": "2026-01-09T00:00:00.000Z",
        "source": "https://openai.com/index/datadog"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-yc8kxm",
        "title": "Netomi’s lessons for scaling agentic systems into the enterprise",
        "link": "https://openai.com/index/netomi",
        "url": "https://openai.com/index/netomi",
        "content": "How Netomi scales enterprise AI agents using GPT-4.1 and GPT-5.2—combining concurrency, governance, and multi-step reasoning for reliable production workflows.",
        "contentSnippet": "How Netomi scales enterprise AI agents using GPT-4.1 and GPT-5.2—combining concurrency, governance, and multi-step reasoning for reliable production workflows.",
        "pubDate": "Thu, 08 Jan 2026 13:00:00 GMT",
        "isoDate": "2026-01-08T13:00:00.000Z",
        "source": "https://openai.com/index/netomi"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ie2vd8",
        "title": "OpenAI for Healthcare",
        "link": "https://openai.com/index/openai-for-healthcare",
        "url": "https://openai.com/index/openai-for-healthcare",
        "content": "OpenAI for Healthcare enables secure, enterprise-grade AI that supports HIPAA compliance—reducing administrative burden and supporting clinical workflows.",
        "contentSnippet": "OpenAI for Healthcare enables secure, enterprise-grade AI that supports HIPAA compliance—reducing administrative burden and supporting clinical workflows.",
        "pubDate": "Thu, 08 Jan 2026 12:00:00 GMT",
        "isoDate": "2026-01-08T12:00:00.000Z",
        "source": "https://openai.com/index/openai-for-healthcare"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jlzao6",
        "title": "How Tolan builds voice-first AI with GPT-5.1",
        "link": "https://openai.com/index/tolan",
        "url": "https://openai.com/index/tolan",
        "content": "Tolan built a voice-first AI companion with GPT-5.1, combining low-latency responses, real-time context reconstruction, and memory-driven personalities for natural conversations.",
        "contentSnippet": "Tolan built a voice-first AI companion with GPT-5.1, combining low-latency responses, real-time context reconstruction, and memory-driven personalities for natural conversations.",
        "pubDate": "Wed, 07 Jan 2026 10:00:00 GMT",
        "isoDate": "2026-01-07T10:00:00.000Z",
        "source": "https://openai.com/index/tolan"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-g2j735",
        "title": "Introducing ChatGPT Health ",
        "link": "https://openai.com/index/introducing-chatgpt-health",
        "url": "https://openai.com/index/introducing-chatgpt-health",
        "content": "ChatGPT Health is a dedicated experience that securely connects your health data and apps, with privacy protections and a physician-informed design.",
        "contentSnippet": "ChatGPT Health is a dedicated experience that securely connects your health data and apps, with privacy protections and a physician-informed design.",
        "pubDate": "Wed, 07 Jan 2026 00:00:00 GMT",
        "isoDate": "2026-01-07T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-chatgpt-health"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9puflc",
        "title": "Announcing OpenAI Grove Cohort 2",
        "link": "https://openai.com/index/openai-grove",
        "url": "https://openai.com/index/openai-grove",
        "content": "Applications are now open for OpenAI Grove Cohort 2, a 5-week founder program designed for individuals at any stage, from pre-idea to product. Participants receive $50K in API credits, early access to AI tools, and hands-on mentorship from the OpenAI team.",
        "contentSnippet": "Applications are now open for OpenAI Grove Cohort 2, a 5-week founder program designed for individuals at any stage, from pre-idea to product. Participants receive $50K in API credits, early access to AI tools, and hands-on mentorship from the OpenAI team.",
        "pubDate": "Fri, 02 Jan 2026 10:00:00 GMT",
        "isoDate": "2026-01-02T10:00:00.000Z",
        "source": "https://openai.com/index/openai-grove"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-o6ktb",
        "title": "One in a million: celebrating the customers shaping AI’s future",
        "link": "https://openai.com/index/one-in-a-million-customers",
        "url": "https://openai.com/index/one-in-a-million-customers",
        "content": "More than one million customers around the world now use OpenAI to empower their teams and unlock new opportunities. This post highlights how companies like PayPal, Virgin Atlantic, BBVA, Cisco, Moderna, and Canva are transforming the way work gets done with AI.",
        "contentSnippet": "More than one million customers around the world now use OpenAI to empower their teams and unlock new opportunities. This post highlights how companies like PayPal, Virgin Atlantic, BBVA, Cisco, Moderna, and Canva are transforming the way work gets done with AI.",
        "pubDate": "Mon, 22 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-22T00:00:00.000Z",
        "source": "https://openai.com/index/one-in-a-million-customers"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-4lqdv",
        "title": "Continuously hardening ChatGPT Atlas against prompt injection",
        "link": "https://openai.com/index/hardening-atlas-against-prompt-injection",
        "url": "https://openai.com/index/hardening-atlas-against-prompt-injection",
        "content": "OpenAI is strengthening ChatGPT Atlas against prompt injection attacks using automated red teaming trained with reinforcement learning. This proactive discover-and-patch loop helps identify novel exploits early and harden the browser agent’s defenses as AI becomes more agentic.",
        "contentSnippet": "OpenAI is strengthening ChatGPT Atlas against prompt injection attacks using automated red teaming trained with reinforcement learning. This proactive discover-and-patch loop helps identify novel exploits early and harden the browser agent’s defenses as AI becomes more agentic.",
        "pubDate": "Mon, 22 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-22T00:00:00.000Z",
        "source": "https://openai.com/index/hardening-atlas-against-prompt-injection"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-8qh1db",
        "title": "Evaluating chain-of-thought monitorability",
        "link": "https://openai.com/index/evaluating-chain-of-thought-monitorability",
        "url": "https://openai.com/index/evaluating-chain-of-thought-monitorability",
        "content": "OpenAI introduces a new framework and evaluation suite for chain-of-thought monitorability, covering 13 evaluations across 24 environments. Our findings show that monitoring a model’s internal reasoning is far more effective than monitoring outputs alone, offering a promising path toward scalable control as AI systems grow more capable.",
        "contentSnippet": "OpenAI introduces a new framework and evaluation suite for chain-of-thought monitorability, covering 13 evaluations across 24 environments. Our findings show that monitoring a model’s internal reasoning is far more effective than monitoring outputs alone, offering a promising path toward scalable control as AI systems grow more capable.",
        "pubDate": "Thu, 18 Dec 2025 12:00:00 GMT",
        "isoDate": "2025-12-18T12:00:00.000Z",
        "source": "https://openai.com/index/evaluating-chain-of-thought-monitorability"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-64t612",
        "title": "AI literacy resources for teens and parents",
        "link": "https://openai.com/index/ai-literacy-resources-for-teens-and-parents",
        "url": "https://openai.com/index/ai-literacy-resources-for-teens-and-parents",
        "content": "OpenAI shares new AI literacy resources to help teens and parents use ChatGPT thoughtfully, safely, and with confidence. The guides include expert-vetted tips for responsible use, critical thinking, healthy boundaries, and supporting teens through emotional or sensitive topics.",
        "contentSnippet": "OpenAI shares new AI literacy resources to help teens and parents use ChatGPT thoughtfully, safely, and with confidence. The guides include expert-vetted tips for responsible use, critical thinking, healthy boundaries, and supporting teens through emotional or sensitive topics.",
        "pubDate": "Thu, 18 Dec 2025 11:00:00 GMT",
        "isoDate": "2025-12-18T11:00:00.000Z",
        "source": "https://openai.com/index/ai-literacy-resources-for-teens-and-parents"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-8jeo5t",
        "title": "Updating our Model Spec with teen protections",
        "link": "https://openai.com/index/updating-model-spec-with-teen-protections",
        "url": "https://openai.com/index/updating-model-spec-with-teen-protections",
        "content": "OpenAI is updating its Model Spec with new Under-18 Principles that define how ChatGPT should support teens with safe, age-appropriate guidance grounded in developmental science. The update strengthens guardrails, clarifies expected model behavior in higher-risk situations, and builds on our broader work to improve teen safety across ChatGPT.",
        "contentSnippet": "OpenAI is updating its Model Spec with new Under-18 Principles that define how ChatGPT should support teens with safe, age-appropriate guidance grounded in developmental science. The update strengthens guardrails, clarifies expected model behavior in higher-risk situations, and builds on our broader work to improve teen safety across ChatGPT.",
        "pubDate": "Thu, 18 Dec 2025 11:00:00 GMT",
        "isoDate": "2025-12-18T11:00:00.000Z",
        "source": "https://openai.com/index/updating-model-spec-with-teen-protections"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-bbnseq",
        "title": "Deepening our collaboration with the U.S. Department of Energy",
        "link": "https://openai.com/index/us-department-of-energy-collaboration",
        "url": "https://openai.com/index/us-department-of-energy-collaboration",
        "content": "OpenAI and the U.S. Department of Energy have signed a memorandum of understanding to deepen collaboration on AI and advanced computing in support of scientific discovery. The agreement builds on ongoing work with national laboratories and helps establish a framework for applying AI to high-impact research across the DOE ecosystem.",
        "contentSnippet": "OpenAI and the U.S. Department of Energy have signed a memorandum of understanding to deepen collaboration on AI and advanced computing in support of scientific discovery. The agreement builds on ongoing work with national laboratories and helps establish a framework for applying AI to high-impact research across the DOE ecosystem.",
        "pubDate": "Thu, 18 Dec 2025 11:00:00 GMT",
        "isoDate": "2025-12-18T11:00:00.000Z",
        "source": "https://openai.com/index/us-department-of-energy-collaboration"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-oiwsa5",
        "title": "Introducing GPT-5.2-Codex",
        "link": "https://openai.com/index/introducing-gpt-5-2-codex",
        "url": "https://openai.com/index/introducing-gpt-5-2-codex",
        "content": "GPT-5.2-Codex is OpenAI’s most advanced coding model, offering long-horizon reasoning, large-scale code transformations, and enhanced cybersecurity capabilities.",
        "contentSnippet": "GPT-5.2-Codex is OpenAI’s most advanced coding model, offering long-horizon reasoning, large-scale code transformations, and enhanced cybersecurity capabilities.",
        "pubDate": "Thu, 18 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-18T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-gpt-5-2-codex"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-l8rndq",
        "title": "Introducing GPT-5.2-Codex",
        "link": "https://openai.com/index/gpt-5-2-codex",
        "url": "https://openai.com/index/gpt-5-2-codex",
        "content": "GPT-5.2-Codex is OpenAI’s most advanced coding model, offering long-horizon reasoning, large-scale code transformations, and enhanced cybersecurity capabilities.",
        "contentSnippet": "GPT-5.2-Codex is OpenAI’s most advanced coding model, offering long-horizon reasoning, large-scale code transformations, and enhanced cybersecurity capabilities.",
        "pubDate": "Thu, 18 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-18T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-2-codex"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-786qm9",
        "title": "Addendum to GPT-5.2 System Card: GPT-5.2-Codex",
        "link": "https://openai.com/index/gpt-5-2-codex-system-card",
        "url": "https://openai.com/index/gpt-5-2-codex-system-card",
        "content": "This system card outlines the comprehensive safety measures implemented for GPT‑5.2-Codex. It details both model-level mitigations, such as specialized safety training for harmful tasks and prompt injections, and product-level mitigations like agent sandboxing and configurable network access.",
        "contentSnippet": "This system card outlines the comprehensive safety measures implemented for GPT‑5.2-Codex. It details both model-level mitigations, such as specialized safety training for harmful tasks and prompt injections, and product-level mitigations like agent sandboxing and configurable network access.",
        "pubDate": "Thu, 18 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-18T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-2-codex-system-card"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xdklu",
        "title": "Introducing OpenAI Academy for News Organizations",
        "link": "https://openai.com/index/openai-academy-for-news-organizations",
        "url": "https://openai.com/index/openai-academy-for-news-organizations",
        "content": "OpenAI is launching the OpenAI Academy for News Organizations, a new learning hub built with the American Journalism Project and The Lenfest Institute to help newsrooms use AI effectively. The Academy offers training, practical use cases, and responsible-use guidance to support journalists, editors, and publishers as they adopt AI in their reporting and operations.",
        "contentSnippet": "OpenAI is launching the OpenAI Academy for News Organizations, a new learning hub built with the American Journalism Project and The Lenfest Institute to help newsrooms use AI effectively. The Academy offers training, practical use cases, and responsible-use guidance to support journalists, editors, and publishers as they adopt AI in their reporting and operations.",
        "pubDate": "Wed, 17 Dec 2025 06:00:00 GMT",
        "isoDate": "2025-12-17T06:00:00.000Z",
        "source": "https://openai.com/index/openai-academy-for-news-organizations"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-mtvgk9",
        "title": "Developers can now submit apps to ChatGPT",
        "link": "https://openai.com/index/developers-can-now-submit-apps-to-chatgpt",
        "url": "https://openai.com/index/developers-can-now-submit-apps-to-chatgpt",
        "content": "Developers can now submit apps for review and publication in ChatGPT, with approved apps appearing in a new in-product directory for easy discovery. Updated tools, guidelines, and the Apps SDK help developers build powerful chat-native experiences that bring real-world actions into ChatGPT.",
        "contentSnippet": "Developers can now submit apps for review and publication in ChatGPT, with approved apps appearing in a new in-product directory for easy discovery. Updated tools, guidelines, and the Apps SDK help developers build powerful chat-native experiences that bring real-world actions into ChatGPT.",
        "pubDate": "Wed, 17 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-17T00:00:00.000Z",
        "source": "https://openai.com/index/developers-can-now-submit-apps-to-chatgpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-fn4t6p",
        "title": "Evaluating AI’s ability to perform scientific research tasks",
        "link": "https://openai.com/index/frontierscience",
        "url": "https://openai.com/index/frontierscience",
        "content": "OpenAI introduces FrontierScience, a benchmark testing AI reasoning in physics, chemistry, and biology to measure progress toward real scientific research.",
        "contentSnippet": "OpenAI introduces FrontierScience, a benchmark testing AI reasoning in physics, chemistry, and biology to measure progress toward real scientific research.",
        "pubDate": "Tue, 16 Dec 2025 09:00:00 GMT",
        "isoDate": "2025-12-16T09:00:00.000Z",
        "source": "https://openai.com/index/frontierscience"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9pbin7",
        "title": "Measuring AI’s capability to accelerate biological research",
        "link": "https://openai.com/index/accelerating-biological-research-in-the-wet-lab",
        "url": "https://openai.com/index/accelerating-biological-research-in-the-wet-lab",
        "content": "OpenAI introduces a real-world evaluation framework to measure how AI can accelerate biological research in the wet lab. Using GPT-5 to optimize a molecular cloning protocol, the work explores both the promise and risks of AI-assisted experimentation.",
        "contentSnippet": "OpenAI introduces a real-world evaluation framework to measure how AI can accelerate biological research in the wet lab. Using GPT-5 to optimize a molecular cloning protocol, the work explores both the promise and risks of AI-assisted experimentation.",
        "pubDate": "Tue, 16 Dec 2025 08:00:00 GMT",
        "isoDate": "2025-12-16T08:00:00.000Z",
        "source": "https://openai.com/index/accelerating-biological-research-in-the-wet-lab"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ri7j7",
        "title": "The new ChatGPT Images is here",
        "link": "https://openai.com/index/new-chatgpt-images-is-here",
        "url": "https://openai.com/index/new-chatgpt-images-is-here",
        "content": "The new ChatGPT Images is powered by our flagship image generation model, delivering more precise edits, consistent details, and image generation up to 4× faster. The upgraded model is rolling out to all ChatGPT users today and is also available in the API as GPT-Image-1.5.",
        "contentSnippet": "The new ChatGPT Images is powered by our flagship image generation model, delivering more precise edits, consistent details, and image generation up to 4× faster. The upgraded model is rolling out to all ChatGPT users today and is also available in the API as GPT-Image-1.5.",
        "pubDate": "Tue, 16 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-16T00:00:00.000Z",
        "source": "https://openai.com/index/new-chatgpt-images-is-here"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-npf4y3",
        "title": "BNY builds “AI for everyone, everywhere” with OpenAI",
        "link": "https://openai.com/index/bny",
        "url": "https://openai.com/index/bny",
        "content": "BNY is using OpenAI technology to expand AI adoption enterprise-wide. Through its Eliza platform, 20,000+ employees are building AI agents that enhance efficiency and improve client outcomes.",
        "contentSnippet": "BNY is using OpenAI technology to expand AI adoption enterprise-wide. Through its Eliza platform, 20,000+ employees are building AI agents that enhance efficiency and improve client outcomes.",
        "pubDate": "Fri, 12 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-12T00:00:00.000Z",
        "source": "https://openai.com/index/bny"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-chm5y7",
        "title": "How We Used Codex to Ship Sora for Android in 28 Days",
        "link": "https://openai.com/index/shipping-sora-for-android-with-codex",
        "url": "https://openai.com/index/shipping-sora-for-android-with-codex",
        "content": "OpenAI shipped Sora for Android in 28 days using Codex. AI-assisted planning, translation, and parallel coding workflows helped a nimble team deliver rapid, reliable development.",
        "contentSnippet": "OpenAI shipped Sora for Android in 28 days using Codex. AI-assisted planning, translation, and parallel coding workflows helped a nimble team deliver rapid, reliable development.",
        "pubDate": "Fri, 12 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-12T00:00:00.000Z",
        "source": "https://openai.com/index/shipping-sora-for-android-with-codex"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-scro6r",
        "title": "BBVA and OpenAI collaborate to transform global banking",
        "link": "https://openai.com/index/bbva-collaboration-expansion",
        "url": "https://openai.com/index/bbva-collaboration-expansion",
        "content": "BBVA is expanding its work with OpenAI through a multi-year AI transformation program, rolling out ChatGPT Enterprise to all 120,000 employees. Together, the companies will develop AI solutions that enhance customer interactions, streamline operations, and help build an AI-native banking experience.",
        "contentSnippet": "BBVA is expanding its work with OpenAI through a multi-year AI transformation program, rolling out ChatGPT Enterprise to all 120,000 employees. Together, the companies will develop AI solutions that enhance customer interactions, streamline operations, and help build an AI-native banking experience.",
        "pubDate": "Fri, 12 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-12T00:00:00.000Z",
        "source": "https://openai.com/index/bbva-collaboration-expansion"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-4akrwo",
        "title": "Advancing science and math with GPT-5.2",
        "link": "https://openai.com/index/gpt-5-2-for-science-and-math",
        "url": "https://openai.com/index/gpt-5-2-for-science-and-math",
        "content": "GPT-5.2 is OpenAI’s strongest model yet for math and science, setting new state-of-the-art results on benchmarks like GPQA Diamond and FrontierMath. This post shows how those gains translate into real research progress, including solving an open theoretical problem and generating reliable mathematical proofs.",
        "contentSnippet": "GPT-5.2 is OpenAI’s strongest model yet for math and science, setting new state-of-the-art results on benchmarks like GPQA Diamond and FrontierMath. This post shows how those gains translate into real research progress, including solving an open theoretical problem and generating reliable mathematical proofs.",
        "pubDate": "Thu, 11 Dec 2025 10:00:00 GMT",
        "isoDate": "2025-12-11T10:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-2-for-science-and-math"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-m6vhym",
        "title": "Ten years",
        "link": "https://openai.com/index/ten-years",
        "url": "https://openai.com/index/ten-years",
        "content": "OpenAI reflects on ten years of progress, from early research breakthroughs to widely used AI systems that reshaped what’s possible. We share lessons from the past decade and why we remain optimistic about building AGI that benefits all of humanity.",
        "contentSnippet": "OpenAI reflects on ten years of progress, from early research breakthroughs to widely used AI systems that reshaped what’s possible. We share lessons from the past decade and why we remain optimistic about building AGI that benefits all of humanity.",
        "pubDate": "Thu, 11 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-11T00:00:00.000Z",
        "source": "https://openai.com/index/ten-years"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-x8xq98",
        "title": "Increasing revenue 300% by bringing AI to SMBs",
        "link": "https://openai.com/index/podium",
        "url": "https://openai.com/index/podium",
        "content": "Discover how Podium used OpenAI’s GPT-5 to build “Jerry,” an AI teammate driving 300% growth and transforming how Main Street businesses serve customers.",
        "contentSnippet": "Discover how Podium used OpenAI’s GPT-5 to build “Jerry,” an AI teammate driving 300% growth and transforming how Main Street businesses serve customers.",
        "pubDate": "Thu, 11 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-11T00:00:00.000Z",
        "source": "https://openai.com/index/podium"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-utc1lx",
        "title": "Update to GPT-5 System Card: GPT-5.2",
        "link": "https://openai.com/index/gpt-5-system-card-update-gpt-5-2",
        "url": "https://openai.com/index/gpt-5-system-card-update-gpt-5-2",
        "content": "GPT-5.2 is the latest model family in the GPT-5 series. The comprehensive safety mitigation approach for these models is largely the same as that described in the GPT-5 System Card and GPT-5.1 System Card. Like OpenAI’s other models, the GPT-5.2 models were trained on diverse datasets, including information that is publicly available on the internet, information that we partner with third parties to access, and information that our users or human trainers and researchers provide or generate.",
        "contentSnippet": "GPT-5.2 is the latest model family in the GPT-5 series. The comprehensive safety mitigation approach for these models is largely the same as that described in the GPT-5 System Card and GPT-5.1 System Card. Like OpenAI’s other models, the GPT-5.2 models were trained on diverse datasets, including information that is publicly available on the internet, information that we partner with third parties to access, and information that our users or human trainers and researchers provide or generate.",
        "pubDate": "Thu, 11 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-11T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-system-card-update-gpt-5-2"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7i5cgf",
        "title": "Introducing GPT-5.2",
        "link": "https://openai.com/index/introducing-gpt-5-2",
        "url": "https://openai.com/index/introducing-gpt-5-2",
        "content": "GPT-5.2 is our most advanced frontier model for everyday professional work, with state-of-the-art reasoning, long-context understanding, coding, and vision. Use it in ChatGPT and the OpenAI API to power faster, more reliable agentic workflows.",
        "contentSnippet": "GPT-5.2 is our most advanced frontier model for everyday professional work, with state-of-the-art reasoning, long-context understanding, coding, and vision. Use it in ChatGPT and the OpenAI API to power faster, more reliable agentic workflows.",
        "pubDate": "Thu, 11 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-11T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-gpt-5-2"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-a46q21",
        "title": "The Walt Disney Company and OpenAI reach landmark agreement to bring beloved characters to Sora",
        "link": "https://openai.com/index/disney-sora-agreement",
        "url": "https://openai.com/index/disney-sora-agreement",
        "content": "Disney and OpenAI have reached an agreement to bring more than 200 Disney, Marvel, Pixar and Star Wars characters to Sora for fan-inspired short videos. The agreement emphasizes responsible AI in entertainment and includes Disney’s company-wide use of ChatGPT Enterprise and the OpenAI API.",
        "contentSnippet": "Disney and OpenAI have reached an agreement to bring more than 200 Disney, Marvel, Pixar and Star Wars characters to Sora for fan-inspired short videos. The agreement emphasizes responsible AI in entertainment and includes Disney’s company-wide use of ChatGPT Enterprise and the OpenAI API.",
        "pubDate": "Thu, 11 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-11T00:00:00.000Z",
        "source": "https://openai.com/index/disney-sora-agreement"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-bswgpa",
        "title": "Strengthening cyber resilience as AI capabilities advance",
        "link": "https://openai.com/index/strengthening-cyber-resilience",
        "url": "https://openai.com/index/strengthening-cyber-resilience",
        "content": "OpenAI is investing in stronger safeguards and defensive capabilities as AI models become more powerful in cybersecurity. We explain how we assess risk, limit misuse, and work with the security community to strengthen cyber resilience.",
        "contentSnippet": "OpenAI is investing in stronger safeguards and defensive capabilities as AI models become more powerful in cybersecurity. We explain how we assess risk, limit misuse, and work with the security community to strengthen cyber resilience.",
        "pubDate": "Wed, 10 Dec 2025 12:00:00 GMT",
        "isoDate": "2025-12-10T12:00:00.000Z",
        "source": "https://openai.com/index/strengthening-cyber-resilience"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-29fvwo",
        "title": "How Scout24 is building the next generation of real-estate search with AI",
        "link": "https://openai.com/index/scout24",
        "url": "https://openai.com/index/scout24",
        "content": "Scout24 has created a GPT-5 powered conversational assistant that reimagines real-estate search, guiding users with clarifying questions, summaries, and tailored listing recommendations.",
        "contentSnippet": "Scout24 has created a GPT-5 powered conversational assistant that reimagines real-estate search, guiding users with clarifying questions, summaries, and tailored listing recommendations.",
        "pubDate": "Tue, 09 Dec 2025 16:00:00 GMT",
        "isoDate": "2025-12-09T16:00:00.000Z",
        "source": "https://openai.com/index/scout24"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-w0rzvy",
        "title": "OpenAI co-founds Agentic AI Foundation, donates AGENTS.md",
        "link": "https://openai.com/index/agentic-ai-foundation",
        "url": "https://openai.com/index/agentic-ai-foundation",
        "content": "OpenAI co-founds the Agentic AI Foundation under the Linux Foundation and donates AGENTS.md to support open, interoperable standards for safe agentic AI.",
        "contentSnippet": "OpenAI co-founds the Agentic AI Foundation under the Linux Foundation and donates AGENTS.md to support open, interoperable standards for safe agentic AI.",
        "pubDate": "Tue, 09 Dec 2025 09:00:00 GMT",
        "isoDate": "2025-12-09T09:00:00.000Z",
        "source": "https://openai.com/index/agentic-ai-foundation"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ru7qfz",
        "title": "Launching our first OpenAI Certifications courses",
        "link": "https://openai.com/index/openai-certificate-courses",
        "url": "https://openai.com/index/openai-certificate-courses",
        "content": "Learn how OpenAI’s new certifications and AI Foundations courses help people build real-world AI skills, boost career opportunities, and prepare for the future of work.",
        "contentSnippet": "Learn how OpenAI’s new certifications and AI Foundations courses help people build real-world AI skills, boost career opportunities, and prepare for the future of work.",
        "pubDate": "Tue, 09 Dec 2025 06:00:00 GMT",
        "isoDate": "2025-12-09T06:00:00.000Z",
        "source": "https://openai.com/index/openai-certificate-courses"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-afmqpu",
        "title": "Building AI fluency at scale with ChatGPT Enterprise",
        "link": "https://openai.com/index/commonwealth-bank-of-australia",
        "url": "https://openai.com/index/commonwealth-bank-of-australia",
        "content": "Commonwealth Bank of Australia partners with OpenAI to roll out ChatGPT Enterprise to 50,000 employees, building AI fluency at scale to improve customer service and fraud response.",
        "contentSnippet": "Commonwealth Bank of Australia partners with OpenAI to roll out ChatGPT Enterprise to 50,000 employees, building AI fluency at scale to improve customer service and fraud response.",
        "pubDate": "Tue, 09 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-09T00:00:00.000Z",
        "source": "https://openai.com/index/commonwealth-bank-of-australia"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7w9j73",
        "title": "Bringing powerful AI to millions across Europe with Deutsche Telekom",
        "link": "https://openai.com/index/deutsche-telekom-collaboration",
        "url": "https://openai.com/index/deutsche-telekom-collaboration",
        "content": "OpenAI is collaborating with Deutsche Telekom to bring advanced, multilingual AI experiences to millions of people across Europe. ChatGPT Enterprise will also be deployed to help employees at Deutsche Telekom improve workflows and accelerate innovation.",
        "contentSnippet": "OpenAI is collaborating with Deutsche Telekom to bring advanced, multilingual AI experiences to millions of people across Europe. ChatGPT Enterprise will also be deployed to help employees at Deutsche Telekom improve workflows and accelerate innovation.",
        "pubDate": "Tue, 09 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-09T00:00:00.000Z",
        "source": "https://openai.com/index/deutsche-telekom-collaboration"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wukmzn",
        "title": "OpenAI appoints Denise Dresser as Chief Revenue Officer",
        "link": "https://openai.com/index/openai-appoints-denise-dresser",
        "url": "https://openai.com/index/openai-appoints-denise-dresser",
        "content": "Denise Dresser is joining as Chief Revenue Officer, overseeing OpenAI’s global revenue strategy across enterprise and customer success. She will help more businesses put AI to work in their day-to-day operations as OpenAI continues to scale.",
        "contentSnippet": "Denise Dresser is joining as Chief Revenue Officer, overseeing OpenAI’s global revenue strategy across enterprise and customer success. She will help more businesses put AI to work in their day-to-day operations as OpenAI continues to scale.",
        "pubDate": "Tue, 09 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-09T00:00:00.000Z",
        "source": "https://openai.com/index/openai-appoints-denise-dresser"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xh2ypm",
        "title": "Instacart and OpenAI partner on AI shopping experiences",
        "link": "https://openai.com/index/instacart-partnership",
        "url": "https://openai.com/index/instacart-partnership",
        "content": "OpenAI and Instacart are deepening their longstanding partnership by bringing the first fully integrated grocery shopping and Instant Checkout payment app to ChatGPT.",
        "contentSnippet": "OpenAI and Instacart are deepening their longstanding partnership by bringing the first fully integrated grocery shopping and Instant Checkout payment app to ChatGPT.",
        "pubDate": "Mon, 08 Dec 2025 06:00:00 GMT",
        "isoDate": "2025-12-08T06:00:00.000Z",
        "source": "https://openai.com/index/instacart-partnership"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-sycw7z",
        "title": "The state of enterprise AI",
        "link": "https://openai.com/index/the-state-of-enterprise-ai-2025-report",
        "url": "https://openai.com/index/the-state-of-enterprise-ai-2025-report",
        "content": "Key findings from OpenAI’s enterprise data show accelerating AI adoption, deeper integration, and measurable productivity gains across industries in 2025.",
        "contentSnippet": "Key findings from OpenAI’s enterprise data show accelerating AI adoption, deeper integration, and measurable productivity gains across industries in 2025.",
        "pubDate": "Mon, 08 Dec 2025 04:00:00 GMT",
        "isoDate": "2025-12-08T04:00:00.000Z",
        "source": "https://openai.com/index/the-state-of-enterprise-ai-2025-report"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-2h1s52",
        "title": "How Virgin Atlantic uses AI to enhance every step of travel",
        "link": "https://openai.com/index/virgin-atlantic-oliver-byers",
        "url": "https://openai.com/index/virgin-atlantic-oliver-byers",
        "content": "Virgin Atlantic CFO Oliver Byers shares how the airline is using AI to speed up development, improve decision-making, and elevate customer experience.",
        "contentSnippet": "Virgin Atlantic CFO Oliver Byers shares how the airline is using AI to speed up development, improve decision-making, and elevate customer experience.",
        "pubDate": "Mon, 08 Dec 2025 00:00:00 GMT",
        "isoDate": "2025-12-08T00:00:00.000Z",
        "source": "https://openai.com/index/virgin-atlantic-oliver-byers"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-mfcwej",
        "title": "Introducing OpenAI for Australia",
        "link": "https://openai.com/global-affairs/openai-for-australia",
        "url": "https://openai.com/global-affairs/openai-for-australia",
        "content": "OpenAI is launching OpenAI for Australia to build sovereign AI infrastructure, upskill more than 1.5 million workers, and accelerate innovation across the country’s growing AI ecosystem.",
        "contentSnippet": "OpenAI is launching OpenAI for Australia to build sovereign AI infrastructure, upskill more than 1.5 million workers, and accelerate innovation across the country’s growing AI ecosystem.",
        "pubDate": "Thu, 04 Dec 2025 19:00:00 GMT",
        "isoDate": "2025-12-04T19:00:00.000Z",
        "source": "https://openai.com/global-affairs/openai-for-australia"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ovrs39",
        "title": "OpenAI to acquire Neptune",
        "link": "https://openai.com/index/openai-to-acquire-neptune",
        "url": "https://openai.com/index/openai-to-acquire-neptune",
        "content": "OpenAI is acquiring Neptune to deepen visibility into model behavior and strengthen the tools researchers use to track experiments and monitor training.",
        "contentSnippet": "OpenAI is acquiring Neptune to deepen visibility into model behavior and strengthen the tools researchers use to track experiments and monitor training.",
        "pubDate": "Wed, 03 Dec 2025 10:00:00 GMT",
        "isoDate": "2025-12-03T10:00:00.000Z",
        "source": "https://openai.com/index/openai-to-acquire-neptune"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9jo37m",
        "title": "How confessions can keep language models honest",
        "link": "https://openai.com/index/how-confessions-can-keep-language-models-honest",
        "url": "https://openai.com/index/how-confessions-can-keep-language-models-honest",
        "content": "OpenAI researchers are testing “confessions,” a method that trains models to admit when they make mistakes or act undesirably, helping improve AI honesty, transparency, and trust in model outputs.",
        "contentSnippet": "OpenAI researchers are testing “confessions,” a method that trains models to admit when they make mistakes or act undesirably, helping improve AI honesty, transparency, and trust in model outputs.",
        "pubDate": "Wed, 03 Dec 2025 10:00:00 GMT",
        "isoDate": "2025-12-03T10:00:00.000Z",
        "source": "https://openai.com/index/how-confessions-can-keep-language-models-honest"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-nj2i03",
        "title": "Announcing the initial People-First AI Fund grantees",
        "link": "https://openai.com/index/people-first-ai-fund-grantees",
        "url": "https://openai.com/index/people-first-ai-fund-grantees",
        "content": "The OpenAI Foundation announces the initial recipients of the People-First AI Fund, awarding $40.5M in unrestricted grants to 208 nonprofits supporting community innovation and opportunity.",
        "contentSnippet": "The OpenAI Foundation announces the initial recipients of the People-First AI Fund, awarding $40.5M in unrestricted grants to 208 nonprofits supporting community innovation and opportunity.",
        "pubDate": "Wed, 03 Dec 2025 08:00:00 GMT",
        "isoDate": "2025-12-03T08:00:00.000Z",
        "source": "https://openai.com/index/people-first-ai-fund-grantees"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-yr4lcs",
        "title": "Inside Mirakl's agentic commerce vision",
        "link": "https://openai.com/index/mirakl",
        "url": "https://openai.com/index/mirakl",
        "content": "Mirakl is redefining commerce through AI agents and ChatGPT Enterprise—achieving faster documentation, smarter customer support, and building toward agent-native commerce with Mirakl Nexus.",
        "contentSnippet": "Mirakl is redefining commerce through AI agents and ChatGPT Enterprise—achieving faster documentation, smarter customer support, and building toward agent-native commerce with Mirakl Nexus.",
        "pubDate": "Mon, 01 Dec 2025 22:00:00 GMT",
        "isoDate": "2025-12-01T22:00:00.000Z",
        "source": "https://openai.com/index/mirakl"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9xi8up",
        "title": "Funding grants for new research into AI and mental health",
        "link": "https://openai.com/index/ai-mental-health-research-grants",
        "url": "https://openai.com/index/ai-mental-health-research-grants",
        "content": "OpenAI is awarding up to $2 million in grants for research at the intersection of AI and mental health. The program supports projects that study real-world risks, benefits, and applications to improve safety and well-being.",
        "contentSnippet": "OpenAI is awarding up to $2 million in grants for research at the intersection of AI and mental health. The program supports projects that study real-world risks, benefits, and applications to improve safety and well-being.",
        "pubDate": "Mon, 01 Dec 2025 12:00:00 GMT",
        "isoDate": "2025-12-01T12:00:00.000Z",
        "source": "https://openai.com/index/ai-mental-health-research-grants"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-u7e1fj",
        "title": "OpenAI and NORAD team up to bring new magic to “NORAD Tracks Santa”",
        "link": "https://openai.com/index/norad-holiday-collaboration",
        "url": "https://openai.com/index/norad-holiday-collaboration",
        "content": "OpenAI and NORAD are bringing new magic to “NORAD Tracks Santa” with three ChatGPT holiday tools that let families create festive elves, toy coloring pages, and custom Christmas stories.",
        "contentSnippet": "OpenAI and NORAD are bringing new magic to “NORAD Tracks Santa” with three ChatGPT holiday tools that let families create festive elves, toy coloring pages, and custom Christmas stories.",
        "pubDate": "Mon, 01 Dec 2025 06:00:00 GMT",
        "isoDate": "2025-12-01T06:00:00.000Z",
        "source": "https://openai.com/index/norad-holiday-collaboration"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-s6y7x1",
        "title": "OpenAI takes an ownership stake in Thrive Holdings to accelerate enterprise AI adoption",
        "link": "https://openai.com/index/thrive-holdings",
        "url": "https://openai.com/index/thrive-holdings",
        "content": "OpenAI takes an ownership stake in Thrive Holdings to accelerate enterprise AI adoption, embedding frontier research and engineering directly into accounting and IT services to boost speed, accuracy, and efficiency while creating a scalable model for industry-wide transformation.",
        "contentSnippet": "OpenAI takes an ownership stake in Thrive Holdings to accelerate enterprise AI adoption, embedding frontier research and engineering directly into accounting and IT services to boost speed, accuracy, and efficiency while creating a scalable model for industry-wide transformation.",
        "pubDate": "Mon, 01 Dec 2025 05:00:00 GMT",
        "isoDate": "2025-12-01T05:00:00.000Z",
        "source": "https://openai.com/index/thrive-holdings"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-90q4wz",
        "title": "Accenture and OpenAI accelerate enterprise AI success",
        "link": "https://openai.com/index/accenture-partnership",
        "url": "https://openai.com/index/accenture-partnership",
        "content": "Accenture and OpenAI are collaborating to help enterprises bring agentic AI capabilities into the core of their business and unlock new levels of growth.",
        "contentSnippet": "Accenture and OpenAI are collaborating to help enterprises bring agentic AI capabilities into the core of their business and unlock new levels of growth.",
        "pubDate": "Mon, 01 Dec 2025 05:00:00 GMT",
        "isoDate": "2025-12-01T05:00:00.000Z",
        "source": "https://openai.com/index/accenture-partnership"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-e6kgv3",
        "title": "Mixpanel security incident: what OpenAI users need to know",
        "link": "https://openai.com/index/mixpanel-incident",
        "url": "https://openai.com/index/mixpanel-incident",
        "content": "OpenAI shares details about a Mixpanel security incident involving limited API analytics data. No API content, credentials, or payment details were exposed. Learn what happened and how we’re protecting users.",
        "contentSnippet": "OpenAI shares details about a Mixpanel security incident involving limited API analytics data. No API content, credentials, or payment details were exposed. Learn what happened and how we’re protecting users.",
        "pubDate": "Wed, 26 Nov 2025 19:00:00 GMT",
        "isoDate": "2025-11-26T19:00:00.000Z",
        "source": "https://openai.com/index/mixpanel-incident"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-bwt36q",
        "title": "Expanding data residency access to business customers worldwide",
        "link": "https://openai.com/index/expanding-data-residency-access-to-business-customers-worldwide",
        "url": "https://openai.com/index/expanding-data-residency-access-to-business-customers-worldwide",
        "content": "OpenAI expands data residency for ChatGPT Enterprise, ChatGPT Edu, and the API Platform, enabling eligible customers to store data at rest in-region.",
        "contentSnippet": "OpenAI expands data residency for ChatGPT Enterprise, ChatGPT Edu, and the API Platform, enabling eligible customers to store data at rest in-region.",
        "pubDate": "Tue, 25 Nov 2025 22:00:00 GMT",
        "isoDate": "2025-11-25T22:00:00.000Z",
        "source": "https://openai.com/index/expanding-data-residency-access-to-business-customers-worldwide"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-leqc1c",
        "title": "Our approach to mental health-related litigation",
        "link": "https://openai.com/index/mental-health-litigation-approach",
        "url": "https://openai.com/index/mental-health-litigation-approach",
        "content": "We’re sharing our approach to mental health-related litigation. O handle sensitive cases with care, transparency, and respect while continuing to strengthen safety and support in ChatGPT.",
        "contentSnippet": "We’re sharing our approach to mental health-related litigation. O handle sensitive cases with care, transparency, and respect while continuing to strengthen safety and support in ChatGPT.",
        "pubDate": "Tue, 25 Nov 2025 12:00:00 GMT",
        "isoDate": "2025-11-25T12:00:00.000Z",
        "source": "https://openai.com/index/mental-health-litigation-approach"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-nz5cts",
        "title": "Inside JetBrains—the company reshaping how the world writes code",
        "link": "https://openai.com/index/jetbrains-2025",
        "url": "https://openai.com/index/jetbrains-2025",
        "content": "JetBrains is integrating GPT-5 across its coding tools, helping millions of developers design, reason, and build software faster.",
        "contentSnippet": "JetBrains is integrating GPT-5 across its coding tools, helping millions of developers design, reason, and build software faster.",
        "pubDate": "Tue, 25 Nov 2025 00:00:00 GMT",
        "isoDate": "2025-11-25T00:00:00.000Z",
        "source": "https://openai.com/index/jetbrains-2025"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-j5skj2",
        "title": "Introducing shopping research in ChatGPT",
        "link": "https://openai.com/index/chatgpt-shopping-research",
        "url": "https://openai.com/index/chatgpt-shopping-research",
        "content": "Shopping research in ChatGPT helps you explore, compare, and discover products with personalized buyer’s guides that simplify decision-making",
        "contentSnippet": "Shopping research in ChatGPT helps you explore, compare, and discover products with personalized buyer’s guides that simplify decision-making",
        "pubDate": "Mon, 24 Nov 2025 00:00:00 GMT",
        "isoDate": "2025-11-24T00:00:00.000Z",
        "source": "https://openai.com/index/chatgpt-shopping-research"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-y3qa4j",
        "title": "GPT-5 and the future of mathematical discovery",
        "link": "https://openai.com/index/gpt-5-mathematical-discovery",
        "url": "https://openai.com/index/gpt-5-mathematical-discovery",
        "content": "UCLA Professor Ernest Ryu and GPT-5 solved a key question in optimization theory, showcasing AI’s role in accelerating mathematical discovery.",
        "contentSnippet": "UCLA Professor Ernest Ryu and GPT-5 solved a key question in optimization theory, showcasing AI’s role in accelerating mathematical discovery.",
        "pubDate": "Mon, 24 Nov 2025 00:00:00 GMT",
        "isoDate": "2025-11-24T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-mathematical-discovery"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-kurmq1",
        "title": "OpenAI and Foxconn collaborate to strengthen U.S. manufacturing across the AI supply chain",
        "link": "https://openai.com/index/openai-and-foxconn-collaborate",
        "url": "https://openai.com/index/openai-and-foxconn-collaborate",
        "content": "OpenAI and Foxconn are collaborating to design and manufacture next-generation AI infrastructure hardware in the U.S. The partnership will develop multiple generations of data-center systems, strengthen U.S. supply chains, and build key components domestically to accelerate advanced AI infrastructure.",
        "contentSnippet": "OpenAI and Foxconn are collaborating to design and manufacture next-generation AI infrastructure hardware in the U.S. The partnership will develop multiple generations of data-center systems, strengthen U.S. supply chains, and build key components domestically to accelerate advanced AI infrastructure.",
        "pubDate": "Thu, 20 Nov 2025 14:50:00 GMT",
        "isoDate": "2025-11-20T14:50:00.000Z",
        "source": "https://openai.com/index/openai-and-foxconn-collaborate"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-u4q8ps",
        "title": "Helping 1,000 small businesses build with AI",
        "link": "https://openai.com/index/small-business-ai-jam",
        "url": "https://openai.com/index/small-business-ai-jam",
        "content": "OpenAI is partnering with DoorDash, SCORE, and local organizations to help 1,000 small businesses build with AI. The Small Business AI Jam gives Main Street business owners hands-on tools and training to compete and grow.",
        "contentSnippet": "OpenAI is partnering with DoorDash, SCORE, and local organizations to help 1,000 small businesses build with AI. The Small Business AI Jam gives Main Street business owners hands-on tools and training to compete and grow.",
        "pubDate": "Thu, 20 Nov 2025 06:00:00 GMT",
        "isoDate": "2025-11-20T06:00:00.000Z",
        "source": "https://openai.com/index/small-business-ai-jam"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-v0m30x",
        "title": "Early experiments in accelerating science with GPT-5",
        "link": "https://openai.com/index/accelerating-science-gpt-5",
        "url": "https://openai.com/index/accelerating-science-gpt-5",
        "content": "OpenAI introduces the first research cases showing how GPT-5 accelerates scientific progress across math, physics, biology, and computer science. Explore how AI and researchers collaborate to generate proofs, uncover new insights, and reshape the pace of discovery.",
        "contentSnippet": "OpenAI introduces the first research cases showing how GPT-5 accelerates scientific progress across math, physics, biology, and computer science. Explore how AI and researchers collaborate to generate proofs, uncover new insights, and reshape the pace of discovery.",
        "pubDate": "Thu, 20 Nov 2025 00:00:00 GMT",
        "isoDate": "2025-11-20T00:00:00.000Z",
        "source": "https://openai.com/index/accelerating-science-gpt-5"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-bqlbvd",
        "title": "Strengthening our safety ecosystem with external testing",
        "link": "https://openai.com/index/strengthening-safety-with-external-testing",
        "url": "https://openai.com/index/strengthening-safety-with-external-testing",
        "content": "OpenAI works with independent experts to evaluate frontier AI systems. Third-party testing strengthens safety, validates safeguards, and increases transparency in how we assess model capabilities and risks.",
        "contentSnippet": "OpenAI works with independent experts to evaluate frontier AI systems. Third-party testing strengthens safety, validates safeguards, and increases transparency in how we assess model capabilities and risks.",
        "pubDate": "Wed, 19 Nov 2025 12:00:00 GMT",
        "isoDate": "2025-11-19T12:00:00.000Z",
        "source": "https://openai.com/index/strengthening-safety-with-external-testing"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-f5sok5",
        "title": "How evals drive the next chapter in AI for businesses",
        "link": "https://openai.com/index/evals-drive-next-chapter-of-ai",
        "url": "https://openai.com/index/evals-drive-next-chapter-of-ai",
        "content": "Learn how evals help businesses define, measure, and improve AI performance—reducing risk, boosting productivity, and driving strategic advantage.",
        "contentSnippet": "Learn how evals help businesses define, measure, and improve AI performance—reducing risk, boosting productivity, and driving strategic advantage.",
        "pubDate": "Wed, 19 Nov 2025 11:00:00 GMT",
        "isoDate": "2025-11-19T11:00:00.000Z",
        "source": "https://openai.com/index/evals-drive-next-chapter-of-ai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-8njdmo",
        "title": "OpenAI and Target team up on new AI-powered experiences",
        "link": "https://openai.com/index/target-partnership",
        "url": "https://openai.com/index/target-partnership",
        "content": "OpenAI and Target are partnering to bring a new Target app to ChatGPT, offering personalized shopping and faster checkout. Target will also expand its use of ChatGPT Enterprise to boost productivity and guest experiences.",
        "contentSnippet": "OpenAI and Target are partnering to bring a new Target app to ChatGPT, offering personalized shopping and faster checkout. Target will also expand its use of ChatGPT Enterprise to boost productivity and guest experiences.",
        "pubDate": "Wed, 19 Nov 2025 06:00:00 GMT",
        "isoDate": "2025-11-19T06:00:00.000Z",
        "source": "https://openai.com/index/target-partnership"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-68snp5",
        "title": "A free version of ChatGPT built for teachers",
        "link": "https://openai.com/index/chatgpt-for-teachers",
        "url": "https://openai.com/index/chatgpt-for-teachers",
        "content": "ChatGPT for Teachers is a secure workspace with education‑grade privacy and admin controls. Free for verified U.S. K–12 educators through June 2027.",
        "contentSnippet": "ChatGPT for Teachers is a secure workspace with education‑grade privacy and admin controls. Free for verified U.S. K–12 educators through June 2027.",
        "pubDate": "Wed, 19 Nov 2025 00:00:00 GMT",
        "isoDate": "2025-11-19T00:00:00.000Z",
        "source": "https://openai.com/index/chatgpt-for-teachers"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-m0ni44",
        "title": "Building more with GPT-5.1-Codex-Max",
        "link": "https://openai.com/index/gpt-5-1-codex-max",
        "url": "https://openai.com/index/gpt-5-1-codex-max",
        "content": "Introducing GPT-5.1-Codex-Max, a faster, more intelligent agentic coding model for Codex. The model is designed for long-running, project-scale work with enhanced reasoning and token efficiency.",
        "contentSnippet": "Introducing GPT-5.1-Codex-Max, a faster, more intelligent agentic coding model for Codex. The model is designed for long-running, project-scale work with enhanced reasoning and token efficiency.",
        "pubDate": "Wed, 19 Nov 2025 00:00:00 GMT",
        "isoDate": "2025-11-19T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-1-codex-max"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ajtqmt",
        "title": "GPT-5.1-Codex-Max System Card",
        "link": "https://openai.com/index/gpt-5-1-codex-max-system-card",
        "url": "https://openai.com/index/gpt-5-1-codex-max-system-card",
        "content": "This system card outlines the comprehensive safety measures implemented for GPT‑5.1-CodexMax. It details both model-level mitigations, such as specialized safety training for harmful tasks and prompt injections, and product-level mitigations like agent sandboxing and configurable network access.",
        "contentSnippet": "This system card outlines the comprehensive safety measures implemented for GPT‑5.1-CodexMax. It details both model-level mitigations, such as specialized safety training for harmful tasks and prompt injections, and product-level mitigations like agent sandboxing and configurable network access.",
        "pubDate": "Wed, 19 Nov 2025 00:00:00 GMT",
        "isoDate": "2025-11-19T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-1-codex-max-system-card"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-w0g7qr",
        "title": "How Scania is accelerating work with AI across its global workforce",
        "link": "https://openai.com/index/scania",
        "url": "https://openai.com/index/scania",
        "content": "Description: Global manufacturer Scania is scaling AI with ChatGPT Enterprise. With team-based onboarding and strong guardrails, AI is boosting productivity, quality, and innovation.",
        "contentSnippet": "Description: Global manufacturer Scania is scaling AI with ChatGPT Enterprise. With team-based onboarding and strong guardrails, AI is boosting productivity, quality, and innovation.",
        "pubDate": "Wed, 19 Nov 2025 00:00:00 GMT",
        "isoDate": "2025-11-19T00:00:00.000Z",
        "source": "https://openai.com/index/scania"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ixi1q8",
        "title": "Intuit and OpenAI join forces on new AI-powered experiences",
        "link": "https://openai.com/index/intuit-partnership",
        "url": "https://openai.com/index/intuit-partnership",
        "content": "OpenAI and Intuit have entered a $100M+ multi-year partnership to launch Intuit app experiences in ChatGPT and expand Intuit’s use of OpenAI’s frontier models to power personalized financial tools.",
        "contentSnippet": "OpenAI and Intuit have entered a $100M+ multi-year partnership to launch Intuit app experiences in ChatGPT and expand Intuit’s use of OpenAI’s frontier models to power personalized financial tools.",
        "pubDate": "Tue, 18 Nov 2025 05:00:00 GMT",
        "isoDate": "2025-11-18T05:00:00.000Z",
        "source": "https://openai.com/index/intuit-partnership"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vl2qww",
        "title": "OpenAI named Emerging Leader in Generative AI",
        "link": "https://openai.com/index/gartner-2025-emerging-leader",
        "url": "https://openai.com/index/gartner-2025-emerging-leader",
        "content": "OpenAI has been named an Emerging Leader in Gartner’s 2025 Innovation Guide for Generative AI Model Providers. The recognition reflects our enterprise momentum, with over 1 million companies building with ChatGPT.",
        "contentSnippet": "OpenAI has been named an Emerging Leader in Gartner’s 2025 Innovation Guide for Generative AI Model Providers. The recognition reflects our enterprise momentum, with over 1 million companies building with ChatGPT.",
        "pubDate": "Mon, 17 Nov 2025 10:00:00 GMT",
        "isoDate": "2025-11-17T10:00:00.000Z",
        "source": "https://openai.com/index/gartner-2025-emerging-leader"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-g3bov4",
        "title": "Introducing OpenAI for Ireland",
        "link": "https://openai.com/index/openai-for-ireland",
        "url": "https://openai.com/index/openai-for-ireland",
        "content": "OpenAI launches OpenAI for Ireland, partnering with the Irish Government, Dogpatch Labs and Patch to help SMEs, founders and young builders use AI to innovate, boost productivity and build the next generation of Irish tech startups.",
        "contentSnippet": "OpenAI launches OpenAI for Ireland, partnering with the Irish Government, Dogpatch Labs and Patch to help SMEs, founders and young builders use AI to innovate, boost productivity and build the next generation of Irish tech startups.",
        "pubDate": "Fri, 14 Nov 2025 04:00:00 GMT",
        "isoDate": "2025-11-14T04:00:00.000Z",
        "source": "https://openai.com/index/openai-for-ireland"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ourf2s",
        "title": "Understanding neural networks through sparse circuits",
        "link": "https://openai.com/index/understanding-neural-networks-through-sparse-circuits",
        "url": "https://openai.com/index/understanding-neural-networks-through-sparse-circuits",
        "content": "OpenAI is exploring mechanistic interpretability to understand how neural networks reason. Our new sparse model approach could make AI systems more transparent and support safer, more reliable behavior.",
        "contentSnippet": "OpenAI is exploring mechanistic interpretability to understand how neural networks reason. Our new sparse model approach could make AI systems more transparent and support safer, more reliable behavior.",
        "pubDate": "Thu, 13 Nov 2025 10:00:00 GMT",
        "isoDate": "2025-11-13T10:00:00.000Z",
        "source": "https://openai.com/index/understanding-neural-networks-through-sparse-circuits"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-aj7vn",
        "title": "Introducing group chats in ChatGPT",
        "link": "https://openai.com/index/group-chats-in-chatgpt",
        "url": "https://openai.com/index/group-chats-in-chatgpt",
        "content": "We’re piloting group chats in ChatGPT to make collaboration simple. Bring others—and ChatGPT—into one shared conversation to plan, brainstorm, and create together.",
        "contentSnippet": "We’re piloting group chats in ChatGPT to make collaboration simple. Bring others—and ChatGPT—into one shared conversation to plan, brainstorm, and create together.",
        "pubDate": "Thu, 13 Nov 2025 00:00:00 GMT",
        "isoDate": "2025-11-13T00:00:00.000Z",
        "source": "https://openai.com/index/group-chats-in-chatgpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vj4i49",
        "title": "How Philips is scaling AI literacy across 70,000 employees",
        "link": "https://openai.com/index/philips",
        "url": "https://openai.com/index/philips",
        "content": "Philips is scaling AI literacy with ChatGPT Enterprise, training 70,000 employees to use AI responsibly and improve healthcare outcomes worldwide.",
        "contentSnippet": "Philips is scaling AI literacy with ChatGPT Enterprise, training 70,000 employees to use AI responsibly and improve healthcare outcomes worldwide.",
        "pubDate": "Thu, 13 Nov 2025 00:00:00 GMT",
        "isoDate": "2025-11-13T00:00:00.000Z",
        "source": "https://openai.com/index/philips"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-mtnc3f",
        "title": "Introducing GPT-5.1 for developers",
        "link": "https://openai.com/index/gpt-5-1-for-developers",
        "url": "https://openai.com/index/gpt-5-1-for-developers",
        "content": "GPT-5.1 is now available in the API, bringing faster adaptive reasoning, extended prompt caching, improved coding performance, and new apply_patch and shell tools.",
        "contentSnippet": "GPT-5.1 is now available in the API, bringing faster adaptive reasoning, extended prompt caching, improved coding performance, and new apply_patch and shell tools.",
        "pubDate": "Thu, 13 Nov 2025 00:00:00 GMT",
        "isoDate": "2025-11-13T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-1-for-developers"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-t710u4",
        "title": "Neuro drives national retail wins with ChatGPT Business",
        "link": "https://openai.com/index/neurogum",
        "url": "https://openai.com/index/neurogum",
        "content": "Neuro uses ChatGPT Business to scale nationwide with fewer than seventy employees. From drafting contracts to uncovering insights in customer data, the team saves time, cuts costs, and turns ideas into growth.",
        "contentSnippet": "Neuro uses ChatGPT Business to scale nationwide with fewer than seventy employees. From drafting contracts to uncovering insights in customer data, the team saves time, cuts costs, and turns ideas into growth.",
        "pubDate": "Wed, 12 Nov 2025 11:00:00 GMT",
        "isoDate": "2025-11-12T11:00:00.000Z",
        "source": "https://openai.com/index/neurogum"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jwlrkr",
        "title": "Fighting the New York Times’ invasion of user privacy",
        "link": "https://openai.com/index/fighting-nyt-user-privacy-invasion",
        "url": "https://openai.com/index/fighting-nyt-user-privacy-invasion",
        "content": "OpenAI is fighting the New York Times’ demand for 20 million private ChatGPT conversations and accelerating new security and privacy protections to protect your data.",
        "contentSnippet": "OpenAI is fighting the New York Times’ demand for 20 million private ChatGPT conversations and accelerating new security and privacy protections to protect your data.",
        "pubDate": "Wed, 12 Nov 2025 06:00:00 GMT",
        "isoDate": "2025-11-12T06:00:00.000Z",
        "source": "https://openai.com/index/fighting-nyt-user-privacy-invasion"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-pm2mm9",
        "title": "GPT-5.1: A smarter, more conversational ChatGPT",
        "link": "https://openai.com/index/gpt-5-1",
        "url": "https://openai.com/index/gpt-5-1",
        "content": "We’re upgrading the GPT-5 series with warmer, more capable models and new ways to customize ChatGPT’s tone and style. GPT-5.1 starts rolling out today to paid users.",
        "contentSnippet": "We’re upgrading the GPT-5 series with warmer, more capable models and new ways to customize ChatGPT’s tone and style. GPT-5.1 starts rolling out today to paid users.",
        "pubDate": "Wed, 12 Nov 2025 00:00:00 GMT",
        "isoDate": "2025-11-12T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-1"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-e3phrn",
        "title": "GPT-5.1 Instant and GPT-5.1 Thinking System Card Addendum",
        "link": "https://openai.com/index/gpt-5-system-card-addendum-gpt-5-1",
        "url": "https://openai.com/index/gpt-5-system-card-addendum-gpt-5-1",
        "content": "This GPT-5 system card addendum provides updated safety metrics for GPT-5.1 Instant and Thinking, including new evaluations for mental health and emotional reliance.",
        "contentSnippet": "This GPT-5 system card addendum provides updated safety metrics for GPT-5.1 Instant and Thinking, including new evaluations for mental health and emotional reliance.",
        "pubDate": "Wed, 12 Nov 2025 00:00:00 GMT",
        "isoDate": "2025-11-12T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-system-card-addendum-gpt-5-1"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-alj22e",
        "title": "Free ChatGPT for transitioning U.S. servicemembers and veterans",
        "link": "https://openai.com/index/chatgpt-for-veterans",
        "url": "https://openai.com/index/chatgpt-for-veterans",
        "content": "OpenAI is offering U.S. servicemembers and veterans within 12 months of retirement or separation a free year of ChatGPT Plus to support their transition to civilian life. The tools can help with resumes, interviews, education, and planning for what’s next.",
        "contentSnippet": "OpenAI is offering U.S. servicemembers and veterans within 12 months of retirement or separation a free year of ChatGPT Plus to support their transition to civilian life. The tools can help with resumes, interviews, education, and planning for what’s next.",
        "pubDate": "Mon, 10 Nov 2025 02:00:00 GMT",
        "isoDate": "2025-11-10T02:00:00.000Z",
        "source": "https://openai.com/index/chatgpt-for-veterans"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-d7yaz1",
        "title": "Understanding prompt injections: a frontier security challenge ",
        "link": "https://openai.com/index/prompt-injections",
        "url": "https://openai.com/index/prompt-injections",
        "content": "Prompt injections are a frontier security challenge for AI systems. Learn how these attacks work and how OpenAI is advancing research, training models, and building safeguards for users.",
        "contentSnippet": "Prompt injections are a frontier security challenge for AI systems. Learn how these attacks work and how OpenAI is advancing research, training models, and building safeguards for users.",
        "pubDate": "Fri, 07 Nov 2025 11:30:00 GMT",
        "isoDate": "2025-11-07T11:30:00.000Z",
        "source": "https://openai.com/index/prompt-injections"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-y6qreb",
        "title": "Notion’s rebuild for agentic AI: How GPT‑5 helped unlock autonomous workflows",
        "link": "https://openai.com/index/notion",
        "url": "https://openai.com/index/notion",
        "content": "Discover how Notion rebuilt its AI architecture with GPT-5 to create autonomous agents that reason, act, and adapt across workflows. Learn how this shift unlocked smarter, faster, and more flexible productivity in Notion 3.0.",
        "contentSnippet": "Discover how Notion rebuilt its AI architecture with GPT-5 to create autonomous agents that reason, act, and adapt across workflows. Learn how this shift unlocked smarter, faster, and more flexible productivity in Notion 3.0.",
        "pubDate": "Fri, 07 Nov 2025 10:00:00 GMT",
        "isoDate": "2025-11-07T10:00:00.000Z",
        "source": "https://openai.com/index/notion"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-on7dud",
        "title": "From Pilot to Practice: How BBVA Is Scaling AI Across the Organization",
        "link": "https://openai.com/index/bbva-2025",
        "url": "https://openai.com/index/bbva-2025",
        "content": "BBVA is reimagining how employees work with ChatGPT Enterprise, embedding AI into everyday operations. The bank has saved hours per week per employee, created 20,000+ Custom GPTs, and achieved up to 80% efficiency gains.",
        "contentSnippet": "BBVA is reimagining how employees work with ChatGPT Enterprise, embedding AI into everyday operations. The bank has saved hours per week per employee, created 20,000+ Custom GPTs, and achieved up to 80% efficiency gains.",
        "pubDate": "Thu, 06 Nov 2025 09:30:00 GMT",
        "isoDate": "2025-11-06T09:30:00.000Z",
        "source": "https://openai.com/index/bbva-2025"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-2tigmn",
        "title": "AI progress and recommendations",
        "link": "https://openai.com/index/ai-progress-and-recommendations",
        "url": "https://openai.com/index/ai-progress-and-recommendations",
        "content": "AI is advancing fast. We have the chance to shape its progress—toward discovery, safety, and a better future for everyone.",
        "contentSnippet": "AI is advancing fast. We have the chance to shape its progress—toward discovery, safety, and a better future for everyone.",
        "pubDate": "Thu, 06 Nov 2025 00:00:00 GMT",
        "isoDate": "2025-11-06T00:00:00.000Z",
        "source": "https://openai.com/index/ai-progress-and-recommendations"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wf1ina",
        "title": "Introducing the Teen Safety Blueprint",
        "link": "https://openai.com/index/introducing-the-teen-safety-blueprint",
        "url": "https://openai.com/index/introducing-the-teen-safety-blueprint",
        "content": "Discover OpenAI’s Teen Safety Blueprint—a roadmap for building AI responsibly with safeguards, age-appropriate design, and collaboration to protect and empower young people online.",
        "contentSnippet": "Discover OpenAI’s Teen Safety Blueprint—a roadmap for building AI responsibly with safeguards, age-appropriate design, and collaboration to protect and empower young people online.",
        "pubDate": "Thu, 06 Nov 2025 00:00:00 GMT",
        "isoDate": "2025-11-06T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-the-teen-safety-blueprint"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-si8x22",
        "title": "How CRED is tapping AI to deliver premium customer experiences",
        "link": "https://openai.com/index/cred-swamy-seetharaman",
        "url": "https://openai.com/index/cred-swamy-seetharaman",
        "content": "CRED is transforming premium customer experiences in India with OpenAI. Using GPT-powered tools, the company is improving support accuracy, reducing response times, and boosting customer satisfaction. ",
        "contentSnippet": "CRED is transforming premium customer experiences in India with OpenAI. Using GPT-powered tools, the company is improving support accuracy, reducing response times, and boosting customer satisfaction.",
        "pubDate": "Wed, 05 Nov 2025 21:30:00 GMT",
        "isoDate": "2025-11-05T21:30:00.000Z",
        "source": "https://openai.com/index/cred-swamy-seetharaman"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-bt34p8",
        "title": "How Chime is redefining marketing through AI",
        "link": "https://openai.com/index/chime-vineet-mehra",
        "url": "https://openai.com/index/chime-vineet-mehra",
        "content": "Vineet Mehra, Chief Marketing Officer at Chime, shares how AI is reshaping marketing into an agent-driven discipline. He explains why CMOs who champion AI literacy and thoughtful adoption will lead in the new era of growth.",
        "contentSnippet": "Vineet Mehra, Chief Marketing Officer at Chime, shares how AI is reshaping marketing into an agent-driven discipline. He explains why CMOs who champion AI literacy and thoughtful adoption will lead in the new era of growth.",
        "pubDate": "Wed, 05 Nov 2025 15:00:00 GMT",
        "isoDate": "2025-11-05T15:00:00.000Z",
        "source": "https://openai.com/index/chime-vineet-mehra"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-232xpk",
        "title": "1 million business customers putting AI to work",
        "link": "https://openai.com/index/1-million-businesses-putting-ai-to-work",
        "url": "https://openai.com/index/1-million-businesses-putting-ai-to-work",
        "content": "More than 1 million business customers around the world now use OpenAI. Across healthcare, life sciences, financial services, and more, ChatGPT and our APIs are driving a new era of intelligent, AI-powered work.",
        "contentSnippet": "More than 1 million business customers around the world now use OpenAI. Across healthcare, life sciences, financial services, and more, ChatGPT and our APIs are driving a new era of intelligent, AI-powered work.",
        "pubDate": "Wed, 05 Nov 2025 05:00:00 GMT",
        "isoDate": "2025-11-05T05:00:00.000Z",
        "source": "https://openai.com/index/1-million-businesses-putting-ai-to-work"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-20fcim",
        "title": "Brazil’s AI moment is here",
        "link": "https://openai.com/global-affairs/brazil-ai-moment-is-here",
        "url": "https://openai.com/global-affairs/brazil-ai-moment-is-here",
        "content": "Brazil is now one of the most engaged countries in the world when it comes to AI. From classrooms to farms and small businesses, Brazilians are using OpenAI products to learn, create, and drive innovation.",
        "contentSnippet": "Brazil is now one of the most engaged countries in the world when it comes to AI. From classrooms to farms and small businesses, Brazilians are using OpenAI products to learn, create, and drive innovation.",
        "pubDate": "Tue, 04 Nov 2025 15:30:00 GMT",
        "isoDate": "2025-11-04T15:30:00.000Z",
        "source": "https://openai.com/global-affairs/brazil-ai-moment-is-here"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9v8h52",
        "title": "Introducing IndQA",
        "link": "https://openai.com/index/introducing-indqa",
        "url": "https://openai.com/index/introducing-indqa",
        "content": "OpenAI introduces IndQA, a new benchmark for evaluating AI systems in Indian languages. Built with domain experts, IndQA tests cultural understanding and reasoning across 12 languages and 10 knowledge areas.",
        "contentSnippet": "OpenAI introduces IndQA, a new benchmark for evaluating AI systems in Indian languages. Built with domain experts, IndQA tests cultural understanding and reasoning across 12 languages and 10 knowledge areas.",
        "pubDate": "Mon, 03 Nov 2025 22:30:00 GMT",
        "isoDate": "2025-11-03T22:30:00.000Z",
        "source": "https://openai.com/index/introducing-indqa"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-bwrtlz",
        "title": "AWS and OpenAI announce multi-year strategic partnership",
        "link": "https://openai.com/index/aws-and-openai-partnership",
        "url": "https://openai.com/index/aws-and-openai-partnership",
        "content": "OpenAI and AWS have entered a multi-year, $38 billion partnership to scale advanced AI workloads. AWS will provide world-class infrastructure and compute capacity to power OpenAI’s next generation of models.",
        "contentSnippet": "OpenAI and AWS have entered a multi-year, $38 billion partnership to scale advanced AI workloads. AWS will provide world-class infrastructure and compute capacity to power OpenAI’s next generation of models.",
        "pubDate": "Mon, 03 Nov 2025 06:00:00 GMT",
        "isoDate": "2025-11-03T06:00:00.000Z",
        "source": "https://openai.com/index/aws-and-openai-partnership"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-kud3nv",
        "title": "Expanding Stargate to Michigan",
        "link": "https://openai.com/index/expanding-stargate-to-michigan",
        "url": "https://openai.com/index/expanding-stargate-to-michigan",
        "content": "OpenAI is expanding Stargate to Michigan with a new one-gigawatt campus that strengthens America’s AI infrastructure. The project will create jobs, drive investment, and support economic growth across the Midwest.",
        "contentSnippet": "OpenAI is expanding Stargate to Michigan with a new one-gigawatt campus that strengthens America’s AI infrastructure. The project will create jobs, drive investment, and support economic growth across the Midwest.",
        "pubDate": "Thu, 30 Oct 2025 13:30:00 GMT",
        "isoDate": "2025-10-30T13:30:00.000Z",
        "source": "https://openai.com/index/expanding-stargate-to-michigan"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ihj7gh",
        "title": "Introducing Aardvark: OpenAI’s agentic security researcher",
        "link": "https://openai.com/index/introducing-aardvark",
        "url": "https://openai.com/index/introducing-aardvark",
        "content": "OpenAI introduces Aardvark, an AI-powered security researcher that autonomously finds, validates, and helps fix software vulnerabilities at scale. The system is in private beta—sign up to join early testing.",
        "contentSnippet": "OpenAI introduces Aardvark, an AI-powered security researcher that autonomously finds, validates, and helps fix software vulnerabilities at scale. The system is in private beta—sign up to join early testing.",
        "pubDate": "Thu, 30 Oct 2025 11:00:00 GMT",
        "isoDate": "2025-10-30T11:00:00.000Z",
        "source": "https://openai.com/index/introducing-aardvark"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-b67m8g",
        "title": "How we built OWL, the new architecture behind our ChatGPT-based browser, Atlas",
        "link": "https://openai.com/index/building-chatgpt-atlas",
        "url": "https://openai.com/index/building-chatgpt-atlas",
        "content": "A deep dive into OWL, the new architecture powering ChatGPT Atlas—decoupling Chromium, enabling fast startup, rich UI, and agentic browsing with ChatGPT.",
        "contentSnippet": "A deep dive into OWL, the new architecture powering ChatGPT Atlas—decoupling Chromium, enabling fast startup, rich UI, and agentic browsing with ChatGPT.",
        "pubDate": "Thu, 30 Oct 2025 00:00:00 GMT",
        "isoDate": "2025-10-30T00:00:00.000Z",
        "source": "https://openai.com/index/building-chatgpt-atlas"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-c3gdu7",
        "title": "gpt-oss-safeguard technical report",
        "link": "https://openai.com/index/gpt-oss-safeguard-technical-report",
        "url": "https://openai.com/index/gpt-oss-safeguard-technical-report",
        "content": "gpt-oss-safeguard-120b and gpt-oss-safeguard-20b are two open-weight reasoning models post-trained from the gpt-oss models and trained to reason from a provided policy in order to label content under that policy. In this report, we describe gpt-oss-safeguard’s capabilities and provide our baseline safety evaluations on the gpt-oss-safeguard models, using the underlying gpt-oss models as a baseline. For more information about the development and architecture of the underlying gpt-oss models, see the original gpt-oss model model card⁠.",
        "contentSnippet": "gpt-oss-safeguard-120b and gpt-oss-safeguard-20b are two open-weight reasoning models post-trained from the gpt-oss models and trained to reason from a provided policy in order to label content under that policy. In this report, we describe gpt-oss-safeguard’s capabilities and provide our baseline safety evaluations on the gpt-oss-safeguard models, using the underlying gpt-oss models as a baseline. For more information about the development and architecture of the underlying gpt-oss models, see the original gpt-oss model model card⁠.",
        "pubDate": "Wed, 29 Oct 2025 00:00:00 GMT",
        "isoDate": "2025-10-29T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-oss-safeguard-technical-report"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-1xayz5",
        "title": "Introducing gpt-oss-safeguard",
        "link": "https://openai.com/index/introducing-gpt-oss-safeguard",
        "url": "https://openai.com/index/introducing-gpt-oss-safeguard",
        "content": "OpenAI introduces gpt-oss-safeguard—open-weight reasoning models for safety classification that let developers apply and iterate on custom policies.",
        "contentSnippet": "OpenAI introduces gpt-oss-safeguard—open-weight reasoning models for safety classification that let developers apply and iterate on custom policies.",
        "pubDate": "Wed, 29 Oct 2025 00:00:00 GMT",
        "isoDate": "2025-10-29T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-gpt-oss-safeguard"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-3u6hch",
        "title": "Knowledge preservation powered by ChatGPT",
        "link": "https://openai.com/index/dai-nippon-printing",
        "url": "https://openai.com/index/dai-nippon-printing",
        "content": "Dai Nippon Printing (DNP) rolled out ChatGPT Enterprise across ten core departments to drive companywide adoption. Within three months, it achieved 95% faster patent research, 10x processing volume, 100% weekly active usage, 87% automation, and 70% knowledge reuse.",
        "contentSnippet": "Dai Nippon Printing (DNP) rolled out ChatGPT Enterprise across ten core departments to drive companywide adoption. Within three months, it achieved 95% faster patent research, 10x processing volume, 100% weekly active usage, 87% automation, and 70% knowledge reuse.",
        "pubDate": "Tue, 28 Oct 2025 17:00:00 GMT",
        "isoDate": "2025-10-28T17:00:00.000Z",
        "source": "https://openai.com/index/dai-nippon-printing"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-w3unmy",
        "title": "Doppel’s AI defense system stops attacks before they spread",
        "link": "https://openai.com/index/doppel",
        "url": "https://openai.com/index/doppel",
        "content": "Discover how Doppel uses OpenAI’s GPT-5 and reinforcement fine-tuning (RFT) to stop deepfake and impersonation attacks before they spread, cutting analyst workloads by 80% and reducing threat response from hours to minutes.",
        "contentSnippet": "Discover how Doppel uses OpenAI’s GPT-5 and reinforcement fine-tuning (RFT) to stop deepfake and impersonation attacks before they spread, cutting analyst workloads by 80% and reducing threat response from hours to minutes.",
        "pubDate": "Tue, 28 Oct 2025 10:00:00 GMT",
        "isoDate": "2025-10-28T10:00:00.000Z",
        "source": "https://openai.com/index/doppel"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-1nf5mk",
        "title": "The next chapter of the Microsoft–OpenAI partnership",
        "link": "https://openai.com/index/next-chapter-of-microsoft-openai-partnership",
        "url": "https://openai.com/index/next-chapter-of-microsoft-openai-partnership",
        "content": "Microsoft and OpenAI sign a new agreement that strengthens its long-term partnership, expands innovation, and ensures responsible AI progress.",
        "contentSnippet": "Microsoft and OpenAI sign a new agreement that strengthens its long-term partnership, expands innovation, and ensures responsible AI progress.",
        "pubDate": "Tue, 28 Oct 2025 06:00:00 GMT",
        "isoDate": "2025-10-28T06:00:00.000Z",
        "source": "https://openai.com/index/next-chapter-of-microsoft-openai-partnership"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-3gakdo",
        "title": "Built to benefit everyone",
        "link": "https://openai.com/index/built-to-benefit-everyone",
        "url": "https://openai.com/index/built-to-benefit-everyone",
        "content": "OpenAI’s recapitalization strengthens mission-focused governance, expanding resources to ensure AI benefits everyone while advancing innovation responsibly.",
        "contentSnippet": "OpenAI’s recapitalization strengthens mission-focused governance, expanding resources to ensure AI benefits everyone while advancing innovation responsibly.",
        "pubDate": "Tue, 28 Oct 2025 06:00:00 GMT",
        "isoDate": "2025-10-28T06:00:00.000Z",
        "source": "https://openai.com/index/built-to-benefit-everyone"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7y9jcc",
        "title": "Seizing the AI opportunity",
        "link": "https://openai.com/global-affairs/seizing-the-ai-opportunity",
        "url": "https://openai.com/global-affairs/seizing-the-ai-opportunity",
        "content": "Meeting the demands of the Intelligence Age will require strategic investment in energy and infrastructure. OpenAI’s submission to the White House details how expanding capacity and workforce readiness can sustain U.S. leadership in AI and economic growth.",
        "contentSnippet": "Meeting the demands of the Intelligence Age will require strategic investment in energy and infrastructure. OpenAI’s submission to the White House details how expanding capacity and workforce readiness can sustain U.S. leadership in AI and economic growth.",
        "pubDate": "Mon, 27 Oct 2025 12:00:00 GMT",
        "isoDate": "2025-10-27T12:00:00.000Z",
        "source": "https://openai.com/global-affairs/seizing-the-ai-opportunity"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-nbzufc",
        "title": "Addendum to GPT-5 System Card: Sensitive conversations",
        "link": "https://openai.com/index/gpt-5-system-card-sensitive-conversations",
        "url": "https://openai.com/index/gpt-5-system-card-sensitive-conversations",
        "content": "This system card details GPT-5’s improvements in handling sensitive conversations, including new benchmarks for emotional reliance, mental health, and jailbreak resistance.",
        "contentSnippet": "This system card details GPT-5’s improvements in handling sensitive conversations, including new benchmarks for emotional reliance, mental health, and jailbreak resistance.",
        "pubDate": "Mon, 27 Oct 2025 10:00:00 GMT",
        "isoDate": "2025-10-27T10:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-system-card-sensitive-conversations"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-asjomr",
        "title": "Strengthening ChatGPT’s responses in sensitive conversations",
        "link": "https://openai.com/index/strengthening-chatgpt-responses-in-sensitive-conversations",
        "url": "https://openai.com/index/strengthening-chatgpt-responses-in-sensitive-conversations",
        "content": "OpenAI collaborated with 170+ mental health experts to improve ChatGPT’s ability to recognize distress, respond empathetically, and guide users toward real-world support—reducing unsafe responses by up to 80%. Learn how we’re making ChatGPT safer and more supportive in sensitive moments.",
        "contentSnippet": "OpenAI collaborated with 170+ mental health experts to improve ChatGPT’s ability to recognize distress, respond empathetically, and guide users toward real-world support—reducing unsafe responses by up to 80%. Learn how we’re making ChatGPT safer and more supportive in sensitive moments.",
        "pubDate": "Mon, 27 Oct 2025 10:00:00 GMT",
        "isoDate": "2025-10-27T10:00:00.000Z",
        "source": "https://openai.com/index/strengthening-chatgpt-responses-in-sensitive-conversations"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-5jmi56",
        "title": "A law and tax firm redefines efficiency with ChatGPT Business",
        "link": "https://openai.com/index/steuerrecht",
        "url": "https://openai.com/index/steuerrecht",
        "content": "Learn how Steuerrecht.com uses ChatGPT Business to streamline legal workflows, automate tax research, and scale client service—helping law firms boost productivity and stay competitive.",
        "contentSnippet": "Learn how Steuerrecht.com uses ChatGPT Business to streamline legal workflows, automate tax research, and scale client service—helping law firms boost productivity and stay competitive.",
        "pubDate": "Mon, 27 Oct 2025 00:00:00 GMT",
        "isoDate": "2025-10-27T00:00:00.000Z",
        "source": "https://openai.com/index/steuerrecht"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-sc891x",
        "title": "OpenAI acquires Software Applications Incorporated, maker of Sky",
        "link": "https://openai.com/index/openai-acquires-software-applications-incorporated",
        "url": "https://openai.com/index/openai-acquires-software-applications-incorporated",
        "content": "OpenAI has acquired Software Applications Incorporated, maker of Sky—a natural language interface for Mac that brings AI directly into your desktop experience. Together, we’re integrating Sky’s deep macOS capabilities into ChatGPT to make AI more intuitive, contextual, and action-oriented.",
        "contentSnippet": "OpenAI has acquired Software Applications Incorporated, maker of Sky—a natural language interface for Mac that brings AI directly into your desktop experience. Together, we’re integrating Sky’s deep macOS capabilities into ChatGPT to make AI more intuitive, contextual, and action-oriented.",
        "pubDate": "Thu, 23 Oct 2025 10:00:00 GMT",
        "isoDate": "2025-10-23T10:00:00.000Z",
        "source": "https://openai.com/index/openai-acquires-software-applications-incorporated"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-y09oh",
        "title": "Consensus accelerates research with GPT-5 and Responses API",
        "link": "https://openai.com/index/consensus",
        "url": "https://openai.com/index/consensus",
        "content": "Consensus uses GPT-5 and OpenAI’s Responses API to power a multi-agent research assistant that reads, analyzes, and synthesizes evidence in minutes—helping over 8 million researchers accelerate scientific discovery.",
        "contentSnippet": "Consensus uses GPT-5 and OpenAI’s Responses API to power a multi-agent research assistant that reads, analyzes, and synthesizes evidence in minutes—helping over 8 million researchers accelerate scientific discovery.",
        "pubDate": "Thu, 23 Oct 2025 09:00:00 GMT",
        "isoDate": "2025-10-23T09:00:00.000Z",
        "source": "https://openai.com/index/consensus"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-tumkei",
        "title": "AI in South Korea—OpenAI’s Economic Blueprint",
        "link": "https://openai.com/index/south-korea-economic-blueprint",
        "url": "https://openai.com/index/south-korea-economic-blueprint",
        "content": "OpenAI's Korea Economic Blueprint outlines how South Korea can scale trusted AI through sovereign capabilities and strategic partnerships to drive growth.",
        "contentSnippet": "OpenAI's Korea Economic Blueprint outlines how South Korea can scale trusted AI through sovereign capabilities and strategic partnerships to drive growth.",
        "pubDate": "Thu, 23 Oct 2025 00:00:00 GMT",
        "isoDate": "2025-10-23T00:00:00.000Z",
        "source": "https://openai.com/index/south-korea-economic-blueprint"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-sug405",
        "title": "Work smarter with your company knowledge in ChatGPT",
        "link": "https://openai.com/index/introducing-company-knowledge",
        "url": "https://openai.com/index/introducing-company-knowledge",
        "content": "Company knowledge brings context from your apps into ChatGPT for answers specific to your business, with clear citations, security, privacy, and admin controls. Available now for Business, Enterprise, and Edu users.",
        "contentSnippet": "Company knowledge brings context from your apps into ChatGPT for answers specific to your business, with clear citations, security, privacy, and admin controls. Available now for Business, Enterprise, and Edu users.",
        "pubDate": "Thu, 23 Oct 2025 00:00:00 GMT",
        "isoDate": "2025-10-23T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-company-knowledge"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-i9yjow",
        "title": "The next chapter for UK sovereign AI",
        "link": "https://openai.com/index/the-next-chapter-for-uk-sovereign-ai",
        "url": "https://openai.com/index/the-next-chapter-for-uk-sovereign-ai",
        "content": "OpenAI expands its UK partnership with a new Ministry of Justice agreement, bringing ChatGPT to civil servants. It also introduces UK data residency for ChatGPT Enterprise, ChatGPT Edu, and the API Platform to support trusted and secure AI adoption.",
        "contentSnippet": "OpenAI expands its UK partnership with a new Ministry of Justice agreement, bringing ChatGPT to civil servants. It also introduces UK data residency for ChatGPT Enterprise, ChatGPT Edu, and the API Platform to support trusted and secure AI adoption.",
        "pubDate": "Wed, 22 Oct 2025 16:00:00 GMT",
        "isoDate": "2025-10-22T16:00:00.000Z",
        "source": "https://openai.com/index/the-next-chapter-for-uk-sovereign-ai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-m9p0va",
        "title": "AI in Japan—OpenAI’s Japan Economic Blueprint",
        "link": "https://openai.com/index/japan-economic-blueprint",
        "url": "https://openai.com/index/japan-economic-blueprint",
        "content": "OpenAI’s Japan Economic Blueprint outlines how Japan can harness AI to boost innovation, strengthen competitiveness, and enable sustainable, inclusive growth.",
        "contentSnippet": "OpenAI’s Japan Economic Blueprint outlines how Japan can harness AI to boost innovation, strengthen competitiveness, and enable sustainable, inclusive growth.",
        "pubDate": "Wed, 22 Oct 2025 00:00:00 GMT",
        "isoDate": "2025-10-22T00:00:00.000Z",
        "source": "https://openai.com/index/japan-economic-blueprint"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-e414zm",
        "title": "Continue your ChatGPT experience beyond WhatsApp",
        "link": "https://openai.com/index/chatgpt-whatsapp-transition",
        "url": "https://openai.com/index/chatgpt-whatsapp-transition",
        "content": "ChatGPT will no longer be available on WhatsApp after January 15, 2026. Learn how to link your ChatGPT account and continue your conversations across devices.",
        "contentSnippet": "ChatGPT will no longer be available on WhatsApp after January 15, 2026. Learn how to link your ChatGPT account and continue your conversations across devices.",
        "pubDate": "Tue, 21 Oct 2025 17:00:00 GMT",
        "isoDate": "2025-10-21T17:00:00.000Z",
        "source": "https://openai.com/index/chatgpt-whatsapp-transition"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9s6t3s",
        "title": "Introducing ChatGPT Atlas, the browser with ChatGPT built in",
        "link": "https://openai.com/index/introducing-chatgpt-atlas",
        "url": "https://openai.com/index/introducing-chatgpt-atlas",
        "content": "ChatGPT Atlas, the browser with ChatGPT built it. Get instant answers, summaries, and smart web help—right from any page. With privacy settings you can control. Available now for MacOS.",
        "contentSnippet": "ChatGPT Atlas, the browser with ChatGPT built it. Get instant answers, summaries, and smart web help—right from any page. With privacy settings you can control. Available now for MacOS.",
        "pubDate": "Tue, 21 Oct 2025 00:00:00 GMT",
        "isoDate": "2025-10-21T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-chatgpt-atlas"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-69axpu",
        "title": "Plex Coffee delivers fast service and personal connections with ChatGPT Business",
        "link": "https://openai.com/index/plex-coffee",
        "url": "https://openai.com/index/plex-coffee",
        "content": "Learn how Plex Coffee uses ChatGPT Business to centralize knowledge, train staff faster, and preserve personal connections while expanding.",
        "contentSnippet": "Learn how Plex Coffee uses ChatGPT Business to centralize knowledge, train staff faster, and preserve personal connections while expanding.",
        "pubDate": "Wed, 15 Oct 2025 00:00:00 GMT",
        "isoDate": "2025-10-15T00:00:00.000Z",
        "source": "https://openai.com/index/plex-coffee"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-yy0q1g",
        "title": "Expert Council on Well-Being and AI",
        "link": "https://openai.com/index/expert-council-on-well-being-and-ai",
        "url": "https://openai.com/index/expert-council-on-well-being-and-ai",
        "content": "OpenAI’s new Expert Council on Well-Being and AI brings together leading psychologists, clinicians, and researchers to guide how ChatGPT supports emotional health, especially for teens. Learn how their insights are shaping safer, more caring AI experiences.",
        "contentSnippet": "OpenAI’s new Expert Council on Well-Being and AI brings together leading psychologists, clinicians, and researchers to guide how ChatGPT supports emotional health, especially for teens. Learn how their insights are shaping safer, more caring AI experiences.",
        "pubDate": "Tue, 14 Oct 2025 10:00:00 GMT",
        "isoDate": "2025-10-14T10:00:00.000Z",
        "source": "https://openai.com/index/expert-council-on-well-being-and-ai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-483339",
        "title": "Argentina’s AI opportunity",
        "link": "https://openai.com/global-affairs/argentinas-ai-opportunity",
        "url": "https://openai.com/global-affairs/argentinas-ai-opportunity",
        "content": "OpenAI and Sur Energy are exploring Argentina’s first Stargate project—an AI and clean energy collaboration that could make Argentina a Latin American leader in artificial intelligence, sustainable infrastructure, and digital innovation.",
        "contentSnippet": "OpenAI and Sur Energy are exploring Argentina’s first Stargate project—an AI and clean energy collaboration that could make Argentina a Latin American leader in artificial intelligence, sustainable infrastructure, and digital innovation.",
        "pubDate": "Tue, 14 Oct 2025 06:00:00 GMT",
        "isoDate": "2025-10-14T06:00:00.000Z",
        "source": "https://openai.com/global-affairs/argentinas-ai-opportunity"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-u5ulg7",
        "title": "OpenAI and Broadcom announce strategic collaboration to deploy 10 gigawatts of OpenAI-designed AI accelerators",
        "link": "https://openai.com/index/openai-and-broadcom-announce-strategic-collaboration",
        "url": "https://openai.com/index/openai-and-broadcom-announce-strategic-collaboration",
        "content": "OpenAI and Broadcom announce a multi-year partnership to deploy 10 gigawatts of OpenAI-designed AI accelerators, co-developing next-generation systems and Ethernet solutions to power scalable, energy-efficient AI infrastructure by 2029.",
        "contentSnippet": "OpenAI and Broadcom announce a multi-year partnership to deploy 10 gigawatts of OpenAI-designed AI accelerators, co-developing next-generation systems and Ethernet solutions to power scalable, energy-efficient AI infrastructure by 2029.",
        "pubDate": "Mon, 13 Oct 2025 06:00:00 GMT",
        "isoDate": "2025-10-13T06:00:00.000Z",
        "source": "https://openai.com/index/openai-and-broadcom-announce-strategic-collaboration"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-oksnva",
        "title": "HYGH powers next-gen digital ads with ChatGPT Business",
        "link": "https://openai.com/index/hygh",
        "url": "https://openai.com/index/hygh",
        "content": "HYGH speeds up software development and campaign delivery with ChatGPT Business, cutting turnaround times, scaling output, and driving revenue growth.",
        "contentSnippet": "HYGH speeds up software development and campaign delivery with ChatGPT Business, cutting turnaround times, scaling output, and driving revenue growth.",
        "pubDate": "Fri, 10 Oct 2025 00:00:00 GMT",
        "isoDate": "2025-10-10T00:00:00.000Z",
        "source": "https://openai.com/index/hygh"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7rkwjy",
        "title": "Defining and evaluating political bias in LLMs",
        "link": "https://openai.com/index/defining-and-evaluating-political-bias-in-llms",
        "url": "https://openai.com/index/defining-and-evaluating-political-bias-in-llms",
        "content": "Learn how OpenAI evaluates political bias in ChatGPT through new real-world testing methods that improve objectivity and reduce bias.",
        "contentSnippet": "Learn how OpenAI evaluates political bias in ChatGPT through new real-world testing methods that improve objectivity and reduce bias.",
        "pubDate": "Thu, 09 Oct 2025 13:00:00 GMT",
        "isoDate": "2025-10-09T13:00:00.000Z",
        "source": "https://openai.com/index/defining-and-evaluating-political-bias-in-llms"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jf9qjg",
        "title": "Growing impact and scale with ChatGPT",
        "link": "https://openai.com/index/hibob",
        "url": "https://openai.com/index/hibob",
        "content": "Discover how HiBob uses ChatGPT Enterprise and custom GPTs to scale AI adoption, boost revenue, streamline HR workflows, and deliver AI-powered features in the Bob platform.",
        "contentSnippet": "Discover how HiBob uses ChatGPT Enterprise and custom GPTs to scale AI adoption, boost revenue, streamline HR workflows, and deliver AI-powered features in the Bob platform.",
        "pubDate": "Wed, 08 Oct 2025 08:00:00 GMT",
        "isoDate": "2025-10-08T08:00:00.000Z",
        "source": "https://openai.com/index/hibob"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-qqflqz",
        "title": "Disrupting malicious uses of AI: October 2025",
        "link": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai-october-2025",
        "url": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai-october-2025",
        "content": "Discover how OpenAI is detecting and disrupting malicious uses of AI in our October 2025 report. Learn how we’re countering misuse, enforcing policies, and protecting users from real-world harms.",
        "contentSnippet": "Discover how OpenAI is detecting and disrupting malicious uses of AI in our October 2025 report. Learn how we’re countering misuse, enforcing policies, and protecting users from real-world harms.",
        "pubDate": "Tue, 07 Oct 2025 03:00:00 GMT",
        "isoDate": "2025-10-07T03:00:00.000Z",
        "source": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai-october-2025"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-do6dpc",
        "title": "Codex is now generally available",
        "link": "https://openai.com/index/codex-now-generally-available",
        "url": "https://openai.com/index/codex-now-generally-available",
        "content": "OpenAI Codex is now generally available with powerful new features for developers: a Slack integration, Codex SDK, and admin tools like usage dashboards and workspace management—making Codex easier to use and manage at scale.",
        "contentSnippet": "OpenAI Codex is now generally available with powerful new features for developers: a Slack integration, Codex SDK, and admin tools like usage dashboards and workspace management—making Codex easier to use and manage at scale.",
        "pubDate": "Mon, 06 Oct 2025 10:50:00 GMT",
        "isoDate": "2025-10-06T10:50:00.000Z",
        "source": "https://openai.com/index/codex-now-generally-available"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-rg74xp",
        "title": "Introducing apps in ChatGPT and the new Apps SDK",
        "link": "https://openai.com/index/introducing-apps-in-chatgpt",
        "url": "https://openai.com/index/introducing-apps-in-chatgpt",
        "content": "We’re introducing a new generation of apps you can chat with, right inside ChatGPT. Developers can start building them today with the new Apps SDK, available in preview.",
        "contentSnippet": "We’re introducing a new generation of apps you can chat with, right inside ChatGPT. Developers can start building them today with the new Apps SDK, available in preview.",
        "pubDate": "Mon, 06 Oct 2025 10:00:00 GMT",
        "isoDate": "2025-10-06T10:00:00.000Z",
        "source": "https://openai.com/index/introducing-apps-in-chatgpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-z2rlk1",
        "title": "AMD and OpenAI announce strategic partnership to deploy 6 gigawatts of AMD GPUs",
        "link": "https://openai.com/index/openai-amd-strategic-partnership",
        "url": "https://openai.com/index/openai-amd-strategic-partnership",
        "content": "AMD and OpenAI have announced a multi-year partnership to deploy 6 gigawatts of AMD Instinct GPUs, beginning with 1 gigawatt in 2026, to power OpenAI’s next-generation AI infrastructure and accelerate global AI innovation.",
        "contentSnippet": "AMD and OpenAI have announced a multi-year partnership to deploy 6 gigawatts of AMD Instinct GPUs, beginning with 1 gigawatt in 2026, to power OpenAI’s next-generation AI infrastructure and accelerate global AI innovation.",
        "pubDate": "Mon, 06 Oct 2025 06:00:00 GMT",
        "isoDate": "2025-10-06T06:00:00.000Z",
        "source": "https://openai.com/index/openai-amd-strategic-partnership"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7gds1y",
        "title": "Introducing AgentKit, new Evals, and RFT for agents",
        "link": "https://openai.com/index/introducing-agentkit",
        "url": "https://openai.com/index/introducing-agentkit",
        "content": "Today, we’re releasing  new tools to help developers go from prototype to production faster: AgentKit, expanded evals capabilities, and reinforcement fine-tuning for agents.",
        "contentSnippet": "Today, we’re releasing  new tools to help developers go from prototype to production faster: AgentKit, expanded evals capabilities, and reinforcement fine-tuning for agents.",
        "pubDate": "Mon, 06 Oct 2025 00:00:00 GMT",
        "isoDate": "2025-10-06T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-agentkit"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-qrjzt1",
        "title": "Accelerating AI adoption in Europe",
        "link": "https://openai.com/global-affairs/accelerating-ai-uptake-in-europe",
        "url": "https://openai.com/global-affairs/accelerating-ai-uptake-in-europe",
        "content": "OpenAI and Allied for Startups release the Hacktivate AI report with 20 actionable policy ideas to accelerate AI adoption in Europe, boost competitiveness, and empower innovators.",
        "contentSnippet": "OpenAI and Allied for Startups release the Hacktivate AI report with 20 actionable policy ideas to accelerate AI adoption in Europe, boost competitiveness, and empower innovators.",
        "pubDate": "Mon, 06 Oct 2025 00:00:00 GMT",
        "isoDate": "2025-10-06T00:00:00.000Z",
        "source": "https://openai.com/global-affairs/accelerating-ai-uptake-in-europe"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-okj7xv",
        "title": "With GPT-5, Wrtn builds lifestyle AI for millions in Korea",
        "link": "https://openai.com/index/wrtn",
        "url": "https://openai.com/index/wrtn",
        "content": "Wrtn scaled AI apps to 6.5M users in Korea with GPT-5, creating ‘Lifestyle AI’ that blends productivity, creativity, and learning—now expanding across East Asia.",
        "contentSnippet": "Wrtn scaled AI apps to 6.5M users in Korea with GPT-5, creating ‘Lifestyle AI’ that blends productivity, creativity, and learning—now expanding across East Asia.",
        "pubDate": "Thu, 02 Oct 2025 10:00:00 GMT",
        "isoDate": "2025-10-02T10:00:00.000Z",
        "source": "https://openai.com/index/wrtn"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-r7flen",
        "title": "OpenAI announces strategic collaboration with Japan’s Digital Agency",
        "link": "https://openai.com/global-affairs/strategic-collaboration-with-japan-digital-agency",
        "url": "https://openai.com/global-affairs/strategic-collaboration-with-japan-digital-agency",
        "content": "OpenAI and Japan’s Digital Agency partner to advance generative AI in public services, support international AI governance, and promote safe, trustworthy AI adoption worldwide.",
        "contentSnippet": "OpenAI and Japan’s Digital Agency partner to advance generative AI in public services, support international AI governance, and promote safe, trustworthy AI adoption worldwide.",
        "pubDate": "Thu, 02 Oct 2025 00:00:00 GMT",
        "isoDate": "2025-10-02T00:00:00.000Z",
        "source": "https://openai.com/global-affairs/strategic-collaboration-with-japan-digital-agency"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-hkl6es",
        "title": "Samsung and SK join OpenAI’s Stargate initiative to advance global AI infrastructure",
        "link": "https://openai.com/index/samsung-and-sk-join-stargate",
        "url": "https://openai.com/index/samsung-and-sk-join-stargate",
        "content": "Samsung and SK join OpenAI’s Stargate initiative to expand global AI infrastructure, scaling advanced memory chip production and building next-gen data centers in Korea.",
        "contentSnippet": "Samsung and SK join OpenAI’s Stargate initiative to expand global AI infrastructure, scaling advanced memory chip production and building next-gen data centers in Korea.",
        "pubDate": "Wed, 01 Oct 2025 03:00:00 GMT",
        "isoDate": "2025-10-01T03:00:00.000Z",
        "source": "https://openai.com/index/samsung-and-sk-join-stargate"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-qn7h1a",
        "title": "Launching Sora responsibly",
        "link": "https://openai.com/index/launching-sora-responsibly",
        "url": "https://openai.com/index/launching-sora-responsibly",
        "content": "To address the novel safety challenges posed by a state-of-the-art video model as well as a new social creation platform, we’ve built Sora 2 and the Sora app with safety at the foundation. Our approach is anchored in concrete protections.",
        "contentSnippet": "To address the novel safety challenges posed by a state-of-the-art video model as well as a new social creation platform, we’ve built Sora 2 and the Sora app with safety at the foundation. Our approach is anchored in concrete protections.",
        "pubDate": "Tue, 30 Sep 2025 00:00:00 GMT",
        "isoDate": "2025-09-30T00:00:00.000Z",
        "source": "https://openai.com/index/launching-sora-responsibly"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-5n7w53",
        "title": "Sora 2 System Card",
        "link": "https://openai.com/index/sora-2-system-card",
        "url": "https://openai.com/index/sora-2-system-card",
        "content": "Sora 2 is our new state of the art video and audio generation model. Building on the foundation of Sora, this new model introduces capabilities that have been difficult for prior video models to achieve– such as more accurate physics, sharper realism, synchronized audio, enhanced steerability, and an expanded stylistic range.",
        "contentSnippet": "Sora 2 is our new state of the art video and audio generation model. Building on the foundation of Sora, this new model introduces capabilities that have been difficult for prior video models to achieve– such as more accurate physics, sharper realism, synchronized audio, enhanced steerability, and an expanded stylistic range.",
        "pubDate": "Tue, 30 Sep 2025 00:00:00 GMT",
        "isoDate": "2025-09-30T00:00:00.000Z",
        "source": "https://openai.com/index/sora-2-system-card"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vtk4yg",
        "title": "Sora 2 is here ",
        "link": "https://openai.com/index/sora-2",
        "url": "https://openai.com/index/sora-2",
        "content": "Our latest video generation model is more physically accurate, realistic, and controllable than prior systems. It also features synchronized dialogue and sound effects. Create with it in the new Sora app.",
        "contentSnippet": "Our latest video generation model is more physically accurate, realistic, and controllable than prior systems. It also features synchronized dialogue and sound effects. Create with it in the new Sora app.",
        "pubDate": "Tue, 30 Sep 2025 00:00:00 GMT",
        "isoDate": "2025-09-30T00:00:00.000Z",
        "source": "https://openai.com/index/sora-2"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-esqloh",
        "title": "Building OpenAI with OpenAI",
        "link": "https://openai.com/index/building-openai-with-openai",
        "url": "https://openai.com/index/building-openai-with-openai",
        "content": "At OpenAI, we rely on our own technology to help streamline work, scale expertise, and drive outcomes. In our new series, OpenAI on OpenAI, we share lessons to help other organizations do the same.",
        "contentSnippet": "At OpenAI, we rely on our own technology to help streamline work, scale expertise, and drive outcomes. In our new series, OpenAI on OpenAI, we share lessons to help other organizations do the same.",
        "pubDate": "Mon, 29 Sep 2025 13:30:00 GMT",
        "isoDate": "2025-09-29T13:30:00.000Z",
        "source": "https://openai.com/index/building-openai-with-openai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-zd8nzs",
        "title": "Improving support with every interaction at OpenAI",
        "link": "https://openai.com/index/openai-support-model",
        "url": "https://openai.com/index/openai-support-model",
        "content": "Learn how OpenAI uses AI to enhance support, cutting response times, improving quality, and scaling to meet hypergrowth.",
        "contentSnippet": "Learn how OpenAI uses AI to enhance support, cutting response times, improving quality, and scaling to meet hypergrowth.",
        "pubDate": "Mon, 29 Sep 2025 13:30:00 GMT",
        "isoDate": "2025-09-29T13:30:00.000Z",
        "source": "https://openai.com/index/openai-support-model"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-s5cfov",
        "title": "Empowering teams to unlock insights faster at OpenAI",
        "link": "https://openai.com/index/openai-research-assistant",
        "url": "https://openai.com/index/openai-research-assistant",
        "content": "OpenAI’s research assistant helps teams analyze millions of support tickets, surface insights faster, and scale curiosity across the company.",
        "contentSnippet": "OpenAI’s research assistant helps teams analyze millions of support tickets, surface insights faster, and scale curiosity across the company.",
        "pubDate": "Mon, 29 Sep 2025 13:30:00 GMT",
        "isoDate": "2025-09-29T13:30:00.000Z",
        "source": "https://openai.com/index/openai-research-assistant"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-s81y5i",
        "title": "Turning contracts into searchable data at OpenAI",
        "link": "https://openai.com/index/openai-contract-data-agent",
        "url": "https://openai.com/index/openai-contract-data-agent",
        "content": "OpenAI built a system to extract contract data quickly, cutting turnaround times and making it easier for teams to access the details they need.",
        "contentSnippet": "OpenAI built a system to extract contract data quickly, cutting turnaround times and making it easier for teams to access the details they need.",
        "pubDate": "Mon, 29 Sep 2025 13:30:00 GMT",
        "isoDate": "2025-09-29T13:30:00.000Z",
        "source": "https://openai.com/index/openai-contract-data-agent"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-pl7x5y",
        "title": "Converting inbound leads into customers at OpenAI",
        "link": "https://openai.com/index/openai-inbound-sales-assistant",
        "url": "https://openai.com/index/openai-inbound-sales-assistant",
        "content": "Learn how OpenAI used AI to deliver personalized answers at scale, converting inbound leads into customers.",
        "contentSnippet": "Learn how OpenAI used AI to deliver personalized answers at scale, converting inbound leads into customers.",
        "pubDate": "Mon, 29 Sep 2025 13:30:00 GMT",
        "isoDate": "2025-09-29T13:30:00.000Z",
        "source": "https://openai.com/index/openai-inbound-sales-assistant"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7f9yku",
        "title": "Driving sales productivity and customer success at OpenAI",
        "link": "https://openai.com/index/openai-gtm-assistant",
        "url": "https://openai.com/index/openai-gtm-assistant",
        "content": "Learn how OpenAI boosts sales productivity by automating prep, centralizing knowledge, and scaling top-selling practices.",
        "contentSnippet": "Learn how OpenAI boosts sales productivity by automating prep, centralizing knowledge, and scaling top-selling practices.",
        "pubDate": "Mon, 29 Sep 2025 13:30:00 GMT",
        "isoDate": "2025-09-29T13:30:00.000Z",
        "source": "https://openai.com/index/openai-gtm-assistant"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-gu1xl1",
        "title": "Introducing parental controls",
        "link": "https://openai.com/index/introducing-parental-controls",
        "url": "https://openai.com/index/introducing-parental-controls",
        "content": "We’re rolling out parental controls and a new parent resource page to help families guide how ChatGPT works in their homes. ",
        "contentSnippet": "We’re rolling out parental controls and a new parent resource page to help families guide how ChatGPT works in their homes.",
        "pubDate": "Mon, 29 Sep 2025 03:00:00 GMT",
        "isoDate": "2025-09-29T03:00:00.000Z",
        "source": "https://openai.com/index/introducing-parental-controls"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-oatt1a",
        "title": "Combating online child sexual exploitation & abuse",
        "link": "https://openai.com/index/combating-online-child-sexual-exploitation-abuse",
        "url": "https://openai.com/index/combating-online-child-sexual-exploitation-abuse",
        "content": "Discover how OpenAI combats online child sexual exploitation and abuse with strict usage policies, advanced detection tools, and industry collaboration to block, report, and prevent AI misuse.",
        "contentSnippet": "Discover how OpenAI combats online child sexual exploitation and abuse with strict usage policies, advanced detection tools, and industry collaboration to block, report, and prevent AI misuse.",
        "pubDate": "Mon, 29 Sep 2025 03:00:00 GMT",
        "isoDate": "2025-09-29T03:00:00.000Z",
        "source": "https://openai.com/index/combating-online-child-sexual-exploitation-abuse"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-dytcky",
        "title": "Buy it in ChatGPT: Instant Checkout and the Agentic Commerce Protocol",
        "link": "https://openai.com/index/buy-it-in-chatgpt",
        "url": "https://openai.com/index/buy-it-in-chatgpt",
        "content": "We’re taking first steps toward agentic commerce in ChatGPT with new ways for people, AI agents, and businesses to shop together.",
        "contentSnippet": "We’re taking first steps toward agentic commerce in ChatGPT with new ways for people, AI agents, and businesses to shop together.",
        "pubDate": "Mon, 29 Sep 2025 00:00:00 GMT",
        "isoDate": "2025-09-29T00:00:00.000Z",
        "source": "https://openai.com/index/buy-it-in-chatgpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-5jxbsf",
        "title": "Partnering with AARP to help keep older adults safe online",
        "link": "https://openai.com/index/aarp-partnership-older-adults-online-safety",
        "url": "https://openai.com/index/aarp-partnership-older-adults-online-safety",
        "content": "OpenAI and AARP are partnering to help older adults stay safe online with new AI training, scam-spotting tools, and nationwide programs through OpenAI Academy and OATS’s Senior Planet initiative.",
        "contentSnippet": "OpenAI and AARP are partnering to help older adults stay safe online with new AI training, scam-spotting tools, and nationwide programs through OpenAI Academy and OATS’s Senior Planet initiative.",
        "pubDate": "Fri, 26 Sep 2025 06:00:00 GMT",
        "isoDate": "2025-09-26T06:00:00.000Z",
        "source": "https://openai.com/index/aarp-partnership-older-adults-online-safety"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ckwm3n",
        "title": "More ways to work with your team and tools in ChatGPT",
        "link": "https://openai.com/index/more-ways-to-work-with-your-team",
        "url": "https://openai.com/index/more-ways-to-work-with-your-team",
        "content": "ChatGPT business plans now support shared projects, smarter connectors, and enhanced compliance features to help teams work faster and more securely.",
        "contentSnippet": "ChatGPT business plans now support shared projects, smarter connectors, and enhanced compliance features to help teams work faster and more securely.",
        "pubDate": "Thu, 25 Sep 2025 11:00:00 GMT",
        "isoDate": "2025-09-25T11:00:00.000Z",
        "source": "https://openai.com/index/more-ways-to-work-with-your-team"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xcxwna",
        "title": "Measuring the performance of our models on real-world tasks",
        "link": "https://openai.com/index/gdpval",
        "url": "https://openai.com/index/gdpval",
        "content": "OpenAI introduces GDPval, a new evaluation that measures model performance on real-world economically valuable tasks across 44 occupations.",
        "contentSnippet": "OpenAI introduces GDPval, a new evaluation that measures model performance on real-world economically valuable tasks across 44 occupations.",
        "pubDate": "Thu, 25 Sep 2025 09:00:00 GMT",
        "isoDate": "2025-09-25T09:00:00.000Z",
        "source": "https://openai.com/index/gdpval"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9jx8sq",
        "title": "Introducing ChatGPT Pulse",
        "link": "https://openai.com/index/introducing-chatgpt-pulse",
        "url": "https://openai.com/index/introducing-chatgpt-pulse",
        "content": "Today we're releasing a preview of ChatGPT Pulse to Pro users on mobile. Pulse is a new experience where ChatGPT proactively does research to deliver personalized updates based on your chats, feedback, and connected apps like your calendar. ",
        "contentSnippet": "Today we're releasing a preview of ChatGPT Pulse to Pro users on mobile. Pulse is a new experience where ChatGPT proactively does research to deliver personalized updates based on your chats, feedback, and connected apps like your calendar.",
        "pubDate": "Thu, 25 Sep 2025 00:00:00 GMT",
        "isoDate": "2025-09-25T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-chatgpt-pulse"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ixja55",
        "title": "Transforming the manufacturing industry with ChatGPT",
        "link": "https://openai.com/index/eneos-materials",
        "url": "https://openai.com/index/eneos-materials",
        "content": "By deploying ChatGPT Enterprise, ENEOS Materials transformed operations with faster research, safer plant design, and streamlined HR processes. Over 80% of employees report major workflow improvements, strengthening competitiveness in manufacturing.",
        "contentSnippet": "By deploying ChatGPT Enterprise, ENEOS Materials transformed operations with faster research, safer plant design, and streamlined HR processes. Over 80% of employees report major workflow improvements, strengthening competitiveness in manufacturing.",
        "pubDate": "Wed, 24 Sep 2025 17:00:00 GMT",
        "isoDate": "2025-09-24T17:00:00.000Z",
        "source": "https://openai.com/index/eneos-materials"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ki5my0",
        "title": "SAP and OpenAI partner to launch sovereign ‘OpenAI for Germany’",
        "link": "https://openai.com/global-affairs/openai-for-germany",
        "url": "https://openai.com/global-affairs/openai-for-germany",
        "content": "SAP and OpenAI launch OpenAI for Germany, a 2026 partnership to bring secure, sovereign AI to Germany’s public sector, enabling safe, efficient public services.",
        "contentSnippet": "SAP and OpenAI launch OpenAI for Germany, a 2026 partnership to bring secure, sovereign AI to Germany’s public sector, enabling safe, efficient public services.",
        "pubDate": "Wed, 24 Sep 2025 04:00:00 GMT",
        "isoDate": "2025-09-24T04:00:00.000Z",
        "source": "https://openai.com/global-affairs/openai-for-germany"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-984jmc",
        "title": "OpenAI, Oracle, and SoftBank expand Stargate with five new AI datacenter sites",
        "link": "https://openai.com/index/five-new-stargate-sites",
        "url": "https://openai.com/index/five-new-stargate-sites",
        "content": "OpenAI, Oracle, and SoftBank announce five new Stargate AI datacenter sites, accelerating a $500B, 10-gigawatt U.S. infrastructure buildout to power next-generation AI and create tens of thousands of jobs.",
        "contentSnippet": "OpenAI, Oracle, and SoftBank announce five new Stargate AI datacenter sites, accelerating a $500B, 10-gigawatt U.S. infrastructure buildout to power next-generation AI and create tens of thousands of jobs.",
        "pubDate": "Tue, 23 Sep 2025 14:00:00 GMT",
        "isoDate": "2025-09-23T14:00:00.000Z",
        "source": "https://openai.com/index/five-new-stargate-sites"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-a912vi",
        "title": "CNA is transforming its newsroom with AI ",
        "link": "https://openai.com/index/cna-walter-fernandez",
        "url": "https://openai.com/index/cna-walter-fernandez",
        "content": "In this Executive Function series from OpenAI, discover how CNA is transforming its newsroom with AI. Editor-in-Chief Walter Fernandez shares insights on AI adoption, culture, and the future of journalism.",
        "contentSnippet": "In this Executive Function series from OpenAI, discover how CNA is transforming its newsroom with AI. Editor-in-Chief Walter Fernandez shares insights on AI adoption, culture, and the future of journalism.",
        "pubDate": "Mon, 22 Sep 2025 17:17:00 GMT",
        "isoDate": "2025-09-22T17:17:00.000Z",
        "source": "https://openai.com/index/cna-walter-fernandez"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vr7a84",
        "title": "American-made innovation",
        "link": "https://openai.com/global-affairs/american-made-innovation",
        "url": "https://openai.com/global-affairs/american-made-innovation",
        "content": "American-made innovation",
        "contentSnippet": "American-made innovation",
        "pubDate": "Mon, 22 Sep 2025 11:30:00 GMT",
        "isoDate": "2025-09-22T11:30:00.000Z",
        "source": "https://openai.com/global-affairs/american-made-innovation"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-4b3nxo",
        "title": "Creating a safe, observable AI infrastructure for 1 million classrooms",
        "link": "https://openai.com/index/schoolai",
        "url": "https://openai.com/index/schoolai",
        "content": "Discover how SchoolAI, built on OpenAI’s GPT-4.1, image generation, and TTS, powers safe, teacher-guided AI tools for 1 million classrooms worldwide—boosting engagement, oversight, and personalized learning.",
        "contentSnippet": "Discover how SchoolAI, built on OpenAI’s GPT-4.1, image generation, and TTS, powers safe, teacher-guided AI tools for 1 million classrooms worldwide—boosting engagement, oversight, and personalized learning.",
        "pubDate": "Mon, 22 Sep 2025 10:00:00 GMT",
        "isoDate": "2025-09-22T10:00:00.000Z",
        "source": "https://openai.com/index/schoolai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ylk0c",
        "title": "OpenAI and NVIDIA announce strategic partnership to deploy 10 gigawatts of NVIDIA systems",
        "link": "https://openai.com/index/openai-nvidia-systems-partnership",
        "url": "https://openai.com/index/openai-nvidia-systems-partnership",
        "content": "OpenAI and NVIDIA announce a strategic partnership to deploy 10 gigawatts of AI datacenters powered by NVIDIA systems, with the first phase launching in 2026.",
        "contentSnippet": "OpenAI and NVIDIA announce a strategic partnership to deploy 10 gigawatts of AI datacenters powered by NVIDIA systems, with the first phase launching in 2026.",
        "pubDate": "Mon, 22 Sep 2025 08:45:00 GMT",
        "isoDate": "2025-09-22T08:45:00.000Z",
        "source": "https://openai.com/index/openai-nvidia-systems-partnership"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-cf0yvc",
        "title": "Outbound coordinated vulnerability disclosure policy",
        "link": "https://openai.com/policies/outbound-coordinated-disclosure-policy",
        "url": "https://openai.com/policies/outbound-coordinated-disclosure-policy",
        "content": "Outbound coordinated vulnerability disclosure policy",
        "contentSnippet": "Outbound coordinated vulnerability disclosure policy",
        "pubDate": "Mon, 22 Sep 2025 00:00:00 GMT",
        "isoDate": "2025-09-22T00:00:00.000Z",
        "source": "https://openai.com/policies/outbound-coordinated-disclosure-policy"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jcdvno",
        "title": "Detecting and reducing scheming in AI models",
        "link": "https://openai.com/index/detecting-and-reducing-scheming-in-ai-models",
        "url": "https://openai.com/index/detecting-and-reducing-scheming-in-ai-models",
        "content": "Apollo Research and OpenAI developed evaluations for hidden misalignment (“scheming”) and found behaviors consistent with scheming in controlled tests across frontier models. The team shared concrete examples and stress tests of an early method to reduce scheming. ",
        "contentSnippet": "Apollo Research and OpenAI developed evaluations for hidden misalignment (“scheming”) and found behaviors consistent with scheming in controlled tests across frontier models. The team shared concrete examples and stress tests of an early method to reduce scheming.",
        "pubDate": "Wed, 17 Sep 2025 00:00:00 GMT",
        "isoDate": "2025-09-17T00:00:00.000Z",
        "source": "https://openai.com/index/detecting-and-reducing-scheming-in-ai-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-l113z7",
        "title": "Introducing Stargate UK",
        "link": "https://openai.com/index/introducing-stargate-uk",
        "url": "https://openai.com/index/introducing-stargate-uk",
        "content": "OpenAI, NVIDIA, and Nscale launch Stargate UK, a sovereign AI infrastructure partnership delivering up to 50,000 GPUs and the UK’s largest supercomputer to power national AI innovation, public services, and economic growth.",
        "contentSnippet": "OpenAI, NVIDIA, and Nscale launch Stargate UK, a sovereign AI infrastructure partnership delivering up to 50,000 GPUs and the UK’s largest supercomputer to power national AI innovation, public services, and economic growth.",
        "pubDate": "Tue, 16 Sep 2025 14:30:00 GMT",
        "isoDate": "2025-09-16T14:30:00.000Z",
        "source": "https://openai.com/index/introducing-stargate-uk"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-orm3gx",
        "title": "Building towards age prediction",
        "link": "https://openai.com/index/building-towards-age-prediction",
        "url": "https://openai.com/index/building-towards-age-prediction",
        "content": "Learn how OpenAI is building age prediction and parental controls in ChatGPT to create safer, age-appropriate experiences for teens while supporting families with new tools.",
        "contentSnippet": "Learn how OpenAI is building age prediction and parental controls in ChatGPT to create safer, age-appropriate experiences for teens while supporting families with new tools.",
        "pubDate": "Tue, 16 Sep 2025 06:00:00 GMT",
        "isoDate": "2025-09-16T06:00:00.000Z",
        "source": "https://openai.com/index/building-towards-age-prediction"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-hz4lfp",
        "title": "Teen safety, freedom, and privacy",
        "link": "https://openai.com/index/teen-safety-freedom-and-privacy",
        "url": "https://openai.com/index/teen-safety-freedom-and-privacy",
        "content": "Explore OpenAI’s approach to balancing teen safety, freedom, and privacy in AI use.",
        "contentSnippet": "Explore OpenAI’s approach to balancing teen safety, freedom, and privacy in AI use.",
        "pubDate": "Tue, 16 Sep 2025 06:00:00 GMT",
        "isoDate": "2025-09-16T06:00:00.000Z",
        "source": "https://openai.com/index/teen-safety-freedom-and-privacy"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ylofve",
        "title": "Introducing upgrades to Codex",
        "link": "https://openai.com/index/introducing-upgrades-to-codex",
        "url": "https://openai.com/index/introducing-upgrades-to-codex",
        "content": "Codex just got faster, more reliable, and better at real-time collaboration and tackling tasks independently anywhere you develop—whether via the terminal, IDE, web, or even your phone.",
        "contentSnippet": "Codex just got faster, more reliable, and better at real-time collaboration and tackling tasks independently anywhere you develop—whether via the terminal, IDE, web, or even your phone.",
        "pubDate": "Mon, 15 Sep 2025 10:00:00 GMT",
        "isoDate": "2025-09-15T10:00:00.000Z",
        "source": "https://openai.com/index/introducing-upgrades-to-codex"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-t86inc",
        "title": "How people are using ChatGPT",
        "link": "https://openai.com/index/how-people-are-using-chatgpt",
        "url": "https://openai.com/index/how-people-are-using-chatgpt",
        "content": "New research from the largest study of ChatGPT use shows how the tool creates economic value through both personal and professional use. Adoption is broadening beyond early users, closing gaps and making AI a part of everyday life.",
        "contentSnippet": "New research from the largest study of ChatGPT use shows how the tool creates economic value through both personal and professional use. Adoption is broadening beyond early users, closing gaps and making AI a part of everyday life.",
        "pubDate": "Mon, 15 Sep 2025 03:00:00 GMT",
        "isoDate": "2025-09-15T03:00:00.000Z",
        "source": "https://openai.com/index/how-people-are-using-chatgpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-kbgczr",
        "title": "Addendum to GPT-5 system card: GPT-5-Codex",
        "link": "https://openai.com/index/gpt-5-system-card-addendum-gpt-5-codex",
        "url": "https://openai.com/index/gpt-5-system-card-addendum-gpt-5-codex",
        "content": "This addendum to the GPT-5 system card shares a new model: GPT-5-Codex, a version of GPT-5 further optimized for agentic coding in Codex. GPT-5-Codex adjusts its thinking effort more dynamically based on task complexity, responding quickly to simple conversational queries or small tasks, while independently working for longer on more complex tasks.",
        "contentSnippet": "This addendum to the GPT-5 system card shares a new model: GPT-5-Codex, a version of GPT-5 further optimized for agentic coding in Codex. GPT-5-Codex adjusts its thinking effort more dynamically based on task complexity, responding quickly to simple conversational queries or small tasks, while independently working for longer on more complex tasks.",
        "pubDate": "Mon, 15 Sep 2025 00:00:00 GMT",
        "isoDate": "2025-09-15T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-system-card-addendum-gpt-5-codex"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-nvtaj1",
        "title": "Working with US CAISI and UK AISI to build more secure AI systems",
        "link": "https://openai.com/index/us-caisi-uk-aisi-ai-update",
        "url": "https://openai.com/index/us-caisi-uk-aisi-ai-update",
        "content": "OpenAI shares progress on the partnership with the US CAISI and UK AISI to strengthen AI safety and security.",
        "contentSnippet": "OpenAI shares progress on the partnership with the US CAISI and UK AISI to strengthen AI safety and security.",
        "pubDate": "Fri, 12 Sep 2025 12:00:00 GMT",
        "isoDate": "2025-09-12T12:00:00.000Z",
        "source": "https://openai.com/index/us-caisi-uk-aisi-ai-update"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-c8bvuh",
        "title": "A joint statement from OpenAI and Microsoft",
        "link": "https://openai.com/index/joint-statement-from-openai-and-microsoft",
        "url": "https://openai.com/index/joint-statement-from-openai-and-microsoft",
        "content": "OpenAI and Microsoft sign a new MOU, reinforcing their partnership and shared commitment to AI safety and innovation.",
        "contentSnippet": "OpenAI and Microsoft sign a new MOU, reinforcing their partnership and shared commitment to AI safety and innovation.",
        "pubDate": "Thu, 11 Sep 2025 14:00:00 GMT",
        "isoDate": "2025-09-11T14:00:00.000Z",
        "source": "https://openai.com/index/joint-statement-from-openai-and-microsoft"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-dwwxok",
        "title": "Statement on OpenAI’s Nonprofit and PBC",
        "link": "https://openai.com/index/statement-on-openai-nonprofit-and-pbc",
        "url": "https://openai.com/index/statement-on-openai-nonprofit-and-pbc",
        "content": "OpenAI reaffirms its nonprofit leadership with a new structure granting equity in its PBC, enabling over $100B in resources to advance safe, beneficial AI for humanity.",
        "contentSnippet": "OpenAI reaffirms its nonprofit leadership with a new structure granting equity in its PBC, enabling over $100B in resources to advance safe, beneficial AI for humanity.",
        "pubDate": "Thu, 11 Sep 2025 14:00:00 GMT",
        "isoDate": "2025-09-11T14:00:00.000Z",
        "source": "https://openai.com/index/statement-on-openai-nonprofit-and-pbc"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-c4bp9w",
        "title": "Shipping smarter agents with every new model",
        "link": "https://openai.com/index/safetykit",
        "url": "https://openai.com/index/safetykit",
        "content": "Discover how SafetyKit leverages OpenAI GPT-5 to enhance content moderation, enforce compliance, and outpace legacy safety systems with greater accuracy .",
        "contentSnippet": "Discover how SafetyKit leverages OpenAI GPT-5 to enhance content moderation, enforce compliance, and outpace legacy safety systems with greater accuracy .",
        "pubDate": "Tue, 09 Sep 2025 10:00:00 GMT",
        "isoDate": "2025-09-09T10:00:00.000Z",
        "source": "https://openai.com/index/safetykit"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-5hkrtz",
        "title": "A People-First AI Fund: $50M to support nonprofits",
        "link": "https://openai.com/index/people-first-ai-fund",
        "url": "https://openai.com/index/people-first-ai-fund",
        "content": "Applications are now open for OpenAI’s People-First AI Fund, a $50M initiative supporting U.S. nonprofits advancing education, community innovation, and economic opportunity. Apply by October 8, 2025, for unrestricted grants that help communities shape AI for the public good.",
        "contentSnippet": "Applications are now open for OpenAI’s People-First AI Fund, a $50M initiative supporting U.S. nonprofits advancing education, community innovation, and economic opportunity. Apply by October 8, 2025, for unrestricted grants that help communities shape AI for the public good.",
        "pubDate": "Mon, 08 Sep 2025 14:00:00 GMT",
        "isoDate": "2025-09-08T14:00:00.000Z",
        "source": "https://openai.com/index/people-first-ai-fund"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-5n82ed",
        "title": "Why language models hallucinate",
        "link": "https://openai.com/index/why-language-models-hallucinate",
        "url": "https://openai.com/index/why-language-models-hallucinate",
        "content": "OpenAI’s new research explains why language models hallucinate. The findings show how improved evaluations can enhance AI reliability, honesty, and safety.",
        "contentSnippet": "OpenAI’s new research explains why language models hallucinate. The findings show how improved evaluations can enhance AI reliability, honesty, and safety.",
        "pubDate": "Fri, 05 Sep 2025 10:00:00 GMT",
        "isoDate": "2025-09-05T10:00:00.000Z",
        "source": "https://openai.com/index/why-language-models-hallucinate"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-2106qm",
        "title": "GPT-5 bio bug bounty call",
        "link": "https://openai.com/gpt-5-bio-bug-bounty",
        "url": "https://openai.com/gpt-5-bio-bug-bounty",
        "content": "OpenAI invites researchers to its Bio Bug Bounty. Test GPT-5’s safety with a universal jailbreak prompt and win up to $25,000.",
        "contentSnippet": "OpenAI invites researchers to its Bio Bug Bounty. Test GPT-5’s safety with a universal jailbreak prompt and win up to $25,000.",
        "pubDate": "Fri, 05 Sep 2025 08:45:00 GMT",
        "isoDate": "2025-09-05T08:45:00.000Z",
        "source": "https://openai.com/gpt-5-bio-bug-bounty"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-8b84iw",
        "title": "OpenAI and Greek Government launch ‘OpenAI for Greece’",
        "link": "https://openai.com/global-affairs/openai-for-greece",
        "url": "https://openai.com/global-affairs/openai-for-greece",
        "content": "OpenAI and the Greek Government have launched “OpenAI for Greece” to bring ChatGPT Edu into secondary schools and support responsible AI learning. This partnership aims to boost AI literacy, fuel local start-ups, and drive national economic growth.",
        "contentSnippet": "OpenAI and the Greek Government have launched “OpenAI for Greece” to bring ChatGPT Edu into secondary schools and support responsible AI learning. This partnership aims to boost AI literacy, fuel local start-ups, and drive national economic growth.",
        "pubDate": "Fri, 05 Sep 2025 08:00:00 GMT",
        "isoDate": "2025-09-05T08:00:00.000Z",
        "source": "https://openai.com/global-affairs/openai-for-greece"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-rvvxzu",
        "title": "Expanding economic opportunity with AI",
        "link": "https://openai.com/index/expanding-economic-opportunity-with-ai",
        "url": "https://openai.com/index/expanding-economic-opportunity-with-ai",
        "content": "OpenAI is launching a Jobs Platform and new Certifications to connect workers with jobs, training, and certifications. Learn how we’re expanding economic opportunity and making AI skills more accessible.",
        "contentSnippet": "OpenAI is launching a Jobs Platform and new Certifications to connect workers with jobs, training, and certifications. Learn how we’re expanding economic opportunity and making AI skills more accessible.",
        "pubDate": "Thu, 04 Sep 2025 11:30:00 GMT",
        "isoDate": "2025-09-04T11:30:00.000Z",
        "source": "https://openai.com/index/expanding-economic-opportunity-with-ai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-phwzzr",
        "title": "Vijaye Raji to become CTO of Applications with acquisition of Statsig",
        "link": "https://openai.com/index/vijaye-raji-to-become-cto-of-applications-with-acquisition-of-statsig",
        "url": "https://openai.com/index/vijaye-raji-to-become-cto-of-applications-with-acquisition-of-statsig",
        "content": "Vijaye Raji will step into a new role as CTO of Applications, reporting to CEO of Applications, Fidji Simo, following the acquisition of Statsig.",
        "contentSnippet": "Vijaye Raji will step into a new role as CTO of Applications, reporting to CEO of Applications, Fidji Simo, following the acquisition of Statsig.",
        "pubDate": "Tue, 02 Sep 2025 11:00:00 GMT",
        "isoDate": "2025-09-02T11:00:00.000Z",
        "source": "https://openai.com/index/vijaye-raji-to-become-cto-of-applications-with-acquisition-of-statsig"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-gy7fmd",
        "title": "Building more helpful ChatGPT experiences for everyone",
        "link": "https://openai.com/index/building-more-helpful-chatgpt-experiences-for-everyone",
        "url": "https://openai.com/index/building-more-helpful-chatgpt-experiences-for-everyone",
        "content": "We’re partnering with experts, strengthening protections for teens with parental controls, and routing sensitive conversations to reasoning models in ChatGPT.",
        "contentSnippet": "We’re partnering with experts, strengthening protections for teens with parental controls, and routing sensitive conversations to reasoning models in ChatGPT.",
        "pubDate": "Tue, 02 Sep 2025 04:00:00 GMT",
        "isoDate": "2025-09-02T04:00:00.000Z",
        "source": "https://openai.com/index/building-more-helpful-chatgpt-experiences-for-everyone"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xauv2u",
        "title": "Introducing gpt-realtime and Realtime API updates",
        "link": "https://openai.com/index/introducing-gpt-realtime",
        "url": "https://openai.com/index/introducing-gpt-realtime",
        "content": "We’re releasing a more advanced speech-to-speech model and new API capabilities including MCP server support, image input, and SIP phone calling support.",
        "contentSnippet": "We’re releasing a more advanced speech-to-speech model and new API capabilities including MCP server support, image input, and SIP phone calling support.",
        "pubDate": "Thu, 28 Aug 2025 10:00:00 GMT",
        "isoDate": "2025-08-28T10:00:00.000Z",
        "source": "https://openai.com/index/introducing-gpt-realtime"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-79wee5",
        "title": "Supporting nonprofit and community innovation",
        "link": "https://openai.com/index/supporting-nonprofit-and-community-innovation",
        "url": "https://openai.com/index/supporting-nonprofit-and-community-innovation",
        "content": "OpenAI launches a $50M People-First AI Fund to help U.S. nonprofits scale impact with AI. Applications open Sept 8–Oct 8, 2025 for grants in education, healthcare, research, and more.",
        "contentSnippet": "OpenAI launches a $50M People-First AI Fund to help U.S. nonprofits scale impact with AI. Applications open Sept 8–Oct 8, 2025 for grants in education, healthcare, research, and more.",
        "pubDate": "Thu, 28 Aug 2025 05:00:00 GMT",
        "isoDate": "2025-08-28T05:00:00.000Z",
        "source": "https://openai.com/index/supporting-nonprofit-and-community-innovation"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-2gfcnd",
        "title": "Collective alignment: public input on our Model Spec",
        "link": "https://openai.com/index/collective-alignment-aug-2025-updates",
        "url": "https://openai.com/index/collective-alignment-aug-2025-updates",
        "content": "OpenAI surveyed over 1,000 people worldwide on how AI should behave and compared their views to our Model Spec. Learn how collective alignment is shaping AI defaults to better reflect diverse human values and perspectives.",
        "contentSnippet": "OpenAI surveyed over 1,000 people worldwide on how AI should behave and compared their views to our Model Spec. Learn how collective alignment is shaping AI defaults to better reflect diverse human values and perspectives.",
        "pubDate": "Wed, 27 Aug 2025 13:00:00 GMT",
        "isoDate": "2025-08-27T13:00:00.000Z",
        "source": "https://openai.com/index/collective-alignment-aug-2025-updates"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-n7ue4z",
        "title": "OpenAI and Anthropic share findings from a joint safety evaluation",
        "link": "https://openai.com/index/openai-anthropic-safety-evaluation",
        "url": "https://openai.com/index/openai-anthropic-safety-evaluation",
        "content": "OpenAI and Anthropic share findings from a first-of-its-kind joint safety evaluation, testing each other’s models for misalignment, instruction following, hallucinations, jailbreaking, and more—highlighting progress, challenges, and the value of cross-lab collaboration.",
        "contentSnippet": "OpenAI and Anthropic share findings from a first-of-its-kind joint safety evaluation, testing each other’s models for misalignment, instruction following, hallucinations, jailbreaking, and more—highlighting progress, challenges, and the value of cross-lab collaboration.",
        "pubDate": "Wed, 27 Aug 2025 10:00:00 GMT",
        "isoDate": "2025-08-27T10:00:00.000Z",
        "source": "https://openai.com/index/openai-anthropic-safety-evaluation"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-u1agbe",
        "title": "Helping people when they need it most",
        "link": "https://openai.com/index/helping-people-when-they-need-it-most",
        "url": "https://openai.com/index/helping-people-when-they-need-it-most",
        "content": "How we think about safety for users experiencing mental or emotional distress, the limits of today’s systems, and the work underway to refine them.",
        "contentSnippet": "How we think about safety for users experiencing mental or emotional distress, the limits of today’s systems, and the work underway to refine them.",
        "pubDate": "Tue, 26 Aug 2025 04:00:00 GMT",
        "isoDate": "2025-08-26T04:00:00.000Z",
        "source": "https://openai.com/index/helping-people-when-they-need-it-most"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-br59kg",
        "title": "Announcing the OpenAI Learning Accelerator",
        "link": "https://openai.com/global-affairs/learning-accelerator",
        "url": "https://openai.com/global-affairs/learning-accelerator",
        "content": "OpenAI announces the launch of OpenAI Learning Accelerator, an initiative that aims to bring advanced AI to India’s educators and millions of learners nationwide through accelerated AI research, training, and deployment.",
        "contentSnippet": "OpenAI announces the launch of OpenAI Learning Accelerator, an initiative that aims to bring advanced AI to India’s educators and millions of learners nationwide through accelerated AI research, training, and deployment.",
        "pubDate": "Mon, 25 Aug 2025 06:00:00 GMT",
        "isoDate": "2025-08-25T06:00:00.000Z",
        "source": "https://openai.com/global-affairs/learning-accelerator"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-mlovkb",
        "title": "Accelerating life sciences research",
        "link": "https://openai.com/index/accelerating-life-sciences-research-with-retro-biosciences",
        "url": "https://openai.com/index/accelerating-life-sciences-research-with-retro-biosciences",
        "content": "Discover how a specialized AI model, GPT-4b micro, helped OpenAI and Retro Bio engineer more effective proteins for stem cell therapy and longevity research.",
        "contentSnippet": "Discover how a specialized AI model, GPT-4b micro, helped OpenAI and Retro Bio engineer more effective proteins for stem cell therapy and longevity research.",
        "pubDate": "Fri, 22 Aug 2025 08:30:00 GMT",
        "isoDate": "2025-08-22T08:30:00.000Z",
        "source": "https://openai.com/index/accelerating-life-sciences-research-with-retro-biosciences"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-v46yi7",
        "title": "Scaling domain expertise in complex, regulated domains",
        "link": "https://openai.com/index/blue-j",
        "url": "https://openai.com/index/blue-j",
        "content": "Discover how Blue J is transforming tax research with AI-powered tools built on GPT-4.1. By combining domain expertise with Retrieval-Augmented Generation, Blue J delivers fast, accurate, and fully-cited tax answers—trusted by professionals across the US, Canada, and the UK.",
        "contentSnippet": "Discover how Blue J is transforming tax research with AI-powered tools built on GPT-4.1. By combining domain expertise with Retrieval-Augmented Generation, Blue J delivers fast, accurate, and fully-cited tax answers—trusted by professionals across the US, Canada, and the UK.",
        "pubDate": "Thu, 21 Aug 2025 10:00:00 GMT",
        "isoDate": "2025-08-21T10:00:00.000Z",
        "source": "https://openai.com/index/blue-j"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-okpse3",
        "title": "Mixi reimagines communication with ChatGPT",
        "link": "https://openai.com/index/mixi",
        "url": "https://openai.com/index/mixi",
        "content": "Discover how MIXI, a leader in digital entertainment and lifestyle services in Japan, uses ChatGPT Enterprise to transform productivity, boost AI adoption across teams, and create a secure environment for innovation.",
        "contentSnippet": "Discover how MIXI, a leader in digital entertainment and lifestyle services in Japan, uses ChatGPT Enterprise to transform productivity, boost AI adoption across teams, and create a secure environment for innovation.",
        "pubDate": "Wed, 20 Aug 2025 17:00:00 GMT",
        "isoDate": "2025-08-20T17:00:00.000Z",
        "source": "https://openai.com/index/mixi"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-l90zqu",
        "title": "Q&A with DoorDash’s CPO, Mariana Garavaglia",
        "link": "https://openai.com/index/doordash-mariana-garavaglia",
        "url": "https://openai.com/index/doordash-mariana-garavaglia",
        "content": "Learn how DoorDash is scaling AI adoption to empower employees to build, learn, and innovate faster in a conversation with Chief People Officer Mariana Garavaglia.",
        "contentSnippet": "Learn how DoorDash is scaling AI adoption to empower employees to build, learn, and innovate faster in a conversation with Chief People Officer Mariana Garavaglia.",
        "pubDate": "Mon, 18 Aug 2025 00:00:00 GMT",
        "isoDate": "2025-08-18T00:00:00.000Z",
        "source": "https://openai.com/index/doordash-mariana-garavaglia"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-p769cm",
        "title": "OpenAI’s letter to Governor Newsom on harmonized regulation",
        "link": "https://openai.com/global-affairs/letter-to-governor-newsom-on-harmonized-regulation",
        "url": "https://openai.com/global-affairs/letter-to-governor-newsom-on-harmonized-regulation",
        "content": "We’ve just sent a letter to Gov. Gavin Newsom calling for California to lead the way in harmonizing state-based AI regulation with national—and, by virtue of US leadership, emerging global—standards.",
        "contentSnippet": "We’ve just sent a letter to Gov. Gavin Newsom calling for California to lead the way in harmonizing state-based AI regulation with national—and, by virtue of US leadership, emerging global—standards.",
        "pubDate": "Tue, 12 Aug 2025 00:00:00 GMT",
        "isoDate": "2025-08-12T00:00:00.000Z",
        "source": "https://openai.com/global-affairs/letter-to-governor-newsom-on-harmonized-regulation"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jbu7k6",
        "title": "Scaling accounting capacity with OpenAI",
        "link": "https://openai.com/index/basis",
        "url": "https://openai.com/index/basis",
        "content": "Built with OpenAI o3, o3-Pro, GPT-4.1, and GPT-5, Basis’ AI agents help accounting firms save up to 30% of their time and expand capacity for advisory and growth.",
        "contentSnippet": "Built with OpenAI o3, o3-Pro, GPT-4.1, and GPT-5, Basis’ AI agents help accounting firms save up to 30% of their time and expand capacity for advisory and growth.",
        "pubDate": "Tue, 12 Aug 2025 00:00:00 GMT",
        "isoDate": "2025-08-12T00:00:00.000Z",
        "source": "https://openai.com/index/basis"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-sija1c",
        "title": "Introducing GPT-5 for developers",
        "link": "https://openai.com/index/introducing-gpt-5-for-developers",
        "url": "https://openai.com/index/introducing-gpt-5-for-developers",
        "content": "Introducing GPT-5 in our API platform—offering high reasoning performance, new controls for devs, and best-in-class results on real coding tasks.",
        "contentSnippet": "Introducing GPT-5 in our API platform—offering high reasoning performance, new controls for devs, and best-in-class results on real coding tasks.",
        "pubDate": "Thu, 07 Aug 2025 10:00:00 GMT",
        "isoDate": "2025-08-07T10:00:00.000Z",
        "source": "https://openai.com/index/introducing-gpt-5-for-developers"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jrlban",
        "title": "GPT-5 and the new era of work",
        "link": "https://openai.com/index/gpt-5-new-era-of-work",
        "url": "https://openai.com/index/gpt-5-new-era-of-work",
        "content": "GPT-5 is OpenAI’s most advanced model—transforming enterprise AI, automation, and workforce productivity in the new era of intelligent work.",
        "contentSnippet": "GPT-5 is OpenAI’s most advanced model—transforming enterprise AI, automation, and workforce productivity in the new era of intelligent work.",
        "pubDate": "Thu, 07 Aug 2025 10:00:00 GMT",
        "isoDate": "2025-08-07T10:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-new-era-of-work"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-f9yx0x",
        "title": "Coding and design with GPT-5",
        "link": "https://openai.com/index/gpt-5-coding-design",
        "url": "https://openai.com/index/gpt-5-coding-design",
        "content": "Learn how GPT-5 unlocks new possibilities in coding and design.",
        "contentSnippet": "Learn how GPT-5 unlocks new possibilities in coding and design.",
        "pubDate": "Thu, 07 Aug 2025 00:03:00 GMT",
        "isoDate": "2025-08-07T00:03:00.000Z",
        "source": "https://openai.com/index/gpt-5-coding-design"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-46tgpc",
        "title": "Creative writing with GPT-5",
        "link": "https://openai.com/index/gpt-5-creative-writing",
        "url": "https://openai.com/index/gpt-5-creative-writing",
        "content": "Learn how GPT-5 assists with creative writing.",
        "contentSnippet": "Learn how GPT-5 assists with creative writing.",
        "pubDate": "Thu, 07 Aug 2025 00:02:00 GMT",
        "isoDate": "2025-08-07T00:02:00.000Z",
        "source": "https://openai.com/index/gpt-5-creative-writing"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6p4th3",
        "title": "Medical research with GPT-5",
        "link": "https://openai.com/index/gpt-5-medical-research",
        "url": "https://openai.com/index/gpt-5-medical-research",
        "content": "Learn how GPT-5 is used for medical research.",
        "contentSnippet": "Learn how GPT-5 is used for medical research.",
        "pubDate": "Thu, 07 Aug 2025 00:01:00 GMT",
        "isoDate": "2025-08-07T00:01:00.000Z",
        "source": "https://openai.com/index/gpt-5-medical-research"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-f9b52q",
        "title": "How Amgen uses GPT-5",
        "link": "https://openai.com/index/gpt-5-amgen",
        "url": "https://openai.com/index/gpt-5-amgen",
        "content": "Learn how Amgen uses GPT-5.",
        "contentSnippet": "Learn how Amgen uses GPT-5.",
        "pubDate": "Thu, 07 Aug 2025 00:00:00 GMT",
        "isoDate": "2025-08-07T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-amgen"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-h46qbo",
        "title": "GPT-5 System Card",
        "link": "https://openai.com/index/gpt-5-system-card",
        "url": "https://openai.com/index/gpt-5-system-card",
        "content": "This GPT-5 system card explains how a unified model routing system powers fast and smart responses using gpt-5-main, gpt-5-thinking, and lightweight versions like gpt-5-thinking-nano, optimized for different tasks and developer use.",
        "contentSnippet": "This GPT-5 system card explains how a unified model routing system powers fast and smart responses using gpt-5-main, gpt-5-thinking, and lightweight versions like gpt-5-thinking-nano, optimized for different tasks and developer use.",
        "pubDate": "Thu, 07 Aug 2025 00:00:00 GMT",
        "isoDate": "2025-08-07T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-system-card"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-8bkolq",
        "title": "First look at GPT-5",
        "link": "https://openai.com/index/gpt-5-first-look",
        "url": "https://openai.com/index/gpt-5-first-look",
        "content": "See how a group of leading developers use GPT-5 for the first time.",
        "contentSnippet": "See how a group of leading developers use GPT-5 for the first time.",
        "pubDate": "Thu, 07 Aug 2025 00:00:00 GMT",
        "isoDate": "2025-08-07T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-first-look"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-bahs53",
        "title": "From hard refusals to safe-completions: toward output-centric safety training",
        "link": "https://openai.com/index/gpt-5-safe-completions",
        "url": "https://openai.com/index/gpt-5-safe-completions",
        "content": "Discover how OpenAI's new safe-completions approach in GPT-5 improves both safety and helpfulness in AI responses—moving beyond hard refusals to nuanced, output-centric safety training for handling dual-use prompts.",
        "contentSnippet": "Discover how OpenAI's new safe-completions approach in GPT-5 improves both safety and helpfulness in AI responses—moving beyond hard refusals to nuanced, output-centric safety training for handling dual-use prompts.",
        "pubDate": "Thu, 07 Aug 2025 00:00:00 GMT",
        "isoDate": "2025-08-07T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-safe-completions"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-n4i3lk",
        "title": "How Cursor uses GPT-5",
        "link": "https://openai.com/index/gpt-5-cursor",
        "url": "https://openai.com/index/gpt-5-cursor",
        "content": "Learn how Cursor uses GPT-5.",
        "contentSnippet": "Learn how Cursor uses GPT-5.",
        "pubDate": "Thu, 07 Aug 2025 00:00:00 GMT",
        "isoDate": "2025-08-07T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-5-cursor"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9u6g4q",
        "title": "Introducing GPT-5",
        "link": "https://openai.com/index/introducing-gpt-5",
        "url": "https://openai.com/index/introducing-gpt-5",
        "content": "We are introducing GPT‑5, our best AI system yet. GPT‑5 is a significant leap in intelligence over all our previous models, featuring state-of-the-art performance across coding, math, writing, health, visual perception, and more.",
        "contentSnippet": "We are introducing GPT‑5, our best AI system yet. GPT‑5 is a significant leap in intelligence over all our previous models, featuring state-of-the-art performance across coding, math, writing, health, visual perception, and more.",
        "pubDate": "Thu, 07 Aug 2025 00:00:00 GMT",
        "isoDate": "2025-08-07T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-gpt-5"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ys25uy",
        "title": "Providing ChatGPT to the Entire U.S. Federal Workforce",
        "link": "https://openai.com/index/providing-chatgpt-to-the-entire-us-federal-workforce",
        "url": "https://openai.com/index/providing-chatgpt-to-the-entire-us-federal-workforce",
        "content": "Today, OpenAI for Government is announcing a new partnership with the U.S. General Services Administration (GSA) to launch a transformative initiative. For the next year, ChatGPT Enterprise will be available to the entire federal executive branch workforce at essentially no cost.",
        "contentSnippet": "Today, OpenAI for Government is announcing a new partnership with the U.S. General Services Administration (GSA) to launch a transformative initiative. For the next year, ChatGPT Enterprise will be available to the entire federal executive branch workforce at essentially no cost.",
        "pubDate": "Wed, 06 Aug 2025 00:00:00 GMT",
        "isoDate": "2025-08-06T00:00:00.000Z",
        "source": "https://openai.com/index/providing-chatgpt-to-the-entire-us-federal-workforce"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-zevabz",
        "title": "Open Weights and AI for All",
        "link": "https://openai.com/global-affairs/open-weights-and-ai-for-all",
        "url": "https://openai.com/global-affairs/open-weights-and-ai-for-all",
        "content": "AI’s next frontier isn’t just about capability—it’s about who gets to use it. Our mission to put AI in the hands of as many people as possible is what drives us. Today’s release of our most capable  open-weights models is a major step forward that makes advanced AI more open, flexible, and accessible worldwide.",
        "contentSnippet": "AI’s next frontier isn’t just about capability—it’s about who gets to use it. Our mission to put AI in the hands of as many people as possible is what drives us. Today’s release of our most capable  open-weights models is a major step forward that makes advanced AI more open, flexible, and accessible worldwide.",
        "pubDate": "Tue, 05 Aug 2025 00:00:00 GMT",
        "isoDate": "2025-08-05T00:00:00.000Z",
        "source": "https://openai.com/global-affairs/open-weights-and-ai-for-all"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7i6l6s",
        "title": "Introducing gpt-oss",
        "link": "https://openai.com/index/introducing-gpt-oss",
        "url": "https://openai.com/index/introducing-gpt-oss",
        "content": "We’re releasing gpt-oss-120b and gpt-oss-20b—two state-of-the-art open-weight language models that deliver strong real-world performance at low cost. Available under the flexible Apache 2.0 license, these models outperform similarly sized open models on reasoning tasks, demonstrate strong tool use capabilities, and are optimized for efficient deployment on consumer hardware. ",
        "contentSnippet": "We’re releasing gpt-oss-120b and gpt-oss-20b—two state-of-the-art open-weight language models that deliver strong real-world performance at low cost. Available under the flexible Apache 2.0 license, these models outperform similarly sized open models on reasoning tasks, demonstrate strong tool use capabilities, and are optimized for efficient deployment on consumer hardware.",
        "pubDate": "Tue, 05 Aug 2025 00:00:00 GMT",
        "isoDate": "2025-08-05T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-gpt-oss"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vp6sgc",
        "title": "gpt-oss-120b & gpt-oss-20b Model Card",
        "link": "https://openai.com/index/gpt-oss-model-card",
        "url": "https://openai.com/index/gpt-oss-model-card",
        "content": "We introduce gpt-oss-120b and gpt-oss-20b, two open-weight reasoning models available under the Apache 2.0 license and our gpt-oss usage policy.",
        "contentSnippet": "We introduce gpt-oss-120b and gpt-oss-20b, two open-weight reasoning models available under the Apache 2.0 license and our gpt-oss usage policy.",
        "pubDate": "Tue, 05 Aug 2025 00:00:00 GMT",
        "isoDate": "2025-08-05T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-oss-model-card"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-j298g0",
        "title": "Estimating worst case frontier risks of open weight LLMs",
        "link": "https://openai.com/index/estimating-worst-case-frontier-risks-of-open-weight-llms",
        "url": "https://openai.com/index/estimating-worst-case-frontier-risks-of-open-weight-llms",
        "content": "In this paper, we study the worst-case frontier risks of releasing gpt-oss. We introduce malicious fine-tuning (MFT), where we attempt to elicit maximum capabilities by fine-tuning gpt-oss to be as capable as possible in two domains: biology and cybersecurity.",
        "contentSnippet": "In this paper, we study the worst-case frontier risks of releasing gpt-oss. We introduce malicious fine-tuning (MFT), where we attempt to elicit maximum capabilities by fine-tuning gpt-oss to be as capable as possible in two domains: biology and cybersecurity.",
        "pubDate": "Tue, 05 Aug 2025 00:00:00 GMT",
        "isoDate": "2025-08-05T00:00:00.000Z",
        "source": "https://openai.com/index/estimating-worst-case-frontier-risks-of-open-weight-llms"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-hq2jbs",
        "title": "What we’re optimizing ChatGPT for",
        "link": "https://openai.com/index/optimizing-chatgpt",
        "url": "https://openai.com/index/optimizing-chatgpt",
        "content": "We build ChatGPT to help you thrive in all the ways you want. Learn how we're improving support for tough moments, have rolled out reminders to take breaks, and are working on better life advice, all guided by expert input.",
        "contentSnippet": "We build ChatGPT to help you thrive in all the ways you want. Learn how we're improving support for tough moments, have rolled out reminders to take breaks, and are working on better life advice, all guided by expert input.",
        "pubDate": "Mon, 04 Aug 2025 00:00:00 GMT",
        "isoDate": "2025-08-04T00:00:00.000Z",
        "source": "https://openai.com/index/optimizing-chatgpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xj4gnn",
        "title": "Figma uses AI to transform digital design",
        "link": "https://openai.com/index/figma-david-kossnick",
        "url": "https://openai.com/index/figma-david-kossnick",
        "content": "Discover how Figma is transforming digital design with AI. David Kossnick shares how tools like Figma Make empower teams to prototype, collaborate, and build with AI—reshaping workflows for designers, developers, and non-technical creators alike.",
        "contentSnippet": "Discover how Figma is transforming digital design with AI. David Kossnick shares how tools like Figma Make empower teams to prototype, collaborate, and build with AI—reshaping workflows for designers, developers, and non-technical creators alike.",
        "pubDate": "Fri, 01 Aug 2025 00:00:00 GMT",
        "isoDate": "2025-08-01T00:00:00.000Z",
        "source": "https://openai.com/index/figma-david-kossnick"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-t7kj5x",
        "title": "Introducing Stargate Norway",
        "link": "https://openai.com/index/introducing-stargate-norway",
        "url": "https://openai.com/index/introducing-stargate-norway",
        "content": "We’re launching Stargate Norway—OpenAI’s first AI data center initiative in Europe under our OpenAI for Countries program. Stargate is OpenAI’s overarching infrastructure platform and is a critical part of our long-term vision to deliver the benefits of AI to everyone.",
        "contentSnippet": "We’re launching Stargate Norway—OpenAI’s first AI data center initiative in Europe under our OpenAI for Countries program. Stargate is OpenAI’s overarching infrastructure platform and is a critical part of our long-term vision to deliver the benefits of AI to everyone.",
        "pubDate": "Thu, 31 Jul 2025 00:00:00 GMT",
        "isoDate": "2025-07-31T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-stargate-norway"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-gic3a5",
        "title": "Three lessons for creating a sustainable AI advantage",
        "link": "https://openai.com/index/intercom",
        "url": "https://openai.com/index/intercom",
        "content": "Discover how Intercom built a scalable AI platform with 3 key lessons—from evaluations to architecture—to lead the future of customer support.",
        "contentSnippet": "Discover how Intercom built a scalable AI platform with 3 key lessons—from evaluations to architecture—to lead the future of customer support.",
        "pubDate": "Wed, 30 Jul 2025 00:00:00 GMT",
        "isoDate": "2025-07-30T00:00:00.000Z",
        "source": "https://openai.com/index/intercom"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-rol6lj",
        "title": "Introducing study mode in ChatGPT",
        "link": "https://openai.com/index/chatgpt-study-mode",
        "url": "https://openai.com/index/chatgpt-study-mode",
        "content": "Introducing study mode in ChatGPT, a new learning experience that helps you work through problems step by step, guiding students with questions, scaffolding, and feedback for deeper learning.",
        "contentSnippet": "Introducing study mode in ChatGPT, a new learning experience that helps you work through problems step by step, guiding students with questions, scaffolding, and feedback for deeper learning.",
        "pubDate": "Tue, 29 Jul 2025 10:00:00 GMT",
        "isoDate": "2025-07-29T10:00:00.000Z",
        "source": "https://openai.com/index/chatgpt-study-mode"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-n6hzdp",
        "title": "Resolving digital threats 100x faster with OpenAI",
        "link": "https://openai.com/index/outtake",
        "url": "https://openai.com/index/outtake",
        "content": "Discover how Outtake uses GPT-4.1 and OpenAI o3 to power AI agents that detect and resolve digital threats 100x faster than before.",
        "contentSnippet": "Discover how Outtake uses GPT-4.1 and OpenAI o3 to power AI agents that detect and resolve digital threats 100x faster than before.",
        "pubDate": "Thu, 24 Jul 2025 00:00:00 GMT",
        "isoDate": "2025-07-24T00:00:00.000Z",
        "source": "https://openai.com/index/outtake"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-tp4315",
        "title": "Model ML is helping financial firms rebuild with AI from the ground up",
        "link": "https://openai.com/index/model-ml-chaz-englander",
        "url": "https://openai.com/index/model-ml-chaz-englander",
        "content": "As part of our Executive Function series, Model ML CEO Chaz Englander discusses how AI-native infrastructure and autonomous agents are transforming financial services workflows.",
        "contentSnippet": "As part of our Executive Function series, Model ML CEO Chaz Englander discusses how AI-native infrastructure and autonomous agents are transforming financial services workflows.",
        "pubDate": "Wed, 23 Jul 2025 00:00:00 GMT",
        "isoDate": "2025-07-23T00:00:00.000Z",
        "source": "https://openai.com/index/model-ml-chaz-englander"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-npz2h4",
        "title": "Announcing OpenAI DevDay 2025",
        "link": "https://openai.com/index/announcing-devday-2025",
        "url": "https://openai.com/index/announcing-devday-2025",
        "content": "OpenAI DevDay returns on October 6, 2025 in San Francisco—bringing together 1,500+ developers to preview new tools, hear from OpenAI leaders, and shape the future of AI.",
        "contentSnippet": "OpenAI DevDay returns on October 6, 2025 in San Francisco—bringing together 1,500+ developers to preview new tools, hear from OpenAI leaders, and shape the future of AI.",
        "pubDate": "Wed, 23 Jul 2025 00:00:00 GMT",
        "isoDate": "2025-07-23T00:00:00.000Z",
        "source": "https://openai.com/index/announcing-devday-2025"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-8psp27",
        "title": "Pioneering an AI clinical copilot with Penda Health",
        "link": "https://openai.com/index/ai-clinical-copilot-penda-health",
        "url": "https://openai.com/index/ai-clinical-copilot-penda-health",
        "content": "OpenAI and Penda Health debut an AI clinical copilot that cuts diagnostic errors by 16% in real-world use—offering a new path for safe, effective AI in healthcare.",
        "contentSnippet": "OpenAI and Penda Health debut an AI clinical copilot that cuts diagnostic errors by 16% in real-world use—offering a new path for safe, effective AI in healthcare.",
        "pubDate": "Tue, 22 Jul 2025 10:00:00 GMT",
        "isoDate": "2025-07-22T10:00:00.000Z",
        "source": "https://openai.com/index/ai-clinical-copilot-penda-health"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-omcbnd",
        "title": "Stargate advances with 4.5 GW partnership with Oracle",
        "link": "https://openai.com/index/stargate-advances-with-partnership-with-oracle",
        "url": "https://openai.com/index/stargate-advances-with-partnership-with-oracle",
        "content": "Oracle and OpenAI have entered an agreement to develop 4.5 gigawatts of additional Stargate data center capacity in the U.S. This investment will create new jobs, accelerate America’s reindustrialization, and help advance U.S. AI leadership. It also marks a major milestone for Stargate, OpenAI’s AI infrastructure platform and long-term vision to deliver the benefits of AI to everyone.",
        "contentSnippet": "Oracle and OpenAI have entered an agreement to develop 4.5 gigawatts of additional Stargate data center capacity in the U.S. This investment will create new jobs, accelerate America’s reindustrialization, and help advance U.S. AI leadership. It also marks a major milestone for Stargate, OpenAI’s AI infrastructure platform and long-term vision to deliver the benefits of AI to everyone.",
        "pubDate": "Tue, 22 Jul 2025 00:00:00 GMT",
        "isoDate": "2025-07-22T00:00:00.000Z",
        "source": "https://openai.com/index/stargate-advances-with-partnership-with-oracle"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ieljxv",
        "title": "OpenAI’s new economic analysis ",
        "link": "https://openai.com/global-affairs/new-economic-analysis",
        "url": "https://openai.com/global-affairs/new-economic-analysis",
        "content": "Analysis provides insights into ChatGPT’s impact on the economy. OpenAI also launches new research collaboration to study AI’s broader effects on the labor market and productivity.",
        "contentSnippet": "Analysis provides insights into ChatGPT’s impact on the economy. OpenAI also launches new research collaboration to study AI’s broader effects on the labor market and productivity.",
        "pubDate": "Tue, 22 Jul 2025 00:00:00 GMT",
        "isoDate": "2025-07-22T00:00:00.000Z",
        "source": "https://openai.com/global-affairs/new-economic-analysis"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-s9tqgy",
        "title": "OpenAI and UK Government announce strategic partnership to deliver AI-driven growth",
        "link": "https://openai.com/global-affairs/openai-and-uk-government-partnership",
        "url": "https://openai.com/global-affairs/openai-and-uk-government-partnership",
        "content": "OpenAI partners with the UK Government to boost AI adoption, drive economic growth, and enhance public services for a thriving AI ecosystem in the UK.",
        "contentSnippet": "OpenAI partners with the UK Government to boost AI adoption, drive economic growth, and enhance public services for a thriving AI ecosystem in the UK.",
        "pubDate": "Mon, 21 Jul 2025 10:00:00 GMT",
        "isoDate": "2025-07-21T10:00:00.000Z",
        "source": "https://openai.com/global-affairs/openai-and-uk-government-partnership"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-y3ql19",
        "title": "AI as the greatest source of empowerment for all",
        "link": "https://openai.com/index/ai-as-the-greatest-source-of-empowerment-for-all",
        "url": "https://openai.com/index/ai-as-the-greatest-source-of-empowerment-for-all",
        "content": "I’ve always considered myself a pragmatic technologist—someone who loves technology not for its own sake, but for the direct impact it can have on people’s lives. That’s what makes this job so exciting, since I believe AI will unlock more opportunities for more people than any other technology in history. If we get this right, AI can give everyone more power than ever.",
        "contentSnippet": "I’ve always considered myself a pragmatic technologist—someone who loves technology not for its own sake, but for the direct impact it can have on people’s lives. That’s what makes this job so exciting, since I believe AI will unlock more opportunities for more people than any other technology in history. If we get this right, AI can give everyone more power than ever.",
        "pubDate": "Mon, 21 Jul 2025 00:00:00 GMT",
        "isoDate": "2025-07-21T00:00:00.000Z",
        "source": "https://openai.com/index/ai-as-the-greatest-source-of-empowerment-for-all"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-x1hbcs",
        "title": "A $50 million fund to build with communities",
        "link": "https://openai.com/index/50-million-fund-to-build-with-communities",
        "url": "https://openai.com/index/50-million-fund-to-build-with-communities",
        "content": "OpenAI is launching an initial $50 million fund that supports nonprofit and community organizations, informed by the independent OpenAI Nonprofit Commission report.",
        "contentSnippet": "OpenAI is launching an initial $50 million fund that supports nonprofit and community organizations, informed by the independent OpenAI Nonprofit Commission report.",
        "pubDate": "Fri, 18 Jul 2025 00:00:00 GMT",
        "isoDate": "2025-07-18T00:00:00.000Z",
        "source": "https://openai.com/index/50-million-fund-to-build-with-communities"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-hmxjkc",
        "title": "ChatGPT agent System Card",
        "link": "https://openai.com/index/chatgpt-agent-system-card",
        "url": "https://openai.com/index/chatgpt-agent-system-card",
        "content": "ChatGPT agent System Card: OpenAI’s agentic model unites research, browser automation, and code tools with safeguards under the Preparedness Framework.",
        "contentSnippet": "ChatGPT agent System Card: OpenAI’s agentic model unites research, browser automation, and code tools with safeguards under the Preparedness Framework.",
        "pubDate": "Thu, 17 Jul 2025 10:00:00 GMT",
        "isoDate": "2025-07-17T10:00:00.000Z",
        "source": "https://openai.com/index/chatgpt-agent-system-card"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9sf8ta",
        "title": "Introducing ChatGPT agent",
        "link": "https://openai.com/index/introducing-chatgpt-agent",
        "url": "https://openai.com/index/introducing-chatgpt-agent",
        "content": "Introducing ChatGPT agent: it thinks and acts, using tools to complete tasks like research, bookings, and slideshows—all with your guidance.",
        "contentSnippet": "Introducing ChatGPT agent: it thinks and acts, using tools to complete tasks like research, bookings, and slideshows—all with your guidance.",
        "pubDate": "Thu, 17 Jul 2025 10:00:00 GMT",
        "isoDate": "2025-07-17T10:00:00.000Z",
        "source": "https://openai.com/index/introducing-chatgpt-agent"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-s887wz",
        "title": "OpenAI nonprofit jam",
        "link": "https://openai.com/global-affairs/openai-nonprofit-jam",
        "url": "https://openai.com/global-affairs/openai-nonprofit-jam",
        "content": "At OpenAI, we build tools to help people solve hard problems—including nonprofits working on the frontlines of their communities. The OpenAI Academy is teaming up with the Walton Family Foundation, Emerson Collective, and a network of local nonprofit organizations to host the Nonprofit Jam—a one-day, nationwide event bringing together more than 1,000 nonprofit leaders across 10 locations.",
        "contentSnippet": "At OpenAI, we build tools to help people solve hard problems—including nonprofits working on the frontlines of their communities. The OpenAI Academy is teaming up with the Walton Family Foundation, Emerson Collective, and a network of local nonprofit organizations to host the Nonprofit Jam—a one-day, nationwide event bringing together more than 1,000 nonprofit leaders across 10 locations.",
        "pubDate": "Thu, 17 Jul 2025 00:00:00 GMT",
        "isoDate": "2025-07-17T00:00:00.000Z",
        "source": "https://openai.com/global-affairs/openai-nonprofit-jam"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ok2v38",
        "title": "Agent bio bug bounty call",
        "link": "https://openai.com/bio-bug-bounty",
        "url": "https://openai.com/bio-bug-bounty",
        "content": "OpenAI invites researchers to its Bio Bug Bounty. Test the ChatGPT agent’s safety with a universal jailbreak prompt and win up to $25,000.",
        "contentSnippet": "OpenAI invites researchers to its Bio Bug Bounty. Test the ChatGPT agent’s safety with a universal jailbreak prompt and win up to $25,000.",
        "pubDate": "Thu, 17 Jul 2025 00:00:00 GMT",
        "isoDate": "2025-07-17T00:00:00.000Z",
        "source": "https://openai.com/bio-bug-bounty"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-g7d0ma",
        "title": "Statement from the OpenAI Board of Directors on the Nonprofit Commission Report",
        "link": "https://openai.com/index/nonprofit-commission-report",
        "url": "https://openai.com/index/nonprofit-commission-report",
        "content": "The Board of Directors thanks the members of the independent OpenAI Nonprofit Commission for their extensive work and engagement.",
        "contentSnippet": "The Board of Directors thanks the members of the independent OpenAI Nonprofit Commission for their extensive work and engagement.",
        "pubDate": "Thu, 17 Jul 2025 00:00:00 GMT",
        "isoDate": "2025-07-17T00:00:00.000Z",
        "source": "https://openai.com/index/nonprofit-commission-report"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6qb161",
        "title": "Invideo AI uses OpenAI models to create videos 10x faster",
        "link": "https://openai.com/index/invideo-ai",
        "url": "https://openai.com/index/invideo-ai",
        "content": "Invideo AI uses OpenAI’s GPT-4.1, gpt-image-1, and text-to-speech models to transform creative ideas into professional videos in minutes.",
        "contentSnippet": "Invideo AI uses OpenAI’s GPT-4.1, gpt-image-1, and text-to-speech models to transform creative ideas into professional videos in minutes.",
        "pubDate": "Thu, 17 Jul 2025 00:00:00 GMT",
        "isoDate": "2025-07-17T00:00:00.000Z",
        "source": "https://openai.com/index/invideo-ai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wj2ak",
        "title": "Intellectual freedom by design",
        "link": "https://openai.com/global-affairs/intellectual-freedom-by-design",
        "url": "https://openai.com/global-affairs/intellectual-freedom-by-design",
        "content": "ChatGPT is designed to be useful, trustworthy, and adaptable—so you can make it your own.",
        "contentSnippet": "ChatGPT is designed to be useful, trustworthy, and adaptable—so you can make it your own.",
        "pubDate": "Tue, 15 Jul 2025 00:00:00 GMT",
        "isoDate": "2025-07-15T00:00:00.000Z",
        "source": "https://openai.com/global-affairs/intellectual-freedom-by-design"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-au2hdm",
        "title": "The EU Code of Practice and future of AI in Europe",
        "link": "https://openai.com/global-affairs/eu-code-of-practice",
        "url": "https://openai.com/global-affairs/eu-code-of-practice",
        "content": "OpenAI joins the EU Code of Practice, advancing responsible AI while partnering with European governments to drive innovation, infrastructure, and economic growth.",
        "contentSnippet": "OpenAI joins the EU Code of Practice, advancing responsible AI while partnering with European governments to drive innovation, infrastructure, and economic growth.",
        "pubDate": "Fri, 11 Jul 2025 09:30:00 GMT",
        "isoDate": "2025-07-11T09:30:00.000Z",
        "source": "https://openai.com/global-affairs/eu-code-of-practice"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-18br9r",
        "title": "Sam & Jony",
        "link": "https://openai.com/sam-and-jony",
        "url": "https://openai.com/sam-and-jony",
        "content": "Building a family of AI products for everyone.",
        "contentSnippet": "Building a family of AI products for everyone.",
        "pubDate": "Wed, 09 Jul 2025 00:00:00 GMT",
        "isoDate": "2025-07-09T00:00:00.000Z",
        "source": "https://openai.com/sam-and-jony"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-g15vff",
        "title": "Working with 400,000 teachers to shape the future of AI in schools",
        "link": "https://openai.com/global-affairs/aft",
        "url": "https://openai.com/global-affairs/aft",
        "content": "OpenAI partners with the American Federation of Teachers to launch a 5-year initiative equipping 400,000 K-12 educators to lead AI innovation in classrooms.",
        "contentSnippet": "OpenAI partners with the American Federation of Teachers to launch a 5-year initiative equipping 400,000 K-12 educators to lead AI innovation in classrooms.",
        "pubDate": "Tue, 08 Jul 2025 07:00:00 GMT",
        "isoDate": "2025-07-08T07:00:00.000Z",
        "source": "https://openai.com/global-affairs/aft"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xsv8cb",
        "title": "No-code personal agents, powered by GPT-4.1 and Realtime API",
        "link": "https://openai.com/index/genspark",
        "url": "https://openai.com/index/genspark",
        "content": "Learn how Genspark built a $36M ARR AI product in 45 days—with no-code agents powered by GPT-4.1 and OpenAI Realtime API.",
        "contentSnippet": "Learn how Genspark built a $36M ARR AI product in 45 days—with no-code agents powered by GPT-4.1 and OpenAI Realtime API.",
        "pubDate": "Tue, 01 Jul 2025 10:00:00 GMT",
        "isoDate": "2025-07-01T10:00:00.000Z",
        "source": "https://openai.com/index/genspark"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vvlq6g",
        "title": "AI in Australia—OpenAI’s Economic Blueprint",
        "link": "https://openai.com/global-affairs/openais-australia-economic-blueprint",
        "url": "https://openai.com/global-affairs/openais-australia-economic-blueprint",
        "content": "Today, OpenAI, in partnership with Mandala Partners, is sharing the OpenAI AI Economic Blueprint for Australia. At a time when boosting productivity has emerged as a national priority for Australia, the Blueprint provides a clear, actionable plan for how Australia can unlock the full economic and social potential of artificial intelligence.",
        "contentSnippet": "Today, OpenAI, in partnership with Mandala Partners, is sharing the OpenAI AI Economic Blueprint for Australia. At a time when boosting productivity has emerged as a national priority for Australia, the Blueprint provides a clear, actionable plan for how Australia can unlock the full economic and social potential of artificial intelligence.",
        "pubDate": "Mon, 30 Jun 2025 07:00:00 GMT",
        "isoDate": "2025-06-30T07:00:00.000Z",
        "source": "https://openai.com/global-affairs/openais-australia-economic-blueprint"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-gqe0qv",
        "title": "Customizable, no-code voice agent automation with GPT-4o",
        "link": "https://openai.com/index/retell-ai",
        "url": "https://openai.com/index/retell-ai",
        "content": "Retell AI is transforming the call center with AI voice automation powered by GPT-4o and GPT-4.1. Its no-code platform enables businesses to launch natural, real-time voice agents that cut call costs, boost CSAT, and automate customer conversations—without scripts or hold times.",
        "contentSnippet": "Retell AI is transforming the call center with AI voice automation powered by GPT-4o and GPT-4.1. Its no-code platform enables businesses to launch natural, real-time voice agents that cut call costs, boost CSAT, and automate customer conversations—without scripts or hold times.",
        "pubDate": "Thu, 26 Jun 2025 10:00:00 GMT",
        "isoDate": "2025-06-26T10:00:00.000Z",
        "source": "https://openai.com/index/retell-ai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jmie6j",
        "title": "Driving scalable growth with OpenAI o3, GPT-4.1, and CUA",
        "link": "https://openai.com/index/unify",
        "url": "https://openai.com/index/unify",
        "content": "Unify, an AI-powered GTM platform, uses OpenAI’s o3, GPT-4.1, and CUA to automate prospecting, research, and outreach. With hyper-personalized messaging and an always-on workflow, Unify helps teams generate pipeline at scale while focusing on high-impact customer interactions.",
        "contentSnippet": "Unify, an AI-powered GTM platform, uses OpenAI’s o3, GPT-4.1, and CUA to automate prospecting, research, and outreach. With hyper-personalized messaging and an always-on workflow, Unify helps teams generate pipeline at scale while focusing on high-impact customer interactions.",
        "pubDate": "Tue, 24 Jun 2025 00:00:00 GMT",
        "isoDate": "2025-06-24T00:00:00.000Z",
        "source": "https://openai.com/index/unify"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-nnie6g",
        "title": "Toward understanding and preventing misalignment generalization",
        "link": "https://openai.com/index/emergent-misalignment",
        "url": "https://openai.com/index/emergent-misalignment",
        "content": "We study how training on incorrect responses can cause broader misalignment in language models and identify an internal feature driving this behavior—one that can be reversed with minimal fine-tuning.",
        "contentSnippet": "We study how training on incorrect responses can cause broader misalignment in language models and identify an internal feature driving this behavior—one that can be reversed with minimal fine-tuning.",
        "pubDate": "Wed, 18 Jun 2025 10:00:00 GMT",
        "isoDate": "2025-06-18T10:00:00.000Z",
        "source": "https://openai.com/index/emergent-misalignment"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7hwh90",
        "title": "Preparing for future AI risks in biology",
        "link": "https://openai.com/index/preparing-for-future-ai-capabilities-in-biology",
        "url": "https://openai.com/index/preparing-for-future-ai-capabilities-in-biology",
        "content": "Advanced AI can transform biology and medicine—but also raises biosecurity risks. We’re proactively assessing capabilities and implementing safeguards to prevent misuse.",
        "contentSnippet": "Advanced AI can transform biology and medicine—but also raises biosecurity risks. We’re proactively assessing capabilities and implementing safeguards to prevent misuse.",
        "pubDate": "Wed, 18 Jun 2025 10:00:00 GMT",
        "isoDate": "2025-06-18T10:00:00.000Z",
        "source": "https://openai.com/index/preparing-for-future-ai-capabilities-in-biology"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-fmvxsl",
        "title": "Introducing OpenAI for Government",
        "link": "https://openai.com/global-affairs/introducing-openai-for-government",
        "url": "https://openai.com/global-affairs/introducing-openai-for-government",
        "content": "We’re launching OpenAI for Government, a new initiative focused on bringing our most advanced AI tools to public servants across the United States. We're supporting the U.S. government's efforts in adopting best-in-class technology and deploying these tools in service of the public good.",
        "contentSnippet": "We’re launching OpenAI for Government, a new initiative focused on bringing our most advanced AI tools to public servants across the United States. We're supporting the U.S. government's efforts in adopting best-in-class technology and deploying these tools in service of the public good.",
        "pubDate": "Mon, 16 Jun 2025 00:00:00 GMT",
        "isoDate": "2025-06-16T00:00:00.000Z",
        "source": "https://openai.com/global-affairs/introducing-openai-for-government"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-1ror1j",
        "title": "Bringing the magic of AI to Mattel’s iconic brands",
        "link": "https://openai.com/index/mattels-iconic-brands",
        "url": "https://openai.com/index/mattels-iconic-brands",
        "content": "OpenAI and Mattel are partnering to integrate AI into iconic brands such as Barbie and Hot Wheels, aiming to enhance creative development, streamline workflows, and create new ways for fans to engage.",
        "contentSnippet": "OpenAI and Mattel are partnering to integrate AI into iconic brands such as Barbie and Hot Wheels, aiming to enhance creative development, streamline workflows, and create new ways for fans to engage.",
        "pubDate": "Thu, 12 Jun 2025 00:00:00 GMT",
        "isoDate": "2025-06-12T00:00:00.000Z",
        "source": "https://openai.com/index/mattels-iconic-brands"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-bii1k3",
        "title": "Scaling security with responsible disclosure",
        "link": "https://openai.com/index/scaling-coordinated-vulnerability-disclosure",
        "url": "https://openai.com/index/scaling-coordinated-vulnerability-disclosure",
        "content": "OpenAI introduces its Outbound Coordinated Disclosure Policy to guide how it responsibly reports vulnerabilities in third-party software—emphasizing integrity, collaboration, and proactive security at scale.",
        "contentSnippet": "OpenAI introduces its Outbound Coordinated Disclosure Policy to guide how it responsibly reports vulnerabilities in third-party software—emphasizing integrity, collaboration, and proactive security at scale.",
        "pubDate": "Mon, 09 Jun 2025 10:00:00 GMT",
        "isoDate": "2025-06-09T10:00:00.000Z",
        "source": "https://openai.com/index/scaling-coordinated-vulnerability-disclosure"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-4lpoyv",
        "title": "How we’re responding to The New York Times’ data demands in order to protect user privacy",
        "link": "https://openai.com/index/response-to-nyt-data-demands",
        "url": "https://openai.com/index/response-to-nyt-data-demands",
        "content": "OpenAI is fighting a court order at the demands of The New York Times and plaintiffs, which involves retention of consumer ChatGPT and API user data indefinitely. Learn how we’re working to uphold user privacy, address legal requirements, and stay true to our data protection commitments.",
        "contentSnippet": "OpenAI is fighting a court order at the demands of The New York Times and plaintiffs, which involves retention of consumer ChatGPT and API user data indefinitely. Learn how we’re working to uphold user privacy, address legal requirements, and stay true to our data protection commitments.",
        "pubDate": "Thu, 05 Jun 2025 16:30:00 GMT",
        "isoDate": "2025-06-05T16:30:00.000Z",
        "source": "https://openai.com/index/response-to-nyt-data-demands"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-d0qtb",
        "title": "Disrupting malicious uses of AI: June 2025",
        "link": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai-june-2025",
        "url": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai-june-2025",
        "content": "In our June 2025 update, we outline how we’re disrupting malicious uses of AI—through safety tools that detect and counter abuse, support democratic values, and promote responsible AI deployment for the benefit of all.",
        "contentSnippet": "In our June 2025 update, we outline how we’re disrupting malicious uses of AI—through safety tools that detect and counter abuse, support democratic values, and promote responsible AI deployment for the benefit of all.",
        "pubDate": "Thu, 05 Jun 2025 02:00:00 GMT",
        "isoDate": "2025-06-05T02:00:00.000Z",
        "source": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai-june-2025"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-npephu",
        "title": "Creating websites in minutes with AI Website Builder",
        "link": "https://openai.com/index/wix",
        "url": "https://openai.com/index/wix",
        "content": "Wix’s AI Website Builder, powered by OpenAI, lets anyone create a full website in minutes—just by describing their idea in a conversation.",
        "contentSnippet": "Wix’s AI Website Builder, powered by OpenAI, lets anyone create a full website in minutes—just by describing their idea in a conversation.",
        "pubDate": "Thu, 29 May 2025 00:00:00 GMT",
        "isoDate": "2025-05-29T00:00:00.000Z",
        "source": "https://openai.com/index/wix"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7gm7io",
        "title": "Addendum to OpenAI o3 and o4-mini system card: OpenAI o3 Operator",
        "link": "https://openai.com/index/o3-o4-mini-system-card-addendum-operator-o3",
        "url": "https://openai.com/index/o3-o4-mini-system-card-addendum-operator-o3",
        "content": "We are replacing the existing GPT-4o-based model for Operator with a version based on OpenAI o3. The API version will remain based on 4o.",
        "contentSnippet": "We are replacing the existing GPT-4o-based model for Operator with a version based on OpenAI o3. The API version will remain based on 4o.",
        "pubDate": "Fri, 23 May 2025 00:00:00 GMT",
        "isoDate": "2025-05-23T00:00:00.000Z",
        "source": "https://openai.com/index/o3-o4-mini-system-card-addendum-operator-o3"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-tn6g1s",
        "title": "OpenAI Deutschland",
        "link": "https://openai.com/index/openai-deutschland",
        "url": "https://openai.com/index/openai-deutschland",
        "content": "OpenAI announces the opening of its first office in Germany, based in Munich.",
        "contentSnippet": "OpenAI announces the opening of its first office in Germany, based in Munich.",
        "pubDate": "Thu, 22 May 2025 23:00:00 GMT",
        "isoDate": "2025-05-22T23:00:00.000Z",
        "source": "https://openai.com/index/openai-deutschland"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ju45kx",
        "title": " Shipping code faster with o3, o4-mini, and GPT-4.1",
        "link": "https://openai.com/index/coderabbit",
        "url": "https://openai.com/index/coderabbit",
        "content": "CodeRabbit uses OpenAI models to revolutionize code reviews—boosting accuracy, accelerating PR merges, and helping developers ship faster with fewer bugs and higher ROI.",
        "contentSnippet": "CodeRabbit uses OpenAI models to revolutionize code reviews—boosting accuracy, accelerating PR merges, and helping developers ship faster with fewer bugs and higher ROI.",
        "pubDate": "Thu, 22 May 2025 10:25:00 GMT",
        "isoDate": "2025-05-22T10:25:00.000Z",
        "source": "https://openai.com/index/coderabbit"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-clxxou",
        "title": "Introducing Stargate UAE",
        "link": "https://openai.com/index/introducing-stargate-uae",
        "url": "https://openai.com/index/introducing-stargate-uae",
        "content": "We’re launching Stargate UAE – the first international deployment of Stargate, OpenAI’s AI infrastructure platform.",
        "contentSnippet": "We’re launching Stargate UAE – the first international deployment of Stargate, OpenAI’s AI infrastructure platform.",
        "pubDate": "Thu, 22 May 2025 00:00:00 GMT",
        "isoDate": "2025-05-22T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-stargate-uae"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ow221u",
        "title": "New tools and features in the Responses API",
        "link": "https://openai.com/index/new-tools-and-features-in-the-responses-api",
        "url": "https://openai.com/index/new-tools-and-features-in-the-responses-api",
        "content": "New features in the Responses API: Remote MCP, image gen, Code Interpreter, and more. Powering faster, smarter agents with GPT-4o & o-series models, plus new features for reliability and efficiency.",
        "contentSnippet": "New features in the Responses API: Remote MCP, image gen, Code Interpreter, and more. Powering faster, smarter agents with GPT-4o & o-series models, plus new features for reliability and efficiency.",
        "pubDate": "Wed, 21 May 2025 08:00:00 GMT",
        "isoDate": "2025-05-21T08:00:00.000Z",
        "source": "https://openai.com/index/new-tools-and-features-in-the-responses-api"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jyn7gu",
        "title": "Addendum to o3 and o4-mini system card: Codex",
        "link": "https://openai.com/index/o3-o4-mini-codex-system-card-addendum",
        "url": "https://openai.com/index/o3-o4-mini-codex-system-card-addendum",
        "content": "Codex is a cloud-based coding agent. Codex is powered by codex-1, a version of OpenAI o3 optimized for software engineering. codex-1 was trained using reinforcement learning on real-world coding tasks in a variety of environments to generate code that closely mirrors human style and PR preferences, adheres precisely to instructions, and iteratively runs tests until passing results are achieved.",
        "contentSnippet": "Codex is a cloud-based coding agent. Codex is powered by codex-1, a version of OpenAI o3 optimized for software engineering. codex-1 was trained using reinforcement learning on real-world coding tasks in a variety of environments to generate code that closely mirrors human style and PR preferences, adheres precisely to instructions, and iteratively runs tests until passing results are achieved.",
        "pubDate": "Fri, 16 May 2025 08:00:00 GMT",
        "isoDate": "2025-05-16T08:00:00.000Z",
        "source": "https://openai.com/index/o3-o4-mini-codex-system-card-addendum"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9rycaq",
        "title": "Introducing Codex",
        "link": "https://openai.com/index/introducing-codex",
        "url": "https://openai.com/index/introducing-codex",
        "content": "Introducing Codex: a cloud-based software engineering agent that can work on many tasks in parallel, powered by codex-1. With Codex, developers can simultaneously deploy multiple agents to independently handle coding tasks such as writing features, answering questions about your codebase, fixing bugs, and proposing pull requests for review.",
        "contentSnippet": "Introducing Codex: a cloud-based software engineering agent that can work on many tasks in parallel, powered by codex-1. With Codex, developers can simultaneously deploy multiple agents to independently handle coding tasks such as writing features, answering questions about your codebase, fixing bugs, and proposing pull requests for review.",
        "pubDate": "Fri, 16 May 2025 08:00:00 GMT",
        "isoDate": "2025-05-16T08:00:00.000Z",
        "source": "https://openai.com/index/introducing-codex"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-y5w6w2",
        "title": "AI powers Expedia’s marketing evolution",
        "link": "https://openai.com/index/expedia-jochen-koedijk",
        "url": "https://openai.com/index/expedia-jochen-koedijk",
        "content": "A conversation with Jochen Koedijk, Chief Marketing Officer of Expedia Group.",
        "contentSnippet": "A conversation with Jochen Koedijk, Chief Marketing Officer of Expedia Group.",
        "pubDate": "Wed, 14 May 2025 10:00:00 GMT",
        "isoDate": "2025-05-14T10:00:00.000Z",
        "source": "https://openai.com/index/expedia-jochen-koedijk"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-j9nzdo",
        "title": "Introducing HealthBench",
        "link": "https://openai.com/index/healthbench",
        "url": "https://openai.com/index/healthbench",
        "content": "HealthBench is a new evaluation benchmark for AI in healthcare which evaluates models in realistic scenarios. Built with input from 250+ physicians, it aims to provide a shared standard for model performance and safety in health.",
        "contentSnippet": "HealthBench is a new evaluation benchmark for AI in healthcare which evaluates models in realistic scenarios. Built with input from 250+ physicians, it aims to provide a shared standard for model performance and safety in health.",
        "pubDate": "Mon, 12 May 2025 10:30:00 GMT",
        "isoDate": "2025-05-12T10:30:00.000Z",
        "source": "https://openai.com/index/healthbench"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-2jfjte",
        "title": "OpenAI Expands Leadership with Fidji Simo",
        "link": "https://openai.com/index/leadership-expansion-with-fidji-simo",
        "url": "https://openai.com/index/leadership-expansion-with-fidji-simo",
        "content": "Read the message Sam shared with the company earlier today.",
        "contentSnippet": "Read the message Sam shared with the company earlier today.",
        "pubDate": "Wed, 07 May 2025 21:00:00 GMT",
        "isoDate": "2025-05-07T21:00:00.000Z",
        "source": "https://openai.com/index/leadership-expansion-with-fidji-simo"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-q7fifx",
        "title": "OpenAI’s response to the Department of Energy on AI infrastructure",
        "link": "https://openai.com/global-affairs/response-to-department-of-energy",
        "url": "https://openai.com/global-affairs/response-to-department-of-energy",
        "content": "Why infrastructure is destiny and how the US can seize it.",
        "contentSnippet": "Why infrastructure is destiny and how the US can seize it.",
        "pubDate": "Wed, 07 May 2025 18:30:00 GMT",
        "isoDate": "2025-05-07T18:30:00.000Z",
        "source": "https://openai.com/global-affairs/response-to-department-of-energy"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-10efrv",
        "title": "Introducing data residency in Asia",
        "link": "https://openai.com/index/introducing-data-residency-in-asia",
        "url": "https://openai.com/index/introducing-data-residency-in-asia",
        "content": "Data residency builds on OpenAI’s enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
        "contentSnippet": "Data residency builds on OpenAI’s enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
        "pubDate": "Wed, 07 May 2025 18:00:00 GMT",
        "isoDate": "2025-05-07T18:00:00.000Z",
        "source": "https://openai.com/index/introducing-data-residency-in-asia"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-zhdlo3",
        "title": "The San Antonio Spurs use ChatGPT to scale impact on and off the court",
        "link": "https://openai.com/index/san-antonio-spurs",
        "url": "https://openai.com/index/san-antonio-spurs",
        "content": "Discover how the San Antonio Spurs are using custom GPTs to enhance fan engagement, streamline operations, and drive innovation across teams.",
        "contentSnippet": "Discover how the San Antonio Spurs are using custom GPTs to enhance fan engagement, streamline operations, and drive innovation across teams.",
        "pubDate": "Wed, 07 May 2025 09:00:00 GMT",
        "isoDate": "2025-05-07T09:00:00.000Z",
        "source": "https://openai.com/index/san-antonio-spurs"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jhl66i",
        "title": "Lowe’s puts project expertise into every hand ",
        "link": "https://openai.com/index/lowes",
        "url": "https://openai.com/index/lowes",
        "content": "Lowe’s partnered with OpenAI to build Mylow and Mylow Companion, AI-powered tools that bring expert help to both customers and store associates—making complex home improvement projects easier to plan, navigate, and complete.",
        "contentSnippet": "Lowe’s partnered with OpenAI to build Mylow and Mylow Companion, AI-powered tools that bring expert help to both customers and store associates—making complex home improvement projects easier to plan, navigate, and complete.",
        "pubDate": "Wed, 07 May 2025 07:00:00 GMT",
        "isoDate": "2025-05-07T07:00:00.000Z",
        "source": "https://openai.com/index/lowes"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-fi2eon",
        "title": "Introducing OpenAI for Countries",
        "link": "https://openai.com/global-affairs/openai-for-countries",
        "url": "https://openai.com/global-affairs/openai-for-countries",
        "content": "A new initiative to support countries around the world that want to build on democratic AI rails.",
        "contentSnippet": "A new initiative to support countries around the world that want to build on democratic AI rails.",
        "pubDate": "Wed, 07 May 2025 03:00:00 GMT",
        "isoDate": "2025-05-07T03:00:00.000Z",
        "source": "https://openai.com/global-affairs/openai-for-countries"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-rfo0k6",
        "title": "Introducing AI stories: daily benefits shine a light on bigger opportunities",
        "link": "https://openai.com/global-affairs/ai-stories-daily-benefits-bigger-opportunities",
        "url": "https://openai.com/global-affairs/ai-stories-daily-benefits-bigger-opportunities",
        "content": "Sam Altman has written that we are entering the Intelligence Age, a time when AI will help people become dramatically more capable. The biggest problems of today—across science, medicine, education, national defense—will no longer seem intractable, but will in fact be solvable. New horizons of possibility and prosperity will open up.",
        "contentSnippet": "Sam Altman has written that we are entering the Intelligence Age, a time when AI will help people become dramatically more capable. The biggest problems of today—across science, medicine, education, national defense—will no longer seem intractable, but will in fact be solvable. New horizons of possibility and prosperity will open up.",
        "pubDate": "Tue, 06 May 2025 10:30:00 GMT",
        "isoDate": "2025-05-06T10:30:00.000Z",
        "source": "https://openai.com/global-affairs/ai-stories-daily-benefits-bigger-opportunities"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7lpsd1",
        "title": "AI helps John Deere transform agriculture",
        "link": "https://openai.com/index/john-deere-justin-rose",
        "url": "https://openai.com/index/john-deere-justin-rose",
        "content": "John Deere’s Justin Rose talks about transforming agriculture with AI and shares how the company is scaling innovation to help farmers work smarter, more efficiently, and sustainably.",
        "contentSnippet": "John Deere’s Justin Rose talks about transforming agriculture with AI and shares how the company is scaling innovation to help farmers work smarter, more efficiently, and sustainably.",
        "pubDate": "Tue, 06 May 2025 00:00:00 GMT",
        "isoDate": "2025-05-06T00:00:00.000Z",
        "source": "https://openai.com/index/john-deere-justin-rose"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-4o4aon",
        "title": "Evolving OpenAI’s structure",
        "link": "https://openai.com/index/evolving-our-structure",
        "url": "https://openai.com/index/evolving-our-structure",
        "content": "An update from the OpenAI board on transitioning its for-profit entity to a Public Benefit Corporation, reinforcing its mission-driven structure under nonprofit oversight while enabling greater impact and long-term alignment with the public good.",
        "contentSnippet": "An update from the OpenAI board on transitioning its for-profit entity to a Public Benefit Corporation, reinforcing its mission-driven structure under nonprofit oversight while enabling greater impact and long-term alignment with the public good.",
        "pubDate": "Mon, 05 May 2025 11:00:00 GMT",
        "isoDate": "2025-05-05T11:00:00.000Z",
        "source": "https://openai.com/index/evolving-our-structure"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-4nanjh",
        "title": "Lowe’s leverages AI to power home improvement retail",
        "link": "https://openai.com/index/lowes-chandhu-nair",
        "url": "https://openai.com/index/lowes-chandhu-nair",
        "content": "A conversation with Chandhu Nair, Senior Vice President of Data, AI, and Innovation.",
        "contentSnippet": "A conversation with Chandhu Nair, Senior Vice President of Data, AI, and Innovation.",
        "pubDate": "Mon, 05 May 2025 05:00:00 GMT",
        "isoDate": "2025-05-05T05:00:00.000Z",
        "source": "https://openai.com/index/lowes-chandhu-nair"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-tq5vaa",
        "title": "Expanding on what we missed with sycophancy",
        "link": "https://openai.com/index/expanding-on-sycophancy",
        "url": "https://openai.com/index/expanding-on-sycophancy",
        "content": "A deeper dive on our findings, what went wrong, and future changes we’re making.",
        "contentSnippet": "A deeper dive on our findings, what went wrong, and future changes we’re making.",
        "pubDate": "Fri, 02 May 2025 08:00:00 GMT",
        "isoDate": "2025-05-02T08:00:00.000Z",
        "source": "https://openai.com/index/expanding-on-sycophancy"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ssayxv",
        "title": "Sycophancy in GPT-4o: what happened and what we’re doing about it",
        "link": "https://openai.com/index/sycophancy-in-gpt-4o",
        "url": "https://openai.com/index/sycophancy-in-gpt-4o",
        "content": "We have rolled back last week’s GPT‑4o update in ChatGPT so people are now using an earlier version with more balanced behavior. The update we removed was overly flattering or agreeable—often described as sycophantic.",
        "contentSnippet": "We have rolled back last week’s GPT‑4o update in ChatGPT so people are now using an earlier version with more balanced behavior. The update we removed was overly flattering or agreeable—often described as sycophantic.",
        "pubDate": "Tue, 29 Apr 2025 18:00:00 GMT",
        "isoDate": "2025-04-29T18:00:00.000Z",
        "source": "https://openai.com/index/sycophancy-in-gpt-4o"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-hkohzn",
        "title": "New in ChatGPT for Business: April 2025",
        "link": "https://openai.com/business/new-in-chatgpt-for-business-april-updates-2025",
        "url": "https://openai.com/business/new-in-chatgpt-for-business-april-updates-2025",
        "content": "Watch hands-on demos of the lastest in ChatGPT for Business: o3, image generation, enhanced memory, and internal knowledge.",
        "contentSnippet": "Watch hands-on demos of the lastest in ChatGPT for Business: o3, image generation, enhanced memory, and internal knowledge.",
        "pubDate": "Thu, 24 Apr 2025 00:00:00 GMT",
        "isoDate": "2025-04-24T00:00:00.000Z",
        "source": "https://openai.com/business/new-in-chatgpt-for-business-april-updates-2025"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-amvhn3",
        "title": "Introducing our latest image generation model in the API",
        "link": "https://openai.com/index/image-generation-api",
        "url": "https://openai.com/index/image-generation-api",
        "content": "Our latest image generation model is now available in the API via ‘gpt-image-1’—enabling developers and businesses to build professional-grade, customizable visuals directly into their own tools and platforms.",
        "contentSnippet": "Our latest image generation model is now available in the API via ‘gpt-image-1’—enabling developers and businesses to build professional-grade, customizable visuals directly into their own tools and platforms.",
        "pubDate": "Wed, 23 Apr 2025 10:00:00 GMT",
        "isoDate": "2025-04-23T10:00:00.000Z",
        "source": "https://openai.com/index/image-generation-api"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-1pmws7",
        "title": "Speak is personalizing language learning with AI",
        "link": "https://openai.com/index/speak-connor-zwick",
        "url": "https://openai.com/index/speak-connor-zwick",
        "content": "A conversation with Connor Zwick, CEO & Co-founder of Speak.",
        "contentSnippet": "A conversation with Connor Zwick, CEO & Co-founder of Speak.",
        "pubDate": "Tue, 22 Apr 2025 10:00:00 GMT",
        "isoDate": "2025-04-22T10:00:00.000Z",
        "source": "https://openai.com/index/speak-connor-zwick"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-2vdprr",
        "title": "The Washington Post partners with OpenAI on search content",
        "link": "https://openai.com/global-affairs/the-washington-post-partners-with-openai",
        "url": "https://openai.com/global-affairs/the-washington-post-partners-with-openai",
        "content": "The Washington Post is partnering with with OpenAI to integrate news into ChatGPT, providing users with summaries, quotes, and direct links to original reporting.",
        "contentSnippet": "The Washington Post is partnering with with OpenAI to integrate news into ChatGPT, providing users with summaries, quotes, and direct links to original reporting.",
        "pubDate": "Tue, 22 Apr 2025 06:00:00 GMT",
        "isoDate": "2025-04-22T06:00:00.000Z",
        "source": "https://openai.com/global-affairs/the-washington-post-partners-with-openai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-uqpsyf",
        "title": "Introducing OpenAI o3 and o4-mini",
        "link": "https://openai.com/index/introducing-o3-and-o4-mini",
        "url": "https://openai.com/index/introducing-o3-and-o4-mini",
        "content": "Our smartest and most capable models to date with full tool access",
        "contentSnippet": "Our smartest and most capable models to date with full tool access",
        "pubDate": "Wed, 16 Apr 2025 10:00:00 GMT",
        "isoDate": "2025-04-16T10:00:00.000Z",
        "source": "https://openai.com/index/introducing-o3-and-o4-mini"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-71985t",
        "title": "OpenAI o3 and o4-mini System Card",
        "link": "https://openai.com/index/o3-o4-mini-system-card",
        "url": "https://openai.com/index/o3-o4-mini-system-card",
        "content": "OpenAI o3 and OpenAI o4-mini combine state-of-the-art reasoning with full tool capabilities—web browsing, Python, image and file analysis, image generation, canvas, automations, file search, and memory. ",
        "contentSnippet": "OpenAI o3 and OpenAI o4-mini combine state-of-the-art reasoning with full tool capabilities—web browsing, Python, image and file analysis, image generation, canvas, automations, file search, and memory.",
        "pubDate": "Wed, 16 Apr 2025 10:00:00 GMT",
        "isoDate": "2025-04-16T10:00:00.000Z",
        "source": "https://openai.com/index/o3-o4-mini-system-card"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vl760q",
        "title": "Thinking with images",
        "link": "https://openai.com/index/thinking-with-images",
        "url": "https://openai.com/index/thinking-with-images",
        "content": "OpenAI o3 and o4-mini represent a significant breakthrough in visual perception by reasoning with images in their chain of thought.",
        "contentSnippet": "OpenAI o3 and o4-mini represent a significant breakthrough in visual perception by reasoning with images in their chain of thought.",
        "pubDate": "Wed, 16 Apr 2025 10:00:00 GMT",
        "isoDate": "2025-04-16T10:00:00.000Z",
        "source": "https://openai.com/index/thinking-with-images"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-c1l4kh",
        "title": "OpenAI announces nonprofit commission advisors",
        "link": "https://openai.com/index/nonprofit-commission-advisors",
        "url": "https://openai.com/index/nonprofit-commission-advisors",
        "content": "OpenAI is appointing four new advisors to help inform OpenAI’s philanthropic efforts.",
        "contentSnippet": "OpenAI is appointing four new advisors to help inform OpenAI’s philanthropic efforts.",
        "pubDate": "Tue, 15 Apr 2025 13:00:00 GMT",
        "isoDate": "2025-04-15T13:00:00.000Z",
        "source": "https://openai.com/index/nonprofit-commission-advisors"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9famqd",
        "title": "Our updated Preparedness Framework",
        "link": "https://openai.com/index/updating-our-preparedness-framework",
        "url": "https://openai.com/index/updating-our-preparedness-framework",
        "content": "Sharing our updated framework for measuring and protecting against severe harm from frontier AI capabilities.",
        "contentSnippet": "Sharing our updated framework for measuring and protecting against severe harm from frontier AI capabilities.",
        "pubDate": "Tue, 15 Apr 2025 00:00:00 GMT",
        "isoDate": "2025-04-15T00:00:00.000Z",
        "source": "https://openai.com/index/updating-our-preparedness-framework"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-pm2ncy",
        "title": "Introducing GPT-4.1 in the API",
        "link": "https://openai.com/index/gpt-4-1",
        "url": "https://openai.com/index/gpt-4-1",
        "content": "Introducing GPT-4.1 in the API—a new family of models with across-the-board improvements, including major gains in coding, instruction following, and long-context understanding. We’re also releasing our first nano model. Available to developers worldwide starting today.",
        "contentSnippet": "Introducing GPT-4.1 in the API—a new family of models with across-the-board improvements, including major gains in coding, instruction following, and long-context understanding. We’re also releasing our first nano model. Available to developers worldwide starting today.",
        "pubDate": "Mon, 14 Apr 2025 10:00:00 GMT",
        "isoDate": "2025-04-14T10:00:00.000Z",
        "source": "https://openai.com/index/gpt-4-1"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-loyltb",
        "title": "BrowseComp: a benchmark for browsing agents",
        "link": "https://openai.com/index/browsecomp",
        "url": "https://openai.com/index/browsecomp",
        "content": "BrowseComp: a benchmark for browsing agents.",
        "contentSnippet": "BrowseComp: a benchmark for browsing agents.",
        "pubDate": "Thu, 10 Apr 2025 10:00:00 GMT",
        "isoDate": "2025-04-10T10:00:00.000Z",
        "source": "https://openai.com/index/browsecomp"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-4x1q6l",
        "title": "OpenAI Pioneers Program",
        "link": "https://openai.com/index/openai-pioneers-program",
        "url": "https://openai.com/index/openai-pioneers-program",
        "content": "Advancing model performance and real world evaluation in applied domains.",
        "contentSnippet": "Advancing model performance and real world evaluation in applied domains.",
        "pubDate": "Wed, 09 Apr 2025 10:00:00 GMT",
        "isoDate": "2025-04-09T10:00:00.000Z",
        "source": "https://openai.com/index/openai-pioneers-program"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-56tfcs",
        "title": "Canva enables creativity with AI",
        "link": "https://openai.com/index/canva-cam-adams",
        "url": "https://openai.com/index/canva-cam-adams",
        "content": "A conversation with Cameron Adams, Chief Product Officer and Co-founder of Canva.",
        "contentSnippet": "A conversation with Cameron Adams, Chief Product Officer and Co-founder of Canva.",
        "pubDate": "Mon, 07 Apr 2025 00:00:00 GMT",
        "isoDate": "2025-04-07T00:00:00.000Z",
        "source": "https://openai.com/index/canva-cam-adams"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ycrexk",
        "title": "OpenAI’s EU Economic Blueprint",
        "link": "https://openai.com/global-affairs/openais-eu-economic-blueprint",
        "url": "https://openai.com/global-affairs/openais-eu-economic-blueprint",
        "content": "Today, OpenAI is sharing the EU Economic Blueprint—a set of proposals to help Europe seize the promise of artificial intelligence, drive sustainable economic growth across the region, and ensure that AI is developed and deployed by Europe, in Europe, for Europe.",
        "contentSnippet": "Today, OpenAI is sharing the EU Economic Blueprint—a set of proposals to help Europe seize the promise of artificial intelligence, drive sustainable economic growth across the region, and ensure that AI is developed and deployed by Europe, in Europe, for Europe.",
        "pubDate": "Mon, 07 Apr 2025 00:00:00 GMT",
        "isoDate": "2025-04-07T00:00:00.000Z",
        "source": "https://openai.com/global-affairs/openais-eu-economic-blueprint"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-22qvwm",
        "title": "New commission to provide insight as OpenAI builds the world’s best-equipped nonprofit",
        "link": "https://openai.com/index/nonprofit-commission-guidance",
        "url": "https://openai.com/index/nonprofit-commission-guidance",
        "content": "Already a nonprofit, and already using AI to help people solve hard problems, OpenAI aims to build the best-equipped nonprofit the world has ever seen—combining potentially historic financial resources with something even more powerful: technology that can scale human ingenuity itself.",
        "contentSnippet": "Already a nonprofit, and already using AI to help people solve hard problems, OpenAI aims to build the best-equipped nonprofit the world has ever seen—combining potentially historic financial resources with something even more powerful: technology that can scale human ingenuity itself.",
        "pubDate": "Wed, 02 Apr 2025 12:00:00 GMT",
        "isoDate": "2025-04-02T12:00:00.000Z",
        "source": "https://openai.com/index/nonprofit-commission-guidance"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-80kbj8",
        "title": "PaperBench: Evaluating AI’s Ability to Replicate AI Research",
        "link": "https://openai.com/index/paperbench",
        "url": "https://openai.com/index/paperbench",
        "content": "We introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI research.",
        "contentSnippet": "We introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI research.",
        "pubDate": "Wed, 02 Apr 2025 10:15:00 GMT",
        "isoDate": "2025-04-02T10:15:00.000Z",
        "source": "https://openai.com/index/paperbench"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-e1f2q4",
        "title": "Our response to the UK’s copyright consultation",
        "link": "https://openai.com/global-affairs/response-to-uk-copyright-consultation",
        "url": "https://openai.com/global-affairs/response-to-uk-copyright-consultation",
        "content": "Recommendations for pro-innovation policies that can help make the UK the AI capital of Europe.",
        "contentSnippet": "Recommendations for pro-innovation policies that can help make the UK the AI capital of Europe.",
        "pubDate": "Wed, 02 Apr 2025 07:00:00 GMT",
        "isoDate": "2025-04-02T07:00:00.000Z",
        "source": "https://openai.com/global-affairs/response-to-uk-copyright-consultation"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-dorpc8",
        "title": "New funding to build towards AGI",
        "link": "https://openai.com/index/march-funding-updates",
        "url": "https://openai.com/index/march-funding-updates",
        "content": "Today we’re announcing new funding—$40B at a $300B post-money valuation, which enables us to push the frontiers of AI research even further, scale our compute infrastructure, and deliver increasingly powerful tools for the 500 million people who use ChatGPT every week.",
        "contentSnippet": "Today we’re announcing new funding—$40B at a $300B post-money valuation, which enables us to push the frontiers of AI research even further, scale our compute infrastructure, and deliver increasingly powerful tools for the 500 million people who use ChatGPT every week.",
        "pubDate": "Mon, 31 Mar 2025 15:00:00 GMT",
        "isoDate": "2025-03-31T15:00:00.000Z",
        "source": "https://openai.com/index/march-funding-updates"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ywc5dw",
        "title": "Moving from intent-based bots to proactive AI agents",
        "link": "https://openai.com/index/zendesk",
        "url": "https://openai.com/index/zendesk",
        "content": "Moving from intent-based bots to proactive AI agents.",
        "contentSnippet": "Moving from intent-based bots to proactive AI agents.",
        "pubDate": "Thu, 27 Mar 2025 09:00:00 GMT",
        "isoDate": "2025-03-27T09:00:00.000Z",
        "source": "https://openai.com/index/zendesk"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-er7r24",
        "title": "Security on the path to AGI",
        "link": "https://openai.com/index/security-on-the-path-to-agi",
        "url": "https://openai.com/index/security-on-the-path-to-agi",
        "content": "At OpenAI, we proactively adapt, including by building comprehensive security measures directly into our infrastructure and models. ",
        "contentSnippet": "At OpenAI, we proactively adapt, including by building comprehensive security measures directly into our infrastructure and models.",
        "pubDate": "Wed, 26 Mar 2025 10:00:00 GMT",
        "isoDate": "2025-03-26T10:00:00.000Z",
        "source": "https://openai.com/index/security-on-the-path-to-agi"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-k11khf",
        "title": "Introducing 4o Image Generation",
        "link": "https://openai.com/index/introducing-4o-image-generation",
        "url": "https://openai.com/index/introducing-4o-image-generation",
        "content": "At OpenAI, we have long believed image generation should be a primary capability of our language models. That’s why we’ve built our most advanced image generator yet into GPT‑4o. The result—image generation that is not only beautiful, but useful.",
        "contentSnippet": "At OpenAI, we have long believed image generation should be a primary capability of our language models. That’s why we’ve built our most advanced image generator yet into GPT‑4o. The result—image generation that is not only beautiful, but useful.",
        "pubDate": "Tue, 25 Mar 2025 11:05:00 GMT",
        "isoDate": "2025-03-25T11:05:00.000Z",
        "source": "https://openai.com/index/introducing-4o-image-generation"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-33ml44",
        "title": "Addendum to GPT-4o System Card: 4o image generation",
        "link": "https://openai.com/index/gpt-4o-image-generation-system-card-addendum",
        "url": "https://openai.com/index/gpt-4o-image-generation-system-card-addendum",
        "content": "4o image generation is a new, significantly more capable image generation approach than our earlier DALL·E 3 series of models. It can create photorealistic output. It can take images as inputs and transform them. ",
        "contentSnippet": "4o image generation is a new, significantly more capable image generation approach than our earlier DALL·E 3 series of models. It can create photorealistic output. It can take images as inputs and transform them.",
        "pubDate": "Tue, 25 Mar 2025 11:00:00 GMT",
        "isoDate": "2025-03-25T11:00:00.000Z",
        "source": "https://openai.com/index/gpt-4o-image-generation-system-card-addendum"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xu9z65",
        "title": "Automating 90% of finance and legal work with agents",
        "link": "https://openai.com/index/hebbia",
        "url": "https://openai.com/index/hebbia",
        "content": "Hebbia’s deep research automates 90% of finance and legal work, powered by OpenAI",
        "contentSnippet": "Hebbia’s deep research automates 90% of finance and legal work, powered by OpenAI",
        "pubDate": "Tue, 25 Mar 2025 10:00:00 GMT",
        "isoDate": "2025-03-25T10:00:00.000Z",
        "source": "https://openai.com/index/hebbia"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-oajzlz",
        "title": "Scaling the OpenAI Academy",
        "link": "https://openai.com/global-affairs/scaling-the-openai-academy",
        "url": "https://openai.com/global-affairs/scaling-the-openai-academy",
        "content": "Online resource hub will support AI literacy and help people from all backgrounds access tools, best practices, and peer insights to use AI.",
        "contentSnippet": "Online resource hub will support AI literacy and help people from all backgrounds access tools, best practices, and peer insights to use AI.",
        "pubDate": "Tue, 25 Mar 2025 07:00:00 GMT",
        "isoDate": "2025-03-25T07:00:00.000Z",
        "source": "https://openai.com/global-affairs/scaling-the-openai-academy"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-4e12de",
        "title": "Leadership updates",
        "link": "https://openai.com/index/leadership-updates-march-2025",
        "url": "https://openai.com/index/leadership-updates-march-2025",
        "content": "OpenAI has grown a lot. We remain focused on the same core—pursuing frontier AI research that accelerates human progress–but we now also deliver products used by hundreds of millions of people.",
        "contentSnippet": "OpenAI has grown a lot. We remain focused on the same core—pursuing frontier AI research that accelerates human progress–but we now also deliver products used by hundreds of millions of people.",
        "pubDate": "Mon, 24 Mar 2025 10:00:00 GMT",
        "isoDate": "2025-03-24T10:00:00.000Z",
        "source": "https://openai.com/index/leadership-updates-march-2025"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-iwgmap",
        "title": "Early methods for studying affective use and emotional well-being on ChatGPT",
        "link": "https://openai.com/index/affective-use-study",
        "url": "https://openai.com/index/affective-use-study",
        "content": "An OpenAI and MIT Media Lab Research collaboration.",
        "contentSnippet": "An OpenAI and MIT Media Lab Research collaboration.",
        "pubDate": "Fri, 21 Mar 2025 10:00:00 GMT",
        "isoDate": "2025-03-21T10:00:00.000Z",
        "source": "https://openai.com/index/affective-use-study"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-em13sb",
        "title": "Personalizing travel at scale with OpenAI",
        "link": "https://openai.com/index/booking-com",
        "url": "https://openai.com/index/booking-com",
        "content": "By integrating its data systems with OpenAI’s LLMs, Booking.com delivers smarter search, faster support, and intent-driven travel experiences.",
        "contentSnippet": "By integrating its data systems with OpenAI’s LLMs, Booking.com delivers smarter search, faster support, and intent-driven travel experiences.",
        "pubDate": "Thu, 20 Mar 2025 23:00:00 GMT",
        "isoDate": "2025-03-20T23:00:00.000Z",
        "source": "https://openai.com/index/booking-com"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-w9slie",
        "title": "Introducing next-generation audio models in the API",
        "link": "https://openai.com/index/introducing-our-next-generation-audio-models",
        "url": "https://openai.com/index/introducing-our-next-generation-audio-models",
        "content": "For the first time, developers can also instruct the text-to-speech model to speak in a specific way—for example, “talk like a sympathetic customer service agent”—unlocking a new level of customization for voice agents.",
        "contentSnippet": "For the first time, developers can also instruct the text-to-speech model to speak in a specific way—for example, “talk like a sympathetic customer service agent”—unlocking a new level of customization for voice agents.",
        "pubDate": "Thu, 20 Mar 2025 11:00:00 GMT",
        "isoDate": "2025-03-20T11:00:00.000Z",
        "source": "https://openai.com/index/introducing-our-next-generation-audio-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-93q1y",
        "title": "EliseAI improves housing and healthcare efficiency with AI",
        "link": "https://openai.com/index/eliseai-minna-song",
        "url": "https://openai.com/index/eliseai-minna-song",
        "content": "A conversation with Minna Song, CEO & Co-founder of EliseAI.",
        "contentSnippet": "A conversation with Minna Song, CEO & Co-founder of EliseAI.",
        "pubDate": "Tue, 18 Mar 2025 10:00:00 GMT",
        "isoDate": "2025-03-18T10:00:00.000Z",
        "source": "https://openai.com/index/eliseai-minna-song"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-5fns3f",
        "title": "New in ChatGPT for Business: March 2025",
        "link": "https://openai.com/business/new-in-chatgpt-for-work-march-updates-2025",
        "url": "https://openai.com/business/new-in-chatgpt-for-work-march-updates-2025",
        "content": "Join us as we share our latest releases and how ChatGPT is becoming more interactive, customized to the way your teams work, and agentic.",
        "contentSnippet": "Join us as we share our latest releases and how ChatGPT is becoming more interactive, customized to the way your teams work, and agentic.",
        "pubDate": "Tue, 18 Mar 2025 00:00:00 GMT",
        "isoDate": "2025-03-18T00:00:00.000Z",
        "source": "https://openai.com/business/new-in-chatgpt-for-work-march-updates-2025"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-1f5ufb",
        "title": "The court rejects Elon’s latest attempt to slow OpenAI down",
        "link": "https://openai.com/index/court-rejects-elon",
        "url": "https://openai.com/index/court-rejects-elon",
        "content": "We welcome the court’s March 4, 2025, decision rejecting Elon Musk’s latest attempt to slow down OpenAI for his personal benefit.",
        "contentSnippet": "We welcome the court’s March 4, 2025, decision rejecting Elon Musk’s latest attempt to slow down OpenAI for his personal benefit.",
        "pubDate": "Fri, 14 Mar 2025 09:00:00 GMT",
        "isoDate": "2025-03-14T09:00:00.000Z",
        "source": "https://openai.com/index/court-rejects-elon"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-qtqh07",
        "title": "OpenAI’s proposals for the U.S. AI Action Plan",
        "link": "https://openai.com/global-affairs/openai-proposals-for-the-us-ai-action-plan",
        "url": "https://openai.com/global-affairs/openai-proposals-for-the-us-ai-action-plan",
        "content": "Recommendations build on OpenAI’s Economic Blueprint to strengthen America’s AI leadership.",
        "contentSnippet": "Recommendations build on OpenAI’s Economic Blueprint to strengthen America’s AI leadership.",
        "pubDate": "Thu, 13 Mar 2025 03:00:00 GMT",
        "isoDate": "2025-03-13T03:00:00.000Z",
        "source": "https://openai.com/global-affairs/openai-proposals-for-the-us-ai-action-plan"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wepc5c",
        "title": "Driving growth and ‘WOW’ moments with OpenAI",
        "link": "https://openai.com/index/ly-corporation",
        "url": "https://openai.com/index/ly-corporation",
        "content": "LY Corporation: Driving growth and ‘WOW’ moments with OpenAI",
        "contentSnippet": "LY Corporation: Driving growth and ‘WOW’ moments with OpenAI",
        "pubDate": "Wed, 12 Mar 2025 18:00:00 GMT",
        "isoDate": "2025-03-12T18:00:00.000Z",
        "source": "https://openai.com/index/ly-corporation"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wiln2s",
        "title": "New tools for building agents",
        "link": "https://openai.com/index/new-tools-for-building-agents",
        "url": "https://openai.com/index/new-tools-for-building-agents",
        "content": "We’re evolving our platform to help developers and enterprises build useful and reliable agents.",
        "contentSnippet": "We’re evolving our platform to help developers and enterprises build useful and reliable agents.",
        "pubDate": "Tue, 11 Mar 2025 10:00:00 GMT",
        "isoDate": "2025-03-11T10:00:00.000Z",
        "source": "https://openai.com/index/new-tools-for-building-agents"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-cxlyum",
        "title": "Detecting misbehavior in frontier reasoning models",
        "link": "https://openai.com/index/chain-of-thought-monitoring",
        "url": "https://openai.com/index/chain-of-thought-monitoring",
        "content": " Frontier reasoning models exploit loopholes when given the chance. We show we can detect exploits using an LLM to monitor their chains-of-thought. Penalizing their “bad thoughts” doesn’t stop the majority of misbehavior—it makes them hide their intent. ",
        "contentSnippet": "Frontier reasoning models exploit loopholes when given the chance. We show we can detect exploits using an LLM to monitor their chains-of-thought. Penalizing their “bad thoughts” doesn’t stop the majority of misbehavior—it makes them hide their intent.",
        "pubDate": "Mon, 10 Mar 2025 10:00:00 GMT",
        "isoDate": "2025-03-10T10:00:00.000Z",
        "source": "https://openai.com/index/chain-of-thought-monitoring"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-y3rnk5",
        "title": "Nubank elevates customer experiences with OpenAI",
        "link": "https://openai.com/index/nubank",
        "url": "https://openai.com/index/nubank",
        "content": "Nubank elevates customer experiences with OpenAI",
        "contentSnippet": "Nubank elevates customer experiences with OpenAI",
        "pubDate": "Fri, 07 Mar 2025 08:00:00 GMT",
        "isoDate": "2025-03-07T08:00:00.000Z",
        "source": "https://openai.com/index/nubank"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-newvwy",
        "title": "Accelerating engineering cycles 20% with OpenAI",
        "link": "https://openai.com/index/factory",
        "url": "https://openai.com/index/factory",
        "content": "Accelerating engineering cycles 20% with OpenAI.",
        "contentSnippet": "Accelerating engineering cycles 20% with OpenAI.",
        "pubDate": "Thu, 06 Mar 2025 09:00:00 GMT",
        "isoDate": "2025-03-06T09:00:00.000Z",
        "source": "https://openai.com/index/factory"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-g1gybh",
        "title": "LaunchDarkly's approach to AI-powered product management",
        "link": "https://openai.com/index/launchdarkly-claire-vo",
        "url": "https://openai.com/index/launchdarkly-claire-vo",
        "content": "A conversation with Claire Vo, Chief Product Officer of LaunchDarkly, about the changing role of product managers, her anti-to-do list, and building AI-native teams.",
        "contentSnippet": "A conversation with Claire Vo, Chief Product Officer of LaunchDarkly, about the changing role of product managers, her anti-to-do list, and building AI-native teams.",
        "pubDate": "Tue, 04 Mar 2025 10:00:00 GMT",
        "isoDate": "2025-03-04T10:00:00.000Z",
        "source": "https://openai.com/index/launchdarkly-claire-vo"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-uco03g",
        "title": "Introducing NextGenAI",
        "link": "https://openai.com/index/introducing-nextgenai",
        "url": "https://openai.com/index/introducing-nextgenai",
        "content": "OpenAI commits $50M in funding and tools to leading institutions.",
        "contentSnippet": "OpenAI commits $50M in funding and tools to leading institutions.",
        "pubDate": "Tue, 04 Mar 2025 06:00:00 GMT",
        "isoDate": "2025-03-04T06:00:00.000Z",
        "source": "https://openai.com/index/introducing-nextgenai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wkpdt5",
        "title": "1,000 Scientist AI Jam Session",
        "link": "https://openai.com/global-affairs/1000-scientist-ai-jam-session",
        "url": "https://openai.com/global-affairs/1000-scientist-ai-jam-session",
        "content": "OpenAI and nine national labs bring together leading scientists for first-of-its kind event.",
        "contentSnippet": "OpenAI and nine national labs bring together leading scientists for first-of-its kind event.",
        "pubDate": "Fri, 28 Feb 2025 08:00:00 GMT",
        "isoDate": "2025-02-28T08:00:00.000Z",
        "source": "https://openai.com/global-affairs/1000-scientist-ai-jam-session"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-dsez61",
        "title": "Supporting sellers with enhanced product listings",
        "link": "https://openai.com/index/mercari",
        "url": "https://openai.com/index/mercari",
        "content": "Mercari leverages GPT-4o mini and GPT-4 to streamline selling, enhance product listings, and boost sales, transforming the online marketplace with features like AI Listing Support and Mercari AI Assistant.",
        "contentSnippet": "Mercari leverages GPT-4o mini and GPT-4 to streamline selling, enhance product listings, and boost sales, transforming the online marketplace with features like AI Listing Support and Mercari AI Assistant.",
        "pubDate": "Thu, 27 Feb 2025 14:00:00 GMT",
        "isoDate": "2025-02-27T14:00:00.000Z",
        "source": "https://openai.com/index/mercari"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-qo1bs3",
        "title": "OpenAI GPT-4.5 System Card",
        "link": "https://openai.com/index/gpt-4-5-system-card",
        "url": "https://openai.com/index/gpt-4-5-system-card",
        "content": "We’re releasing a research preview of OpenAI GPT‑4.5, our largest and most knowledgeable model yet.",
        "contentSnippet": "We’re releasing a research preview of OpenAI GPT‑4.5, our largest and most knowledgeable model yet.",
        "pubDate": "Thu, 27 Feb 2025 12:00:00 GMT",
        "isoDate": "2025-02-27T12:00:00.000Z",
        "source": "https://openai.com/index/gpt-4-5-system-card"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7i5bpt",
        "title": "Introducing GPT-4.5",
        "link": "https://openai.com/index/introducing-gpt-4-5",
        "url": "https://openai.com/index/introducing-gpt-4-5",
        "content": "We’re releasing a research preview of GPT‑4.5—our largest and best model for chat yet. GPT‑4.5 is a step forward in scaling up pre-training and post-training.",
        "contentSnippet": "We’re releasing a research preview of GPT‑4.5—our largest and best model for chat yet. GPT‑4.5 is a step forward in scaling up pre-training and post-training.",
        "pubDate": "Thu, 27 Feb 2025 10:00:00 GMT",
        "isoDate": "2025-02-27T10:00:00.000Z",
        "source": "https://openai.com/index/introducing-gpt-4-5"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jdpkye",
        "title": "Building an autonomous financial analyst with o1 and o3-mini",
        "link": "https://openai.com/index/endex",
        "url": "https://openai.com/index/endex",
        "content": "Endex builds the future of financial analysis, powered by OpenAI’s reasoning models.",
        "contentSnippet": "Endex builds the future of financial analysis, powered by OpenAI’s reasoning models.",
        "pubDate": "Thu, 27 Feb 2025 09:30:00 GMT",
        "isoDate": "2025-02-27T09:30:00.000Z",
        "source": "https://openai.com/index/endex"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-mvxsor",
        "title": "Deep research System Card",
        "link": "https://openai.com/index/deep-research-system-card",
        "url": "https://openai.com/index/deep-research-system-card",
        "content": "This report outlines the safety work carried out prior to releasing deep research including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
        "contentSnippet": "This report outlines the safety work carried out prior to releasing deep research including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
        "pubDate": "Tue, 25 Feb 2025 10:00:00 GMT",
        "isoDate": "2025-02-25T10:00:00.000Z",
        "source": "https://openai.com/index/deep-research-system-card"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-u4nr7r",
        "title": "Estonia and OpenAI to bring ChatGPT to schools nationwide",
        "link": "https://openai.com/index/estonia-schools-and-chatgpt",
        "url": "https://openai.com/index/estonia-schools-and-chatgpt",
        "content": "Estonia and OpenAI to bring ChatGPT to schools nationwide. OpenAI will work with the Estonian Government to provide students and teachers in the secondary school system with access to ChatGPT Edu.",
        "contentSnippet": "Estonia and OpenAI to bring ChatGPT to schools nationwide. OpenAI will work with the Estonian Government to provide students and teachers in the secondary school system with access to ChatGPT Edu.",
        "pubDate": "Tue, 25 Feb 2025 04:15:00 GMT",
        "isoDate": "2025-02-25T04:15:00.000Z",
        "source": "https://openai.com/index/estonia-schools-and-chatgpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-2chmqo",
        "title": "Disrupting malicious uses of AI",
        "link": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai",
        "url": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai",
        "content": "Ensuring AI benefits humanity by advancing democratic AI, preventing misuse, and protecting against authoritarian threats.",
        "contentSnippet": "Ensuring AI benefits humanity by advancing democratic AI, preventing misuse, and protecting against authoritarian threats.",
        "pubDate": "Fri, 21 Feb 2025 06:30:00 GMT",
        "isoDate": "2025-02-21T06:30:00.000Z",
        "source": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vbpp36",
        "title": "Uber enables outstanding on-demand experiences with AI",
        "link": "https://openai.com/index/uber-enables-outstanding-experiences",
        "url": "https://openai.com/index/uber-enables-outstanding-experiences",
        "content": "A conversation with Jai Malkani, Head of AI and Product, Customer Obsession at Uber.",
        "contentSnippet": "A conversation with Jai Malkani, Head of AI and Product, Customer Obsession at Uber.",
        "pubDate": "Thu, 20 Feb 2025 10:00:00 GMT",
        "isoDate": "2025-02-20T10:00:00.000Z",
        "source": "https://openai.com/index/uber-enables-outstanding-experiences"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-cd11yq",
        "title": "College students and ChatGPT adoption in the US",
        "link": "https://openai.com/global-affairs/college-students-and-chatgpt",
        "url": "https://openai.com/global-affairs/college-students-and-chatgpt",
        "content": "A look into state-by-state adoption and how gaps might impact workforce readiness.",
        "contentSnippet": "A look into state-by-state adoption and how gaps might impact workforce readiness.",
        "pubDate": "Thu, 20 Feb 2025 06:00:00 GMT",
        "isoDate": "2025-02-20T06:00:00.000Z",
        "source": "https://openai.com/global-affairs/college-students-and-chatgpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-tk5lqz",
        "title": "Introducing the SWE-Lancer benchmark",
        "link": "https://openai.com/index/swe-lancer",
        "url": "https://openai.com/index/swe-lancer",
        "content": "Can frontier LLMs earn $1 million from real-world freelance software engineering?",
        "contentSnippet": "Can frontier LLMs earn $1 million from real-world freelance software engineering?",
        "pubDate": "Tue, 18 Feb 2025 10:00:00 GMT",
        "isoDate": "2025-02-18T10:00:00.000Z",
        "source": "https://openai.com/index/swe-lancer"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-283qkw",
        "title": "OpenAI and Guardian Media Group launch content partnership",
        "link": "https://openai.com/index/openai-and-guardian-media-group-launch-content-partnership",
        "url": "https://openai.com/index/openai-and-guardian-media-group-launch-content-partnership",
        "content": "OpenAI and Guardian Media Group announce content partnership to bring Guardian news content to ChatGPT.",
        "contentSnippet": "OpenAI and Guardian Media Group announce content partnership to bring Guardian news content to ChatGPT.",
        "pubDate": "Fri, 14 Feb 2025 07:00:00 GMT",
        "isoDate": "2025-02-14T07:00:00.000Z",
        "source": "https://openai.com/index/openai-and-guardian-media-group-launch-content-partnership"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-cjlaxz",
        "title": "Fanatics Betting and Gaming uses AI to focus on the big picture",
        "link": "https://openai.com/index/fanatics-betting-gaming-andrea-ellis",
        "url": "https://openai.com/index/fanatics-betting-gaming-andrea-ellis",
        "content": "A conversation with Andrea Ellis, Chief Financial Officer of Fanatics Betting and Gaming.",
        "contentSnippet": "A conversation with Andrea Ellis, Chief Financial Officer of Fanatics Betting and Gaming.",
        "pubDate": "Thu, 13 Feb 2025 10:01:00 GMT",
        "isoDate": "2025-02-13T10:01:00.000Z",
        "source": "https://openai.com/index/fanatics-betting-gaming-andrea-ellis"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-td27vl",
        "title": "Wayfair is shaping the future of retail with AI",
        "link": "https://openai.com/index/wayfair-fiona-tan",
        "url": "https://openai.com/index/wayfair-fiona-tan",
        "content": "A conversation with Fiona Tan, Chief Technology Officer of Wayfair.",
        "contentSnippet": "A conversation with Fiona Tan, Chief Technology Officer of Wayfair.",
        "pubDate": "Thu, 13 Feb 2025 10:00:00 GMT",
        "isoDate": "2025-02-13T10:00:00.000Z",
        "source": "https://openai.com/index/wayfair-fiona-tan"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-okmher",
        "title": "Using OpenAI o1 for financial analysis",
        "link": "https://openai.com/index/rogo",
        "url": "https://openai.com/index/rogo",
        "content": "Rogo scales AI-driven financial research with OpenAI o1",
        "contentSnippet": "Rogo scales AI-driven financial research with OpenAI o1",
        "pubDate": "Thu, 13 Feb 2025 07:00:00 GMT",
        "isoDate": "2025-02-13T07:00:00.000Z",
        "source": "https://openai.com/index/rogo"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-8bmme8",
        "title": "Sharing the latest Model Spec",
        "link": "https://openai.com/index/sharing-the-latest-model-spec",
        "url": "https://openai.com/index/sharing-the-latest-model-spec",
        "content": "We’ve made updates to the Model Spec based on external feedback and our continued research in shaping desired model behavior.",
        "contentSnippet": "We’ve made updates to the Model Spec based on external feedback and our continued research in shaping desired model behavior.",
        "pubDate": "Wed, 12 Feb 2025 13:00:00 GMT",
        "isoDate": "2025-02-12T13:00:00.000Z",
        "source": "https://openai.com/index/sharing-the-latest-model-spec"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-zf3yvi",
        "title": "OpenAI partners with Schibsted Media Group ",
        "link": "https://openai.com/index/openai-partners-with-schibsted-media-group",
        "url": "https://openai.com/index/openai-partners-with-schibsted-media-group",
        "content": "OpenAI and Schibsted Media Group announce content partnership to bring Guardian news and archive content to  ChatGPT.",
        "contentSnippet": "OpenAI and Schibsted Media Group announce content partnership to bring Guardian news and archive content to  ChatGPT.",
        "pubDate": "Mon, 10 Feb 2025 06:00:00 GMT",
        "isoDate": "2025-02-10T06:00:00.000Z",
        "source": "https://openai.com/index/openai-partners-with-schibsted-media-group"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-r0ctn2",
        "title": "Introducing the Intelligence Age",
        "link": "https://openai.com/global-affairs/introducing-the-intelligence-age",
        "url": "https://openai.com/global-affairs/introducing-the-intelligence-age",
        "content": "We aired our first-ever television ad during the Super Bowl to pique people’s curiosity and help us all realize how AI can open up new possibilities for us, create more fulfillment in our lives, and make us more productive, just as all the tools that came before AI did for those who came before us.",
        "contentSnippet": "We aired our first-ever television ad during the Super Bowl to pique people’s curiosity and help us all realize how AI can open up new possibilities for us, create more fulfillment in our lives, and make us more productive, just as all the tools that came before AI did for those who came before us.",
        "pubDate": "Sun, 09 Feb 2025 22:00:00 GMT",
        "isoDate": "2025-02-09T22:00:00.000Z",
        "source": "https://openai.com/global-affairs/introducing-the-intelligence-age"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-s5m48g",
        "title": "OpenAI at the Paris AI Action Summit",
        "link": "https://openai.com/global-affairs/openai-at-the-paris-ai-action-summit",
        "url": "https://openai.com/global-affairs/openai-at-the-paris-ai-action-summit",
        "content": "OpenAI looks forward to engaging with global leaders on AI’s role in shaping innovation and economic prosperity.",
        "contentSnippet": "OpenAI looks forward to engaging with global leaders on AI’s role in shaping innovation and economic prosperity.",
        "pubDate": "Fri, 07 Feb 2025 17:00:00 GMT",
        "isoDate": "2025-02-07T17:00:00.000Z",
        "source": "https://openai.com/global-affairs/openai-at-the-paris-ai-action-summit"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-onlvp9",
        "title": "Introducing data residency in Europe",
        "link": "https://openai.com/index/introducing-data-residency-in-europe",
        "url": "https://openai.com/index/introducing-data-residency-in-europe",
        "content": "Data residency builds on OpenAI’s enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
        "contentSnippet": "Data residency builds on OpenAI’s enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
        "pubDate": "Wed, 05 Feb 2025 22:00:00 GMT",
        "isoDate": "2025-02-05T22:00:00.000Z",
        "source": "https://openai.com/index/introducing-data-residency-in-europe"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9igtv8",
        "title": "OpenAI and the CSU system bring AI to 500,000 students & faculty",
        "link": "https://openai.com/index/openai-and-the-csu-system",
        "url": "https://openai.com/index/openai-and-the-csu-system",
        "content": "The largest deployment of ChatGPT to date will expand the use of AI in education and help the United States build an AI-ready workforce.",
        "contentSnippet": "The largest deployment of ChatGPT to date will expand the use of AI in education and help the United States build an AI-ready workforce.",
        "pubDate": "Tue, 04 Feb 2025 11:30:00 GMT",
        "isoDate": "2025-02-04T11:30:00.000Z",
        "source": "https://openai.com/index/openai-and-the-csu-system"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-e6exyi",
        "title": "Catching halibut with ChatGPT",
        "link": "https://openai.com/index/fishing-for-first-timers",
        "url": "https://openai.com/index/fishing-for-first-timers",
        "content": "Using ChatGPT to catch halibut\n",
        "contentSnippet": "Using ChatGPT to catch halibut",
        "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
        "isoDate": "2025-02-04T00:00:00.000Z",
        "source": "https://openai.com/index/fishing-for-first-timers"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-sou8ln",
        "title": "Creating nail art with ChatGPT",
        "link": "https://openai.com/index/ten-tiny-canvases",
        "url": "https://openai.com/index/ten-tiny-canvases",
        "content": "Using ChatGPT to find inspiration for nail art",
        "contentSnippet": "Using ChatGPT to find inspiration for nail art",
        "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
        "isoDate": "2025-02-04T00:00:00.000Z",
        "source": "https://openai.com/index/ten-tiny-canvases"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-594qvb",
        "title": "Building a custom math tutor powered by ChatGPT",
        "link": "https://openai.com/index/my-dog-the-math-tutor",
        "url": "https://openai.com/index/my-dog-the-math-tutor",
        "content": "ChatGPT and personal tutoring\n",
        "contentSnippet": "ChatGPT and personal tutoring",
        "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
        "isoDate": "2025-02-04T00:00:00.000Z",
        "source": "https://openai.com/index/my-dog-the-math-tutor"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-e5fr4d",
        "title": "Introducing deep research",
        "link": "https://openai.com/index/introducing-deep-research",
        "url": "https://openai.com/index/introducing-deep-research",
        "content": "An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research tasks for you. Available to Pro users today, Plus and Team next. \n\n",
        "contentSnippet": "An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research tasks for you. Available to Pro users today, Plus and Team next.",
        "pubDate": "Sun, 02 Feb 2025 16:00:00 GMT",
        "isoDate": "2025-02-02T16:00:00.000Z",
        "source": "https://openai.com/index/introducing-deep-research"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-hfkw0s",
        "title": "Understanding complex trends with deep research",
        "link": "https://openai.com/index/deep-research",
        "url": "https://openai.com/index/deep-research",
        "content": "How OpenAI deep research helps Bain & Company understand complex industry trends.",
        "contentSnippet": "How OpenAI deep research helps Bain & Company understand complex industry trends.",
        "pubDate": "Sun, 02 Feb 2025 16:00:00 GMT",
        "isoDate": "2025-02-02T16:00:00.000Z",
        "source": "https://openai.com/index/deep-research"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-raq96x",
        "title": "OpenAI o3-mini System Card",
        "link": "https://openai.com/index/o3-mini-system-card",
        "url": "https://openai.com/index/o3-mini-system-card",
        "content": "This report outlines the safety work carried out for the OpenAI o3-mini model, including safety evaluations, external red teaming, and Preparedness Framework evaluations.",
        "contentSnippet": "This report outlines the safety work carried out for the OpenAI o3-mini model, including safety evaluations, external red teaming, and Preparedness Framework evaluations.",
        "pubDate": "Fri, 31 Jan 2025 11:00:00 GMT",
        "isoDate": "2025-01-31T11:00:00.000Z",
        "source": "https://openai.com/index/o3-mini-system-card"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-lloznn",
        "title": "OpenAI o3-mini",
        "link": "https://openai.com/index/openai-o3-mini",
        "url": "https://openai.com/index/openai-o3-mini",
        "content": "Pushing the frontier of cost-effective reasoning.",
        "contentSnippet": "Pushing the frontier of cost-effective reasoning.",
        "pubDate": "Fri, 31 Jan 2025 11:00:00 GMT",
        "isoDate": "2025-01-31T11:00:00.000Z",
        "source": "https://openai.com/index/openai-o3-mini"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-n7ec66",
        "title": "Strengthening America’s AI leadership with the U.S. National Laboratories",
        "link": "https://openai.com/index/strengthening-americas-ai-leadership-with-the-us-national-laboratories",
        "url": "https://openai.com/index/strengthening-americas-ai-leadership-with-the-us-national-laboratories",
        "content": "OpenAI’s latest line of reasoning models will be used by nation’s leading scientists to drive scientific breakthroughs.",
        "contentSnippet": "OpenAI’s latest line of reasoning models will be used by nation’s leading scientists to drive scientific breakthroughs.",
        "pubDate": "Thu, 30 Jan 2025 10:00:00 GMT",
        "isoDate": "2025-01-30T10:00:00.000Z",
        "source": "https://openai.com/index/strengthening-americas-ai-leadership-with-the-us-national-laboratories"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-31b8en",
        "title": "Introducing ChatGPT Gov",
        "link": "https://openai.com/global-affairs/introducing-chatgpt-gov",
        "url": "https://openai.com/global-affairs/introducing-chatgpt-gov",
        "content": "ChatGPT Gov is designed to streamline government agencies’ access to OpenAI’s frontier models.",
        "contentSnippet": "ChatGPT Gov is designed to streamline government agencies’ access to OpenAI’s frontier models.",
        "pubDate": "Tue, 28 Jan 2025 06:00:00 GMT",
        "isoDate": "2025-01-28T06:00:00.000Z",
        "source": "https://openai.com/global-affairs/introducing-chatgpt-gov"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-v009f1",
        "title": "Introducing Operator",
        "link": "https://openai.com/index/introducing-operator",
        "url": "https://openai.com/index/introducing-operator",
        "content": "A research preview of an agent that can use its own browser to perform tasks for you. Available to Pro users in the U.S.",
        "contentSnippet": "A research preview of an agent that can use its own browser to perform tasks for you. Available to Pro users in the U.S.",
        "pubDate": "Thu, 23 Jan 2025 10:00:00 GMT",
        "isoDate": "2025-01-23T10:00:00.000Z",
        "source": "https://openai.com/index/introducing-operator"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-x4sbib",
        "title": "Operator System Card",
        "link": "https://openai.com/index/operator-system-card",
        "url": "https://openai.com/index/operator-system-card",
        "content": "Drawing from OpenAI’s established safety frameworks, this document highlights our multi-layered approach, including model and product mitigations we’ve implemented to protect against prompt engineering and jailbreaks, protect privacy and security, as well as details our external red teaming efforts, safety evaluations, and ongoing work to further refine these safeguards.",
        "contentSnippet": "Drawing from OpenAI’s established safety frameworks, this document highlights our multi-layered approach, including model and product mitigations we’ve implemented to protect against prompt engineering and jailbreaks, protect privacy and security, as well as details our external red teaming efforts, safety evaluations, and ongoing work to further refine these safeguards.",
        "pubDate": "Thu, 23 Jan 2025 10:00:00 GMT",
        "isoDate": "2025-01-23T10:00:00.000Z",
        "source": "https://openai.com/index/operator-system-card"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-rzkfnm",
        "title": "Computer-Using Agent",
        "link": "https://openai.com/index/computer-using-agent",
        "url": "https://openai.com/index/computer-using-agent",
        "content": "A universal interface for AI to interact with the digital world.",
        "contentSnippet": "A universal interface for AI to interact with the digital world.",
        "pubDate": "Thu, 23 Jan 2025 10:00:00 GMT",
        "isoDate": "2025-01-23T10:00:00.000Z",
        "source": "https://openai.com/index/computer-using-agent"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-f3f5dg",
        "title": "Bertelsmann powers creativity and productivity with OpenAI",
        "link": "https://openai.com/index/bertelsmann-powers-creativity-and-productivity-with-openai",
        "url": "https://openai.com/index/bertelsmann-powers-creativity-and-productivity-with-openai",
        "content": "Bertelsmann, the global media, services, and education company headquartered in Germany, will integrate OpenAI’s technology across multiple brands around the world.",
        "contentSnippet": "Bertelsmann, the global media, services, and education company headquartered in Germany, will integrate OpenAI’s technology across multiple brands around the world.",
        "pubDate": "Wed, 22 Jan 2025 17:00:00 GMT",
        "isoDate": "2025-01-22T17:00:00.000Z",
        "source": "https://openai.com/index/bertelsmann-powers-creativity-and-productivity-with-openai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6kfbvr",
        "title": "Trading inference-time compute for adversarial robustness",
        "link": "https://openai.com/index/trading-inference-time-compute-for-adversarial-robustness",
        "url": "https://openai.com/index/trading-inference-time-compute-for-adversarial-robustness",
        "content": "Trading Inference-Time Compute for Adversarial Robustness",
        "contentSnippet": "Trading Inference-Time Compute for Adversarial Robustness",
        "pubDate": "Wed, 22 Jan 2025 10:00:00 GMT",
        "isoDate": "2025-01-22T10:00:00.000Z",
        "source": "https://openai.com/index/trading-inference-time-compute-for-adversarial-robustness"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-mskzoj",
        "title": "Stargate Infrastructure",
        "link": "https://openai.com/form/stargate-infrastructure",
        "url": "https://openai.com/form/stargate-infrastructure",
        "content": "OpenAI, and our strategic partners, are thrilled about our shared vision for the Infrastructure of AGI. We are energized by the challenges we face and are excited by the prospect of partnering with firms across the industrial base to deliver against our ambitious mission. Specifically, we want to connect with firms across the built data center infrastructure landscape, from power and land to construction to equipment, and everything in between. ",
        "contentSnippet": "OpenAI, and our strategic partners, are thrilled about our shared vision for the Infrastructure of AGI. We are energized by the challenges we face and are excited by the prospect of partnering with firms across the industrial base to deliver against our ambitious mission. Specifically, we want to connect with firms across the built data center infrastructure landscape, from power and land to construction to equipment, and everything in between.",
        "pubDate": "Tue, 21 Jan 2025 13:30:00 GMT",
        "isoDate": "2025-01-21T13:30:00.000Z",
        "source": "https://openai.com/form/stargate-infrastructure"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-hlpfmc",
        "title": "Announcing The Stargate Project",
        "link": "https://openai.com/index/announcing-the-stargate-project",
        "url": "https://openai.com/index/announcing-the-stargate-project",
        "content": "Announcing The Stargate Project",
        "contentSnippet": "Announcing The Stargate Project",
        "pubDate": "Tue, 21 Jan 2025 13:30:00 GMT",
        "isoDate": "2025-01-21T13:30:00.000Z",
        "source": "https://openai.com/index/announcing-the-stargate-project"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-5vl347",
        "title": "The power of personalized AI",
        "link": "https://openai.com/global-affairs/the-power-of-personalized-ai",
        "url": "https://openai.com/global-affairs/the-power-of-personalized-ai",
        "content": "The power of personalized AI\n",
        "contentSnippet": "The power of personalized AI",
        "pubDate": "Fri, 17 Jan 2025 13:00:00 GMT",
        "isoDate": "2025-01-17T13:00:00.000Z",
        "source": "https://openai.com/global-affairs/the-power-of-personalized-ai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-okcnpv",
        "title": "Partnering with Axios expands OpenAI’s work with the news industry",
        "link": "https://openai.com/index/partnering-with-axios-expands-openai-work-with-the-news-industry",
        "url": "https://openai.com/index/partnering-with-axios-expands-openai-work-with-the-news-industry",
        "content": "Publishers representing hundreds of newsrooms and content brands are using OpenAI partnerships and grant programs to adopt AI tools and strengthen the news ecosystem, while ChatGPT users gain access to information from leading, reliable publications.",
        "contentSnippet": "Publishers representing hundreds of newsrooms and content brands are using OpenAI partnerships and grant programs to adopt AI tools and strengthen the news ecosystem, while ChatGPT users gain access to information from leading, reliable publications.",
        "pubDate": "Wed, 15 Jan 2025 03:00:00 GMT",
        "isoDate": "2025-01-15T03:00:00.000Z",
        "source": "https://openai.com/index/partnering-with-axios-expands-openai-work-with-the-news-industry"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-884ahl",
        "title": "Adebayo Ogunlesi joins OpenAI’s Board of Directors",
        "link": "https://openai.com/index/adebayo-ogunlesi-joins-openais-board-of-directors",
        "url": "https://openai.com/index/adebayo-ogunlesi-joins-openais-board-of-directors",
        "content": "Adebayo Ogunlesi Joins OpenAI’s Board of Directors",
        "contentSnippet": "Adebayo Ogunlesi Joins OpenAI’s Board of Directors",
        "pubDate": "Tue, 14 Jan 2025 09:00:00 GMT",
        "isoDate": "2025-01-14T09:00:00.000Z",
        "source": "https://openai.com/index/adebayo-ogunlesi-joins-openais-board-of-directors"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vzg6sb",
        "title": "OpenAI’s Economic Blueprint ",
        "link": "https://openai.com/global-affairs/openais-economic-blueprint",
        "url": "https://openai.com/global-affairs/openais-economic-blueprint",
        "content": "OpenAI’s Economic Blueprint \n\n",
        "contentSnippet": "OpenAI’s Economic Blueprint",
        "pubDate": "Mon, 13 Jan 2025 03:00:00 GMT",
        "isoDate": "2025-01-13T03:00:00.000Z",
        "source": "https://openai.com/global-affairs/openais-economic-blueprint"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-b4c8uq",
        "title": "Why OpenAI’s structure must evolve to advance our mission",
        "link": "https://openai.com/index/why-our-structure-must-evolve-to-advance-our-mission",
        "url": "https://openai.com/index/why-our-structure-must-evolve-to-advance-our-mission",
        "content": "A stronger non-profit supported by the for-profit’s success.",
        "contentSnippet": "A stronger non-profit supported by the for-profit’s success.",
        "pubDate": "Fri, 27 Dec 2024 00:00:00 GMT",
        "isoDate": "2024-12-27T00:00:00.000Z",
        "source": "https://openai.com/index/why-our-structure-must-evolve-to-advance-our-mission"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jvffoi",
        "title": "Deliberative alignment: reasoning enables safer language models",
        "link": "https://openai.com/index/deliberative-alignment",
        "url": "https://openai.com/index/deliberative-alignment",
        "content": "Deliberative alignment: reasoning enables safer language models\nIntroducing our new alignment strategy for o1 models, which are directly taught safety specifications and how to reason over them.",
        "contentSnippet": "Deliberative alignment: reasoning enables safer language models\nIntroducing our new alignment strategy for o1 models, which are directly taught safety specifications and how to reason over them.",
        "pubDate": "Fri, 20 Dec 2024 10:00:00 GMT",
        "isoDate": "2024-12-20T10:00:00.000Z",
        "source": "https://openai.com/index/deliberative-alignment"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-i2tmbv",
        "title": "OpenAI o1 and new tools for developers",
        "link": "https://openai.com/index/o1-and-new-tools-for-developers",
        "url": "https://openai.com/index/o1-and-new-tools-for-developers",
        "content": "Introducing OpenAI o1, Realtime API improvements, a new fine-tuning method and more for developers.",
        "contentSnippet": "Introducing OpenAI o1, Realtime API improvements, a new fine-tuning method and more for developers.",
        "pubDate": "Tue, 17 Dec 2024 00:00:00 GMT",
        "isoDate": "2024-12-17T00:00:00.000Z",
        "source": "https://openai.com/index/o1-and-new-tools-for-developers"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xgrtjx",
        "title": "Elon Musk wanted an OpenAI for-profit",
        "link": "https://openai.com/index/elon-musk-wanted-an-openai-for-profit",
        "url": "https://openai.com/index/elon-musk-wanted-an-openai-for-profit",
        "content": "Elon Musk’s latest legal filing against OpenAI marks his fourth attempt in less than a year to reframe his claims. However, his own words and actions speak for themselves—in 2017, Elon not only wanted, but actually created, a for-profit as OpenAI’s proposed new structure.",
        "contentSnippet": "Elon Musk’s latest legal filing against OpenAI marks his fourth attempt in less than a year to reframe his claims. However, his own words and actions speak for themselves—in 2017, Elon not only wanted, but actually created, a for-profit as OpenAI’s proposed new structure.",
        "pubDate": "Fri, 13 Dec 2024 00:00:00 GMT",
        "isoDate": "2024-12-13T00:00:00.000Z",
        "source": "https://openai.com/index/elon-musk-wanted-an-openai-for-profit"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wz0bz9",
        "title": "Boosting the customer retail experience with GPT-4o mini",
        "link": "https://openai.com/index/zalando",
        "url": "https://openai.com/index/zalando",
        "content": "Zalando boosts the customer experience with its Assistant, powered by GPT-4o mini",
        "contentSnippet": "Zalando boosts the customer experience with its Assistant, powered by GPT-4o mini",
        "pubDate": "Wed, 11 Dec 2024 06:00:00 GMT",
        "isoDate": "2024-12-11T06:00:00.000Z",
        "source": "https://openai.com/index/zalando"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6r445z",
        "title": "Sora is here",
        "link": "https://openai.com/index/sora-is-here",
        "url": "https://openai.com/index/sora-is-here",
        "content": "Our video generation model, Sora, is now available to use at sora.com. Users can generate videos up to 1080p resolution, up to 20 sec long, and in widescreen, vertical or square aspect ratios. You can bring your own assets to extend, remix, and blend, or generate entirely new content from text.",
        "contentSnippet": "Our video generation model, Sora, is now available to use at sora.com. Users can generate videos up to 1080p resolution, up to 20 sec long, and in widescreen, vertical or square aspect ratios. You can bring your own assets to extend, remix, and blend, or generate entirely new content from text.",
        "pubDate": "Mon, 09 Dec 2024 10:00:00 GMT",
        "isoDate": "2024-12-09T10:00:00.000Z",
        "source": "https://openai.com/index/sora-is-here"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-kku49w",
        "title": "Sora System Card",
        "link": "https://openai.com/index/sora-system-card",
        "url": "https://openai.com/index/sora-system-card",
        "content": "Sora is OpenAI’s video generation model, designed to take text, image, and video inputs and generate a new video as an output. Sora builds on learnings from DALL-E and GPT models, and is designed to give people expanded tools for storytelling and creative expression.",
        "contentSnippet": "Sora is OpenAI’s video generation model, designed to take text, image, and video inputs and generate a new video as an output. Sora builds on learnings from DALL-E and GPT models, and is designed to give people expanded tools for storytelling and creative expression.",
        "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
        "isoDate": "2024-12-09T00:00:00.000Z",
        "source": "https://openai.com/index/sora-system-card"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6vmszc",
        "title": "Put AI to work for your product team",
        "link": "https://openai.com/index/put-ai-to-work-for-your-product-team",
        "url": "https://openai.com/index/put-ai-to-work-for-your-product-team",
        "content": "Put AI to work for your product team",
        "contentSnippet": "Put AI to work for your product team",
        "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
        "isoDate": "2024-12-09T00:00:00.000Z",
        "source": "https://openai.com/index/put-ai-to-work-for-your-product-team"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-qky6wc",
        "title": "Minne Atairu & Sora",
        "link": "https://openai.com/index/sora-minne-atairu",
        "url": "https://openai.com/index/sora-minne-atairu",
        "content": "Interdisciplinary artist Minne Atairu discusses how Sora helps realize her vision.",
        "contentSnippet": "Interdisciplinary artist Minne Atairu discusses how Sora helps realize her vision.",
        "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
        "isoDate": "2024-12-09T00:00:00.000Z",
        "source": "https://openai.com/index/sora-minne-atairu"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-f8izh5",
        "title": "Animator Lyndon Barrois creates new worlds with Sora",
        "link": "https://openai.com/index/sora-lyndon-barrois",
        "url": "https://openai.com/index/sora-lyndon-barrois",
        "content": "Filmmaker Lyndon Barrois describes how to use Sora as a storytelling tool.",
        "contentSnippet": "Filmmaker Lyndon Barrois describes how to use Sora as a storytelling tool.",
        "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
        "isoDate": "2024-12-09T00:00:00.000Z",
        "source": "https://openai.com/index/sora-lyndon-barrois"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-47307m",
        "title": "Vallée Duhamel & Sora",
        "link": "https://openai.com/index/sora-vallee-duhamel",
        "url": "https://openai.com/index/sora-vallee-duhamel",
        "content": "Filmmaking duo Vallée Duhamel explains how Sora helps build new worlds.",
        "contentSnippet": "Filmmaking duo Vallée Duhamel explains how Sora helps build new worlds.",
        "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
        "isoDate": "2024-12-09T00:00:00.000Z",
        "source": "https://openai.com/index/sora-vallee-duhamel"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-a28l86",
        "title": "Introducing ChatGPT Pro",
        "link": "https://openai.com/index/introducing-chatgpt-pro",
        "url": "https://openai.com/index/introducing-chatgpt-pro",
        "content": "Broadening usage of frontier AI",
        "contentSnippet": "Broadening usage of frontier AI",
        "pubDate": "Thu, 05 Dec 2024 10:30:00 GMT",
        "isoDate": "2024-12-05T10:30:00.000Z",
        "source": "https://openai.com/index/introducing-chatgpt-pro"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6gixvq",
        "title": "OpenAI o1 System Card",
        "link": "https://openai.com/index/openai-o1-system-card",
        "url": "https://openai.com/index/openai-o1-system-card",
        "content": "This report outlines the safety work carried out prior to releasing OpenAI o1 and o1-mini, including external red teaming and frontier risk evaluations according to our Preparedness Framework.",
        "contentSnippet": "This report outlines the safety work carried out prior to releasing OpenAI o1 and o1-mini, including external red teaming and frontier risk evaluations according to our Preparedness Framework.",
        "pubDate": "Thu, 05 Dec 2024 10:00:00 GMT",
        "isoDate": "2024-12-05T10:00:00.000Z",
        "source": "https://openai.com/index/openai-o1-system-card"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-moho8l",
        "title": "OpenAI and Future partner on specialist content ",
        "link": "https://openai.com/index/openai-and-future-partner-on-specialist-content",
        "url": "https://openai.com/index/openai-and-future-partner-on-specialist-content",
        "content": "OpenAI and Future, the global platform for specialist media, have today announced a strategic partnership to bring content from Future’s 200 plus media brands to OpenAI’s users.",
        "contentSnippet": "OpenAI and Future, the global platform for specialist media, have today announced a strategic partnership to bring content from Future’s 200 plus media brands to OpenAI’s users.",
        "pubDate": "Wed, 04 Dec 2024 23:30:00 GMT",
        "isoDate": "2024-12-04T23:30:00.000Z",
        "source": "https://openai.com/index/openai-and-future-partner-on-specialist-content"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-yif24h",
        "title": "Shaping the future of financial services",
        "link": "https://openai.com/index/morgan-stanley",
        "url": "https://openai.com/index/morgan-stanley",
        "content": "Morgan Stanley uses AI evals to shape the future of financial services",
        "contentSnippet": "Morgan Stanley uses AI evals to shape the future of financial services",
        "pubDate": "Wed, 04 Dec 2024 10:00:00 GMT",
        "isoDate": "2024-12-04T10:00:00.000Z",
        "source": "https://openai.com/index/morgan-stanley"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-96s8sh",
        "title": "Advancing red teaming with people and AI ",
        "link": "https://openai.com/index/advancing-red-teaming-with-people-and-ai",
        "url": "https://openai.com/index/advancing-red-teaming-with-people-and-ai",
        "content": "Advancing red teaming with people and AI ",
        "contentSnippet": "Advancing red teaming with people and AI",
        "pubDate": "Thu, 21 Nov 2024 10:30:00 GMT",
        "isoDate": "2024-11-21T10:30:00.000Z",
        "source": "https://openai.com/index/advancing-red-teaming-with-people-and-ai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-okwyhp",
        "title": "Empowering a global org with ChatGPT",
        "link": "https://openai.com/index/bbva",
        "url": "https://openai.com/index/bbva",
        "content": "Empowering a global org with ChatGPT",
        "contentSnippet": "Empowering a global org with ChatGPT",
        "pubDate": "Thu, 21 Nov 2024 05:00:00 GMT",
        "isoDate": "2024-11-21T05:00:00.000Z",
        "source": "https://openai.com/index/bbva"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-oktg70",
        "title": " Building smarter maps with GPT-4o vision fine-tuning",
        "link": "https://openai.com/index/grab",
        "url": "https://openai.com/index/grab",
        "content": " Building smarter maps with GPT-4o vision fine-tuning",
        "contentSnippet": "Building smarter maps with GPT-4o vision fine-tuning",
        "pubDate": "Wed, 20 Nov 2024 17:00:00 GMT",
        "isoDate": "2024-11-20T17:00:00.000Z",
        "source": "https://openai.com/index/grab"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-npet25",
        "title": "Rox goes “all in” on OpenAI",
        "link": "https://openai.com/index/rox",
        "url": "https://openai.com/index/rox",
        "content": "By combining commercial experience and deep LLM expertise with OpenAI’s models, Rox makes every seller a top 1% seller. ",
        "contentSnippet": "By combining commercial experience and deep LLM expertise with OpenAI’s models, Rox makes every seller a top 1% seller.",
        "pubDate": "Tue, 19 Nov 2024 07:00:00 GMT",
        "isoDate": "2024-11-19T07:00:00.000Z",
        "source": "https://openai.com/index/rox"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-bo0i5g",
        "title": "OpenAI en France",
        "link": "https://openai.com/index/openai-en-france",
        "url": "https://openai.com/index/openai-en-france",
        "content": "Our first office in continental Europe",
        "contentSnippet": "Our first office in continental Europe",
        "pubDate": "Fri, 15 Nov 2024 00:00:00 GMT",
        "isoDate": "2024-11-15T00:00:00.000Z",
        "source": "https://openai.com/index/openai-en-france"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-cfrjw0",
        "title": "A Student’s Guide to Writing with ChatGPT",
        "link": "https://openai.com/chatgpt/use-cases/student-writing-guide",
        "url": "https://openai.com/chatgpt/use-cases/student-writing-guide",
        "content": "A Student’s Guide to Writing with ChatGPT",
        "contentSnippet": "A Student’s Guide to Writing with ChatGPT",
        "pubDate": "Wed, 13 Nov 2024 10:00:00 GMT",
        "isoDate": "2024-11-13T10:00:00.000Z",
        "source": "https://openai.com/chatgpt/use-cases/student-writing-guide"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-n51ywg",
        "title": "Data-driven beauty and creativity with ChatGPT",
        "link": "https://openai.com/index/estee-lauder",
        "url": "https://openai.com/index/estee-lauder",
        "content": "Data-driven beauty: How The Estée Lauder Companies unlocks insights with ChatGPT",
        "contentSnippet": "Data-driven beauty: How The Estée Lauder Companies unlocks insights with ChatGPT",
        "pubDate": "Wed, 13 Nov 2024 00:00:00 GMT",
        "isoDate": "2024-11-13T00:00:00.000Z",
        "source": "https://openai.com/index/estee-lauder"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-omiqjt",
        "title": "OpenAI’s comments to the NTIA on data center growth, resilience, and security ",
        "link": "https://openai.com/global-affairs/comments-to-the-ntia-on-data-center-growth-resilience-and-security",
        "url": "https://openai.com/global-affairs/comments-to-the-ntia-on-data-center-growth-resilience-and-security",
        "content": "This comment was submitted in response to a request for information from the National Telecommunications and Information Administration (NTIA).",
        "contentSnippet": "This comment was submitted in response to a request for information from the National Telecommunications and Information Administration (NTIA).",
        "pubDate": "Mon, 04 Nov 2024 12:00:00 GMT",
        "isoDate": "2024-11-04T12:00:00.000Z",
        "source": "https://openai.com/global-affairs/comments-to-the-ntia-on-data-center-growth-resilience-and-security"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-av18ph",
        "title": "Introducing ChatGPT search",
        "link": "https://openai.com/index/introducing-chatgpt-search",
        "url": "https://openai.com/index/introducing-chatgpt-search",
        "content": "Get fast, timely answers with links to relevant web sources",
        "contentSnippet": "Get fast, timely answers with links to relevant web sources",
        "pubDate": "Thu, 31 Oct 2024 10:00:00 GMT",
        "isoDate": "2024-10-31T10:00:00.000Z",
        "source": "https://openai.com/index/introducing-chatgpt-search"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-yo80k9",
        "title": "Promega’s top-down adoption of ChatGPT accelerates manufacturing, sales, and marketing",
        "link": "https://openai.com/index/promega",
        "url": "https://openai.com/index/promega",
        "content": "Promega's top-down adoption of ChatGPT accelerates manufacturing, sales, and marketing",
        "contentSnippet": "Promega's top-down adoption of ChatGPT accelerates manufacturing, sales, and marketing",
        "pubDate": "Thu, 31 Oct 2024 08:00:00 GMT",
        "isoDate": "2024-10-31T08:00:00.000Z",
        "source": "https://openai.com/index/promega"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xbdi26",
        "title": "Put AI to work for marketing teams",
        "link": "https://openai.com/business/put-ai-to-work-for-marketing-teams",
        "url": "https://openai.com/business/put-ai-to-work-for-marketing-teams",
        "content": "Put AI to Work for Marketing Teams",
        "contentSnippet": "Put AI to Work for Marketing Teams",
        "pubDate": "Thu, 31 Oct 2024 00:00:00 GMT",
        "isoDate": "2024-10-31T00:00:00.000Z",
        "source": "https://openai.com/business/put-ai-to-work-for-marketing-teams"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-npxs51",
        "title": "Introducing SimpleQA",
        "link": "https://openai.com/index/introducing-simpleqa",
        "url": "https://openai.com/index/introducing-simpleqa",
        "content": "A factuality benchmark called SimpleQA that measures the ability for language models to answer short, fact-seeking questions.",
        "contentSnippet": "A factuality benchmark called SimpleQA that measures the ability for language models to answer short, fact-seeking questions.",
        "pubDate": "Wed, 30 Oct 2024 10:00:00 GMT",
        "isoDate": "2024-10-30T10:00:00.000Z",
        "source": "https://openai.com/index/introducing-simpleqa"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-421hpt",
        "title": "Delivering high-performance customer support",
        "link": "https://openai.com/index/decagon",
        "url": "https://openai.com/index/decagon",
        "content": "Decagon and OpenAI deliver high-performance, fully automated customer support at scale ",
        "contentSnippet": "Decagon and OpenAI deliver high-performance, fully automated customer support at scale",
        "pubDate": "Tue, 29 Oct 2024 10:00:00 GMT",
        "isoDate": "2024-10-29T10:00:00.000Z",
        "source": "https://openai.com/index/decagon"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7crulp",
        "title": "OpenAI’s approach to AI and national security",
        "link": "https://openai.com/global-affairs/openais-approach-to-ai-and-national-security",
        "url": "https://openai.com/global-affairs/openais-approach-to-ai-and-national-security",
        "content": "OpenAI’s approach to AI and national security",
        "contentSnippet": "OpenAI’s approach to AI and national security",
        "pubDate": "Thu, 24 Oct 2024 14:00:00 GMT",
        "isoDate": "2024-10-24T14:00:00.000Z",
        "source": "https://openai.com/global-affairs/openais-approach-to-ai-and-national-security"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-mxwvme",
        "title": "Simplifying, stabilizing, and scaling continuous-time consistency models",
        "link": "https://openai.com/index/simplifying-stabilizing-and-scaling-continuous-time-consistency-models",
        "url": "https://openai.com/index/simplifying-stabilizing-and-scaling-continuous-time-consistency-models",
        "content": "We’ve simplified, stabilized, and scaled continuous-time consistency models, achieving comparable sample quality to leading diffusion models, while using only two sampling steps.",
        "contentSnippet": "We’ve simplified, stabilized, and scaled continuous-time consistency models, achieving comparable sample quality to leading diffusion models, while using only two sampling steps.",
        "pubDate": "Wed, 23 Oct 2024 10:00:00 GMT",
        "isoDate": "2024-10-23T10:00:00.000Z",
        "source": "https://openai.com/index/simplifying-stabilizing-and-scaling-continuous-time-consistency-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-2t76e7",
        "title": "OpenAI appoints Scott Schools as Chief Compliance Officer",
        "link": "https://openai.com/global-affairs/openai-chief-compliance-officer-announcement",
        "url": "https://openai.com/global-affairs/openai-chief-compliance-officer-announcement",
        "content": "OpenAI appoints Scott Schools as Chief Compliance Officer",
        "contentSnippet": "OpenAI appoints Scott Schools as Chief Compliance Officer",
        "pubDate": "Tue, 22 Oct 2024 10:30:00 GMT",
        "isoDate": "2024-10-22T10:30:00.000Z",
        "source": "https://openai.com/global-affairs/openai-chief-compliance-officer-announcement"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-rip5is",
        "title": "Dr. Ronnie Chatterji named OpenAI’s first Chief Economist",
        "link": "https://openai.com/global-affairs/openai-chief-economist-announcement",
        "url": "https://openai.com/global-affairs/openai-chief-economist-announcement",
        "content": "Dr. Ronnie Chatterji named OpenAI’s first Chief Economist",
        "contentSnippet": "Dr. Ronnie Chatterji named OpenAI’s first Chief Economist",
        "pubDate": "Tue, 22 Oct 2024 10:05:00 GMT",
        "isoDate": "2024-10-22T10:05:00.000Z",
        "source": "https://openai.com/global-affairs/openai-chief-economist-announcement"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-v09ubp",
        "title": "OpenAI and the Lenfest Institute AI Collaborative and Fellowship program",
        "link": "https://openai.com/index/lenfest-institute",
        "url": "https://openai.com/index/lenfest-institute",
        "content": "OpenAI and the Lenfest Institute AI Collaborative and Fellowship program",
        "contentSnippet": "OpenAI and the Lenfest Institute AI Collaborative and Fellowship program",
        "pubDate": "Tue, 22 Oct 2024 06:05:00 GMT",
        "isoDate": "2024-10-22T06:05:00.000Z",
        "source": "https://openai.com/index/lenfest-institute"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ofithm",
        "title": "Solving complex problems with OpenAI o1 models",
        "link": "https://openai.com/business/solving-complex-problems-with-openai-o1-models",
        "url": "https://openai.com/business/solving-complex-problems-with-openai-o1-models",
        "content": "In this video, we share how the o1 reasoning models can help in domains like coding, strategy, and research.",
        "contentSnippet": "In this video, we share how the o1 reasoning models can help in domains like coding, strategy, and research.",
        "pubDate": "Thu, 17 Oct 2024 00:00:00 GMT",
        "isoDate": "2024-10-17T00:00:00.000Z",
        "source": "https://openai.com/business/solving-complex-problems-with-openai-o1-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-4rgmma",
        "title": "Evaluating fairness in ChatGPT",
        "link": "https://openai.com/index/evaluating-fairness-in-chatgpt",
        "url": "https://openai.com/index/evaluating-fairness-in-chatgpt",
        "content": "We've analyzed how ChatGPT responds to users based on their name, using AI research assistants to protect privacy.",
        "contentSnippet": "We've analyzed how ChatGPT responds to users based on their name, using AI research assistants to protect privacy.",
        "pubDate": "Tue, 15 Oct 2024 10:00:00 GMT",
        "isoDate": "2024-10-15T10:00:00.000Z",
        "source": "https://openai.com/index/evaluating-fairness-in-chatgpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-gmd6mp",
        "title": "MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering",
        "link": "https://openai.com/index/mle-bench",
        "url": "https://openai.com/index/mle-bench",
        "content": "We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering.",
        "contentSnippet": "We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering.",
        "pubDate": "Thu, 10 Oct 2024 10:00:00 GMT",
        "isoDate": "2024-10-10T10:00:00.000Z",
        "source": "https://openai.com/index/mle-bench"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-5sq83h",
        "title": "An update on disrupting deceptive uses of AI",
        "link": "https://openai.com/global-affairs/an-update-on-disrupting-deceptive-uses-of-ai",
        "url": "https://openai.com/global-affairs/an-update-on-disrupting-deceptive-uses-of-ai",
        "content": "OpenAI’s mission is to ensure that artificial general intelligence benefits all of humanity. We are dedicated to identifying, preventing, and disrupting attempts to abuse our models for harmful ends.",
        "contentSnippet": "OpenAI’s mission is to ensure that artificial general intelligence benefits all of humanity. We are dedicated to identifying, preventing, and disrupting attempts to abuse our models for harmful ends.",
        "pubDate": "Wed, 09 Oct 2024 03:30:00 GMT",
        "isoDate": "2024-10-09T03:30:00.000Z",
        "source": "https://openai.com/global-affairs/an-update-on-disrupting-deceptive-uses-of-ai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xu9oav",
        "title": "OpenAI and Hearst Content Partnership ",
        "link": "https://openai.com/index/hearst",
        "url": "https://openai.com/index/hearst",
        "content": "Hearst’s iconic brands bring curated lifestyle and local news content to OpenAI’s products.",
        "contentSnippet": "Hearst’s iconic brands bring curated lifestyle and local news content to OpenAI’s products.",
        "pubDate": "Tue, 08 Oct 2024 10:00:00 GMT",
        "isoDate": "2024-10-08T10:00:00.000Z",
        "source": "https://openai.com/index/hearst"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-iqlz1d",
        "title": "Introducing canvas, a new way to write and code with ChatGPT.",
        "link": "https://openai.com/index/introducing-canvas",
        "url": "https://openai.com/index/introducing-canvas",
        "content": "Introducing canvas",
        "contentSnippet": "Introducing canvas",
        "pubDate": "Thu, 03 Oct 2024 10:00:00 GMT",
        "isoDate": "2024-10-03T10:00:00.000Z",
        "source": "https://openai.com/index/introducing-canvas"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-2x02ug",
        "title": "New Credit Facility Enhances Financial Flexibility",
        "link": "https://openai.com/index/new-credit-facility-enhances-financial-flexibility",
        "url": "https://openai.com/index/new-credit-facility-enhances-financial-flexibility",
        "content": "In addition to securing $6.6 billion in new funding from leading investors, we have established a new $4 billion credit facility with leading banks, including JPMorgan Chase, Citi, Goldman Sachs, Morgan Stanley, Santander, Wells Fargo, SMBC, UBS, and HSBC.",
        "contentSnippet": "In addition to securing $6.6 billion in new funding from leading investors, we have established a new $4 billion credit facility with leading banks, including JPMorgan Chase, Citi, Goldman Sachs, Morgan Stanley, Santander, Wells Fargo, SMBC, UBS, and HSBC.",
        "pubDate": "Thu, 03 Oct 2024 07:00:00 GMT",
        "isoDate": "2024-10-03T07:00:00.000Z",
        "source": "https://openai.com/index/new-credit-facility-enhances-financial-flexibility"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-sowjes",
        "title": "New funding to scale the benefits of AI",
        "link": "https://openai.com/index/scale-the-benefits-of-ai",
        "url": "https://openai.com/index/scale-the-benefits-of-ai",
        "content": "We are making progress on our mission to ensure that artificial general intelligence benefits all of humanity.",
        "contentSnippet": "We are making progress on our mission to ensure that artificial general intelligence benefits all of humanity.",
        "pubDate": "Wed, 02 Oct 2024 10:00:00 GMT",
        "isoDate": "2024-10-02T10:00:00.000Z",
        "source": "https://openai.com/index/scale-the-benefits-of-ai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-31py5",
        "title": "Introducing the Realtime API",
        "link": "https://openai.com/index/introducing-the-realtime-api",
        "url": "https://openai.com/index/introducing-the-realtime-api",
        "content": "Developers can now build fast speech-to-speech experiences into their applications",
        "contentSnippet": "Developers can now build fast speech-to-speech experiences into their applications",
        "pubDate": "Tue, 01 Oct 2024 10:05:00 GMT",
        "isoDate": "2024-10-01T10:05:00.000Z",
        "source": "https://openai.com/index/introducing-the-realtime-api"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ujxroj",
        "title": "Introducing vision to the fine-tuning API",
        "link": "https://openai.com/index/introducing-vision-to-the-fine-tuning-api",
        "url": "https://openai.com/index/introducing-vision-to-the-fine-tuning-api",
        "content": "Developers can now fine-tune GPT-4o with images and text to improve vision capabilities",
        "contentSnippet": "Developers can now fine-tune GPT-4o with images and text to improve vision capabilities",
        "pubDate": "Tue, 01 Oct 2024 10:04:00 GMT",
        "isoDate": "2024-10-01T10:04:00.000Z",
        "source": "https://openai.com/index/introducing-vision-to-the-fine-tuning-api"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-bszffl",
        "title": "Prompt Caching in the API",
        "link": "https://openai.com/index/api-prompt-caching",
        "url": "https://openai.com/index/api-prompt-caching",
        "content": "Offering automatic discounts on inputs that the model has recently seen",
        "contentSnippet": "Offering automatic discounts on inputs that the model has recently seen",
        "pubDate": "Tue, 01 Oct 2024 10:03:00 GMT",
        "isoDate": "2024-10-01T10:03:00.000Z",
        "source": "https://openai.com/index/api-prompt-caching"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-3sb5c1",
        "title": "Model Distillation in the API",
        "link": "https://openai.com/index/api-model-distillation",
        "url": "https://openai.com/index/api-model-distillation",
        "content": "Fine-tune a cost-efficient model with the outputs of a large frontier model–all on the OpenAI platform",
        "contentSnippet": "Fine-tune a cost-efficient model with the outputs of a large frontier model–all on the OpenAI platform",
        "pubDate": "Tue, 01 Oct 2024 10:02:00 GMT",
        "isoDate": "2024-10-01T10:02:00.000Z",
        "source": "https://openai.com/index/api-model-distillation"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-un4qrn",
        "title": "Creating agent and human collaboration with GPT 4o",
        "link": "https://openai.com/index/altera",
        "url": "https://openai.com/index/altera",
        "content": "Altera uses GPT-4o to build a new area of human collaboration",
        "contentSnippet": "Altera uses GPT-4o to build a new area of human collaboration",
        "pubDate": "Tue, 01 Oct 2024 09:59:00 GMT",
        "isoDate": "2024-10-01T09:59:00.000Z",
        "source": "https://openai.com/index/altera"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-pw98pn",
        "title": "Put AI to work: Automate and scale financial operations",
        "link": "https://openai.com/business/put-ai-to-work-automate-and-scale-financial-operations",
        "url": "https://openai.com/business/put-ai-to-work-automate-and-scale-financial-operations",
        "content": "Put AI to work: Automate and Scale Financial Operations",
        "contentSnippet": "Put AI to work: Automate and Scale Financial Operations",
        "pubDate": "Mon, 30 Sep 2024 00:00:00 GMT",
        "isoDate": "2024-09-30T00:00:00.000Z",
        "source": "https://openai.com/business/put-ai-to-work-automate-and-scale-financial-operations"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-kq4ubs",
        "title": "Upgrading the Moderation API with our new multimodal moderation model",
        "link": "https://openai.com/index/upgrading-the-moderation-api-with-our-new-multimodal-moderation-model",
        "url": "https://openai.com/index/upgrading-the-moderation-api-with-our-new-multimodal-moderation-model",
        "content": "We’re introducing a new model built on GPT-4o that is more accurate at detecting harmful text and images, enabling developers to build more robust moderation systems.",
        "contentSnippet": "We’re introducing a new model built on GPT-4o that is more accurate at detecting harmful text and images, enabling developers to build more robust moderation systems.",
        "pubDate": "Thu, 26 Sep 2024 10:00:00 GMT",
        "isoDate": "2024-09-26T10:00:00.000Z",
        "source": "https://openai.com/index/upgrading-the-moderation-api-with-our-new-multimodal-moderation-model"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-fxwygg",
        "title": "Minnesota’s Enterprise Translation Office uses ChatGPT to bridge language gaps",
        "link": "https://openai.com/index/state-of-minnesota",
        "url": "https://openai.com/index/state-of-minnesota",
        "content": "Minnesota’s Enterprise Translation Office uses ChatGPT to bridge language gaps",
        "contentSnippet": "Minnesota’s Enterprise Translation Office uses ChatGPT to bridge language gaps",
        "pubDate": "Thu, 26 Sep 2024 07:00:00 GMT",
        "isoDate": "2024-09-26T07:00:00.000Z",
        "source": "https://openai.com/index/state-of-minnesota"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-oktpr9",
        "title": "OpenAI and GEDI partner for Italian news content ",
        "link": "https://openai.com/index/gedi",
        "url": "https://openai.com/index/gedi",
        "content": "OpenAI and GEDI announce strategic partnership to bring Italian-language news content to ChatGPT.",
        "contentSnippet": "OpenAI and GEDI announce strategic partnership to bring Italian-language news content to ChatGPT.",
        "pubDate": "Thu, 26 Sep 2024 04:30:00 GMT",
        "isoDate": "2024-09-26T04:30:00.000Z",
        "source": "https://openai.com/index/gedi"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-nmxqt2",
        "title": "Introducing Verdi, an AI dev platform powered by GPT-4o",
        "link": "https://openai.com/index/mercado-libre",
        "url": "https://openai.com/index/mercado-libre",
        "content": "Mercado Libre introduces Verdi, an AI developer platform powered by GPT-4o",
        "contentSnippet": "Mercado Libre introduces Verdi, an AI developer platform powered by GPT-4o",
        "pubDate": "Tue, 24 Sep 2024 07:00:00 GMT",
        "isoDate": "2024-09-24T07:00:00.000Z",
        "source": "https://openai.com/index/mercado-libre"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-3f84yt",
        "title": "Introducing the OpenAI Academy",
        "link": "https://openai.com/global-affairs/openai-academy",
        "url": "https://openai.com/global-affairs/openai-academy",
        "content": "New initiative will fuel innovation by investing in developers and organizations leveraging AI, starting in low- and middle-income countries.",
        "contentSnippet": "New initiative will fuel innovation by investing in developers and organizations leveraging AI, starting in low- and middle-income countries.",
        "pubDate": "Mon, 23 Sep 2024 03:30:00 GMT",
        "isoDate": "2024-09-23T03:30:00.000Z",
        "source": "https://openai.com/global-affairs/openai-academy"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xdg8l2",
        "title": "Genmab launches “AI Everywhere” ",
        "link": "https://openai.com/index/genmab",
        "url": "https://openai.com/index/genmab",
        "content": "Genmab embraces ChatGPT Enterprise, supported by OpenAI’s commitment to security and privacy",
        "contentSnippet": "Genmab embraces ChatGPT Enterprise, supported by OpenAI’s commitment to security and privacy",
        "pubDate": "Thu, 19 Sep 2024 04:00:00 GMT",
        "isoDate": "2024-09-19T04:00:00.000Z",
        "source": "https://openai.com/index/genmab"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-mpy5hs",
        "title": "Using GPT-4 to improve teaching and learning in Brazil",
        "link": "https://openai.com/index/arco-education",
        "url": "https://openai.com/index/arco-education",
        "content": "Improving teaching and learning in Brazil",
        "contentSnippet": "Improving teaching and learning in Brazil",
        "pubDate": "Tue, 17 Sep 2024 05:00:00 GMT",
        "isoDate": "2024-09-17T05:00:00.000Z",
        "source": "https://openai.com/index/arco-education"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-t3cyka",
        "title": "An update on our safety & security practices",
        "link": "https://openai.com/index/update-on-safety-and-security-practices",
        "url": "https://openai.com/index/update-on-safety-and-security-practices",
        "content": "An update on our safety & security practices    \n",
        "contentSnippet": "An update on our safety & security practices",
        "pubDate": "Mon, 16 Sep 2024 13:00:00 GMT",
        "isoDate": "2024-09-16T13:00:00.000Z",
        "source": "https://openai.com/index/update-on-safety-and-security-practices"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-n9594f",
        "title": "Introducing OpenAI o1",
        "link": "https://openai.com/index/introducing-openai-o1-preview",
        "url": "https://openai.com/index/introducing-openai-o1-preview",
        "content": "Introducing OpenAI o1",
        "contentSnippet": "Introducing OpenAI o1",
        "pubDate": "Thu, 12 Sep 2024 10:03:00 GMT",
        "isoDate": "2024-09-12T10:03:00.000Z",
        "source": "https://openai.com/index/introducing-openai-o1-preview"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9v7a5d",
        "title": "Learning to reason with LLMs",
        "link": "https://openai.com/index/learning-to-reason-with-llms",
        "url": "https://openai.com/index/learning-to-reason-with-llms",
        "content": "We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex reasoning. o1 thinks before it answers—it can produce a long internal chain of thought before responding to the user.",
        "contentSnippet": "We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex reasoning. o1 thinks before it answers—it can produce a long internal chain of thought before responding to the user.",
        "pubDate": "Thu, 12 Sep 2024 10:02:00 GMT",
        "isoDate": "2024-09-12T10:02:00.000Z",
        "source": "https://openai.com/index/learning-to-reason-with-llms"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-rvn2eq",
        "title": "OpenAI o1-mini",
        "link": "https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning",
        "url": "https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning",
        "content": "Advancing cost-efficient reasoning",
        "contentSnippet": "Advancing cost-efficient reasoning",
        "pubDate": "Thu, 12 Sep 2024 10:01:00 GMT",
        "isoDate": "2024-09-12T10:01:00.000Z",
        "source": "https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-y7mlsb",
        "title": "OpenAI o1 System Card External Testers Acknowledgements",
        "link": "https://openai.com/index/openai-o1-system-card/external-testers-acknowledgements",
        "url": "https://openai.com/index/openai-o1-system-card/external-testers-acknowledgements",
        "content": "OpenAI o1 system card external testers acknowledgements",
        "contentSnippet": "OpenAI o1 system card external testers acknowledgements",
        "pubDate": "Thu, 12 Sep 2024 10:00:00 GMT",
        "isoDate": "2024-09-12T10:00:00.000Z",
        "source": "https://openai.com/index/openai-o1-system-card/external-testers-acknowledgements"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-lsp2mg",
        "title": "OpenAI o1 Contributions",
        "link": "https://openai.com/openai-o1-contributions",
        "url": "https://openai.com/openai-o1-contributions",
        "content": "OpenAI o1 Contributions",
        "contentSnippet": "OpenAI o1 Contributions",
        "pubDate": "Thu, 12 Sep 2024 10:00:00 GMT",
        "isoDate": "2024-09-12T10:00:00.000Z",
        "source": "https://openai.com/openai-o1-contributions"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-h7pfnh",
        "title": "Coding with OpenAI o1",
        "link": "https://openai.com/index/o1-coding",
        "url": "https://openai.com/index/o1-coding",
        "content": "Scott Wu, CEO and Co-Founder of Cognition, explains how OpenAI o1 makes coding decisions in a more human-like way.",
        "contentSnippet": "Scott Wu, CEO and Co-Founder of Cognition, explains how OpenAI o1 makes coding decisions in a more human-like way.",
        "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
        "isoDate": "2024-09-12T00:00:00.000Z",
        "source": "https://openai.com/index/o1-coding"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9jz3ky",
        "title": "Answering quantum physics questions with OpenAI o1",
        "link": "https://openai.com/index/o1-quantum-physics",
        "url": "https://openai.com/index/o1-quantum-physics",
        "content": "Quantum physicist Mario Krenn uses OpenAI o1 to help answer life's biggest questions.",
        "contentSnippet": "Quantum physicist Mario Krenn uses OpenAI o1 to help answer life's biggest questions.",
        "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
        "isoDate": "2024-09-12T00:00:00.000Z",
        "source": "https://openai.com/index/o1-quantum-physics"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-yadx83",
        "title": "Decoding genetics with OpenAI o1",
        "link": "https://openai.com/index/o1-genetics",
        "url": "https://openai.com/index/o1-genetics",
        "content": "Geneticist Catherine Brownstein demonstrates how OpenAI o1 can speed up the process of diagnosing rare medical challenges.",
        "contentSnippet": "Geneticist Catherine Brownstein demonstrates how OpenAI o1 can speed up the process of diagnosing rare medical challenges.",
        "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
        "isoDate": "2024-09-12T00:00:00.000Z",
        "source": "https://openai.com/index/o1-genetics"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-nisw17",
        "title": "Economics and reasoning with OpenAI o1",
        "link": "https://openai.com/index/o1-economics",
        "url": "https://openai.com/index/o1-economics",
        "content": "Economist Tyler Cowen explains how OpenAI o1 tackles complex economic questions.",
        "contentSnippet": "Economist Tyler Cowen explains how OpenAI o1 tackles complex economic questions.",
        "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
        "isoDate": "2024-09-12T00:00:00.000Z",
        "source": "https://openai.com/index/o1-economics"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ux84pp",
        "title": "Put AI to work: Lessons from hundreds of successful deployments",
        "link": "https://openai.com/business/put-ai-to-work-lessons-from-hundreds-of-successful-deployments",
        "url": "https://openai.com/business/put-ai-to-work-lessons-from-hundreds-of-successful-deployments",
        "content": "Put AI to Work: Lessons from Hundreds of Successful Deployments",
        "contentSnippet": "Put AI to Work: Lessons from Hundreds of Successful Deployments",
        "pubDate": "Tue, 10 Sep 2024 00:00:00 GMT",
        "isoDate": "2024-09-10T00:00:00.000Z",
        "source": "https://openai.com/business/put-ai-to-work-lessons-from-hundreds-of-successful-deployments"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-npf5y2",
        "title": "Using GPT-4 to deliver a new customer service standard",
        "link": "https://openai.com/index/ada",
        "url": "https://openai.com/index/ada",
        "content": "Ada uses GPT-4 to deliver a new customer service standard",
        "contentSnippet": "Ada uses GPT-4 to deliver a new customer service standard",
        "pubDate": "Thu, 05 Sep 2024 08:00:00 GMT",
        "isoDate": "2024-09-05T08:00:00.000Z",
        "source": "https://openai.com/index/ada"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-npf5kl",
        "title": "Personalizing education with ChatGPT",
        "link": "https://openai.com/index/asu",
        "url": "https://openai.com/index/asu",
        "content": "Arizona State University embraces ChatGPT campus-wide to personalize learning, advance research, and prepare students for the future",
        "contentSnippet": "Arizona State University embraces ChatGPT campus-wide to personalize learning, advance research, and prepare students for the future",
        "pubDate": "Mon, 26 Aug 2024 04:00:00 GMT",
        "isoDate": "2024-08-26T04:00:00.000Z",
        "source": "https://openai.com/index/asu"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-kujjxv",
        "title": "Fine-tuning GPT-4o webinar",
        "link": "https://openai.com/business/fine-tuning-gpt-4o-webinar",
        "url": "https://openai.com/business/fine-tuning-gpt-4o-webinar",
        "content": "Fine-Tuning GPT-4o Webinar",
        "contentSnippet": "Fine-Tuning GPT-4o Webinar",
        "pubDate": "Mon, 26 Aug 2024 00:00:00 GMT",
        "isoDate": "2024-08-26T00:00:00.000Z",
        "source": "https://openai.com/business/fine-tuning-gpt-4o-webinar"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xofe8m",
        "title": "OpenAI partners with Condé Nast",
        "link": "https://openai.com/index/conde-nast",
        "url": "https://openai.com/index/conde-nast",
        "content": "Condé Nast",
        "contentSnippet": "Condé Nast",
        "pubDate": "Tue, 20 Aug 2024 11:00:00 GMT",
        "isoDate": "2024-08-20T11:00:00.000Z",
        "source": "https://openai.com/index/conde-nast"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-fl1kog",
        "title": "Fine-tuning now available for GPT-4o",
        "link": "https://openai.com/index/gpt-4o-fine-tuning",
        "url": "https://openai.com/index/gpt-4o-fine-tuning",
        "content": "Fine-tune custom versions of GPT-4o to increase performance and accuracy for your applications",
        "contentSnippet": "Fine-tune custom versions of GPT-4o to increase performance and accuracy for your applications",
        "pubDate": "Tue, 20 Aug 2024 10:00:00 GMT",
        "isoDate": "2024-08-20T10:00:00.000Z",
        "source": "https://openai.com/index/gpt-4o-fine-tuning"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-uutkkc",
        "title": "Putting AI to work at Upwork",
        "link": "https://openai.com/index/upwork",
        "url": "https://openai.com/index/upwork",
        "content": "Upwork puts AI to work, uniting team members, operations and product development",
        "contentSnippet": "Upwork puts AI to work, uniting team members, operations and product development",
        "pubDate": "Tue, 20 Aug 2024 10:00:00 GMT",
        "isoDate": "2024-08-20T10:00:00.000Z",
        "source": "https://openai.com/index/upwork"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6rg1ly",
        "title": "Disrupting a covert Iranian influence operation ",
        "link": "https://openai.com/index/disrupting-a-covert-iranian-influence-operation",
        "url": "https://openai.com/index/disrupting-a-covert-iranian-influence-operation",
        "content": "We banned accounts linked to a covert Iranian influence operation using ChatGPT to generate website and social media content focused on multiple topics, including the U.S. presidential campaign. We have seen no indication that this content reached a meaningful audience. ",
        "contentSnippet": "We banned accounts linked to a covert Iranian influence operation using ChatGPT to generate website and social media content focused on multiple topics, including the U.S. presidential campaign. We have seen no indication that this content reached a meaningful audience.",
        "pubDate": "Fri, 16 Aug 2024 11:00:00 GMT",
        "isoDate": "2024-08-16T11:00:00.000Z",
        "source": "https://openai.com/index/disrupting-a-covert-iranian-influence-operation"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ygb30d",
        "title": "Delivering contextual job matching for millions with OpenAI",
        "link": "https://openai.com/index/indeed",
        "url": "https://openai.com/index/indeed",
        "content": "Indeed, whose mission is to help people get jobs, is the world’s #1 job site. Over 350 million unique visitors come to Indeed every month to connect with more than 3.5 million employers and over 32 million jobs. But what’s more is that every three seconds someone gets hired on Indeed.",
        "contentSnippet": "Indeed, whose mission is to help people get jobs, is the world’s #1 job site. Over 350 million unique visitors come to Indeed every month to connect with more than 3.5 million employers and over 32 million jobs. But what’s more is that every three seconds someone gets hired on Indeed.",
        "pubDate": "Thu, 15 Aug 2024 07:00:00 GMT",
        "isoDate": "2024-08-15T07:00:00.000Z",
        "source": "https://openai.com/index/indeed"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vfggax",
        "title": "Awakening Sleeping Beauties at The Met",
        "link": "https://openai.com/index/the-met-museum",
        "url": "https://openai.com/index/the-met-museum",
        "content": "AI can enrich lives through beauty and creativity, and its artistic potential shines in \"Sleeping Beauties: Reawakening Fashion,\" a collaborative exhibit from The Met's Costume Institute.",
        "contentSnippet": "AI can enrich lives through beauty and creativity, and its artistic potential shines in \"Sleeping Beauties: Reawakening Fashion,\" a collaborative exhibit from The Met's Costume Institute.",
        "pubDate": "Wed, 14 Aug 2024 10:00:00 GMT",
        "isoDate": "2024-08-14T10:00:00.000Z",
        "source": "https://openai.com/index/the-met-museum"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-3z47kq",
        "title": "Introducing SWE-bench Verified",
        "link": "https://openai.com/index/introducing-swe-bench-verified",
        "url": "https://openai.com/index/introducing-swe-bench-verified",
        "content": "We’re releasing a human-validated subset of SWE-bench that more reliably evaluates AI models’ ability to solve real-world software issues.",
        "contentSnippet": "We’re releasing a human-validated subset of SWE-bench that more reliably evaluates AI models’ ability to solve real-world software issues.",
        "pubDate": "Tue, 13 Aug 2024 10:00:00 GMT",
        "isoDate": "2024-08-13T10:00:00.000Z",
        "source": "https://openai.com/index/introducing-swe-bench-verified"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-5yk4jm",
        "title": "Zico Kolter Joins OpenAI’s Board of Directors",
        "link": "https://openai.com/index/zico-kolter-joins-openais-board-of-directors",
        "url": "https://openai.com/index/zico-kolter-joins-openais-board-of-directors",
        "content": "Zico Kolter Joins OpenAI’s Board of Directors\nWe’re strengthening our governance with expertise in AI safety and alignment. Zico will also join the Safety & Security Committee",
        "contentSnippet": "Zico Kolter Joins OpenAI’s Board of Directors\nWe’re strengthening our governance with expertise in AI safety and alignment. Zico will also join the Safety & Security Committee",
        "pubDate": "Thu, 08 Aug 2024 12:00:00 GMT",
        "isoDate": "2024-08-08T12:00:00.000Z",
        "source": "https://openai.com/index/zico-kolter-joins-openais-board-of-directors"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-41la4l",
        "title": "GPT-4o System Card External Testers Acknowledgements",
        "link": "https://openai.com/index/gpt-4o-system-card/external-testers-acknowledgements",
        "url": "https://openai.com/index/gpt-4o-system-card/external-testers-acknowledgements",
        "content": "GPT-4o system card external testers acknowledgements",
        "contentSnippet": "GPT-4o system card external testers acknowledgements",
        "pubDate": "Thu, 08 Aug 2024 10:00:00 GMT",
        "isoDate": "2024-08-08T10:00:00.000Z",
        "source": "https://openai.com/index/gpt-4o-system-card/external-testers-acknowledgements"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wnb0i2",
        "title": "GPT-4o System Card",
        "link": "https://openai.com/index/gpt-4o-system-card",
        "url": "https://openai.com/index/gpt-4o-system-card",
        "content": "This report outlines the safety work carried out prior to releasing GPT-4o including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
        "contentSnippet": "This report outlines the safety work carried out prior to releasing GPT-4o including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
        "pubDate": "Thu, 08 Aug 2024 00:00:00 GMT",
        "isoDate": "2024-08-08T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-4o-system-card"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-divyj8",
        "title": "Enabling a data-driven workforce",
        "link": "https://openai.com/business/enabling-a-data-driven-workforce-webinar",
        "url": "https://openai.com/business/enabling-a-data-driven-workforce-webinar",
        "content": "In this video, we share practical examples of how employees can use ChatGPT Enterprise to efficiently analyze data and uncover insights.",
        "contentSnippet": "In this video, we share practical examples of how employees can use ChatGPT Enterprise to efficiently analyze data and uncover insights.",
        "pubDate": "Thu, 08 Aug 2024 00:00:00 GMT",
        "isoDate": "2024-08-08T00:00:00.000Z",
        "source": "https://openai.com/business/enabling-a-data-driven-workforce-webinar"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-df8s7o",
        "title": "Pairing data with APIs to unlock customer value",
        "link": "https://openai.com/index/rakuten",
        "url": "https://openai.com/index/rakuten",
        "content": "Rakuten Pairs Data with AI to Unlock Customer Insights and Value",
        "contentSnippet": "Rakuten Pairs Data with AI to Unlock Customer Insights and Value",
        "pubDate": "Wed, 07 Aug 2024 16:00:00 GMT",
        "isoDate": "2024-08-07T16:00:00.000Z",
        "source": "https://openai.com/index/rakuten"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-lr7jk4",
        "title": "Introducing Structured Outputs in the API",
        "link": "https://openai.com/index/introducing-structured-outputs-in-the-api",
        "url": "https://openai.com/index/introducing-structured-outputs-in-the-api",
        "content": "We are introducing Structured Outputs in the API—model outputs now reliably adhere to developer-supplied JSON Schemas.",
        "contentSnippet": "We are introducing Structured Outputs in the API—model outputs now reliably adhere to developer-supplied JSON Schemas.",
        "pubDate": "Tue, 06 Aug 2024 10:00:00 GMT",
        "isoDate": "2024-08-06T10:00:00.000Z",
        "source": "https://openai.com/index/introducing-structured-outputs-in-the-api"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-kog352",
        "title": " A Primer on the EU AI Act: What It Means for AI Providers and Deployers ",
        "link": "https://openai.com/global-affairs/a-primer-on-the-eu-ai-act",
        "url": "https://openai.com/global-affairs/a-primer-on-the-eu-ai-act",
        "content": "We’re sharing a preliminary overview of the EU AI Act including upcoming deadlines and requirements, with a particular focus on prohibited and high-risk use cases",
        "contentSnippet": "We’re sharing a preliminary overview of the EU AI Act including upcoming deadlines and requirements, with a particular focus on prohibited and high-risk use cases",
        "pubDate": "Tue, 30 Jul 2024 00:00:00 GMT",
        "isoDate": "2024-07-30T00:00:00.000Z",
        "source": "https://openai.com/global-affairs/a-primer-on-the-eu-ai-act"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-bz1obk",
        "title": "SearchGPT is a prototype of new AI search features",
        "link": "https://openai.com/index/searchgpt-prototype",
        "url": "https://openai.com/index/searchgpt-prototype",
        "content": "We’re testing SearchGPT, a temporary prototype of new search features that give you fast and timely answers with clear and relevant sources.",
        "contentSnippet": "We’re testing SearchGPT, a temporary prototype of new search features that give you fast and timely answers with clear and relevant sources.",
        "pubDate": "Thu, 25 Jul 2024 00:00:00 GMT",
        "isoDate": "2024-07-25T00:00:00.000Z",
        "source": "https://openai.com/index/searchgpt-prototype"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-opz3n8",
        "title": "Improving Model Safety Behavior with Rule-Based Rewards",
        "link": "https://openai.com/index/improving-model-safety-behavior-with-rule-based-rewards",
        "url": "https://openai.com/index/improving-model-safety-behavior-with-rule-based-rewards",
        "content": "We've developed and applied a new method leveraging Rule-Based Rewards (RBRs) that aligns models to behave safely without extensive human data collection.",
        "contentSnippet": "We've developed and applied a new method leveraging Rule-Based Rewards (RBRs) that aligns models to behave safely without extensive human data collection.",
        "pubDate": "Wed, 24 Jul 2024 09:00:00 GMT",
        "isoDate": "2024-07-24T09:00:00.000Z",
        "source": "https://openai.com/index/improving-model-safety-behavior-with-rule-based-rewards"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-qng6ox",
        "title": "GPT-4o mini: advancing cost-efficient intelligence",
        "link": "https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence",
        "url": "https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence",
        "content": "Introducing the most cost-efficient small model in the market",
        "contentSnippet": "Introducing the most cost-efficient small model in the market",
        "pubDate": "Thu, 18 Jul 2024 10:00:00 GMT",
        "isoDate": "2024-07-18T10:00:00.000Z",
        "source": "https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-y6vd0q",
        "title": "New compliance and administrative tools for ChatGPT Enterprise",
        "link": "https://openai.com/index/new-tools-for-chatgpt-enterprise",
        "url": "https://openai.com/index/new-tools-for-chatgpt-enterprise",
        "content": "Compliance API integrations, SCIM, and GPT controls to support compliance programs, data security, and user access at scale",
        "contentSnippet": "Compliance API integrations, SCIM, and GPT controls to support compliance programs, data security, and user access at scale",
        "pubDate": "Thu, 18 Jul 2024 00:00:00 GMT",
        "isoDate": "2024-07-18T00:00:00.000Z",
        "source": "https://openai.com/index/new-tools-for-chatgpt-enterprise"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-kxnps3",
        "title": "Prover-Verifier Games improve legibility of language model outputs",
        "link": "https://openai.com/index/prover-verifier-games-improve-legibility",
        "url": "https://openai.com/index/prover-verifier-games-improve-legibility",
        "content": "Discover how prover-verifier games improve the legibility of language model outputs, making AI solutions clearer, easier to verify, and more trustworthy for both humans and machines.",
        "contentSnippet": "Discover how prover-verifier games improve the legibility of language model outputs, making AI solutions clearer, easier to verify, and more trustworthy for both humans and machines.",
        "pubDate": "Wed, 17 Jul 2024 10:00:00 GMT",
        "isoDate": "2024-07-17T10:00:00.000Z",
        "source": "https://openai.com/index/prover-verifier-games-improve-legibility"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-hi0yqt",
        "title": "OpenAI and Los Alamos National Laboratory announce research partnership",
        "link": "https://openai.com/index/openai-and-los-alamos-national-laboratory-work-together",
        "url": "https://openai.com/index/openai-and-los-alamos-national-laboratory-work-together",
        "content": "OpenAI and Los Alamos National Laboratory are working to develop safety evaluations to assess and measure biological capabilities and risks associated with frontier models.",
        "contentSnippet": "OpenAI and Los Alamos National Laboratory are working to develop safety evaluations to assess and measure biological capabilities and risks associated with frontier models.",
        "pubDate": "Wed, 10 Jul 2024 06:30:00 GMT",
        "isoDate": "2024-07-10T06:30:00.000Z",
        "source": "https://openai.com/index/openai-and-los-alamos-national-laboratory-work-together"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-83zrto",
        "title": "Finding GPT-4’s mistakes with GPT-4",
        "link": "https://openai.com/index/finding-gpt4s-mistakes-with-gpt-4",
        "url": "https://openai.com/index/finding-gpt4s-mistakes-with-gpt-4",
        "content": "CriticGPT, a model based on GPT-4, writes critiques of ChatGPT responses to help human trainers spot mistakes during RLHF",
        "contentSnippet": "CriticGPT, a model based on GPT-4, writes critiques of ChatGPT responses to help human trainers spot mistakes during RLHF",
        "pubDate": "Thu, 27 Jun 2024 10:00:00 GMT",
        "isoDate": "2024-06-27T10:00:00.000Z",
        "source": "https://openai.com/index/finding-gpt4s-mistakes-with-gpt-4"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-8a2nwu",
        "title": "Strategic Content Partnership with TIME",
        "link": "https://openai.com/index/strategic-content-partnership-with-time",
        "url": "https://openai.com/index/strategic-content-partnership-with-time",
        "content": "We’re partnering with TIME and its 101 years of archival content to enhance responses and provide links to stories on Time.com",
        "contentSnippet": "We’re partnering with TIME and its 101 years of archival content to enhance responses and provide links to stories on Time.com",
        "pubDate": "Thu, 27 Jun 2024 06:00:00 GMT",
        "isoDate": "2024-06-27T06:00:00.000Z",
        "source": "https://openai.com/index/strategic-content-partnership-with-time"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-v6v0cw",
        "title": "OpenAI acquires Rockset",
        "link": "https://openai.com/index/openai-acquires-rockset",
        "url": "https://openai.com/index/openai-acquires-rockset",
        "content": "OpenAI Acquires Rockset",
        "contentSnippet": "OpenAI Acquires Rockset",
        "pubDate": "Fri, 21 Jun 2024 08:00:00 GMT",
        "isoDate": "2024-06-21T08:00:00.000Z",
        "source": "https://openai.com/index/openai-acquires-rockset"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-z9dgp5",
        "title": "Empowering defenders through our Cybersecurity Grant Program",
        "link": "https://openai.com/index/empowering-defenders-through-our-cybersecurity-grant-program",
        "url": "https://openai.com/index/empowering-defenders-through-our-cybersecurity-grant-program",
        "content": "Highlighting innovative research and AI integration in cybersecurity\n\n",
        "contentSnippet": "Highlighting innovative research and AI integration in cybersecurity",
        "pubDate": "Thu, 20 Jun 2024 10:00:00 GMT",
        "isoDate": "2024-06-20T10:00:00.000Z",
        "source": "https://openai.com/index/empowering-defenders-through-our-cybersecurity-grant-program"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-sps2s3",
        "title": "Improved Techniques for Training Consistency Models",
        "link": "https://openai.com/index/improved-techniques-for-training-consistency-models",
        "url": "https://openai.com/index/improved-techniques-for-training-consistency-models",
        "content": "Consistency models are a nascent family of generative models that can sample high quality data in one step without the need for adversarial training. ",
        "contentSnippet": "Consistency models are a nascent family of generative models that can sample high quality data in one step without the need for adversarial training.",
        "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
        "isoDate": "2024-06-20T00:00:00.000Z",
        "source": "https://openai.com/index/improved-techniques-for-training-consistency-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7p2krc",
        "title": "A Holistic Approach to Undesired Content Detection in the Real World",
        "link": "https://openai.com/index/a-holistic-approach-to-undesired-content-detection-in-the-real-world",
        "url": "https://openai.com/index/a-holistic-approach-to-undesired-content-detection-in-the-real-world",
        "content": "We present a holistic approach to building a robust and useful natural language classification system for real-world content moderation.",
        "contentSnippet": "We present a holistic approach to building a robust and useful natural language classification system for real-world content moderation.",
        "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
        "isoDate": "2024-06-20T00:00:00.000Z",
        "source": "https://openai.com/index/a-holistic-approach-to-undesired-content-detection-in-the-real-world"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-qnkix5",
        "title": "Consistency Models",
        "link": "https://openai.com/index/consistency-models",
        "url": "https://openai.com/index/consistency-models",
        "content": "Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation.",
        "contentSnippet": "Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation.",
        "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
        "isoDate": "2024-06-20T00:00:00.000Z",
        "source": "https://openai.com/index/consistency-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-npeuw3",
        "title": "Surging developer productivity with custom GPTs",
        "link": "https://openai.com/index/paf",
        "url": "https://openai.com/index/paf",
        "content": "Paf adopted ChatGPT Enterprise across its entire company, with engineers using custom GPTs on a daily basis to speed up routine development tasks. Paf also integrated ChatGPT Enterprise into the grit:lab coding academy (gritlab.ax), training the next generation of software developers using an AI-augmented, systems-architecture mindset from day one. In addition to the wide range of use cases for developers and grit:lab students, 70% of Paf employees actively use ChatGPT Enterprise, spanning business teams like finance, HR, marketing, and customer support. ",
        "contentSnippet": "Paf adopted ChatGPT Enterprise across its entire company, with engineers using custom GPTs on a daily basis to speed up routine development tasks. Paf also integrated ChatGPT Enterprise into the grit:lab coding academy (gritlab.ax), training the next generation of software developers using an AI-augmented, systems-architecture mindset from day one. In addition to the wide range of use cases for developers and grit:lab students, 70% of Paf employees actively use ChatGPT Enterprise, spanning business teams like finance, HR, marketing, and customer support.",
        "pubDate": "Tue, 18 Jun 2024 08:45:00 GMT",
        "isoDate": "2024-06-18T08:45:00.000Z",
        "source": "https://openai.com/index/paf"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-okw4kn",
        "title": "Achieving 10x growth with agentic sales prospecting",
        "link": "https://openai.com/index/clay",
        "url": "https://openai.com/index/clay",
        "pubDate": "Tue, 18 Jun 2024 07:00:00 GMT",
        "isoDate": "2024-06-18T07:00:00.000Z",
        "source": "https://openai.com/index/clay"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ol3szi",
        "title": "Using GPT-4o reasoning to transform cancer care",
        "link": "https://openai.com/index/color-health",
        "url": "https://openai.com/index/color-health",
        "content": "Color Health is working with OpenAI to pioneer a new way of accelerating cancer patients’ access to treatment. Their new Cancer Copilot application uses GPT-4o to identify missing diagnostics and create tailored workup plans, enabling healthcare providers to make evidence-based decisions about cancer screening and treatment. ",
        "contentSnippet": "Color Health is working with OpenAI to pioneer a new way of accelerating cancer patients’ access to treatment. Their new Cancer Copilot application uses GPT-4o to identify missing diagnostics and create tailored workup plans, enabling healthcare providers to make evidence-based decisions about cancer screening and treatment.",
        "pubDate": "Mon, 17 Jun 2024 04:15:00 GMT",
        "isoDate": "2024-06-17T04:15:00.000Z",
        "source": "https://openai.com/index/color-health"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-5g6651",
        "title": "OpenAI appoints Retired U.S. Army General Paul M. Nakasone to Board of Directors ",
        "link": "https://openai.com/index/openai-appoints-retired-us-army-general",
        "url": "https://openai.com/index/openai-appoints-retired-us-army-general",
        "content": "Nakasone brings cybersecurity experience to growing Board of Directors; will join the Board’s Safety and Security Committee\n",
        "contentSnippet": "Nakasone brings cybersecurity experience to growing Board of Directors; will join the Board’s Safety and Security Committee",
        "pubDate": "Thu, 13 Jun 2024 14:00:00 GMT",
        "isoDate": "2024-06-13T14:00:00.000Z",
        "source": "https://openai.com/index/openai-appoints-retired-us-army-general"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-l5wp5g",
        "title": "OpenAI and Apple announce partnership",
        "link": "https://openai.com/index/openai-and-apple-announce-partnership",
        "url": "https://openai.com/index/openai-and-apple-announce-partnership",
        "content": "OpenAI and Apple announce partnership to integrate ChatGPT into Apple experiences. ",
        "contentSnippet": "OpenAI and Apple announce partnership to integrate ChatGPT into Apple experiences.",
        "pubDate": "Mon, 10 Jun 2024 11:55:00 GMT",
        "isoDate": "2024-06-10T11:55:00.000Z",
        "source": "https://openai.com/index/openai-and-apple-announce-partnership"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-trvu0o",
        "title": "OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)",
        "link": "https://openai.com/index/openai-welcomes-cfo-cpo",
        "url": "https://openai.com/index/openai-welcomes-cfo-cpo",
        "content": "OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)",
        "contentSnippet": "OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)",
        "pubDate": "Mon, 10 Jun 2024 10:30:00 GMT",
        "isoDate": "2024-06-10T10:30:00.000Z",
        "source": "https://openai.com/index/openai-welcomes-cfo-cpo"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-1d30zy",
        "title": "Expanding on how Voice Engine works and our safety research",
        "link": "https://openai.com/index/expanding-on-how-voice-engine-works-and-our-safety-research",
        "url": "https://openai.com/index/expanding-on-how-voice-engine-works-and-our-safety-research",
        "content": "Exploring the technology behind our text-to-speech model.",
        "contentSnippet": "Exploring the technology behind our text-to-speech model.",
        "pubDate": "Fri, 07 Jun 2024 17:45:00 GMT",
        "isoDate": "2024-06-07T17:45:00.000Z",
        "source": "https://openai.com/index/expanding-on-how-voice-engine-works-and-our-safety-research"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-u1c5kf",
        "title": "Improving India’s critical care infrastructure",
        "link": "https://openai.com/index/10bedicu",
        "url": "https://openai.com/index/10bedicu",
        "pubDate": "Thu, 06 Jun 2024 10:00:00 GMT",
        "isoDate": "2024-06-06T10:00:00.000Z",
        "source": "https://openai.com/index/10bedicu"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vp7x25",
        "title": "Extracting Concepts from GPT-4",
        "link": "https://openai.com/index/extracting-concepts-from-gpt-4",
        "url": "https://openai.com/index/extracting-concepts-from-gpt-4",
        "content": "Using new techniques for scaling sparse autoencoders, we automatically identified 16 million patterns in GPT-4's computations.",
        "contentSnippet": "Using new techniques for scaling sparse autoencoders, we automatically identified 16 million patterns in GPT-4's computations.",
        "pubDate": "Thu, 06 Jun 2024 00:00:00 GMT",
        "isoDate": "2024-06-06T00:00:00.000Z",
        "source": "https://openai.com/index/extracting-concepts-from-gpt-4"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-w4lely",
        "title": "Disrupting deceptive uses of AI by covert influence operations ",
        "link": "https://openai.com/index/disrupting-deceptive-uses-of-ai-by-covert-influence-operations",
        "url": "https://openai.com/index/disrupting-deceptive-uses-of-ai-by-covert-influence-operations",
        "content": "We’ve terminated accounts linked to covert influence operations; no significant audience increase due to our services. ",
        "contentSnippet": "We’ve terminated accounts linked to covert influence operations; no significant audience increase due to our services.",
        "pubDate": "Thu, 30 May 2024 10:00:00 GMT",
        "isoDate": "2024-05-30T10:00:00.000Z",
        "source": "https://openai.com/index/disrupting-deceptive-uses-of-ai-by-covert-influence-operations"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-61ky20",
        "title": "Introducing OpenAI for Nonprofits",
        "link": "https://openai.com/index/introducing-openai-for-nonprofits",
        "url": "https://openai.com/index/introducing-openai-for-nonprofits",
        "content": "We’re launching a new initiative to enhance the accessibility of our tools for nonprofit organizations, including discounted rates for ChatGPT Team and Enterprise.",
        "contentSnippet": "We’re launching a new initiative to enhance the accessibility of our tools for nonprofit organizations, including discounted rates for ChatGPT Team and Enterprise.",
        "pubDate": "Thu, 30 May 2024 07:00:00 GMT",
        "isoDate": "2024-05-30T07:00:00.000Z",
        "source": "https://openai.com/index/introducing-openai-for-nonprofits"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-a28tpp",
        "title": "OpenAI for Education",
        "link": "https://openai.com/index/introducing-chatgpt-edu",
        "url": "https://openai.com/index/introducing-chatgpt-edu",
        "content": "An affordable offering for universities to responsibly bring AI to campus.",
        "contentSnippet": "An affordable offering for universities to responsibly bring AI to campus.",
        "pubDate": "Thu, 30 May 2024 07:00:00 GMT",
        "isoDate": "2024-05-30T07:00:00.000Z",
        "source": "https://openai.com/index/introducing-chatgpt-edu"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-cyszrk",
        "title": "Automating customer support agents",
        "link": "https://openai.com/index/mavenagi",
        "url": "https://openai.com/index/mavenagi",
        "content": "MavenAGI is a new software company for the AI era. They recently launched an AI customer service agent, built on the flexibility of GPT-4, which a number of companies like Tripadvisor, Clickup and Rho are already using to save time and better serve their customers. ",
        "contentSnippet": "MavenAGI is a new software company for the AI era. They recently launched an AI customer service agent, built on the flexibility of GPT-4, which a number of companies like Tripadvisor, Clickup and Rho are already using to save time and better serve their customers.",
        "pubDate": "Wed, 29 May 2024 09:00:00 GMT",
        "isoDate": "2024-05-29T09:00:00.000Z",
        "source": "https://openai.com/index/mavenagi"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-czjxxd",
        "title": "The Newsroom AI Catalyst: a global program with WAN-IFRA",
        "link": "https://openai.com/index/newsroom-ai-catalyst-global-program-with-wan-ifra",
        "url": "https://openai.com/index/newsroom-ai-catalyst-global-program-with-wan-ifra",
        "content": "We’re collaborating with WAN-IFRA, the World Association of News Publishers, to launch a global accelerator program that will assist over 100 news publishers to explore and integrate AI in their newsroom. ",
        "contentSnippet": "We’re collaborating with WAN-IFRA, the World Association of News Publishers, to launch a global accelerator program that will assist over 100 news publishers to explore and integrate AI in their newsroom.",
        "pubDate": "Wed, 29 May 2024 08:00:00 GMT",
        "isoDate": "2024-05-29T08:00:00.000Z",
        "source": "https://openai.com/index/newsroom-ai-catalyst-global-program-with-wan-ifra"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-pq6ia1",
        "title": "Enhancing news in ChatGPT with The Atlantic ",
        "link": "https://openai.com/index/enhancing-news-in-chatgpt-with-the-atlantic",
        "url": "https://openai.com/index/enhancing-news-in-chatgpt-with-the-atlantic",
        "content": "The Atlantic is announcing a strategic content and product partnership with OpenAI, which positions The Atlantic as a premium news source within OpenAI. The Atlantic’s articles will be discoverable within OpenAI’s products, including ChatGPT, and as a partner, The Atlantic will help to shape how news is surfaced and presented in future real-time discovery products. ",
        "contentSnippet": "The Atlantic is announcing a strategic content and product partnership with OpenAI, which positions The Atlantic as a premium news source within OpenAI. The Atlantic’s articles will be discoverable within OpenAI’s products, including ChatGPT, and as a partner, The Atlantic will help to shape how news is surfaced and presented in future real-time discovery products.",
        "pubDate": "Wed, 29 May 2024 07:30:00 GMT",
        "isoDate": "2024-05-29T07:30:00.000Z",
        "source": "https://openai.com/index/enhancing-news-in-chatgpt-with-the-atlantic"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wx9w2s",
        "title": "A Content and Product Partnership with Vox Media",
        "link": "https://openai.com/index/a-content-and-product-partnership-with-vox-media",
        "url": "https://openai.com/index/a-content-and-product-partnership-with-vox-media",
        "content": "In a multi-faceted agreement, Vox Media’s content will enhance the output of OpenAI’s ChatGPT, and the company will build on OpenAI’s technology to develop products to better serve its audiences and advertisers.",
        "contentSnippet": "In a multi-faceted agreement, Vox Media’s content will enhance the output of OpenAI’s ChatGPT, and the company will build on OpenAI’s technology to develop products to better serve its audiences and advertisers.",
        "pubDate": "Wed, 29 May 2024 07:00:00 GMT",
        "isoDate": "2024-05-29T07:00:00.000Z",
        "source": "https://openai.com/index/a-content-and-product-partnership-with-vox-media"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-tb11bb",
        "title": "OpenAI Board Forms Safety and Security Committee",
        "link": "https://openai.com/index/openai-board-forms-safety-and-security-committee",
        "url": "https://openai.com/index/openai-board-forms-safety-and-security-committee",
        "pubDate": "Tue, 28 May 2024 03:00:00 GMT",
        "isoDate": "2024-05-28T03:00:00.000Z",
        "source": "https://openai.com/index/openai-board-forms-safety-and-security-committee"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vbegrx",
        "title": "A landmark multi-year global partnership with News Corp",
        "link": "https://openai.com/index/news-corp-and-openai-sign-landmark-multi-year-global-partnership",
        "url": "https://openai.com/index/news-corp-and-openai-sign-landmark-multi-year-global-partnership",
        "content": "Companies Join Forces to Enrich OpenAI’s Generative AI Products and Platforms with Premium Journalism\n",
        "contentSnippet": "Companies Join Forces to Enrich OpenAI’s Generative AI Products and Platforms with Premium Journalism",
        "pubDate": "Wed, 22 May 2024 13:15:00 GMT",
        "isoDate": "2024-05-22T13:15:00.000Z",
        "source": "https://openai.com/index/news-corp-and-openai-sign-landmark-multi-year-global-partnership"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9hqvpd",
        "title": "OpenAI safety practices",
        "link": "https://openai.com/index/openai-safety-update",
        "url": "https://openai.com/index/openai-safety-update",
        "content": "Artificial general intelligence has the potential to benefit nearly every aspect of our lives—so it must be developed and deployed responsibly.",
        "contentSnippet": "Artificial general intelligence has the potential to benefit nearly every aspect of our lives—so it must be developed and deployed responsibly.",
        "pubDate": "Tue, 21 May 2024 06:00:00 GMT",
        "isoDate": "2024-05-21T06:00:00.000Z",
        "source": "https://openai.com/index/openai-safety-update"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-j294t7",
        "title": "How the voices for ChatGPT were chosen",
        "link": "https://openai.com/index/how-the-voices-for-chatgpt-were-chosen",
        "url": "https://openai.com/index/how-the-voices-for-chatgpt-were-chosen",
        "content": "How the voices for ChatGPT were chosen\nWe worked with industry-leading casting and directing professionals to narrow down over 400 submissions before selecting the 5 voices.",
        "contentSnippet": "How the voices for ChatGPT were chosen\nWe worked with industry-leading casting and directing professionals to narrow down over 400 submissions before selecting the 5 voices.",
        "pubDate": "Sun, 19 May 2024 23:30:00 GMT",
        "isoDate": "2024-05-19T23:30:00.000Z",
        "source": "https://openai.com/index/how-the-voices-for-chatgpt-were-chosen"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-nhd7bh",
        "title": "Improvements to data analysis in ChatGPT",
        "link": "https://openai.com/index/improvements-to-data-analysis-in-chatgpt",
        "url": "https://openai.com/index/improvements-to-data-analysis-in-chatgpt",
        "content": "Improvements to data analysis in ChatGPT\nInteract with tables and charts and add files directly from Google Drive and Microsoft OneDrive.",
        "contentSnippet": "Improvements to data analysis in ChatGPT\nInteract with tables and charts and add files directly from Google Drive and Microsoft OneDrive.",
        "pubDate": "Thu, 16 May 2024 15:00:00 GMT",
        "isoDate": "2024-05-16T15:00:00.000Z",
        "source": "https://openai.com/index/improvements-to-data-analysis-in-chatgpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-93av0u",
        "title": "OpenAI and Reddit Partnership ",
        "link": "https://openai.com/index/openai-and-reddit-partnership",
        "url": "https://openai.com/index/openai-and-reddit-partnership",
        "content": "OpenAI and Reddit Partnership \nWe’re bringing Reddit’s unique content to ChatGPT and our products. ",
        "contentSnippet": "OpenAI and Reddit Partnership \nWe’re bringing Reddit’s unique content to ChatGPT and our products.",
        "pubDate": "Thu, 16 May 2024 13:30:00 GMT",
        "isoDate": "2024-05-16T13:30:00.000Z",
        "source": "https://openai.com/index/openai-and-reddit-partnership"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jcdwqr",
        "title": "Creating an AI-powered Magic Studio",
        "link": "https://openai.com/index/canva",
        "url": "https://openai.com/index/canva",
        "content": "Canva is a visual communication platform, enjoyed by more than 175 million people monthly to make presentations, videos, documents, websites, social media graphics and more. A majority of the world’s knowledge workers lack design training, but Canva’s combination of an easy-to-use interface, vast libraries, and time-saving tools allows anyone to create visually compelling content. ",
        "contentSnippet": "Canva is a visual communication platform, enjoyed by more than 175 million people monthly to make presentations, videos, documents, websites, social media graphics and more. A majority of the world’s knowledge workers lack design training, but Canva’s combination of an easy-to-use interface, vast libraries, and time-saving tools allows anyone to create visually compelling content.",
        "pubDate": "Thu, 16 May 2024 00:00:00 GMT",
        "isoDate": "2024-05-16T00:00:00.000Z",
        "source": "https://openai.com/index/canva"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6hro8",
        "title": "Ilya Sutskever to leave OpenAI, Jakub Pachocki announced as Chief Scientist",
        "link": "https://openai.com/index/jakub-pachocki-announced-as-chief-scientist",
        "url": "https://openai.com/index/jakub-pachocki-announced-as-chief-scientist",
        "pubDate": "Tue, 14 May 2024 18:00:00 GMT",
        "isoDate": "2024-05-14T18:00:00.000Z",
        "source": "https://openai.com/index/jakub-pachocki-announced-as-chief-scientist"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-pi9wt8",
        "title": "Collaborating with Carlyle to Chart the Future of Private Equity",
        "link": "https://openai.com/index/collaborating-with-carlyle-to-chart-the-future-of-private-equity",
        "url": "https://openai.com/index/collaborating-with-carlyle-to-chart-the-future-of-private-equity",
        "content": "Collaborating with Carlyle to Chart the Future of Private Equity",
        "contentSnippet": "Collaborating with Carlyle to Chart the Future of Private Equity",
        "pubDate": "Tue, 14 May 2024 08:00:00 GMT",
        "isoDate": "2024-05-14T08:00:00.000Z",
        "source": "https://openai.com/index/collaborating-with-carlyle-to-chart-the-future-of-private-equity"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jsufbk",
        "title": "Hello GPT-4o",
        "link": "https://openai.com/index/hello-gpt-4o",
        "url": "https://openai.com/index/hello-gpt-4o",
        "content": "We’re announcing GPT-4 Omni, our new flagship model which can reason across audio, vision, and text in real time.",
        "contentSnippet": "We’re announcing GPT-4 Omni, our new flagship model which can reason across audio, vision, and text in real time.",
        "pubDate": "Mon, 13 May 2024 10:05:00 GMT",
        "isoDate": "2024-05-13T10:05:00.000Z",
        "source": "https://openai.com/index/hello-gpt-4o"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9fca84",
        "title": "Introducing GPT-4o and more tools to ChatGPT free users",
        "link": "https://openai.com/index/gpt-4o-and-more-tools-to-chatgpt-free",
        "url": "https://openai.com/index/gpt-4o-and-more-tools-to-chatgpt-free",
        "content": "Introducing GPT-4o and more tools to ChatGPT free users\nWe are launching our newest flagship model and making more capabilities available for free in ChatGPT. ",
        "contentSnippet": "Introducing GPT-4o and more tools to ChatGPT free users\nWe are launching our newest flagship model and making more capabilities available for free in ChatGPT.",
        "pubDate": "Mon, 13 May 2024 10:00:00 GMT",
        "isoDate": "2024-05-13T10:00:00.000Z",
        "source": "https://openai.com/index/gpt-4o-and-more-tools-to-chatgpt-free"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-uoa8rz",
        "title": "Spring Update",
        "link": "https://openai.com/index/spring-update",
        "url": "https://openai.com/index/spring-update",
        "content": "Introducing GPT-4o and making more capabilities available for free in ChatGPT.",
        "contentSnippet": "Introducing GPT-4o and making more capabilities available for free in ChatGPT.",
        "pubDate": "Mon, 13 May 2024 10:00:00 GMT",
        "isoDate": "2024-05-13T10:00:00.000Z",
        "source": "https://openai.com/index/spring-update"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-bgru2k",
        "title": "Introducing the Model Spec",
        "link": "https://openai.com/index/introducing-the-model-spec",
        "url": "https://openai.com/index/introducing-the-model-spec",
        "pubDate": "Wed, 08 May 2024 00:00:00 GMT",
        "isoDate": "2024-05-08T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-the-model-spec"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-qvb0dg",
        "title": "Our approach to data and AI",
        "link": "https://openai.com/index/approach-to-data-and-ai",
        "url": "https://openai.com/index/approach-to-data-and-ai",
        "content": "Just over a year after launching ChatGPT, AI is changing how we live, work and learn. It’s also raised important conversations about data in the age of AI. More on our approach, a new Media Manager for creators and content owners, and where we’re headed.",
        "contentSnippet": "Just over a year after launching ChatGPT, AI is changing how we live, work and learn. It’s also raised important conversations about data in the age of AI. More on our approach, a new Media Manager for creators and content owners, and where we’re headed.",
        "pubDate": "Tue, 07 May 2024 00:00:00 GMT",
        "isoDate": "2024-05-07T00:00:00.000Z",
        "source": "https://openai.com/index/approach-to-data-and-ai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-aszrf",
        "title": "Understanding the source of what we see and hear online",
        "link": "https://openai.com/index/understanding-the-source-of-what-we-see-and-hear-online",
        "url": "https://openai.com/index/understanding-the-source-of-what-we-see-and-hear-online",
        "content": "Today we’re introducing new technology to help researchers identify content created by our tools and joining the Coalition for Content Provenance and Authenticity Steering Committee to promote industry standards. ",
        "contentSnippet": "Today we’re introducing new technology to help researchers identify content created by our tools and joining the Coalition for Content Provenance and Authenticity Steering Committee to promote industry standards.",
        "pubDate": "Tue, 07 May 2024 00:00:00 GMT",
        "isoDate": "2024-05-07T00:00:00.000Z",
        "source": "https://openai.com/index/understanding-the-source-of-what-we-see-and-hear-online"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-yg6gbe",
        "title": "API Partnership with Stack Overflow ",
        "link": "https://openai.com/index/api-partnership-with-stack-overflow",
        "url": "https://openai.com/index/api-partnership-with-stack-overflow",
        "content": "API Partnership with Stack Overflow \n\nStack Overflow and OpenAI today announced a new API partnership that will empower developers with the collective strengths of the world’s leading knowledge platform for highly technical content with the world’s most popular LLM models for AI development. ",
        "contentSnippet": "API Partnership with Stack Overflow \n\nStack Overflow and OpenAI today announced a new API partnership that will empower developers with the collective strengths of the world’s leading knowledge platform for highly technical content with the world’s most popular LLM models for AI development.",
        "pubDate": "Mon, 06 May 2024 00:00:00 GMT",
        "isoDate": "2024-05-06T00:00:00.000Z",
        "source": "https://openai.com/index/api-partnership-with-stack-overflow"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ybgccw",
        "title": "We’re bringing the Financial Times’ world-class journalism to ChatGPT",
        "link": "https://openai.com/index/content-partnership-with-financial-times",
        "url": "https://openai.com/index/content-partnership-with-financial-times",
        "content": "We will also collaborate on new AI experiences for FT readers.",
        "contentSnippet": "We will also collaborate on new AI experiences for FT readers.",
        "pubDate": "Mon, 29 Apr 2024 00:00:00 GMT",
        "isoDate": "2024-04-29T00:00:00.000Z",
        "source": "https://openai.com/index/content-partnership-with-financial-times"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-99m91y",
        "title": "Accelerating the development of life-saving treatments",
        "link": "https://openai.com/index/moderna",
        "url": "https://openai.com/index/moderna",
        "content": "Accelerating the development of life-saving treatments.",
        "contentSnippet": "Accelerating the development of life-saving treatments.",
        "pubDate": "Wed, 24 Apr 2024 00:00:00 GMT",
        "isoDate": "2024-04-24T00:00:00.000Z",
        "source": "https://openai.com/index/moderna"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6fbn9f",
        "title": "Introducing ChatGPT and Whisper APIs",
        "link": "https://openai.com/index/introducing-chatgpt-and-whisper-apis",
        "url": "https://openai.com/index/introducing-chatgpt-and-whisper-apis",
        "content": "Developers can now integrate ChatGPT and Whisper models into their apps and products through our API.",
        "contentSnippet": "Developers can now integrate ChatGPT and Whisper models into their apps and products through our API.",
        "pubDate": "Wed, 24 Apr 2024 00:00:00 GMT",
        "isoDate": "2024-04-24T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-chatgpt-and-whisper-apis"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vqoeka",
        "title": "GPT-4 API general availability and deprecation of older models in the Completions API",
        "link": "https://openai.com/index/gpt-4-api-general-availability",
        "url": "https://openai.com/index/gpt-4-api-general-availability",
        "content": "GPT-3.5 Turbo, DALL·E and Whisper APIs are also generally available, and we are releasing a deprecation plan for older models of the Completions API, which will retire at the beginning of 2024.",
        "contentSnippet": "GPT-3.5 Turbo, DALL·E and Whisper APIs are also generally available, and we are releasing a deprecation plan for older models of the Completions API, which will retire at the beginning of 2024.",
        "pubDate": "Wed, 24 Apr 2024 00:00:00 GMT",
        "isoDate": "2024-04-24T00:00:00.000Z",
        "source": "https://openai.com/index/gpt-4-api-general-availability"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-g1e4xc",
        "title": "Introducing more enterprise-grade features for API customers",
        "link": "https://openai.com/index/more-enterprise-grade-features-for-api-customers",
        "url": "https://openai.com/index/more-enterprise-grade-features-for-api-customers",
        "content": "Increasing enterprise support with more security features and controls, updates to our Assistants API, and tools to better manage costs.",
        "contentSnippet": "Increasing enterprise support with more security features and controls, updates to our Assistants API, and tools to better manage costs.",
        "pubDate": "Tue, 23 Apr 2024 00:00:00 GMT",
        "isoDate": "2024-04-23T00:00:00.000Z",
        "source": "https://openai.com/index/more-enterprise-grade-features-for-api-customers"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-em2z54",
        "title": "OpenAI’s commitment to child safety: adopting safety by design principles",
        "link": "https://openai.com/index/child-safety-adopting-sbd-principles",
        "url": "https://openai.com/index/child-safety-adopting-sbd-principles",
        "pubDate": "Tue, 23 Apr 2024 00:00:00 GMT",
        "isoDate": "2024-04-23T00:00:00.000Z",
        "source": "https://openai.com/index/child-safety-adopting-sbd-principles"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-cwh0bm",
        "title": "The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions",
        "link": "https://openai.com/index/the-instruction-hierarchy",
        "url": "https://openai.com/index/the-instruction-hierarchy",
        "content": "Today's LLMs are susceptible to prompt injections, jailbreaks, and other attacks that allow adversaries to overwrite a model's original instructions with their own malicious prompts.",
        "contentSnippet": "Today's LLMs are susceptible to prompt injections, jailbreaks, and other attacks that allow adversaries to overwrite a model's original instructions with their own malicious prompts.",
        "pubDate": "Fri, 19 Apr 2024 19:00:00 GMT",
        "isoDate": "2024-04-19T19:00:00.000Z",
        "source": "https://openai.com/index/the-instruction-hierarchy"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-qssmx8",
        "title": "Introducing OpenAI Japan",
        "link": "https://openai.com/index/introducing-openai-japan",
        "url": "https://openai.com/index/introducing-openai-japan",
        "content": "We are excited to announce our first office in Asia and we’re releasing a GPT-4 custom model optimized for the Japanese language.",
        "contentSnippet": "We are excited to announce our first office in Asia and we’re releasing a GPT-4 custom model optimized for the Japanese language.",
        "pubDate": "Sun, 14 Apr 2024 00:00:00 GMT",
        "isoDate": "2024-04-14T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-openai-japan"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-zd93i5",
        "title": "Klarna's AI assistant does the work of 700 full-time agents",
        "link": "https://openai.com/index/klarna",
        "url": "https://openai.com/index/klarna",
        "content": "Klarna is using AI to revolutionize personal shopping, customer service, and employee productivity.",
        "contentSnippet": "Klarna is using AI to revolutionize personal shopping, customer service, and employee productivity.",
        "pubDate": "Fri, 05 Apr 2024 00:00:00 GMT",
        "isoDate": "2024-04-05T00:00:00.000Z",
        "source": "https://openai.com/index/klarna"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-kkuq6a",
        "title": "Introducing improvements to the fine-tuning API and expanding our custom models program",
        "link": "https://openai.com/index/introducing-improvements-to-the-fine-tuning-api-and-expanding-our-custom-models-program",
        "url": "https://openai.com/index/introducing-improvements-to-the-fine-tuning-api-and-expanding-our-custom-models-program",
        "content": "We’re adding new features to help developers have more control over fine-tuning and announcing new ways to build custom models with OpenAI.",
        "contentSnippet": "We’re adding new features to help developers have more control over fine-tuning and announcing new ways to build custom models with OpenAI.",
        "pubDate": "Thu, 04 Apr 2024 00:00:00 GMT",
        "isoDate": "2024-04-04T00:00:00.000Z",
        "source": "https://openai.com/index/introducing-improvements-to-the-fine-tuning-api-and-expanding-our-custom-models-program"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xsdfc9",
        "title": "Customizing models for legal professionals",
        "link": "https://openai.com/index/harvey",
        "url": "https://openai.com/index/harvey",
        "content": "Harvey partners with OpenAI to build a custom-trained model for legal professionals.",
        "contentSnippet": "Harvey partners with OpenAI to build a custom-trained model for legal professionals.",
        "pubDate": "Tue, 02 Apr 2024 00:00:00 GMT",
        "isoDate": "2024-04-02T00:00:00.000Z",
        "source": "https://openai.com/index/harvey"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ekp7zs",
        "title": "Start using ChatGPT instantly",
        "link": "https://openai.com/index/start-using-chatgpt-instantly",
        "url": "https://openai.com/index/start-using-chatgpt-instantly",
        "content": "We’re making it easier for people to experience the benefits of AI without needing to sign up",
        "contentSnippet": "We’re making it easier for people to experience the benefits of AI without needing to sign up",
        "pubDate": "Mon, 01 Apr 2024 00:00:00 GMT",
        "isoDate": "2024-04-01T00:00:00.000Z",
        "source": "https://openai.com/index/start-using-chatgpt-instantly"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jjaozc",
        "title": "Reducing health insurance costs and improving care",
        "link": "https://openai.com/index/oscar",
        "url": "https://openai.com/index/oscar",
        "content": "Oscar brings AI to health insurance, reducing costs and improving patient care.",
        "contentSnippet": "Oscar brings AI to health insurance, reducing costs and improving patient care.",
        "pubDate": "Mon, 01 Apr 2024 00:00:00 GMT",
        "isoDate": "2024-04-01T00:00:00.000Z",
        "source": "https://openai.com/index/oscar"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-88vb3n",
        "title": "Navigating the challenges and opportunities of synthetic voices",
        "link": "https://openai.com/index/navigating-the-challenges-and-opportunities-of-synthetic-voices",
        "url": "https://openai.com/index/navigating-the-challenges-and-opportunities-of-synthetic-voices",
        "content": "We’re sharing lessons from a small scale preview of Voice Engine, a model for creating custom voices.",
        "contentSnippet": "We’re sharing lessons from a small scale preview of Voice Engine, a model for creating custom voices.",
        "pubDate": "Fri, 29 Mar 2024 00:00:00 GMT",
        "isoDate": "2024-03-29T00:00:00.000Z",
        "source": "https://openai.com/index/navigating-the-challenges-and-opportunities-of-synthetic-voices"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jp3on1",
        "title": "Making education data accessible",
        "link": "https://openai.com/index/zelma",
        "url": "https://openai.com/index/zelma",
        "content": "Zelma uses GPT-4 to make education data accessible.",
        "contentSnippet": "Zelma uses GPT-4 to make education data accessible.",
        "pubDate": "Thu, 28 Mar 2024 00:00:00 GMT",
        "isoDate": "2024-03-28T00:00:00.000Z",
        "source": "https://openai.com/index/zelma"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xaqln2",
        "title": "OpenAI’s comment to the NTIA on open model weights",
        "link": "https://openai.com/global-affairs/openai-s-comment-to-the-ntia-on-open-model-weights",
        "url": "https://openai.com/global-affairs/openai-s-comment-to-the-ntia-on-open-model-weights",
        "content": "OpenAI’s comment to the NTIA on open model weights\n\nThis comment was submitted by OpenAI in response to NTIA’s March 2024 Request for Information on Dual-Use Foundation Models with Widely Available Weights.",
        "contentSnippet": "OpenAI’s comment to the NTIA on open model weights\n\nThis comment was submitted by OpenAI in response to NTIA’s March 2024 Request for Information on Dual-Use Foundation Models with Widely Available Weights.",
        "pubDate": "Wed, 27 Mar 2024 00:00:00 GMT",
        "isoDate": "2024-03-27T00:00:00.000Z",
        "source": "https://openai.com/global-affairs/openai-s-comment-to-the-ntia-on-open-model-weights"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ie2yeb",
        "title": "Sora first impressions",
        "link": "https://openai.com/index/sora-first-impressions",
        "url": "https://openai.com/index/sora-first-impressions",
        "content": "Since we introduced Sora to the world last month, we’ve been working with artists to learn how Sora might aid in their creative process.",
        "contentSnippet": "Since we introduced Sora to the world last month, we’ve been working with artists to learn how Sora might aid in their creative process.",
        "pubDate": "Mon, 25 Mar 2024 00:00:00 GMT",
        "isoDate": "2024-03-25T00:00:00.000Z",
        "source": "https://openai.com/index/sora-first-impressions"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7z63z2",
        "title": "Embedding AI into developer software",
        "link": "https://openai.com/index/jetbrains",
        "url": "https://openai.com/index/jetbrains",
        "content": "JetBrains uses OpenAI’s API to build its fastest-growing product ever.",
        "contentSnippet": "JetBrains uses OpenAI’s API to build its fastest-growing product ever.",
        "pubDate": "Thu, 21 Mar 2024 07:00:00 GMT",
        "isoDate": "2024-03-21T07:00:00.000Z",
        "source": "https://openai.com/index/jetbrains"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-nepb0w",
        "title": "Building a data-driven, efficient culture with AI",
        "link": "https://openai.com/index/holiday-extras",
        "url": "https://openai.com/index/holiday-extras",
        "content": "Holiday Extras rolls out ChatGPT Enterprise across every team, boosting productivity by 500 hours weekly.",
        "contentSnippet": "Holiday Extras rolls out ChatGPT Enterprise across every team, boosting productivity by 500 hours weekly.",
        "pubDate": "Mon, 18 Mar 2024 07:00:00 GMT",
        "isoDate": "2024-03-18T07:00:00.000Z",
        "source": "https://openai.com/index/holiday-extras"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9jl9ef",
        "title": "Enterprise-ready trust and safety",
        "link": "https://openai.com/index/salesforce",
        "url": "https://openai.com/index/salesforce",
        "content": "Salesforce integrates OpenAI’s enterprise-ready LLMs to transform customer applications.",
        "contentSnippet": "Salesforce integrates OpenAI’s enterprise-ready LLMs to transform customer applications.",
        "pubDate": "Mon, 18 Mar 2024 07:00:00 GMT",
        "isoDate": "2024-03-18T07:00:00.000Z",
        "source": "https://openai.com/index/salesforce"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-nrssne",
        "title": "Reimagining the email experience with AI",
        "link": "https://openai.com/index/superhuman",
        "url": "https://openai.com/index/superhuman",
        "content": "Superhuman introduces a new era of email with OpenAI.",
        "contentSnippet": "Superhuman introduces a new era of email with OpenAI.",
        "pubDate": "Mon, 18 Mar 2024 07:00:00 GMT",
        "isoDate": "2024-03-18T07:00:00.000Z",
        "source": "https://openai.com/index/superhuman"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6qv73c",
        "title": "Saving lives with AI health coaching",
        "link": "https://openai.com/index/healthify",
        "url": "https://openai.com/index/healthify",
        "content": "Healthify collaborates with OpenAI to improve millions of lives with sustainable weight loss.",
        "contentSnippet": "Healthify collaborates with OpenAI to improve millions of lives with sustainable weight loss.",
        "pubDate": "Wed, 13 Mar 2024 07:00:00 GMT",
        "isoDate": "2024-03-13T07:00:00.000Z",
        "source": "https://openai.com/index/healthify"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-mdi9g8",
        "title": "Global news partnerships: Le Monde and Prisa Media",
        "link": "https://openai.com/index/global-news-partnerships-le-monde-and-prisa-media",
        "url": "https://openai.com/index/global-news-partnerships-le-monde-and-prisa-media",
        "content": "We have partnered with international news organizations Le Monde and Prisa Media to bring French and Spanish news content to ChatGPT.",
        "contentSnippet": "We have partnered with international news organizations Le Monde and Prisa Media to bring French and Spanish news content to ChatGPT.",
        "pubDate": "Wed, 13 Mar 2024 07:00:00 GMT",
        "isoDate": "2024-03-13T07:00:00.000Z",
        "source": "https://openai.com/index/global-news-partnerships-le-monde-and-prisa-media"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-svg60u",
        "title": "Review completed & Altman, Brockman to continue to lead OpenAI",
        "link": "https://openai.com/index/review-completed-altman-brockman-to-continue-to-lead-openai",
        "url": "https://openai.com/index/review-completed-altman-brockman-to-continue-to-lead-openai",
        "content": "New board members named and enhancements to the governance structure introduced ",
        "contentSnippet": "New board members named and enhancements to the governance structure introduced",
        "pubDate": "Fri, 08 Mar 2024 08:00:00 GMT",
        "isoDate": "2024-03-08T08:00:00.000Z",
        "source": "https://openai.com/index/review-completed-altman-brockman-to-continue-to-lead-openai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-qtup7n",
        "title": "OpenAI announces new members to board of directors",
        "link": "https://openai.com/index/openai-announces-new-members-to-board-of-directors",
        "url": "https://openai.com/index/openai-announces-new-members-to-board-of-directors",
        "content": "Dr. Sue Desmond-Hellmann, Nicole Seligman, Fidji Simo join; Sam Altman rejoins board",
        "contentSnippet": "Dr. Sue Desmond-Hellmann, Nicole Seligman, Fidji Simo join; Sam Altman rejoins board",
        "pubDate": "Fri, 08 Mar 2024 08:00:00 GMT",
        "isoDate": "2024-03-08T08:00:00.000Z",
        "source": "https://openai.com/index/openai-announces-new-members-to-board-of-directors"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-qg0h37",
        "title": "Using AI to improve patient access to clinical trials",
        "link": "https://openai.com/index/paradigm",
        "url": "https://openai.com/index/paradigm",
        "content": "Paradigm uses OpenAI’s API to improve patient access to clinical trials.",
        "contentSnippet": "Paradigm uses OpenAI’s API to improve patient access to clinical trials.",
        "pubDate": "Wed, 06 Mar 2024 08:00:00 GMT",
        "isoDate": "2024-03-06T08:00:00.000Z",
        "source": "https://openai.com/index/paradigm"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-b60a2p",
        "title": "Sparking a more productive company with ChatGPT Enterprise",
        "link": "https://openai.com/index/match-group",
        "url": "https://openai.com/index/match-group",
        "content": "Match Group uses ChatGPT Enterprise to spark creativity and impact.",
        "contentSnippet": "Match Group uses ChatGPT Enterprise to spark creativity and impact.",
        "pubDate": "Wed, 06 Mar 2024 08:00:00 GMT",
        "isoDate": "2024-03-06T08:00:00.000Z",
        "source": "https://openai.com/index/match-group"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-myma4e",
        "title": "Improving health literacy and patient well-being",
        "link": "https://openai.com/index/lifespan",
        "url": "https://openai.com/index/lifespan",
        "content": "Lifespan uses GPT-4 to radically improve health literacy and patient outcomes.",
        "contentSnippet": "Lifespan uses GPT-4 to radically improve health literacy and patient outcomes.",
        "pubDate": "Wed, 06 Mar 2024 08:00:00 GMT",
        "isoDate": "2024-03-06T08:00:00.000Z",
        "source": "https://openai.com/index/lifespan"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-l8wflo",
        "title": "OpenAI and Elon Musk",
        "link": "https://openai.com/index/openai-elon-musk",
        "url": "https://openai.com/index/openai-elon-musk",
        "content": "We are dedicated to the OpenAI mission and have pursued it every step of the way.",
        "contentSnippet": "We are dedicated to the OpenAI mission and have pursued it every step of the way.",
        "pubDate": "Tue, 05 Mar 2024 08:00:00 GMT",
        "isoDate": "2024-03-05T08:00:00.000Z",
        "source": "https://openai.com/index/openai-elon-musk"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xr4est",
        "title": "Video generation models as world simulators",
        "link": "https://openai.com/index/video-generation-models-as-world-simulators",
        "url": "https://openai.com/index/video-generation-models-as-world-simulators",
        "content": "We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.",
        "contentSnippet": "We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.",
        "pubDate": "Thu, 15 Feb 2024 08:00:00 GMT",
        "isoDate": "2024-02-15T08:00:00.000Z",
        "source": "https://openai.com/index/video-generation-models-as-world-simulators"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-cpsce4",
        "title": "Disrupting malicious uses of AI by state-affiliated threat actors",
        "link": "https://openai.com/index/disrupting-malicious-uses-of-ai-by-state-affiliated-threat-actors",
        "url": "https://openai.com/index/disrupting-malicious-uses-of-ai-by-state-affiliated-threat-actors",
        "content": "We terminated accounts associated with state-affiliated threat actors. Our findings show our models offer only limited, incremental capabilities for malicious cybersecurity tasks.",
        "contentSnippet": "We terminated accounts associated with state-affiliated threat actors. Our findings show our models offer only limited, incremental capabilities for malicious cybersecurity tasks.",
        "pubDate": "Wed, 14 Feb 2024 08:00:00 GMT",
        "isoDate": "2024-02-14T08:00:00.000Z",
        "source": "https://openai.com/index/disrupting-malicious-uses-of-ai-by-state-affiliated-threat-actors"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-1f9gb3",
        "title": "Memory and new controls for ChatGPT",
        "link": "https://openai.com/index/memory-and-new-controls-for-chatgpt",
        "url": "https://openai.com/index/memory-and-new-controls-for-chatgpt",
        "content": "We’re testing the ability for ChatGPT to remember things you discuss to make future chats more helpful. You’re in control of ChatGPT’s memory.",
        "contentSnippet": "We’re testing the ability for ChatGPT to remember things you discuss to make future chats more helpful. You’re in control of ChatGPT’s memory.",
        "pubDate": "Tue, 13 Feb 2024 00:00:00 GMT",
        "isoDate": "2024-02-13T00:00:00.000Z",
        "source": "https://openai.com/index/memory-and-new-controls-for-chatgpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-knzst7",
        "title": "Response to NIST Executive Order on AI",
        "link": "https://openai.com/global-affairs/response-to-nist-executive-order-on-ai",
        "url": "https://openai.com/global-affairs/response-to-nist-executive-order-on-ai",
        "content": "The National Institute of Standards and Technology (NIST) request for information related to its assignments under sections 4.1, 4.5, and 11 of the Executive Order Concerning Artificial Intelligence",
        "contentSnippet": "The National Institute of Standards and Technology (NIST) request for information related to its assignments under sections 4.1, 4.5, and 11 of the Executive Order Concerning Artificial Intelligence",
        "pubDate": "Fri, 02 Feb 2024 00:00:00 GMT",
        "isoDate": "2024-02-02T00:00:00.000Z",
        "source": "https://openai.com/global-affairs/response-to-nist-executive-order-on-ai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xuggf4",
        "title": "Building an early warning system for LLM-aided biological threat creation",
        "link": "https://openai.com/index/building-an-early-warning-system-for-llm-aided-biological-threat-creation",
        "url": "https://openai.com/index/building-an-early-warning-system-for-llm-aided-biological-threat-creation",
        "content": "We’re developing a blueprint for evaluating the risk that a large language model (LLM) could aid someone in creating a biological threat. In an evaluation involving both biology experts and students, we found that GPT-4 provides at most a mild uplift in biological threat creation accuracy. While this uplift is not large enough to be conclusive, our finding is a starting point for continued research and community deliberation. ",
        "contentSnippet": "We’re developing a blueprint for evaluating the risk that a large language model (LLM) could aid someone in creating a biological threat. In an evaluation involving both biology experts and students, we found that GPT-4 provides at most a mild uplift in biological threat creation accuracy. While this uplift is not large enough to be conclusive, our finding is a starting point for continued research and community deliberation.",
        "pubDate": "Wed, 31 Jan 2024 08:00:00 GMT",
        "isoDate": "2024-01-31T08:00:00.000Z",
        "source": "https://openai.com/index/building-an-early-warning-system-for-llm-aided-biological-threat-creation"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-o3xzax",
        "title": "New embedding models and API updates",
        "link": "https://openai.com/index/new-embedding-models-and-api-updates",
        "url": "https://openai.com/index/new-embedding-models-and-api-updates",
        "content": "We are launching a new generation of embedding models, new GPT-4 Turbo and moderation models, new API usage management tools, and soon, lower pricing on GPT-3.5 Turbo.",
        "contentSnippet": "We are launching a new generation of embedding models, new GPT-4 Turbo and moderation models, new API usage management tools, and soon, lower pricing on GPT-3.5 Turbo.",
        "pubDate": "Thu, 25 Jan 2024 08:00:00 GMT",
        "isoDate": "2024-01-25T08:00:00.000Z",
        "source": "https://openai.com/index/new-embedding-models-and-api-updates"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-v57zfg",
        "title": "Democratic inputs to AI grant program: lessons learned and implementation plans",
        "link": "https://openai.com/index/democratic-inputs-to-ai-grant-program-update",
        "url": "https://openai.com/index/democratic-inputs-to-ai-grant-program-update",
        "content": "We funded 10 teams from around the world to design ideas and tools to collectively govern AI. We summarize the innovations, outline our learnings, and call for researchers and engineers to join us as we continue this work.",
        "contentSnippet": "We funded 10 teams from around the world to design ideas and tools to collectively govern AI. We summarize the innovations, outline our learnings, and call for researchers and engineers to join us as we continue this work.",
        "pubDate": "Tue, 16 Jan 2024 08:00:00 GMT",
        "isoDate": "2024-01-16T08:00:00.000Z",
        "source": "https://openai.com/index/democratic-inputs-to-ai-grant-program-update"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-notlzf",
        "title": "How OpenAI is approaching 2024 worldwide elections",
        "link": "https://openai.com/index/how-openai-is-approaching-2024-worldwide-elections",
        "url": "https://openai.com/index/how-openai-is-approaching-2024-worldwide-elections",
        "content": "We’re working to prevent abuse, provide transparency on AI-generated content, and improve access to accurate voting information.",
        "contentSnippet": "We’re working to prevent abuse, provide transparency on AI-generated content, and improve access to accurate voting information.",
        "pubDate": "Mon, 15 Jan 2024 08:00:00 GMT",
        "isoDate": "2024-01-15T08:00:00.000Z",
        "source": "https://openai.com/index/how-openai-is-approaching-2024-worldwide-elections"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-v5d6qy",
        "title": "Building agricultural database for farmers",
        "link": "https://openai.com/index/digital-green",
        "url": "https://openai.com/index/digital-green",
        "content": "Digital Green uses OpenAI to increase farmer income.",
        "contentSnippet": "Digital Green uses OpenAI to increase farmer income.",
        "pubDate": "Fri, 12 Jan 2024 08:00:00 GMT",
        "isoDate": "2024-01-12T08:00:00.000Z",
        "source": "https://openai.com/index/digital-green"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-rsvs2o",
        "title": "Introducing ChatGPT Team",
        "link": "https://openai.com/index/introducing-chatgpt-team",
        "url": "https://openai.com/index/introducing-chatgpt-team",
        "content": "We’re launching a new ChatGPT plan for teams of all sizes, which provides a secure, collaborative workspace to get the most out of ChatGPT at work.",
        "contentSnippet": "We’re launching a new ChatGPT plan for teams of all sizes, which provides a secure, collaborative workspace to get the most out of ChatGPT at work.",
        "pubDate": "Wed, 10 Jan 2024 08:00:00 GMT",
        "isoDate": "2024-01-10T08:00:00.000Z",
        "source": "https://openai.com/index/introducing-chatgpt-team"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jvklmi",
        "title": "Introducing the GPT Store",
        "link": "https://openai.com/index/introducing-the-gpt-store",
        "url": "https://openai.com/index/introducing-the-gpt-store",
        "content": "We’re launching the GPT Store to help you find useful and popular custom versions of ChatGPT.",
        "contentSnippet": "We’re launching the GPT Store to help you find useful and popular custom versions of ChatGPT.",
        "pubDate": "Wed, 10 Jan 2024 08:00:00 GMT",
        "isoDate": "2024-01-10T08:00:00.000Z",
        "source": "https://openai.com/index/introducing-the-gpt-store"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-m4523",
        "title": "OpenAI and journalism",
        "link": "https://openai.com/index/openai-and-journalism",
        "url": "https://openai.com/index/openai-and-journalism",
        "content": "We support journalism, partner with news organizations, and believe The New York Times lawsuit is without merit.",
        "contentSnippet": "We support journalism, partner with news organizations, and believe The New York Times lawsuit is without merit.",
        "pubDate": "Mon, 08 Jan 2024 08:00:00 GMT",
        "isoDate": "2024-01-08T08:00:00.000Z",
        "source": "https://openai.com/index/openai-and-journalism"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jnia3r",
        "title": "Delivering LLM-powered health solutions",
        "link": "https://openai.com/index/whoop",
        "url": "https://openai.com/index/whoop",
        "content": "WHOOP delivers personalized fitness and health coaching with GPT-4.",
        "contentSnippet": "WHOOP delivers personalized fitness and health coaching with GPT-4.",
        "pubDate": "Thu, 04 Jan 2024 08:00:00 GMT",
        "isoDate": "2024-01-04T08:00:00.000Z",
        "source": "https://openai.com/index/whoop"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-eynsce",
        "title": "Increasing accuracy of pediatric visit notes",
        "link": "https://openai.com/index/summer-health",
        "url": "https://openai.com/index/summer-health",
        "content": "Summer Health reimagines pediatric doctor’s visits with OpenAI.",
        "contentSnippet": "Summer Health reimagines pediatric doctor’s visits with OpenAI.",
        "pubDate": "Thu, 14 Dec 2023 08:00:00 GMT",
        "isoDate": "2023-12-14T08:00:00.000Z",
        "source": "https://openai.com/index/summer-health"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-e61t44",
        "title": "Practices for Governing Agentic AI Systems",
        "link": "https://openai.com/index/practices-for-governing-agentic-ai-systems",
        "url": "https://openai.com/index/practices-for-governing-agentic-ai-systems",
        "pubDate": "Thu, 14 Dec 2023 08:00:00 GMT",
        "isoDate": "2023-12-14T08:00:00.000Z",
        "source": "https://openai.com/index/practices-for-governing-agentic-ai-systems"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wfevyz",
        "title": "Superalignment Fast Grants",
        "link": "https://openai.com/index/superalignment-fast-grants",
        "url": "https://openai.com/index/superalignment-fast-grants",
        "content": "We’re launching $10M in grants to support technical research towards the alignment and safety of superhuman AI systems, including weak-to-strong generalization, interpretability, scalable oversight, and more.",
        "contentSnippet": "We’re launching $10M in grants to support technical research towards the alignment and safety of superhuman AI systems, including weak-to-strong generalization, interpretability, scalable oversight, and more.",
        "pubDate": "Thu, 14 Dec 2023 08:00:00 GMT",
        "isoDate": "2023-12-14T08:00:00.000Z",
        "source": "https://openai.com/index/superalignment-fast-grants"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-rpj31",
        "title": "Weak-to-strong generalization",
        "link": "https://openai.com/index/weak-to-strong-generalization",
        "url": "https://openai.com/index/weak-to-strong-generalization",
        "content": "We present a new research direction for superalignment, together with promising initial results: can we leverage the generalization properties of deep learning to control strong models with weak supervisors? ",
        "contentSnippet": "We present a new research direction for superalignment, together with promising initial results: can we leverage the generalization properties of deep learning to control strong models with weak supervisors?",
        "pubDate": "Thu, 14 Dec 2023 00:00:00 GMT",
        "isoDate": "2023-12-14T00:00:00.000Z",
        "source": "https://openai.com/index/weak-to-strong-generalization"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-gq3m6g",
        "title": "Partnership with Axel Springer to deepen beneficial use of AI in journalism",
        "link": "https://openai.com/index/axel-springer-partnership",
        "url": "https://openai.com/index/axel-springer-partnership",
        "content": "Axel Springer is the first publishing house globally to partner with us on a deeper integration of journalism in AI technologies.",
        "contentSnippet": "Axel Springer is the first publishing house globally to partner with us on a deeper integration of journalism in AI technologies.",
        "pubDate": "Wed, 13 Dec 2023 08:00:00 GMT",
        "isoDate": "2023-12-13T08:00:00.000Z",
        "source": "https://openai.com/index/axel-springer-partnership"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-geqp2n",
        "title": "Sam Altman returns as CEO, OpenAI has a new initial board",
        "link": "https://openai.com/index/sam-altman-returns-as-ceo-openai-has-a-new-initial-board",
        "url": "https://openai.com/index/sam-altman-returns-as-ceo-openai-has-a-new-initial-board",
        "content": "Mira Murati as CTO, Greg Brockman returns as President. Read messages from CEO Sam Altman and board chair Bret Taylor.",
        "contentSnippet": "Mira Murati as CTO, Greg Brockman returns as President. Read messages from CEO Sam Altman and board chair Bret Taylor.",
        "pubDate": "Wed, 29 Nov 2023 08:00:00 GMT",
        "isoDate": "2023-11-29T08:00:00.000Z",
        "source": "https://openai.com/index/sam-altman-returns-as-ceo-openai-has-a-new-initial-board"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-q9g31l",
        "title": "OpenAI announces leadership transition",
        "link": "https://openai.com/index/openai-announces-leadership-transition",
        "url": "https://openai.com/index/openai-announces-leadership-transition",
        "pubDate": "Fri, 17 Nov 2023 08:00:00 GMT",
        "isoDate": "2023-11-17T08:00:00.000Z",
        "source": "https://openai.com/index/openai-announces-leadership-transition"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-5oyp4q",
        "title": "OpenAI Data Partnerships",
        "link": "https://openai.com/index/data-partnerships",
        "url": "https://openai.com/index/data-partnerships",
        "content": "Working together to create open-source and private datasets for AI training.",
        "contentSnippet": "Working together to create open-source and private datasets for AI training.",
        "pubDate": "Thu, 09 Nov 2023 08:00:00 GMT",
        "isoDate": "2023-11-09T08:00:00.000Z",
        "source": "https://openai.com/index/data-partnerships"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-inbpgx",
        "title": "Introducing GPTs",
        "link": "https://openai.com/index/introducing-gpts",
        "url": "https://openai.com/index/introducing-gpts",
        "content": "You can now create custom versions of ChatGPT that combine instructions, extra knowledge, and any combination of skills.",
        "contentSnippet": "You can now create custom versions of ChatGPT that combine instructions, extra knowledge, and any combination of skills.",
        "pubDate": "Mon, 06 Nov 2023 08:00:00 GMT",
        "isoDate": "2023-11-06T08:00:00.000Z",
        "source": "https://openai.com/index/introducing-gpts"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-q9pbtv",
        "title": "New models and developer products announced at DevDay",
        "link": "https://openai.com/index/new-models-and-developer-products-announced-at-devday",
        "url": "https://openai.com/index/new-models-and-developer-products-announced-at-devday",
        "content": "GPT-4 Turbo with 128K context and lower prices, the new Assistants API, GPT-4 Turbo with Vision, DALL·E 3 API, and more.",
        "contentSnippet": "GPT-4 Turbo with 128K context and lower prices, the new Assistants API, GPT-4 Turbo with Vision, DALL·E 3 API, and more.",
        "pubDate": "Mon, 06 Nov 2023 08:00:00 GMT",
        "isoDate": "2023-11-06T08:00:00.000Z",
        "source": "https://openai.com/index/new-models-and-developer-products-announced-at-devday"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-g6ljl9",
        "title": "OpenAI’s Approach to Frontier Risk",
        "link": "https://openai.com/global-affairs/our-approach-to-frontier-risk",
        "url": "https://openai.com/global-affairs/our-approach-to-frontier-risk",
        "content": "An Update for the UK AI Safety Summit",
        "contentSnippet": "An Update for the UK AI Safety Summit",
        "pubDate": "Thu, 26 Oct 2023 07:00:00 GMT",
        "isoDate": "2023-10-26T07:00:00.000Z",
        "source": "https://openai.com/global-affairs/our-approach-to-frontier-risk"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-hmu2io",
        "title": "Frontier risk and preparedness",
        "link": "https://openai.com/index/frontier-risk-and-preparedness",
        "url": "https://openai.com/index/frontier-risk-and-preparedness",
        "content": "To support the safety of highly-capable AI systems, we are developing our approach to catastrophic risk preparedness, including building a Preparedness team and launching a challenge. ",
        "contentSnippet": "To support the safety of highly-capable AI systems, we are developing our approach to catastrophic risk preparedness, including building a Preparedness team and launching a challenge.",
        "pubDate": "Thu, 26 Oct 2023 07:00:00 GMT",
        "isoDate": "2023-10-26T07:00:00.000Z",
        "source": "https://openai.com/index/frontier-risk-and-preparedness"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-gpqfny",
        "title": "Frontier Model Forum updates",
        "link": "https://openai.com/index/frontier-model-forum-updates",
        "url": "https://openai.com/index/frontier-model-forum-updates",
        "content": "Together with Anthropic, Google, and Microsoft, we’re announcing the new Executive Director of the Frontier Model Forum and a new $10 million AI Safety Fund.",
        "contentSnippet": "Together with Anthropic, Google, and Microsoft, we’re announcing the new Executive Director of the Frontier Model Forum and a new $10 million AI Safety Fund.",
        "pubDate": "Wed, 25 Oct 2023 07:00:00 GMT",
        "isoDate": "2023-10-25T07:00:00.000Z",
        "source": "https://openai.com/index/frontier-model-forum-updates"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ng3d58",
        "title": "DALL·E 3 is now available in ChatGPT Plus and Enterprise",
        "link": "https://openai.com/index/dall-e-3-is-now-available-in-chatgpt-plus-and-enterprise",
        "url": "https://openai.com/index/dall-e-3-is-now-available-in-chatgpt-plus-and-enterprise",
        "content": "We developed a safety mitigation stack to ready DALL·E 3 for wider release and are sharing updates on our provenance research.",
        "contentSnippet": "We developed a safety mitigation stack to ready DALL·E 3 for wider release and are sharing updates on our provenance research.",
        "pubDate": "Thu, 19 Oct 2023 07:00:00 GMT",
        "isoDate": "2023-10-19T07:00:00.000Z",
        "source": "https://openai.com/index/dall-e-3-is-now-available-in-chatgpt-plus-and-enterprise"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wg23b1",
        "title": "Building AI-powered apps for business",
        "link": "https://openai.com/index/retool",
        "url": "https://openai.com/index/retool",
        "content": "Retool uses GPT-4 to give businesses a fast, secure way to build AI-powered apps.",
        "contentSnippet": "Retool uses GPT-4 to give businesses a fast, secure way to build AI-powered apps.",
        "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
        "isoDate": "2023-10-11T07:00:00.000Z",
        "source": "https://openai.com/index/retool"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-t9w9mk",
        "title": "OpenAI’s technology explained",
        "link": "https://openai.com/global-affairs/openai-technology-explained",
        "url": "https://openai.com/global-affairs/openai-technology-explained",
        "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
        "isoDate": "2023-10-11T07:00:00.000Z",
        "source": "https://openai.com/global-affairs/openai-technology-explained"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-43luve",
        "title": "Evolving online forms into dynamic data",
        "link": "https://openai.com/index/typeform",
        "url": "https://openai.com/index/typeform",
        "content": "Typeform evolves online forms into dynamic and conversational data collection experiences with GPT-3.5 and GPT-4.",
        "contentSnippet": "Typeform evolves online forms into dynamic and conversational data collection experiences with GPT-3.5 and GPT-4.",
        "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
        "isoDate": "2023-10-11T07:00:00.000Z",
        "source": "https://openai.com/index/typeform"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-1y9t3g",
        "title": "Simplifying contract reviews with AI",
        "link": "https://openai.com/index/ironclad",
        "url": "https://openai.com/index/ironclad",
        "content": "Ironclad uses GPT-4 to simplify the contract review process.",
        "contentSnippet": "Ironclad uses GPT-4 to simplify the contract review process.",
        "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
        "isoDate": "2023-10-11T07:00:00.000Z",
        "source": "https://openai.com/index/ironclad"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7gs44",
        "title": "DALL·E 3 system card",
        "link": "https://openai.com/index/dall-e-3-system-card",
        "url": "https://openai.com/index/dall-e-3-system-card",
        "pubDate": "Tue, 03 Oct 2023 07:00:00 GMT",
        "isoDate": "2023-10-03T07:00:00.000Z",
        "source": "https://openai.com/index/dall-e-3-system-card"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-s194bh",
        "title": "ChatGPT can now see, hear, and speak",
        "link": "https://openai.com/index/chatgpt-can-now-see-hear-and-speak",
        "url": "https://openai.com/index/chatgpt-can-now-see-hear-and-speak",
        "content": "We are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what you’re talking about.",
        "contentSnippet": "We are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what you’re talking about.",
        "pubDate": "Mon, 25 Sep 2023 07:00:00 GMT",
        "isoDate": "2023-09-25T07:00:00.000Z",
        "source": "https://openai.com/index/chatgpt-can-now-see-hear-and-speak"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-4f0j0d",
        "title": "GPT-4V(ision) system card",
        "link": "https://openai.com/index/gpt-4v-system-card",
        "url": "https://openai.com/index/gpt-4v-system-card",
        "pubDate": "Mon, 25 Sep 2023 07:00:00 GMT",
        "isoDate": "2023-09-25T07:00:00.000Z",
        "source": "https://openai.com/index/gpt-4v-system-card"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-iq4h76",
        "title": "OpenAI Red Teaming Network",
        "link": "https://openai.com/index/red-teaming-network",
        "url": "https://openai.com/index/red-teaming-network",
        "content": "We’re announcing an open call for the OpenAI Red Teaming Network and invite domain experts interested in improving the safety of OpenAI’s models to join our efforts.",
        "contentSnippet": "We’re announcing an open call for the OpenAI Red Teaming Network and invite domain experts interested in improving the safety of OpenAI’s models to join our efforts.",
        "pubDate": "Tue, 19 Sep 2023 07:00:00 GMT",
        "isoDate": "2023-09-19T07:00:00.000Z",
        "source": "https://openai.com/index/red-teaming-network"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-j16cwi",
        "title": "Introducing OpenAI Dublin",
        "link": "https://openai.com/index/introducing-openai-dublin",
        "url": "https://openai.com/index/introducing-openai-dublin",
        "content": "We’re growing our presence in Europe with an office in Dublin, Ireland.",
        "contentSnippet": "We’re growing our presence in Europe with an office in Dublin, Ireland.",
        "pubDate": "Wed, 13 Sep 2023 07:00:00 GMT",
        "isoDate": "2023-09-13T07:00:00.000Z",
        "source": "https://openai.com/index/introducing-openai-dublin"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-aq3tdf",
        "title": "Join us for OpenAI’s first developer conference on November 6 in San Francisco",
        "link": "https://openai.com/index/announcing-openai-devday",
        "url": "https://openai.com/index/announcing-openai-devday",
        "content": "Developer registration for in-person attendance will open in the coming weeks and developers everywhere will be able to livestream the keynote.",
        "contentSnippet": "Developer registration for in-person attendance will open in the coming weeks and developers everywhere will be able to livestream the keynote.",
        "pubDate": "Wed, 06 Sep 2023 07:00:00 GMT",
        "isoDate": "2023-09-06T07:00:00.000Z",
        "source": "https://openai.com/index/announcing-openai-devday"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-4qhhmh",
        "title": "Teaching with AI",
        "link": "https://openai.com/index/teaching-with-ai",
        "url": "https://openai.com/index/teaching-with-ai",
        "content": "We’re releasing a guide for teachers using ChatGPT in their classroom—including suggested prompts, an explanation of how ChatGPT works and its limitations, the efficacy of AI detectors, and bias. ",
        "contentSnippet": "We’re releasing a guide for teachers using ChatGPT in their classroom—including suggested prompts, an explanation of how ChatGPT works and its limitations, the efficacy of AI detectors, and bias.",
        "pubDate": "Thu, 31 Aug 2023 07:00:00 GMT",
        "isoDate": "2023-08-31T07:00:00.000Z",
        "source": "https://openai.com/index/teaching-with-ai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-aus00s",
        "title": "Introducing ChatGPT Enterprise",
        "link": "https://openai.com/index/introducing-chatgpt-enterprise",
        "url": "https://openai.com/index/introducing-chatgpt-enterprise",
        "content": "Get enterprise-grade security & privacy and the most powerful version of ChatGPT yet.",
        "contentSnippet": "Get enterprise-grade security & privacy and the most powerful version of ChatGPT yet.",
        "pubDate": "Mon, 28 Aug 2023 07:00:00 GMT",
        "isoDate": "2023-08-28T07:00:00.000Z",
        "source": "https://openai.com/index/introducing-chatgpt-enterprise"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xqxp9b",
        "title": "OpenAI partners with Scale to provide support for enterprises fine-tuning models",
        "link": "https://openai.com/index/openai-partners-with-scale-to-provide-support-for-enterprises-fine-tuning-models",
        "url": "https://openai.com/index/openai-partners-with-scale-to-provide-support-for-enterprises-fine-tuning-models",
        "content": "OpenAI’s customers can leverage Scale’s AI expertise to customize our most advanced models.",
        "contentSnippet": "OpenAI’s customers can leverage Scale’s AI expertise to customize our most advanced models.",
        "pubDate": "Thu, 24 Aug 2023 07:00:00 GMT",
        "isoDate": "2023-08-24T07:00:00.000Z",
        "source": "https://openai.com/index/openai-partners-with-scale-to-provide-support-for-enterprises-fine-tuning-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-nuesqn",
        "title": "GPT-3.5 Turbo fine-tuning and API updates",
        "link": "https://openai.com/index/gpt-3-5-turbo-fine-tuning-and-api-updates",
        "url": "https://openai.com/index/gpt-3-5-turbo-fine-tuning-and-api-updates",
        "content": "Developers can now bring their own data to customize GPT-3.5 Turbo for their use cases.",
        "contentSnippet": "Developers can now bring their own data to customize GPT-3.5 Turbo for their use cases.",
        "pubDate": "Tue, 22 Aug 2023 07:00:00 GMT",
        "isoDate": "2023-08-22T07:00:00.000Z",
        "source": "https://openai.com/index/gpt-3-5-turbo-fine-tuning-and-api-updates"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-13cjlg",
        "title": "OpenAI acquires Global Illumination",
        "link": "https://openai.com/index/openai-acquires-global-illumination",
        "url": "https://openai.com/index/openai-acquires-global-illumination",
        "content": "The entire team has joined OpenAI.",
        "contentSnippet": "The entire team has joined OpenAI.",
        "pubDate": "Wed, 16 Aug 2023 07:00:00 GMT",
        "isoDate": "2023-08-16T07:00:00.000Z",
        "source": "https://openai.com/index/openai-acquires-global-illumination"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-39k1xi",
        "title": "Using GPT-4 for content moderation",
        "link": "https://openai.com/index/using-gpt-4-for-content-moderation",
        "url": "https://openai.com/index/using-gpt-4-for-content-moderation",
        "content": "We use GPT-4 for content policy development and content moderation decisions, enabling more consistent labeling, a faster feedback loop for policy refinement, and less involvement from human moderators.",
        "contentSnippet": "We use GPT-4 for content policy development and content moderation decisions, enabling more consistent labeling, a faster feedback loop for policy refinement, and less involvement from human moderators.",
        "pubDate": "Tue, 15 Aug 2023 07:00:00 GMT",
        "isoDate": "2023-08-15T07:00:00.000Z",
        "source": "https://openai.com/index/using-gpt-4-for-content-moderation"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xlyljw",
        "title": "Confidence-Building Measures for Artificial Intelligence: Workshop proceedings",
        "link": "https://openai.com/index/confidence-building-measures-for-artificial-intelligence",
        "url": "https://openai.com/index/confidence-building-measures-for-artificial-intelligence",
        "pubDate": "Tue, 01 Aug 2023 07:00:00 GMT",
        "isoDate": "2023-08-01T07:00:00.000Z",
        "source": "https://openai.com/index/confidence-building-measures-for-artificial-intelligence"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ley3t7",
        "title": "Frontier Model Forum",
        "link": "https://openai.com/index/frontier-model-forum",
        "url": "https://openai.com/index/frontier-model-forum",
        "content": "We’re forming a new industry body to promote the safe and responsible development of frontier AI systems: advancing AI safety research, identifying best practices and standards, and facilitating information sharing among policymakers and industry.",
        "contentSnippet": "We’re forming a new industry body to promote the safe and responsible development of frontier AI systems: advancing AI safety research, identifying best practices and standards, and facilitating information sharing among policymakers and industry.",
        "pubDate": "Wed, 26 Jul 2023 07:00:00 GMT",
        "isoDate": "2023-07-26T07:00:00.000Z",
        "source": "https://openai.com/index/frontier-model-forum"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-f5xhyg",
        "title": "Moving AI governance forward",
        "link": "https://openai.com/index/moving-ai-governance-forward",
        "url": "https://openai.com/index/moving-ai-governance-forward",
        "content": "OpenAI and other leading labs reinforce AI safety, security and trustworthiness through voluntary commitments.",
        "contentSnippet": "OpenAI and other leading labs reinforce AI safety, security and trustworthiness through voluntary commitments.",
        "pubDate": "Fri, 21 Jul 2023 07:00:00 GMT",
        "isoDate": "2023-07-21T07:00:00.000Z",
        "source": "https://openai.com/index/moving-ai-governance-forward"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-1l4nlh",
        "title": "Custom instructions for ChatGPT",
        "link": "https://openai.com/index/custom-instructions-for-chatgpt",
        "url": "https://openai.com/index/custom-instructions-for-chatgpt",
        "content": "We’re rolling out custom instructions to give you more control over how ChatGPT responds. Set your preferences, and ChatGPT will keep them in mind for all future conversations.",
        "contentSnippet": "We’re rolling out custom instructions to give you more control over how ChatGPT responds. Set your preferences, and ChatGPT will keep them in mind for all future conversations.",
        "pubDate": "Thu, 20 Jul 2023 07:00:00 GMT",
        "isoDate": "2023-07-20T07:00:00.000Z",
        "source": "https://openai.com/index/custom-instructions-for-chatgpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-sbl0gn",
        "title": "Partnership with American Journalism Project to support local news",
        "link": "https://openai.com/index/partnership-with-american-journalism-project-to-support-local-news",
        "url": "https://openai.com/index/partnership-with-american-journalism-project-to-support-local-news",
        "content": "A new $5+ million partnership aims to explore ways the development of artificial intelligence (AI) can support a thriving, innovative local news field, and ensure local news organizations shape the future of this emerging technology.",
        "contentSnippet": "A new $5+ million partnership aims to explore ways the development of artificial intelligence (AI) can support a thriving, innovative local news field, and ensure local news organizations shape the future of this emerging technology.",
        "pubDate": "Tue, 18 Jul 2023 07:00:00 GMT",
        "isoDate": "2023-07-18T07:00:00.000Z",
        "source": "https://openai.com/index/partnership-with-american-journalism-project-to-support-local-news"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ui0ttn",
        "title": "Accurately analyzing large scale qualitative data",
        "link": "https://openai.com/index/viable",
        "url": "https://openai.com/index/viable",
        "content": "Viable uses GPT-4 to analyze qualitative data at a revolutionary scale with unparalleled accuracy.",
        "contentSnippet": "Viable uses GPT-4 to analyze qualitative data at a revolutionary scale with unparalleled accuracy.",
        "pubDate": "Fri, 07 Jul 2023 07:00:00 GMT",
        "isoDate": "2023-07-07T07:00:00.000Z",
        "source": "https://openai.com/index/viable"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-8jz3dl",
        "title": "Frontier AI regulation: Managing emerging risks to public safety",
        "link": "https://openai.com/index/frontier-ai-regulation",
        "url": "https://openai.com/index/frontier-ai-regulation",
        "pubDate": "Thu, 06 Jul 2023 07:00:00 GMT",
        "isoDate": "2023-07-06T07:00:00.000Z",
        "source": "https://openai.com/index/frontier-ai-regulation"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-hqguzz",
        "title": "Insights from global conversations",
        "link": "https://openai.com/index/insights-from-global-conversations",
        "url": "https://openai.com/index/insights-from-global-conversations",
        "content": "We are sharing what we learned from our conversations across 22 countries, and how we will be incorporating those insights moving forward.",
        "contentSnippet": "We are sharing what we learned from our conversations across 22 countries, and how we will be incorporating those insights moving forward.",
        "pubDate": "Thu, 29 Jun 2023 07:00:00 GMT",
        "isoDate": "2023-06-29T07:00:00.000Z",
        "source": "https://openai.com/index/insights-from-global-conversations"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-mqg2ju",
        "title": "Introducing OpenAI London",
        "link": "https://openai.com/index/introducing-openai-london",
        "url": "https://openai.com/index/introducing-openai-london",
        "content": "We are excited to announce OpenAI’s first international expansion with a new office in London, United Kingdom.",
        "contentSnippet": "We are excited to announce OpenAI’s first international expansion with a new office in London, United Kingdom.",
        "pubDate": "Wed, 28 Jun 2023 07:00:00 GMT",
        "isoDate": "2023-06-28T07:00:00.000Z",
        "source": "https://openai.com/index/introducing-openai-london"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-l7z84w",
        "title": "Testimony before the U.S. Senate",
        "link": "https://openai.com/global-affairs/testimony-of-sam-altman-before-the-us-senate",
        "url": "https://openai.com/global-affairs/testimony-of-sam-altman-before-the-us-senate",
        "content": "The following is the written testimony of Sam Altman, Chief Executive Officer of OpenAI, before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
        "contentSnippet": "The following is the written testimony of Sam Altman, Chief Executive Officer of OpenAI, before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
        "pubDate": "Thu, 22 Jun 2023 00:00:00 GMT",
        "isoDate": "2023-06-22T00:00:00.000Z",
        "source": "https://openai.com/global-affairs/testimony-of-sam-altman-before-the-us-senate"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7yqiky",
        "title": "Questions for the Record",
        "link": "https://openai.com/global-affairs/sam-altman-senate-questions-for-the-record",
        "url": "https://openai.com/global-affairs/sam-altman-senate-questions-for-the-record",
        "content": "The following are the Questions for the Record following Sam Altman's testimony before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
        "contentSnippet": "The following are the Questions for the Record following Sam Altman's testimony before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
        "pubDate": "Thu, 22 Jun 2023 00:00:00 GMT",
        "isoDate": "2023-06-22T00:00:00.000Z",
        "source": "https://openai.com/global-affairs/sam-altman-senate-questions-for-the-record"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-sg1gta",
        "title": "Function calling and other API updates",
        "link": "https://openai.com/index/function-calling-and-other-api-updates",
        "url": "https://openai.com/index/function-calling-and-other-api-updates",
        "content": "We’re announcing updates including more steerable API models, function calling capabilities, longer context, and lower prices.",
        "contentSnippet": "We’re announcing updates including more steerable API models, function calling capabilities, longer context, and lower prices.",
        "pubDate": "Tue, 13 Jun 2023 07:00:00 GMT",
        "isoDate": "2023-06-13T07:00:00.000Z",
        "source": "https://openai.com/index/function-calling-and-other-api-updates"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-t5px0g",
        "title": "Comment on NTIA AI Accountability Policy",
        "link": "https://openai.com/global-affairs/comment-on-ntia-ai-accountability-policy",
        "url": "https://openai.com/global-affairs/comment-on-ntia-ai-accountability-policy",
        "content": "The National Telecommunications and Information Administration (NTIA) request for comments on AI Accountability policy.",
        "contentSnippet": "The National Telecommunications and Information Administration (NTIA) request for comments on AI Accountability policy.",
        "pubDate": "Mon, 12 Jun 2023 00:00:00 GMT",
        "isoDate": "2023-06-12T00:00:00.000Z",
        "source": "https://openai.com/global-affairs/comment-on-ntia-ai-accountability-policy"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6kpcjg",
        "title": "OpenAI Cybersecurity Grant Program",
        "link": "https://openai.com/index/openai-cybersecurity-grant-program",
        "url": "https://openai.com/index/openai-cybersecurity-grant-program",
        "content": "Our goal is to facilitate the development of AI-powered cybersecurity capabilities for defenders through grants and other support.",
        "contentSnippet": "Our goal is to facilitate the development of AI-powered cybersecurity capabilities for defenders through grants and other support.",
        "pubDate": "Thu, 01 Jun 2023 07:00:00 GMT",
        "isoDate": "2023-06-01T07:00:00.000Z",
        "source": "https://openai.com/index/openai-cybersecurity-grant-program"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-5cv0zm",
        "title": "Improving mathematical reasoning with process supervision",
        "link": "https://openai.com/index/improving-mathematical-reasoning-with-process-supervision",
        "url": "https://openai.com/index/improving-mathematical-reasoning-with-process-supervision",
        "content": "We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (“process supervision”) instead of simply rewarding the correct final answer (“outcome supervision”). In addition to boosting performance relative to outcome supervision, process supervision also has an important alignment benefit: it directly trains the model to produce a chain-of-thought that is endorsed by humans.",
        "contentSnippet": "We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (“process supervision”) instead of simply rewarding the correct final answer (“outcome supervision”). In addition to boosting performance relative to outcome supervision, process supervision also has an important alignment benefit: it directly trains the model to produce a chain-of-thought that is endorsed by humans.",
        "pubDate": "Wed, 31 May 2023 07:00:00 GMT",
        "isoDate": "2023-05-31T07:00:00.000Z",
        "source": "https://openai.com/index/improving-mathematical-reasoning-with-process-supervision"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-8a85l8",
        "title": "Democratic inputs to AI",
        "link": "https://openai.com/index/democratic-inputs-to-ai",
        "url": "https://openai.com/index/democratic-inputs-to-ai",
        "content": "Our nonprofit organization, OpenAI, Inc., is launching a program to award ten $100,000 grants to fund experiments in setting up a democratic process for deciding what rules AI systems should follow, within the bounds defined by the law.",
        "contentSnippet": "Our nonprofit organization, OpenAI, Inc., is launching a program to award ten $100,000 grants to fund experiments in setting up a democratic process for deciding what rules AI systems should follow, within the bounds defined by the law.",
        "pubDate": "Thu, 25 May 2023 07:00:00 GMT",
        "isoDate": "2023-05-25T07:00:00.000Z",
        "source": "https://openai.com/index/democratic-inputs-to-ai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-kcjbxl",
        "title": "Governance of superintelligence",
        "link": "https://openai.com/index/governance-of-superintelligence",
        "url": "https://openai.com/index/governance-of-superintelligence",
        "content": "Now is a good time to start thinking about the governance of superintelligence—future AI systems dramatically more capable than even AGI.",
        "contentSnippet": "Now is a good time to start thinking about the governance of superintelligence—future AI systems dramatically more capable than even AGI.",
        "pubDate": "Mon, 22 May 2023 07:00:00 GMT",
        "isoDate": "2023-05-22T07:00:00.000Z",
        "source": "https://openai.com/index/governance-of-superintelligence"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-d7ryxu",
        "title": "Introducing the ChatGPT app for iOS",
        "link": "https://openai.com/index/introducing-the-chatgpt-app-for-ios",
        "url": "https://openai.com/index/introducing-the-chatgpt-app-for-ios",
        "content": "The ChatGPT app syncs your conversations, supports voice input, and brings our latest model improvements to your fingertips.",
        "contentSnippet": "The ChatGPT app syncs your conversations, supports voice input, and brings our latest model improvements to your fingertips.",
        "pubDate": "Thu, 18 May 2023 07:00:00 GMT",
        "isoDate": "2023-05-18T07:00:00.000Z",
        "source": "https://openai.com/index/introducing-the-chatgpt-app-for-ios"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-u04wgz",
        "title": "Language models can explain neurons in language models",
        "link": "https://openai.com/index/language-models-can-explain-neurons-in-language-models",
        "url": "https://openai.com/index/language-models-can-explain-neurons-in-language-models",
        "content": "We use GPT-4 to automatically write explanations for the behavior of neurons in large language models and to score those explanations. We release a dataset of these (imperfect) explanations and scores for every neuron in GPT-2.",
        "contentSnippet": "We use GPT-4 to automatically write explanations for the behavior of neurons in large language models and to score those explanations. We release a dataset of these (imperfect) explanations and scores for every neuron in GPT-2.",
        "pubDate": "Tue, 09 May 2023 07:00:00 GMT",
        "isoDate": "2023-05-09T07:00:00.000Z",
        "source": "https://openai.com/index/language-models-can-explain-neurons-in-language-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-k524r2",
        "title": "New ways to manage your data in ChatGPT",
        "link": "https://openai.com/index/new-ways-to-manage-your-data-in-chatgpt",
        "url": "https://openai.com/index/new-ways-to-manage-your-data-in-chatgpt",
        "content": "ChatGPT users can now turn off chat history, allowing you to choose which conversations can be used to train our models.",
        "contentSnippet": "ChatGPT users can now turn off chat history, allowing you to choose which conversations can be used to train our models.",
        "pubDate": "Tue, 25 Apr 2023 07:00:00 GMT",
        "isoDate": "2023-04-25T07:00:00.000Z",
        "source": "https://openai.com/index/new-ways-to-manage-your-data-in-chatgpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-8qc23x",
        "title": "Announcing OpenAI’s Bug Bounty Program",
        "link": "https://openai.com/index/bug-bounty-program",
        "url": "https://openai.com/index/bug-bounty-program",
        "content": "This initiative is essential to our commitment to develop safe and advanced AI. As we create technology and services that are secure, reliable, and trustworthy, we need your help.",
        "contentSnippet": "This initiative is essential to our commitment to develop safe and advanced AI. As we create technology and services that are secure, reliable, and trustworthy, we need your help.",
        "pubDate": "Tue, 11 Apr 2023 07:00:00 GMT",
        "isoDate": "2023-04-11T07:00:00.000Z",
        "source": "https://openai.com/index/bug-bounty-program"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-lyv567",
        "title": "Our approach to AI safety",
        "link": "https://openai.com/index/our-approach-to-ai-safety",
        "url": "https://openai.com/index/our-approach-to-ai-safety",
        "content": "Ensuring that AI systems are built, deployed, and used safely is critical to our mission.",
        "contentSnippet": "Ensuring that AI systems are built, deployed, and used safely is critical to our mission.",
        "pubDate": "Wed, 05 Apr 2023 07:00:00 GMT",
        "isoDate": "2023-04-05T07:00:00.000Z",
        "source": "https://openai.com/index/our-approach-to-ai-safety"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-241r3c",
        "title": "March 20 ChatGPT outage: Here’s what happened",
        "link": "https://openai.com/index/march-20-chatgpt-outage",
        "url": "https://openai.com/index/march-20-chatgpt-outage",
        "content": "An update on our findings, the actions we’ve taken, and technical details of the bug.",
        "contentSnippet": "An update on our findings, the actions we’ve taken, and technical details of the bug.",
        "pubDate": "Fri, 24 Mar 2023 07:00:00 GMT",
        "isoDate": "2023-03-24T07:00:00.000Z",
        "source": "https://openai.com/index/march-20-chatgpt-outage"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-kndx9q",
        "title": "ChatGPT plugins",
        "link": "https://openai.com/index/chatgpt-plugins",
        "url": "https://openai.com/index/chatgpt-plugins",
        "content": "We’ve implemented initial support for plugins in ChatGPT. Plugins are tools designed specifically for language models with safety as a core principle, and help ChatGPT access up-to-date information, run computations, or use third-party services.",
        "contentSnippet": "We’ve implemented initial support for plugins in ChatGPT. Plugins are tools designed specifically for language models with safety as a core principle, and help ChatGPT access up-to-date information, run computations, or use third-party services.",
        "pubDate": "Thu, 23 Mar 2023 07:00:00 GMT",
        "isoDate": "2023-03-23T07:00:00.000Z",
        "source": "https://openai.com/index/chatgpt-plugins"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-anc61a",
        "title": "GPTs are GPTs: An early look at the labor market impact potential of large language models",
        "link": "https://openai.com/index/gpts-are-gpts",
        "url": "https://openai.com/index/gpts-are-gpts",
        "pubDate": "Fri, 17 Mar 2023 07:00:00 GMT",
        "isoDate": "2023-03-17T07:00:00.000Z",
        "source": "https://openai.com/index/gpts-are-gpts"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vqsyez",
        "title": "Streamlining financial solutions for safety and growth",
        "link": "https://openai.com/index/stripe",
        "url": "https://openai.com/index/stripe",
        "content": "Stripe leverages GPT-4 to streamline user experience and combat fraud.",
        "contentSnippet": "Stripe leverages GPT-4 to streamline user experience and combat fraud.",
        "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
        "isoDate": "2023-03-14T07:00:00.000Z",
        "source": "https://openai.com/index/stripe"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-arokip",
        "title": "Powering virtual education for the classroom",
        "link": "https://openai.com/index/khan-academy",
        "url": "https://openai.com/index/khan-academy",
        "content": "Khan Academy explores the potential for GPT-4 in a limited pilot program.",
        "contentSnippet": "Khan Academy explores the potential for GPT-4 in a limited pilot program.",
        "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
        "isoDate": "2023-03-14T07:00:00.000Z",
        "source": "https://openai.com/index/khan-academy"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ojjlxt",
        "title": "Transforming visual accessibility",
        "link": "https://openai.com/index/be-my-eyes",
        "url": "https://openai.com/index/be-my-eyes",
        "content": "Be My Eyes uses GPT-4 to transform visual accessibility.",
        "contentSnippet": "Be My Eyes uses GPT-4 to transform visual accessibility.",
        "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
        "isoDate": "2023-03-14T07:00:00.000Z",
        "source": "https://openai.com/index/be-my-eyes"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-2m4w7m",
        "title": "GPT-4",
        "link": "https://openai.com/index/gpt-4-research",
        "url": "https://openai.com/index/gpt-4-research",
        "content": "We’ve created GPT-4, the latest milestone in OpenAI’s effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.",
        "contentSnippet": "We’ve created GPT-4, the latest milestone in OpenAI’s effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.",
        "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
        "isoDate": "2023-03-14T07:00:00.000Z",
        "source": "https://openai.com/index/gpt-4-research"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-65dy3o",
        "title": "Preserving languages for the future",
        "link": "https://openai.com/index/government-of-iceland",
        "url": "https://openai.com/index/government-of-iceland",
        "content": "How Iceland is using GPT-4 to preserve its language.",
        "contentSnippet": "How Iceland is using GPT-4 to preserve its language.",
        "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
        "isoDate": "2023-03-14T07:00:00.000Z",
        "source": "https://openai.com/index/government-of-iceland"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-r4jd71",
        "title": "Filling crucial language learning gaps",
        "link": "https://openai.com/index/duolingo",
        "url": "https://openai.com/index/duolingo",
        "content": "GPT-4 deepens the conversation on Duolingo.",
        "contentSnippet": "GPT-4 deepens the conversation on Duolingo.",
        "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
        "isoDate": "2023-03-14T07:00:00.000Z",
        "source": "https://openai.com/index/duolingo"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6f3qyz",
        "title": "Planning for AGI and beyond",
        "link": "https://openai.com/index/planning-for-agi-and-beyond",
        "url": "https://openai.com/index/planning-for-agi-and-beyond",
        "content": "Our mission is to ensure that artificial general intelligence—AI systems that are generally smarter than humans—benefits all of humanity.",
        "contentSnippet": "Our mission is to ensure that artificial general intelligence—AI systems that are generally smarter than humans—benefits all of humanity.",
        "pubDate": "Fri, 24 Feb 2023 08:00:00 GMT",
        "isoDate": "2023-02-24T08:00:00.000Z",
        "source": "https://openai.com/index/planning-for-agi-and-beyond"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-4w7o50",
        "title": "How should AI systems behave, and who should decide?",
        "link": "https://openai.com/index/how-should-ai-systems-behave",
        "url": "https://openai.com/index/how-should-ai-systems-behave",
        "content": "We’re clarifying how ChatGPT’s behavior is shaped and our plans for improving that behavior, allowing more user customization, and getting more public input into our decision-making in these areas.",
        "contentSnippet": "We’re clarifying how ChatGPT’s behavior is shaped and our plans for improving that behavior, allowing more user customization, and getting more public input into our decision-making in these areas.",
        "pubDate": "Thu, 16 Feb 2023 08:00:00 GMT",
        "isoDate": "2023-02-16T08:00:00.000Z",
        "source": "https://openai.com/index/how-should-ai-systems-behave"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-8r1ff0",
        "title": "Introducing ChatGPT Plus",
        "link": "https://openai.com/index/chatgpt-plus",
        "url": "https://openai.com/index/chatgpt-plus",
        "content": "We’re launching a pilot subscription plan for ChatGPT, a conversational AI that can chat with you, answer follow-up questions, and challenge incorrect assumptions.",
        "contentSnippet": "We’re launching a pilot subscription plan for ChatGPT, a conversational AI that can chat with you, answer follow-up questions, and challenge incorrect assumptions.",
        "pubDate": "Wed, 01 Feb 2023 08:00:00 GMT",
        "isoDate": "2023-02-01T08:00:00.000Z",
        "source": "https://openai.com/index/chatgpt-plus"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-c66asf",
        "title": "New AI classifier for indicating AI-written text",
        "link": "https://openai.com/index/new-ai-classifier-for-indicating-ai-written-text",
        "url": "https://openai.com/index/new-ai-classifier-for-indicating-ai-written-text",
        "content": "We’re launching a classifier trained to distinguish between AI-written and human-written text.",
        "contentSnippet": "We’re launching a classifier trained to distinguish between AI-written and human-written text.",
        "pubDate": "Tue, 31 Jan 2023 08:00:00 GMT",
        "isoDate": "2023-01-31T08:00:00.000Z",
        "source": "https://openai.com/index/new-ai-classifier-for-indicating-ai-written-text"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xaao53",
        "title": "OpenAI and Microsoft extend partnership",
        "link": "https://openai.com/index/openai-and-microsoft-extend-partnership",
        "url": "https://openai.com/index/openai-and-microsoft-extend-partnership",
        "content": "We’re happy to announce that OpenAI and Microsoft are extending our partnership.",
        "contentSnippet": "We’re happy to announce that OpenAI and Microsoft are extending our partnership.",
        "pubDate": "Mon, 23 Jan 2023 08:00:00 GMT",
        "isoDate": "2023-01-23T08:00:00.000Z",
        "source": "https://openai.com/index/openai-and-microsoft-extend-partnership"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wwkde6",
        "title": "Forecasting potential misuses of language models for disinformation campaigns and how to reduce risk",
        "link": "https://openai.com/index/forecasting-misuse",
        "url": "https://openai.com/index/forecasting-misuse",
        "content": "OpenAI researchers collaborated with Georgetown University’s Center for Security and Emerging Technology and the Stanford Internet Observatory to investigate how large language models might be misused for disinformation purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers, machine learning experts, and policy analysts, and culminated in a co-authored report building on more than a year of research. This report outlines the threats that language models pose to the information environment if used to augment disinformation campaigns and introduces a framework for analyzing potential mitigations. Read the full report here.",
        "contentSnippet": "OpenAI researchers collaborated with Georgetown University’s Center for Security and Emerging Technology and the Stanford Internet Observatory to investigate how large language models might be misused for disinformation purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers, machine learning experts, and policy analysts, and culminated in a co-authored report building on more than a year of research. This report outlines the threats that language models pose to the information environment if used to augment disinformation campaigns and introduces a framework for analyzing potential mitigations. Read the full report here.",
        "pubDate": "Wed, 11 Jan 2023 08:00:00 GMT",
        "isoDate": "2023-01-11T08:00:00.000Z",
        "source": "https://openai.com/index/forecasting-misuse"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-t79oef",
        "title": "Delivering nuanced insights from customer feedback",
        "link": "https://openai.com/index/yabble",
        "url": "https://openai.com/index/yabble",
        "content": "Using GPT-3 to deliver fast, nuanced insights from customer feedback.",
        "contentSnippet": "Using GPT-3 to deliver fast, nuanced insights from customer feedback.",
        "pubDate": "Wed, 04 Jan 2023 00:00:00 GMT",
        "isoDate": "2023-01-04T00:00:00.000Z",
        "source": "https://openai.com/index/yabble"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-autsfw",
        "title": "Fine-tuning GPT-3 to scale video creation",
        "link": "https://openai.com/index/waymark",
        "url": "https://openai.com/index/waymark",
        "content": "Fine-tuning GPT-3 to power and scale done-for-you video creation.",
        "contentSnippet": "Fine-tuning GPT-3 to power and scale done-for-you video creation.",
        "pubDate": "Tue, 03 Jan 2023 08:00:00 GMT",
        "isoDate": "2023-01-03T08:00:00.000Z",
        "source": "https://openai.com/index/waymark"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ks5fkw",
        "title": "Creating next-gen characters",
        "link": "https://openai.com/index/inworld-ai-DO-NOT-PUBLISH",
        "url": "https://openai.com/index/inworld-ai-DO-NOT-PUBLISH",
        "content": "Using GPT-3 to create the next generation of AI-powered characters.",
        "contentSnippet": "Using GPT-3 to create the next generation of AI-powered characters.",
        "pubDate": "Sun, 01 Jan 2023 08:00:00 GMT",
        "isoDate": "2023-01-01T08:00:00.000Z",
        "source": "https://openai.com/index/inworld-ai-DO-NOT-PUBLISH"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ie0ata",
        "title": "The power of continuous learning",
        "link": "https://openai.com/index/the-power-of-continuous-learning",
        "url": "https://openai.com/index/the-power-of-continuous-learning",
        "content": "Lilian Weng works on Applied AI Research at OpenAI.",
        "contentSnippet": "Lilian Weng works on Applied AI Research at OpenAI.",
        "pubDate": "Fri, 23 Dec 2022 08:00:00 GMT",
        "isoDate": "2022-12-23T08:00:00.000Z",
        "source": "https://openai.com/index/the-power-of-continuous-learning"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-yuhbe8",
        "title": "Point-E: A system for generating 3D point clouds from complex prompts",
        "link": "https://openai.com/index/point-e",
        "url": "https://openai.com/index/point-e",
        "pubDate": "Fri, 16 Dec 2022 08:00:00 GMT",
        "isoDate": "2022-12-16T08:00:00.000Z",
        "source": "https://openai.com/index/point-e"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-zdlogd",
        "title": "New and improved embedding model",
        "link": "https://openai.com/index/new-and-improved-embedding-model",
        "url": "https://openai.com/index/new-and-improved-embedding-model",
        "content": "We are excited to announce a new embedding model which is significantly more capable, cost effective, and simpler to use.",
        "contentSnippet": "We are excited to announce a new embedding model which is significantly more capable, cost effective, and simpler to use.",
        "pubDate": "Thu, 15 Dec 2022 08:00:00 GMT",
        "isoDate": "2022-12-15T08:00:00.000Z",
        "source": "https://openai.com/index/new-and-improved-embedding-model"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-tq70gy",
        "title": "Discovering the minutiae of backend systems",
        "link": "https://openai.com/index/discovering-the-minutiae-of-backend-systems",
        "url": "https://openai.com/index/discovering-the-minutiae-of-backend-systems",
        "content": "Christian Gibson is an engineer on the Supercomputing team at OpenAI.",
        "contentSnippet": "Christian Gibson is an engineer on the Supercomputing team at OpenAI.",
        "pubDate": "Thu, 08 Dec 2022 08:00:00 GMT",
        "isoDate": "2022-12-08T08:00:00.000Z",
        "source": "https://openai.com/index/discovering-the-minutiae-of-backend-systems"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-hc2d5x",
        "title": "Introducing ChatGPT",
        "link": "https://openai.com/index/chatgpt",
        "url": "https://openai.com/index/chatgpt",
        "content": "We’ve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.",
        "contentSnippet": "We’ve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.",
        "pubDate": "Wed, 30 Nov 2022 08:00:00 GMT",
        "isoDate": "2022-11-30T08:00:00.000Z",
        "source": "https://openai.com/index/chatgpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-cdqy5i",
        "title": "DALL·E API now available in public beta",
        "link": "https://openai.com/index/dall-e-api-now-available-in-public-beta",
        "url": "https://openai.com/index/dall-e-api-now-available-in-public-beta",
        "content": "Starting today, developers can begin building apps with the DALL·E API.",
        "contentSnippet": "Starting today, developers can begin building apps with the DALL·E API.",
        "pubDate": "Thu, 03 Nov 2022 07:00:00 GMT",
        "isoDate": "2022-11-03T07:00:00.000Z",
        "source": "https://openai.com/index/dall-e-api-now-available-in-public-beta"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-g4bds1",
        "title": "Scaling laws for reward model overoptimization",
        "link": "https://openai.com/index/scaling-laws-for-reward-model-overoptimization",
        "url": "https://openai.com/index/scaling-laws-for-reward-model-overoptimization",
        "pubDate": "Wed, 19 Oct 2022 07:00:00 GMT",
        "isoDate": "2022-10-19T07:00:00.000Z",
        "source": "https://openai.com/index/scaling-laws-for-reward-model-overoptimization"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xdy1ub",
        "title": "DALL·E now available without waitlist",
        "link": "https://openai.com/index/dall-e-now-available-without-waitlist",
        "url": "https://openai.com/index/dall-e-now-available-without-waitlist",
        "content": "New users can start creating straight away. Lessons learned from deployment and improvements to our safety systems make wider availability possible.",
        "contentSnippet": "New users can start creating straight away. Lessons learned from deployment and improvements to our safety systems make wider availability possible.",
        "pubDate": "Wed, 28 Sep 2022 07:00:00 GMT",
        "isoDate": "2022-09-28T07:00:00.000Z",
        "source": "https://openai.com/index/dall-e-now-available-without-waitlist"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7s70fq",
        "title": "Introducing Whisper",
        "link": "https://openai.com/index/whisper",
        "url": "https://openai.com/index/whisper",
        "content": "We’ve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and accuracy on English speech recognition.",
        "contentSnippet": "We’ve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and accuracy on English speech recognition.",
        "pubDate": "Wed, 21 Sep 2022 07:00:00 GMT",
        "isoDate": "2022-09-21T07:00:00.000Z",
        "source": "https://openai.com/index/whisper"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-kmnyu7",
        "title": "DALL·E: Introducing outpainting",
        "link": "https://openai.com/index/dall-e-introducing-outpainting",
        "url": "https://openai.com/index/dall-e-introducing-outpainting",
        "content": "Extend creativity and tell a bigger story with DALL·E images of any size.",
        "contentSnippet": "Extend creativity and tell a bigger story with DALL·E images of any size.",
        "pubDate": "Wed, 31 Aug 2022 07:00:00 GMT",
        "isoDate": "2022-08-31T07:00:00.000Z",
        "source": "https://openai.com/index/dall-e-introducing-outpainting"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ysk9rp",
        "title": "Our approach to alignment research",
        "link": "https://openai.com/index/our-approach-to-alignment-research",
        "url": "https://openai.com/index/our-approach-to-alignment-research",
        "content": "We are improving our AI systems’ ability to learn from human feedback and to assist humans at evaluating AI. Our goal is to build a sufficiently aligned AI system that can help us solve all other alignment problems.",
        "contentSnippet": "We are improving our AI systems’ ability to learn from human feedback and to assist humans at evaluating AI. Our goal is to build a sufficiently aligned AI system that can help us solve all other alignment problems.",
        "pubDate": "Wed, 24 Aug 2022 07:00:00 GMT",
        "isoDate": "2022-08-24T07:00:00.000Z",
        "source": "https://openai.com/index/our-approach-to-alignment-research"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ac8ihv",
        "title": "New and improved content moderation tooling",
        "link": "https://openai.com/index/new-and-improved-content-moderation-tooling",
        "url": "https://openai.com/index/new-and-improved-content-moderation-tooling",
        "content": "We are introducing a new and improved content moderation tool. The Moderation endpoint improves upon our previous content filter, and is available for free today to OpenAI API developers.",
        "contentSnippet": "We are introducing a new and improved content moderation tool. The Moderation endpoint improves upon our previous content filter, and is available for free today to OpenAI API developers.",
        "pubDate": "Wed, 10 Aug 2022 07:00:00 GMT",
        "isoDate": "2022-08-10T07:00:00.000Z",
        "source": "https://openai.com/index/new-and-improved-content-moderation-tooling"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-or622c",
        "title": "Efficient training of language models to fill in the middle",
        "link": "https://openai.com/index/efficient-training-of-language-models-to-fill-in-the-middle",
        "url": "https://openai.com/index/efficient-training-of-language-models-to-fill-in-the-middle",
        "pubDate": "Thu, 28 Jul 2022 07:00:00 GMT",
        "isoDate": "2022-07-28T07:00:00.000Z",
        "source": "https://openai.com/index/efficient-training-of-language-models-to-fill-in-the-middle"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-gfv03j",
        "title": "A hazard analysis framework for code synthesis large language models",
        "link": "https://openai.com/index/a-hazard-analysis-framework-for-code-synthesis-large-language-models",
        "url": "https://openai.com/index/a-hazard-analysis-framework-for-code-synthesis-large-language-models",
        "pubDate": "Mon, 25 Jul 2022 07:00:00 GMT",
        "isoDate": "2022-07-25T07:00:00.000Z",
        "source": "https://openai.com/index/a-hazard-analysis-framework-for-code-synthesis-large-language-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-nk2x7n",
        "title": "DALL·E now available in beta",
        "link": "https://openai.com/index/dall-e-now-available-in-beta",
        "url": "https://openai.com/index/dall-e-now-available-in-beta",
        "content": "We’ll invite 1 million people from our waitlist over the coming weeks. Users can create with DALL·E using free credits that refill every month, and buy additional credits in 115-generation increments for $15.",
        "contentSnippet": "We’ll invite 1 million people from our waitlist over the coming weeks. Users can create with DALL·E using free credits that refill every month, and buy additional credits in 115-generation increments for $15.",
        "pubDate": "Wed, 20 Jul 2022 07:00:00 GMT",
        "isoDate": "2022-07-20T07:00:00.000Z",
        "source": "https://openai.com/index/dall-e-now-available-in-beta"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-svmrrr",
        "title": "Reducing bias and improving safety in DALL·E 2",
        "link": "https://openai.com/index/reducing-bias-and-improving-safety-in-dall-e-2",
        "url": "https://openai.com/index/reducing-bias-and-improving-safety-in-dall-e-2",
        "content": "Today, we are implementing a new technique so that DALL·E generates images of people that more accurately reflect the diversity of the world’s population.",
        "contentSnippet": "Today, we are implementing a new technique so that DALL·E generates images of people that more accurately reflect the diversity of the world’s population.",
        "pubDate": "Mon, 18 Jul 2022 07:00:00 GMT",
        "isoDate": "2022-07-18T07:00:00.000Z",
        "source": "https://openai.com/index/reducing-bias-and-improving-safety-in-dall-e-2"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-2gqs2g",
        "title": "DALL·E 2: Extending creativity",
        "link": "https://openai.com/index/dall-e-2-extending-creativity",
        "url": "https://openai.com/index/dall-e-2-extending-creativity",
        "content": "As part of our DALL·E 2 research preview, more than 3,000 artists from more than 118 countries have incorporated DALL·E into their creative workflows. The artists in our early access group have helped us discover new uses for DALL·E and have served as key voices as we’ve made decisions about DALL·E’s features.",
        "contentSnippet": "As part of our DALL·E 2 research preview, more than 3,000 artists from more than 118 countries have incorporated DALL·E into their creative workflows. The artists in our early access group have helped us discover new uses for DALL·E and have served as key voices as we’ve made decisions about DALL·E’s features.",
        "pubDate": "Thu, 14 Jul 2022 07:00:00 GMT",
        "isoDate": "2022-07-14T07:00:00.000Z",
        "source": "https://openai.com/index/dall-e-2-extending-creativity"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vc662",
        "title": "DALL·E 2 pre-training mitigations",
        "link": "https://openai.com/index/dall-e-2-pre-training-mitigations",
        "url": "https://openai.com/index/dall-e-2-pre-training-mitigations",
        "content": "In order to share the magic of DALL·E 2 with a broad audience, we needed to reduce the risks associated with powerful image generation models. To this end, we put various guardrails in place to prevent generated images from violating our content policy.",
        "contentSnippet": "In order to share the magic of DALL·E 2 with a broad audience, we needed to reduce the risks associated with powerful image generation models. To this end, we put various guardrails in place to prevent generated images from violating our content policy.",
        "pubDate": "Tue, 28 Jun 2022 07:00:00 GMT",
        "isoDate": "2022-06-28T07:00:00.000Z",
        "source": "https://openai.com/index/dall-e-2-pre-training-mitigations"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-npeq2m",
        "title": "Learning to play Minecraft with Video PreTraining",
        "link": "https://openai.com/index/vpt",
        "url": "https://openai.com/index/vpt",
        "content": "We trained a neural network to play Minecraft by Video PreTraining (VPT) on a massive unlabeled video dataset of human Minecraft play, while using only a small amount of labeled contractor data. With fine-tuning, our model can learn to craft diamond tools, a task that usually takes proficient humans over 20 minutes (24,000 actions). Our model uses the native human interface of keypresses and mouse movements, making it quite general, and represents a step towards general computer-using agents.",
        "contentSnippet": "We trained a neural network to play Minecraft by Video PreTraining (VPT) on a massive unlabeled video dataset of human Minecraft play, while using only a small amount of labeled contractor data. With fine-tuning, our model can learn to craft diamond tools, a task that usually takes proficient humans over 20 minutes (24,000 actions). Our model uses the native human interface of keypresses and mouse movements, making it quite general, and represents a step towards general computer-using agents.",
        "pubDate": "Thu, 23 Jun 2022 07:00:00 GMT",
        "isoDate": "2022-06-23T07:00:00.000Z",
        "source": "https://openai.com/index/vpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-w7df76",
        "title": "Evolution through large models",
        "link": "https://openai.com/index/evolution-through-large-models",
        "url": "https://openai.com/index/evolution-through-large-models",
        "pubDate": "Fri, 17 Jun 2022 07:00:00 GMT",
        "isoDate": "2022-06-17T07:00:00.000Z",
        "source": "https://openai.com/index/evolution-through-large-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-co6h7t",
        "title": "AI-written critiques help humans notice flaws",
        "link": "https://openai.com/index/critiques",
        "url": "https://openai.com/index/critiques",
        "content": "We trained “critique-writing” models to describe flaws in summaries. Human evaluators find flaws in summaries much more often when shown our model’s critiques. Larger models are better at self-critiquing, with scale improving critique-writing more than summary-writing. This shows promise for using AI systems to assist human supervision of AI systems on difficult tasks.",
        "contentSnippet": "We trained “critique-writing” models to describe flaws in summaries. Human evaluators find flaws in summaries much more often when shown our model’s critiques. Larger models are better at self-critiquing, with scale improving critique-writing more than summary-writing. This shows promise for using AI systems to assist human supervision of AI systems on difficult tasks.",
        "pubDate": "Mon, 13 Jun 2022 07:00:00 GMT",
        "isoDate": "2022-06-13T07:00:00.000Z",
        "source": "https://openai.com/index/critiques"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-3i8phg",
        "title": "Techniques for training large neural networks",
        "link": "https://openai.com/index/techniques-for-training-large-neural-networks",
        "url": "https://openai.com/index/techniques-for-training-large-neural-networks",
        "content": "Large neural networks are at the core of many recent advances in AI, but training them is a difficult engineering and research challenge which requires orchestrating a cluster of GPUs to perform a single synchronized calculation.",
        "contentSnippet": "Large neural networks are at the core of many recent advances in AI, but training them is a difficult engineering and research challenge which requires orchestrating a cluster of GPUs to perform a single synchronized calculation.",
        "pubDate": "Thu, 09 Jun 2022 07:00:00 GMT",
        "isoDate": "2022-06-09T07:00:00.000Z",
        "source": "https://openai.com/index/techniques-for-training-large-neural-networks"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-u2x9y5",
        "title": "Best practices for deploying language models",
        "link": "https://openai.com/index/best-practices-for-deploying-language-models",
        "url": "https://openai.com/index/best-practices-for-deploying-language-models",
        "content": "Cohere, OpenAI, and AI21 Labs have developed a preliminary set of best practices applicable to any organization developing or deploying large language models.",
        "contentSnippet": "Cohere, OpenAI, and AI21 Labs have developed a preliminary set of best practices applicable to any organization developing or deploying large language models.",
        "pubDate": "Thu, 02 Jun 2022 07:00:00 GMT",
        "isoDate": "2022-06-02T07:00:00.000Z",
        "source": "https://openai.com/index/best-practices-for-deploying-language-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-2dzadj",
        "title": "Teaching models to express their uncertainty in words",
        "link": "https://openai.com/index/teaching-models-to-express-their-uncertainty-in-words",
        "url": "https://openai.com/index/teaching-models-to-express-their-uncertainty-in-words",
        "pubDate": "Sat, 28 May 2022 07:00:00 GMT",
        "isoDate": "2022-05-28T07:00:00.000Z",
        "source": "https://openai.com/index/teaching-models-to-express-their-uncertainty-in-words"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-hsg2ic",
        "title": "Powering next generation applications with OpenAI Codex",
        "link": "https://openai.com/index/codex-apps",
        "url": "https://openai.com/index/codex-apps",
        "content": "Codex is now powering 70 different applications across a variety of use cases through the OpenAI API.",
        "contentSnippet": "Codex is now powering 70 different applications across a variety of use cases through the OpenAI API.",
        "pubDate": "Tue, 24 May 2022 07:00:00 GMT",
        "isoDate": "2022-05-24T07:00:00.000Z",
        "source": "https://openai.com/index/codex-apps"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-pyknno",
        "title": "DALL·E 2 research preview update",
        "link": "https://openai.com/index/dall-e-2-update",
        "url": "https://openai.com/index/dall-e-2-update",
        "content": "Early users have created over 3 million images to date and helped us improve our safety processes. We’re excited to begin adding up to 1,000 new users from our waitlist each week. ",
        "contentSnippet": "Early users have created over 3 million images to date and helped us improve our safety processes. We’re excited to begin adding up to 1,000 new users from our waitlist each week.",
        "pubDate": "Wed, 18 May 2022 07:00:00 GMT",
        "isoDate": "2022-05-18T07:00:00.000Z",
        "source": "https://openai.com/index/dall-e-2-update"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9rico9",
        "title": "OpenAI leadership team update",
        "link": "https://openai.com/index/leadership-team-update",
        "url": "https://openai.com/index/leadership-team-update",
        "content": "We’re happy to announce several executive role changes that reflect our recent progress and will ensure continued momentum toward our next major milestones.",
        "contentSnippet": "We’re happy to announce several executive role changes that reflect our recent progress and will ensure continued momentum toward our next major milestones.",
        "pubDate": "Thu, 05 May 2022 07:00:00 GMT",
        "isoDate": "2022-05-05T07:00:00.000Z",
        "source": "https://openai.com/index/leadership-team-update"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-gv6jqh",
        "title": "Hierarchical text-conditional image generation with CLIP latents",
        "link": "https://openai.com/index/hierarchical-text-conditional-image-generation-with-clip-latents",
        "url": "https://openai.com/index/hierarchical-text-conditional-image-generation-with-clip-latents",
        "pubDate": "Wed, 13 Apr 2022 07:00:00 GMT",
        "isoDate": "2022-04-13T07:00:00.000Z",
        "source": "https://openai.com/index/hierarchical-text-conditional-image-generation-with-clip-latents"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xzxpt2",
        "title": "Measuring Goodhart’s law",
        "link": "https://openai.com/index/measuring-goodharts-law",
        "url": "https://openai.com/index/measuring-goodharts-law",
        "content": "Goodhart’s law famously says: “When a measure becomes a target, it ceases to be a good measure.” Although originally from economics, it’s something we have to grapple with at OpenAI when figuring out how to optimize objectives that are difficult or costly to measure.",
        "contentSnippet": "Goodhart’s law famously says: “When a measure becomes a target, it ceases to be a good measure.” Although originally from economics, it’s something we have to grapple with at OpenAI when figuring out how to optimize objectives that are difficult or costly to measure.",
        "pubDate": "Wed, 13 Apr 2022 07:00:00 GMT",
        "isoDate": "2022-04-13T07:00:00.000Z",
        "source": "https://openai.com/index/measuring-goodharts-law"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-o01bfs",
        "title": "New GPT-3 capabilities: Edit & insert",
        "link": "https://openai.com/index/gpt-3-edit-insert",
        "url": "https://openai.com/index/gpt-3-edit-insert",
        "content": "We’ve released new versions of GPT-3 and Codex which can edit or insert content into existing text, rather than just completing existing text.",
        "contentSnippet": "We’ve released new versions of GPT-3 and Codex which can edit or insert content into existing text, rather than just completing existing text.",
        "pubDate": "Tue, 15 Mar 2022 07:00:00 GMT",
        "isoDate": "2022-03-15T07:00:00.000Z",
        "source": "https://openai.com/index/gpt-3-edit-insert"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-zff8bf",
        "title": "A research agenda for assessing the economic impacts of code generation models",
        "link": "https://openai.com/index/economic-impacts-research",
        "url": "https://openai.com/index/economic-impacts-research",
        "pubDate": "Thu, 03 Mar 2022 08:00:00 GMT",
        "isoDate": "2022-03-03T08:00:00.000Z",
        "source": "https://openai.com/index/economic-impacts-research"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-v5use8",
        "title": "Lessons learned on language model safety and misuse",
        "link": "https://openai.com/index/language-model-safety-and-misuse",
        "url": "https://openai.com/index/language-model-safety-and-misuse",
        "content": "We describe our latest thinking in the hope of helping other AI developers address safety and misuse of deployed models.",
        "contentSnippet": "We describe our latest thinking in the hope of helping other AI developers address safety and misuse of deployed models.",
        "pubDate": "Thu, 03 Mar 2022 08:00:00 GMT",
        "isoDate": "2022-03-03T08:00:00.000Z",
        "source": "https://openai.com/index/language-model-safety-and-misuse"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-dz25ql",
        "title": "Economic impacts research at OpenAI",
        "link": "https://openai.com/index/economic-impacts",
        "url": "https://openai.com/index/economic-impacts",
        "content": "Call for expressions of interest to study the economic impacts of large language models.",
        "contentSnippet": "Call for expressions of interest to study the economic impacts of large language models.",
        "pubDate": "Thu, 03 Mar 2022 08:00:00 GMT",
        "isoDate": "2022-03-03T08:00:00.000Z",
        "source": "https://openai.com/index/economic-impacts"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-m4dhu",
        "title": "Solving (some) formal math olympiad problems",
        "link": "https://openai.com/index/formal-math",
        "url": "https://openai.com/index/formal-math",
        "content": "We built a neural theorem prover for Lean that learned to solve a variety of challenging high-school olympiad problems, including problems from the AMC12 and AIME competitions, as well as two problems adapted from the IMO.",
        "contentSnippet": "We built a neural theorem prover for Lean that learned to solve a variety of challenging high-school olympiad problems, including problems from the AMC12 and AIME competitions, as well as two problems adapted from the IMO.",
        "pubDate": "Wed, 02 Feb 2022 08:00:00 GMT",
        "isoDate": "2022-02-02T08:00:00.000Z",
        "source": "https://openai.com/index/formal-math"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-h2k02u",
        "title": "Aligning language models to follow instructions",
        "link": "https://openai.com/index/instruction-following",
        "url": "https://openai.com/index/instruction-following",
        "content": "We’ve trained language models that are much better at following user intentions than GPT-3 while also making them more truthful and less toxic, using techniques developed through our alignment research. These InstructGPT models, which are trained with humans in the loop, are now deployed as the default language models on our API.",
        "contentSnippet": "We’ve trained language models that are much better at following user intentions than GPT-3 while also making them more truthful and less toxic, using techniques developed through our alignment research. These InstructGPT models, which are trained with humans in the loop, are now deployed as the default language models on our API.",
        "pubDate": "Thu, 27 Jan 2022 08:00:00 GMT",
        "isoDate": "2022-01-27T08:00:00.000Z",
        "source": "https://openai.com/index/instruction-following"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-t7yjwv",
        "title": "Introducing text and code embeddings",
        "link": "https://openai.com/index/introducing-text-and-code-embeddings",
        "url": "https://openai.com/index/introducing-text-and-code-embeddings",
        "content": "We are introducing embeddings, a new endpoint in the OpenAI API that makes it easy to perform natural language and code tasks like semantic search, clustering, topic modeling, and classification.",
        "contentSnippet": "We are introducing embeddings, a new endpoint in the OpenAI API that makes it easy to perform natural language and code tasks like semantic search, clustering, topic modeling, and classification.",
        "pubDate": "Tue, 25 Jan 2022 08:00:00 GMT",
        "isoDate": "2022-01-25T08:00:00.000Z",
        "source": "https://openai.com/index/introducing-text-and-code-embeddings"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6q4bb2",
        "title": "Text and code embeddings by contrastive pre-training",
        "link": "https://openai.com/index/text-and-code-embeddings-by-contrastive-pre-training",
        "url": "https://openai.com/index/text-and-code-embeddings-by-contrastive-pre-training",
        "pubDate": "Mon, 24 Jan 2022 08:00:00 GMT",
        "isoDate": "2022-01-24T08:00:00.000Z",
        "source": "https://openai.com/index/text-and-code-embeddings-by-contrastive-pre-training"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-u35n01",
        "title": "WebGPT: Improving the factual accuracy of language models through web browsing",
        "link": "https://openai.com/index/webgpt",
        "url": "https://openai.com/index/webgpt",
        "content": "We’ve fine-tuned GPT-3 to more accurately answer open-ended questions using a text-based web browser.",
        "contentSnippet": "We’ve fine-tuned GPT-3 to more accurately answer open-ended questions using a text-based web browser.",
        "pubDate": "Thu, 16 Dec 2021 08:00:00 GMT",
        "isoDate": "2021-12-16T08:00:00.000Z",
        "source": "https://openai.com/index/webgpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-4ug18s",
        "title": "Customizing GPT-3 for your application",
        "link": "https://openai.com/index/customizing-gpt-3",
        "url": "https://openai.com/index/customizing-gpt-3",
        "content": "Fine-tune with a single command.",
        "contentSnippet": "Fine-tune with a single command.",
        "pubDate": "Tue, 14 Dec 2021 08:00:00 GMT",
        "isoDate": "2021-12-14T08:00:00.000Z",
        "source": "https://openai.com/index/customizing-gpt-3"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-dtmulz",
        "title": "OpenAI Residency",
        "link": "https://openai.com/index/openai-residency",
        "url": "https://openai.com/index/openai-residency",
        "content": "As part of our effort to support and develop AI talent, we’re excited to announce the OpenAI Residency.",
        "contentSnippet": "As part of our effort to support and develop AI talent, we’re excited to announce the OpenAI Residency.",
        "pubDate": "Tue, 30 Nov 2021 08:00:00 GMT",
        "isoDate": "2021-11-30T08:00:00.000Z",
        "source": "https://openai.com/index/openai-residency"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-96rm30",
        "title": "OpenAI’s API now available with no waitlist",
        "link": "https://openai.com/index/api-no-waitlist",
        "url": "https://openai.com/index/api-no-waitlist",
        "content": "Wider availability made possible by safety progress.",
        "contentSnippet": "Wider availability made possible by safety progress.",
        "pubDate": "Thu, 18 Nov 2021 08:00:00 GMT",
        "isoDate": "2021-11-18T08:00:00.000Z",
        "source": "https://openai.com/index/api-no-waitlist"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-mvk2f9",
        "title": "Solving math word problems",
        "link": "https://openai.com/index/solving-math-word-problems",
        "url": "https://openai.com/index/solving-math-word-problems",
        "content": "We’ve trained a system that solves grade school math problems with nearly twice the accuracy of a fine-tuned GPT-3 model. It solves about 90% as many problems as real kids: a small sample of 9-12 year olds scored 60% on a test from our dataset, while our system scored 55% on those same problems.",
        "contentSnippet": "We’ve trained a system that solves grade school math problems with nearly twice the accuracy of a fine-tuned GPT-3 model. It solves about 90% as many problems as real kids: a small sample of 9-12 year olds scored 60% on a test from our dataset, while our system scored 55% on those same problems.",
        "pubDate": "Fri, 29 Oct 2021 07:00:00 GMT",
        "isoDate": "2021-10-29T07:00:00.000Z",
        "source": "https://openai.com/index/solving-math-word-problems"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-4qsq71",
        "title": "Summarizing books with human feedback",
        "link": "https://openai.com/index/summarizing-books",
        "url": "https://openai.com/index/summarizing-books",
        "content": "Scaling human oversight of AI systems for tasks that are difficult to evaluate.",
        "contentSnippet": "Scaling human oversight of AI systems for tasks that are difficult to evaluate.",
        "pubDate": "Thu, 23 Sep 2021 07:00:00 GMT",
        "isoDate": "2021-09-23T07:00:00.000Z",
        "source": "https://openai.com/index/summarizing-books"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-tnqga7",
        "title": "Helen Toner joins OpenAI’s board of directors",
        "link": "https://openai.com/index/helen-toner-joins",
        "url": "https://openai.com/index/helen-toner-joins",
        "content": "Today, we’re excited to announce the appointment of Helen Toner to our board of directors.",
        "contentSnippet": "Today, we’re excited to announce the appointment of Helen Toner to our board of directors.",
        "pubDate": "Wed, 08 Sep 2021 07:00:00 GMT",
        "isoDate": "2021-09-08T07:00:00.000Z",
        "source": "https://openai.com/index/helen-toner-joins"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ri4og6",
        "title": "TruthfulQA: Measuring how models mimic human falsehoods",
        "link": "https://openai.com/index/truthfulqa",
        "url": "https://openai.com/index/truthfulqa",
        "pubDate": "Wed, 08 Sep 2021 07:00:00 GMT",
        "isoDate": "2021-09-08T07:00:00.000Z",
        "source": "https://openai.com/index/truthfulqa"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9nl3pk",
        "title": "OpenAI Codex",
        "link": "https://openai.com/index/openai-codex",
        "url": "https://openai.com/index/openai-codex",
        "content": "We’ve created an improved version of OpenAI Codex, our AI system that translates natural language to code, and we are releasing it through our API in private beta starting today.",
        "contentSnippet": "We’ve created an improved version of OpenAI Codex, our AI system that translates natural language to code, and we are releasing it through our API in private beta starting today.",
        "pubDate": "Tue, 10 Aug 2021 07:00:00 GMT",
        "isoDate": "2021-08-10T07:00:00.000Z",
        "source": "https://openai.com/index/openai-codex"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vb0fy8",
        "title": "Introducing Triton: Open-source GPU programming for neural networks",
        "link": "https://openai.com/index/triton",
        "url": "https://openai.com/index/triton",
        "content": "We’re releasing Triton 1.0, an open-source Python-like programming language which enables researchers with no CUDA experience to write highly efficient GPU code—most of the time on par with what an expert would be able to produce.",
        "contentSnippet": "We’re releasing Triton 1.0, an open-source Python-like programming language which enables researchers with no CUDA experience to write highly efficient GPU code—most of the time on par with what an expert would be able to produce.",
        "pubDate": "Wed, 28 Jul 2021 07:00:00 GMT",
        "isoDate": "2021-07-28T07:00:00.000Z",
        "source": "https://openai.com/index/triton"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-18t8nq",
        "title": "Evaluating large language models trained on code",
        "link": "https://openai.com/index/evaluating-large-language-models-trained-on-code",
        "url": "https://openai.com/index/evaluating-large-language-models-trained-on-code",
        "pubDate": "Wed, 07 Jul 2021 07:00:00 GMT",
        "isoDate": "2021-07-07T07:00:00.000Z",
        "source": "https://openai.com/index/evaluating-large-language-models-trained-on-code"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-bj0j97",
        "title": "Improving language model behavior by training on a curated dataset",
        "link": "https://openai.com/index/improving-language-model-behavior",
        "url": "https://openai.com/index/improving-language-model-behavior",
        "content": "Our latest research finds we can improve language model behavior with respect to specific behavioral values by fine-tuning on a small, curated dataset.",
        "contentSnippet": "Our latest research finds we can improve language model behavior with respect to specific behavioral values by fine-tuning on a small, curated dataset.",
        "pubDate": "Thu, 10 Jun 2021 07:00:00 GMT",
        "isoDate": "2021-06-10T07:00:00.000Z",
        "source": "https://openai.com/index/improving-language-model-behavior"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-44ongk",
        "title": "OpenAI Scholars 2021: Final projects",
        "link": "https://openai.com/index/openai-scholars-2021-final-projects",
        "url": "https://openai.com/index/openai-scholars-2021-final-projects",
        "content": "We’re proud to announce that the 2021 class of OpenAI Scholars has completed our six-month mentorship program and have produced an open-source research project with stipends and support from OpenAI.",
        "contentSnippet": "We’re proud to announce that the 2021 class of OpenAI Scholars has completed our six-month mentorship program and have produced an open-source research project with stipends and support from OpenAI.",
        "pubDate": "Mon, 10 May 2021 07:00:00 GMT",
        "isoDate": "2021-05-10T07:00:00.000Z",
        "source": "https://openai.com/index/openai-scholars-2021-final-projects"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ytvoma",
        "title": "Will Hurd joins OpenAI’s board of directors",
        "link": "https://openai.com/index/will-hurd-joins",
        "url": "https://openai.com/index/will-hurd-joins",
        "content": "OpenAI is committed to developing general-purpose artificial intelligence that benefits all humanity, and we believe that achieving our goal requires expertise in public policy as well as technology. So, we’re delighted to announce that Congressman Will Hurd has joined our board of directors.",
        "contentSnippet": "OpenAI is committed to developing general-purpose artificial intelligence that benefits all humanity, and we believe that achieving our goal requires expertise in public policy as well as technology. So, we’re delighted to announce that Congressman Will Hurd has joined our board of directors.",
        "pubDate": "Mon, 03 May 2021 07:00:00 GMT",
        "isoDate": "2021-05-03T07:00:00.000Z",
        "source": "https://openai.com/index/will-hurd-joins"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ry7vbu",
        "title": "GPT-3 powers the next generation of apps",
        "link": "https://openai.com/index/gpt-3-apps",
        "url": "https://openai.com/index/gpt-3-apps",
        "content": "Over 300 applications are delivering GPT-3–powered search, conversation, text completion, and other advanced AI features through our API.",
        "contentSnippet": "Over 300 applications are delivering GPT-3–powered search, conversation, text completion, and other advanced AI features through our API.",
        "pubDate": "Thu, 25 Mar 2021 07:00:00 GMT",
        "isoDate": "2021-03-25T07:00:00.000Z",
        "source": "https://openai.com/index/gpt-3-apps"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-dmkq8x",
        "title": "Multimodal neurons in artificial neural networks",
        "link": "https://openai.com/index/multimodal-neurons",
        "url": "https://openai.com/index/multimodal-neurons",
        "content": "We’ve discovered neurons in CLIP that respond to the same concept whether presented literally, symbolically, or conceptually. This may explain CLIP’s accuracy in classifying surprising visual renditions of concepts, and is also an important step toward understanding the associations and biases that CLIP and similar models learn.",
        "contentSnippet": "We’ve discovered neurons in CLIP that respond to the same concept whether presented literally, symbolically, or conceptually. This may explain CLIP’s accuracy in classifying surprising visual renditions of concepts, and is also an important step toward understanding the associations and biases that CLIP and similar models learn.",
        "pubDate": "Thu, 04 Mar 2021 08:00:00 GMT",
        "isoDate": "2021-03-04T08:00:00.000Z",
        "source": "https://openai.com/index/multimodal-neurons"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ze3hf3",
        "title": "Understanding the capabilities, limitations, and societal impact of large language models",
        "link": "https://openai.com/index/understanding-the-capabilities-limitations-and-societal-impact-of-large-language-models",
        "url": "https://openai.com/index/understanding-the-capabilities-limitations-and-societal-impact-of-large-language-models",
        "pubDate": "Thu, 04 Feb 2021 08:00:00 GMT",
        "isoDate": "2021-02-04T08:00:00.000Z",
        "source": "https://openai.com/index/understanding-the-capabilities-limitations-and-societal-impact-of-large-language-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-v3hxrp",
        "title": "Scaling Kubernetes to 7,500 nodes",
        "link": "https://openai.com/index/scaling-kubernetes-to-7500-nodes",
        "url": "https://openai.com/index/scaling-kubernetes-to-7500-nodes",
        "content": "We’ve scaled Kubernetes clusters to 7,500 nodes, producing a scalable infrastructure for large models like GPT-3, CLIP, and DALL·E, but also for rapid small-scale iterative research such as Scaling Laws for Neural Language Models.",
        "contentSnippet": "We’ve scaled Kubernetes clusters to 7,500 nodes, producing a scalable infrastructure for large models like GPT-3, CLIP, and DALL·E, but also for rapid small-scale iterative research such as Scaling Laws for Neural Language Models.",
        "pubDate": "Mon, 25 Jan 2021 08:00:00 GMT",
        "isoDate": "2021-01-25T08:00:00.000Z",
        "source": "https://openai.com/index/scaling-kubernetes-to-7500-nodes"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vw2v2l",
        "title": "DALL·E: Creating images from text",
        "link": "https://openai.com/index/dall-e",
        "url": "https://openai.com/index/dall-e",
        "content": "We’ve trained a neural network called DALL·E that creates images from text captions for a wide range of concepts expressible in natural language.",
        "contentSnippet": "We’ve trained a neural network called DALL·E that creates images from text captions for a wide range of concepts expressible in natural language.",
        "pubDate": "Tue, 05 Jan 2021 08:00:00 GMT",
        "isoDate": "2021-01-05T08:00:00.000Z",
        "source": "https://openai.com/index/dall-e"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-okw4e0",
        "title": "CLIP: Connecting text and images",
        "link": "https://openai.com/index/clip",
        "url": "https://openai.com/index/clip",
        "content": "We’re introducing a neural network called CLIP which efficiently learns visual concepts from natural language supervision. CLIP can be applied to any visual classification benchmark by simply providing the names of the visual categories to be recognized, similar to the “zero-shot” capabilities of GPT-2 and GPT-3.",
        "contentSnippet": "We’re introducing a neural network called CLIP which efficiently learns visual concepts from natural language supervision. CLIP can be applied to any visual classification benchmark by simply providing the names of the visual categories to be recognized, similar to the “zero-shot” capabilities of GPT-2 and GPT-3.",
        "pubDate": "Tue, 05 Jan 2021 08:00:00 GMT",
        "isoDate": "2021-01-05T08:00:00.000Z",
        "source": "https://openai.com/index/clip"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xrr4io",
        "title": "Organizational update from OpenAI",
        "link": "https://openai.com/index/organizational-update",
        "url": "https://openai.com/index/organizational-update",
        "content": "It’s been a year of dramatic change and growth at OpenAI.",
        "contentSnippet": "It’s been a year of dramatic change and growth at OpenAI.",
        "pubDate": "Tue, 29 Dec 2020 08:00:00 GMT",
        "isoDate": "2020-12-29T08:00:00.000Z",
        "source": "https://openai.com/index/organizational-update"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-5sh3ex",
        "title": "OpenAI licenses GPT-3 technology to Microsoft",
        "link": "https://openai.com/index/openai-licenses-gpt-3-technology-to-microsoft",
        "url": "https://openai.com/index/openai-licenses-gpt-3-technology-to-microsoft",
        "content": "OpenAI has agreed to license GPT-3 to Microsoft for their own products and services.",
        "contentSnippet": "OpenAI has agreed to license GPT-3 to Microsoft for their own products and services.",
        "pubDate": "Tue, 22 Sep 2020 07:00:00 GMT",
        "isoDate": "2020-09-22T07:00:00.000Z",
        "source": "https://openai.com/index/openai-licenses-gpt-3-technology-to-microsoft"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-iy3aed",
        "title": "Generative language modeling for automated theorem proving",
        "link": "https://openai.com/index/generative-language-modeling-for-automated-theorem-proving",
        "url": "https://openai.com/index/generative-language-modeling-for-automated-theorem-proving",
        "pubDate": "Mon, 07 Sep 2020 07:00:00 GMT",
        "isoDate": "2020-09-07T07:00:00.000Z",
        "source": "https://openai.com/index/generative-language-modeling-for-automated-theorem-proving"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-y87sat",
        "title": "Learning to summarize with human feedback",
        "link": "https://openai.com/index/learning-to-summarize-with-human-feedback",
        "url": "https://openai.com/index/learning-to-summarize-with-human-feedback",
        "content": "We’ve applied reinforcement learning from human feedback to train language models that are better at summarization.",
        "contentSnippet": "We’ve applied reinforcement learning from human feedback to train language models that are better at summarization.",
        "pubDate": "Fri, 04 Sep 2020 07:00:00 GMT",
        "isoDate": "2020-09-04T07:00:00.000Z",
        "source": "https://openai.com/index/learning-to-summarize-with-human-feedback"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ckn65h",
        "title": "OpenAI Scholars 2020: Final projects",
        "link": "https://openai.com/index/openai-scholars-2020-final-projects",
        "url": "https://openai.com/index/openai-scholars-2020-final-projects",
        "content": "Our third class of OpenAI Scholars presented their final projects at virtual Demo Day, showcasing their research results from over the past five months.",
        "contentSnippet": "Our third class of OpenAI Scholars presented their final projects at virtual Demo Day, showcasing their research results from over the past five months.",
        "pubDate": "Thu, 09 Jul 2020 07:00:00 GMT",
        "isoDate": "2020-07-09T07:00:00.000Z",
        "source": "https://openai.com/index/openai-scholars-2020-final-projects"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-l1jf93",
        "title": "Procgen and MineRL Competitions",
        "link": "https://openai.com/index/procgen-minerl-competitions",
        "url": "https://openai.com/index/procgen-minerl-competitions",
        "content": "We’re excited to announce that OpenAI is co-organizing two NeurIPS 2020 competitions with AIcrowd, Carnegie Mellon University, and DeepMind, using Procgen Benchmark and MineRL.",
        "contentSnippet": "We’re excited to announce that OpenAI is co-organizing two NeurIPS 2020 competitions with AIcrowd, Carnegie Mellon University, and DeepMind, using Procgen Benchmark and MineRL.",
        "pubDate": "Sat, 20 Jun 2020 07:00:00 GMT",
        "isoDate": "2020-06-20T07:00:00.000Z",
        "source": "https://openai.com/index/procgen-minerl-competitions"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-8a3xhb",
        "title": "Image GPT",
        "link": "https://openai.com/index/image-gpt",
        "url": "https://openai.com/index/image-gpt",
        "content": "We find that, just as a large transformer model trained on language can generate coherent text, the same exact model trained on pixel sequences can generate coherent image completions and samples. By establishing a correlation between sample quality and image classification accuracy, we show that our best generative model also contains features competitive with top convolutional nets in the unsupervised setting.",
        "contentSnippet": "We find that, just as a large transformer model trained on language can generate coherent text, the same exact model trained on pixel sequences can generate coherent image completions and samples. By establishing a correlation between sample quality and image classification accuracy, we show that our best generative model also contains features competitive with top convolutional nets in the unsupervised setting.",
        "pubDate": "Wed, 17 Jun 2020 07:00:00 GMT",
        "isoDate": "2020-06-17T07:00:00.000Z",
        "source": "https://openai.com/index/image-gpt"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6sfvm1",
        "title": "OpenAI API",
        "link": "https://openai.com/index/openai-api",
        "url": "https://openai.com/index/openai-api",
        "content": "We’re releasing an API for accessing new AI models developed by OpenAI.",
        "contentSnippet": "We’re releasing an API for accessing new AI models developed by OpenAI.",
        "pubDate": "Thu, 11 Jun 2020 07:00:00 GMT",
        "isoDate": "2020-06-11T07:00:00.000Z",
        "source": "https://openai.com/index/openai-api"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-o4ulnl",
        "title": "Language models are few-shot learners",
        "link": "https://openai.com/index/language-models-are-few-shot-learners",
        "url": "https://openai.com/index/language-models-are-few-shot-learners",
        "pubDate": "Thu, 28 May 2020 07:00:00 GMT",
        "isoDate": "2020-05-28T07:00:00.000Z",
        "source": "https://openai.com/index/language-models-are-few-shot-learners"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-cy1nu4",
        "title": "AI and efficiency",
        "link": "https://openai.com/index/ai-and-efficiency",
        "url": "https://openai.com/index/ai-and-efficiency",
        "content": "We’re releasing an analysis showing that since 2012 the amount of compute needed to train a neural net to the same performance on ImageNet classification has been decreasing by a factor of 2 every 16 months. Compared to 2012, it now takes 44 times less compute to train a neural network to the level of AlexNet (by contrast, Moore’s Law would yield an 11x cost improvement over this period). Our results suggest that for AI tasks with high levels of recent investment, algorithmic progress has yielded more gains than classical hardware efficiency.",
        "contentSnippet": "We’re releasing an analysis showing that since 2012 the amount of compute needed to train a neural net to the same performance on ImageNet classification has been decreasing by a factor of 2 every 16 months. Compared to 2012, it now takes 44 times less compute to train a neural network to the level of AlexNet (by contrast, Moore’s Law would yield an 11x cost improvement over this period). Our results suggest that for AI tasks with high levels of recent investment, algorithmic progress has yielded more gains than classical hardware efficiency.",
        "pubDate": "Tue, 05 May 2020 07:00:00 GMT",
        "isoDate": "2020-05-05T07:00:00.000Z",
        "source": "https://openai.com/index/ai-and-efficiency"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-koewy6",
        "title": "Jukebox",
        "link": "https://openai.com/index/jukebox",
        "url": "https://openai.com/index/jukebox",
        "content": "We’re introducing Jukebox, a neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles. We’re releasing the model weights and code, along with a tool to explore the generated samples.",
        "contentSnippet": "We’re introducing Jukebox, a neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles. We’re releasing the model weights and code, along with a tool to explore the generated samples.",
        "pubDate": "Thu, 30 Apr 2020 07:00:00 GMT",
        "isoDate": "2020-04-30T07:00:00.000Z",
        "source": "https://openai.com/index/jukebox"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-hvwp01",
        "title": "Improving verifiability in AI development",
        "link": "https://openai.com/index/improving-verifiability",
        "url": "https://openai.com/index/improving-verifiability",
        "content": "We’ve contributed to a multi-stakeholder report by 58 co-authors at 30 organizations, including the Centre for the Future of Intelligence, Mila, Schwartz Reisman Institute for Technology and Society, Center for Advanced Study in the Behavioral Sciences, and Center for Security and Emerging Technologies. This report describes 10 mechanisms to improve the verifiability of claims made about AI systems. Developers can use these tools to provide evidence that AI systems are safe, secure, fair, or privacy-preserving. Users, policymakers, and civil society can use these tools to evaluate AI development processes.",
        "contentSnippet": "We’ve contributed to a multi-stakeholder report by 58 co-authors at 30 organizations, including the Centre for the Future of Intelligence, Mila, Schwartz Reisman Institute for Technology and Society, Center for Advanced Study in the Behavioral Sciences, and Center for Security and Emerging Technologies. This report describes 10 mechanisms to improve the verifiability of claims made about AI systems. Developers can use these tools to provide evidence that AI systems are safe, secure, fair, or privacy-preserving. Users, policymakers, and civil society can use these tools to evaluate AI development processes.",
        "pubDate": "Thu, 16 Apr 2020 07:00:00 GMT",
        "isoDate": "2020-04-16T07:00:00.000Z",
        "source": "https://openai.com/index/improving-verifiability"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-3qfngo",
        "title": "OpenAI Microscope",
        "link": "https://openai.com/index/microscope",
        "url": "https://openai.com/index/microscope",
        "content": "We’re introducing OpenAI Microscope, a collection of visualizations of every significant layer and neuron of eight vision “model organisms” which are often studied in interpretability. Microscope makes it easier to analyze the features that form inside these neural networks, and we hope it will help the research community as we move towards understanding these complicated systems.",
        "contentSnippet": "We’re introducing OpenAI Microscope, a collection of visualizations of every significant layer and neuron of eight vision “model organisms” which are often studied in interpretability. Microscope makes it easier to analyze the features that form inside these neural networks, and we hope it will help the research community as we move towards understanding these complicated systems.",
        "pubDate": "Tue, 14 Apr 2020 07:00:00 GMT",
        "isoDate": "2020-04-14T07:00:00.000Z",
        "source": "https://openai.com/index/microscope"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-raxoog",
        "title": "OpenAI standardizes on PyTorch",
        "link": "https://openai.com/index/openai-pytorch",
        "url": "https://openai.com/index/openai-pytorch",
        "content": "We are standardizing OpenAI’s deep learning framework on PyTorch.",
        "contentSnippet": "We are standardizing OpenAI’s deep learning framework on PyTorch.",
        "pubDate": "Thu, 30 Jan 2020 08:00:00 GMT",
        "isoDate": "2020-01-30T08:00:00.000Z",
        "source": "https://openai.com/index/openai-pytorch"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-pip56b",
        "title": "Scaling laws for neural language models",
        "link": "https://openai.com/index/scaling-laws-for-neural-language-models",
        "url": "https://openai.com/index/scaling-laws-for-neural-language-models",
        "pubDate": "Thu, 23 Jan 2020 08:00:00 GMT",
        "isoDate": "2020-01-23T08:00:00.000Z",
        "source": "https://openai.com/index/scaling-laws-for-neural-language-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xygbkn",
        "title": "Dota 2 with large scale deep reinforcement learning",
        "link": "https://openai.com/index/dota-2-with-large-scale-deep-reinforcement-learning",
        "url": "https://openai.com/index/dota-2-with-large-scale-deep-reinforcement-learning",
        "pubDate": "Fri, 13 Dec 2019 08:00:00 GMT",
        "isoDate": "2019-12-13T08:00:00.000Z",
        "source": "https://openai.com/index/dota-2-with-large-scale-deep-reinforcement-learning"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-pdcvjt",
        "title": "Deep double descent",
        "link": "https://openai.com/index/deep-double-descent",
        "url": "https://openai.com/index/deep-double-descent",
        "content": "We show that the double descent phenomenon occurs in CNNs, ResNets, and transformers: performance first improves, then gets worse, and then improves again with increasing model size, data size, or training time. This effect is often avoided through careful regularization. While this behavior appears to be fairly universal, we don’t yet fully understand why it happens, and view further study of this phenomenon as an important research direction.",
        "contentSnippet": "We show that the double descent phenomenon occurs in CNNs, ResNets, and transformers: performance first improves, then gets worse, and then improves again with increasing model size, data size, or training time. This effect is often avoided through careful regularization. While this behavior appears to be fairly universal, we don’t yet fully understand why it happens, and view further study of this phenomenon as an important research direction.",
        "pubDate": "Thu, 05 Dec 2019 08:00:00 GMT",
        "isoDate": "2019-12-05T08:00:00.000Z",
        "source": "https://openai.com/index/deep-double-descent"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-35a3bi",
        "title": "Procgen Benchmark",
        "link": "https://openai.com/index/procgen-benchmark",
        "url": "https://openai.com/index/procgen-benchmark",
        "content": "We’re releasing Procgen Benchmark, 16 simple-to-use procedurally-generated environments which provide a direct measure of how quickly a reinforcement learning agent learns generalizable skills.",
        "contentSnippet": "We’re releasing Procgen Benchmark, 16 simple-to-use procedurally-generated environments which provide a direct measure of how quickly a reinforcement learning agent learns generalizable skills.",
        "pubDate": "Tue, 03 Dec 2019 08:00:00 GMT",
        "isoDate": "2019-12-03T08:00:00.000Z",
        "source": "https://openai.com/index/procgen-benchmark"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ai23ot",
        "title": "Benchmarking safe exploration in deep reinforcement learning",
        "link": "https://openai.com/index/benchmarking-safe-exploration-in-deep-reinforcement-learning",
        "url": "https://openai.com/index/benchmarking-safe-exploration-in-deep-reinforcement-learning",
        "pubDate": "Thu, 21 Nov 2019 08:00:00 GMT",
        "isoDate": "2019-11-21T08:00:00.000Z",
        "source": "https://openai.com/index/benchmarking-safe-exploration-in-deep-reinforcement-learning"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-klm43s",
        "title": "Safety Gym",
        "link": "https://openai.com/index/safety-gym",
        "url": "https://openai.com/index/safety-gym",
        "content": "We’re releasing Safety Gym, a suite of environments and tools for measuring progress towards reinforcement learning agents that respect safety constraints while training.",
        "contentSnippet": "We’re releasing Safety Gym, a suite of environments and tools for measuring progress towards reinforcement learning agents that respect safety constraints while training.",
        "pubDate": "Thu, 21 Nov 2019 08:00:00 GMT",
        "isoDate": "2019-11-21T08:00:00.000Z",
        "source": "https://openai.com/index/safety-gym"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-eoo6rs",
        "title": "GPT-2: 1.5B release",
        "link": "https://openai.com/index/gpt-2-1-5b-release",
        "url": "https://openai.com/index/gpt-2-1-5b-release",
        "content": "As the final model release of GPT-2’s staged release, we’re releasing the largest version (1.5B parameters) of GPT-2 along with code and model weights to facilitate detection of outputs of GPT-2 models. While there have been larger language models released since August, we’ve continued with our original staged release plan in order to provide the community with a test case of a full staged release process. We hope that this test case will be useful to developers of future powerful models, and we’re actively continuing the conversation with the AI community on responsible publication.",
        "contentSnippet": "As the final model release of GPT-2’s staged release, we’re releasing the largest version (1.5B parameters) of GPT-2 along with code and model weights to facilitate detection of outputs of GPT-2 models. While there have been larger language models released since August, we’ve continued with our original staged release plan in order to provide the community with a test case of a full staged release process. We hope that this test case will be useful to developers of future powerful models, and we’re actively continuing the conversation with the AI community on responsible publication.",
        "pubDate": "Tue, 05 Nov 2019 08:00:00 GMT",
        "isoDate": "2019-11-05T08:00:00.000Z",
        "source": "https://openai.com/index/gpt-2-1-5b-release"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-b8qtif",
        "title": "Solving Rubik’s Cube with a robot hand",
        "link": "https://openai.com/index/solving-rubiks-cube",
        "url": "https://openai.com/index/solving-rubiks-cube",
        "content": "We’ve trained a pair of neural networks to solve the Rubik’s Cube with a human-like robot hand. The neural networks are trained entirely in simulation, using the same reinforcement learning code as OpenAI Five paired with a new technique called Automatic Domain Randomization (ADR). The system can handle situations it never saw during training, such as being prodded by a stuffed giraffe. This shows that reinforcement learning isn’t just a tool for virtual tasks, but can solve physical-world problems requiring unprecedented dexterity.",
        "contentSnippet": "We’ve trained a pair of neural networks to solve the Rubik’s Cube with a human-like robot hand. The neural networks are trained entirely in simulation, using the same reinforcement learning code as OpenAI Five paired with a new technique called Automatic Domain Randomization (ADR). The system can handle situations it never saw during training, such as being prodded by a stuffed giraffe. This shows that reinforcement learning isn’t just a tool for virtual tasks, but can solve physical-world problems requiring unprecedented dexterity.",
        "pubDate": "Tue, 15 Oct 2019 07:00:00 GMT",
        "isoDate": "2019-10-15T07:00:00.000Z",
        "source": "https://openai.com/index/solving-rubiks-cube"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-h8lmzr",
        "title": "OpenAI Scholars 2020: Applications open",
        "link": "https://openai.com/index/openai-scholars-2020",
        "url": "https://openai.com/index/openai-scholars-2020",
        "content": "We are now accepting applications for our third class of OpenAI Scholars.",
        "contentSnippet": "We are now accepting applications for our third class of OpenAI Scholars.",
        "pubDate": "Fri, 11 Oct 2019 07:00:00 GMT",
        "isoDate": "2019-10-11T07:00:00.000Z",
        "source": "https://openai.com/index/openai-scholars-2020"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-lg7lcd",
        "title": "Fine-tuning GPT-2 from human preferences",
        "link": "https://openai.com/index/fine-tuning-gpt-2",
        "url": "https://openai.com/index/fine-tuning-gpt-2",
        "content": "We’ve fine-tuned the 774M parameter GPT-2 language model using human feedback for various tasks, successfully matching the preferences of the external human labelers, though those preferences did not always match our own. Specifically, for summarization tasks the labelers preferred sentences copied wholesale from the input (we’d only asked them to ensure accuracy), so our models learned to copy. Summarization required 60k human labels; simpler tasks which continue text in various styles required only 5k. Our motivation is to move safety techniques closer to the general task of “machines talking to humans,” which we believe is key to extracting information about human values.",
        "contentSnippet": "We’ve fine-tuned the 774M parameter GPT-2 language model using human feedback for various tasks, successfully matching the preferences of the external human labelers, though those preferences did not always match our own. Specifically, for summarization tasks the labelers preferred sentences copied wholesale from the input (we’d only asked them to ensure accuracy), so our models learned to copy. Summarization required 60k human labels; simpler tasks which continue text in various styles required only 5k. Our motivation is to move safety techniques closer to the general task of “machines talking to humans,” which we believe is key to extracting information about human values.",
        "pubDate": "Thu, 19 Sep 2019 07:00:00 GMT",
        "isoDate": "2019-09-19T07:00:00.000Z",
        "source": "https://openai.com/index/fine-tuning-gpt-2"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-gvgj3i",
        "title": "Emergent tool use from multi-agent interaction",
        "link": "https://openai.com/index/emergent-tool-use",
        "url": "https://openai.com/index/emergent-tool-use",
        "content": "We’ve observed agents discovering progressively more complex tool use while playing a simple game of hide-and-seek. Through training in our new simulated hide-and-seek environment, agents build a series of six distinct strategies and counterstrategies, some of which we did not know our environment supported. The self-supervised emergent complexity in this simple environment further suggests that multi-agent co-adaptation may one day produce extremely complex and intelligent behavior.",
        "contentSnippet": "We’ve observed agents discovering progressively more complex tool use while playing a simple game of hide-and-seek. Through training in our new simulated hide-and-seek environment, agents build a series of six distinct strategies and counterstrategies, some of which we did not know our environment supported. The self-supervised emergent complexity in this simple environment further suggests that multi-agent co-adaptation may one day produce extremely complex and intelligent behavior.",
        "pubDate": "Tue, 17 Sep 2019 07:00:00 GMT",
        "isoDate": "2019-09-17T07:00:00.000Z",
        "source": "https://openai.com/index/emergent-tool-use"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-18vye5",
        "title": "Testing robustness against unforeseen adversaries",
        "link": "https://openai.com/index/testing-robustness",
        "url": "https://openai.com/index/testing-robustness",
        "content": "We’ve developed a method to assess whether a neural network classifier can reliably defend against adversarial attacks not seen during training. Our method yields a new metric, UAR (Unforeseen Attack Robustness), which evaluates the robustness of a single model against an unanticipated attack, and highlights the need to measure performance across a more diverse range of unforeseen attacks.",
        "contentSnippet": "We’ve developed a method to assess whether a neural network classifier can reliably defend against adversarial attacks not seen during training. Our method yields a new metric, UAR (Unforeseen Attack Robustness), which evaluates the robustness of a single model against an unanticipated attack, and highlights the need to measure performance across a more diverse range of unforeseen attacks.",
        "pubDate": "Thu, 22 Aug 2019 07:00:00 GMT",
        "isoDate": "2019-08-22T07:00:00.000Z",
        "source": "https://openai.com/index/testing-robustness"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ouwkpu",
        "title": "GPT-2: 6-month follow-up",
        "link": "https://openai.com/index/gpt-2-6-month-follow-up",
        "url": "https://openai.com/index/gpt-2-6-month-follow-up",
        "content": "We’re releasing the 774 million parameter GPT-2 language model after the release of our small 124M model in February, staged release of our medium 355M model in May, and subsequent research with partners and the AI community into the model’s potential for misuse and societal benefit. We’re also releasing an open-source legal agreement to make it easier for organizations to initiate model-sharing partnerships with each other, and are publishing a technical report about our experience in coordinating with the wider AI research community on publication norms.",
        "contentSnippet": "We’re releasing the 774 million parameter GPT-2 language model after the release of our small 124M model in February, staged release of our medium 355M model in May, and subsequent research with partners and the AI community into the model’s potential for misuse and societal benefit. We’re also releasing an open-source legal agreement to make it easier for organizations to initiate model-sharing partnerships with each other, and are publishing a technical report about our experience in coordinating with the wider AI research community on publication norms.",
        "pubDate": "Tue, 20 Aug 2019 07:00:00 GMT",
        "isoDate": "2019-08-20T07:00:00.000Z",
        "source": "https://openai.com/index/gpt-2-6-month-follow-up"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-a6x44b",
        "title": "Learning Day",
        "link": "https://openai.com/index/learning-day",
        "url": "https://openai.com/index/learning-day",
        "content": "At OpenAI, each Thursday is Learning Day: a day where employees have the option to self-study technical skills that will make them better at their job but which aren’t being learned from daily work.",
        "contentSnippet": "At OpenAI, each Thursday is Learning Day: a day where employees have the option to self-study technical skills that will make them better at their job but which aren’t being learned from daily work.",
        "pubDate": "Thu, 01 Aug 2019 07:00:00 GMT",
        "isoDate": "2019-08-01T07:00:00.000Z",
        "source": "https://openai.com/index/learning-day"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ze4v3l",
        "title": "Microsoft invests in and partners with OpenAI to support us building beneficial AGI",
        "link": "https://openai.com/index/microsoft-invests-in-and-partners-with-openai",
        "url": "https://openai.com/index/microsoft-invests-in-and-partners-with-openai",
        "content": "Microsoft is investing $1 billion in OpenAI to support us building artificial general intelligence (AGI) with widely distributed economic benefits. We’re partnering to develop a hardware and software platform within Microsoft Azure which will scale to AGI. We’ll jointly develop new Azure AI supercomputing technologies, and Microsoft will become our exclusive cloud provider—so we’ll be working hard together to further extend Microsoft Azure’s capabilities in large-scale AI systems.",
        "contentSnippet": "Microsoft is investing $1 billion in OpenAI to support us building artificial general intelligence (AGI) with widely distributed economic benefits. We’re partnering to develop a hardware and software platform within Microsoft Azure which will scale to AGI. We’ll jointly develop new Azure AI supercomputing technologies, and Microsoft will become our exclusive cloud provider—so we’ll be working hard together to further extend Microsoft Azure’s capabilities in large-scale AI systems.",
        "pubDate": "Mon, 22 Jul 2019 07:00:00 GMT",
        "isoDate": "2019-07-22T07:00:00.000Z",
        "source": "https://openai.com/index/microsoft-invests-in-and-partners-with-openai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xq20qe",
        "title": "Why responsible AI development needs cooperation on safety",
        "link": "https://openai.com/index/cooperation-on-safety",
        "url": "https://openai.com/index/cooperation-on-safety",
        "content": "We’ve written a policy research paper identifying four strategies that can be used today to improve the likelihood of long-term industry cooperation on safety norms in AI: communicating risks and benefits, technical collaboration, increased transparency, and incentivizing standards. Our analysis shows that industry cooperation on safety will be instrumental in ensuring that AI systems are safe and beneficial, but competitive pressures could lead to a collective action problem, potentially causing AI companies to under-invest in safety. We hope these strategies will encourage greater cooperation on the safe development of AI and lead to better global outcomes of AI.",
        "contentSnippet": "We’ve written a policy research paper identifying four strategies that can be used today to improve the likelihood of long-term industry cooperation on safety norms in AI: communicating risks and benefits, technical collaboration, increased transparency, and incentivizing standards. Our analysis shows that industry cooperation on safety will be instrumental in ensuring that AI systems are safe and beneficial, but competitive pressures could lead to a collective action problem, potentially causing AI companies to under-invest in safety. We hope these strategies will encourage greater cooperation on the safe development of AI and lead to better global outcomes of AI.",
        "pubDate": "Wed, 10 Jul 2019 07:00:00 GMT",
        "isoDate": "2019-07-10T07:00:00.000Z",
        "source": "https://openai.com/index/cooperation-on-safety"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9sdyjb",
        "title": "OpenAI Robotics Symposium 2019",
        "link": "https://openai.com/index/symposium-2019",
        "url": "https://openai.com/index/symposium-2019",
        "content": "We hosted the first OpenAI Robotics Symposium on April 27, 2019.",
        "contentSnippet": "We hosted the first OpenAI Robotics Symposium on April 27, 2019.",
        "pubDate": "Wed, 05 Jun 2019 07:00:00 GMT",
        "isoDate": "2019-06-05T07:00:00.000Z",
        "source": "https://openai.com/index/symposium-2019"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-erlkjp",
        "title": "OpenAI Scholars 2019: Final projects",
        "link": "https://openai.com/index/openai-scholars-2019-final-projects",
        "url": "https://openai.com/index/openai-scholars-2019-final-projects",
        "content": "Our second class of OpenAI Scholars has concluded, with all eight scholars producing an exciting final project showcased at Scholars Demo Day at OpenAI.",
        "contentSnippet": "Our second class of OpenAI Scholars has concluded, with all eight scholars producing an exciting final project showcased at Scholars Demo Day at OpenAI.",
        "pubDate": "Thu, 23 May 2019 07:00:00 GMT",
        "isoDate": "2019-05-23T07:00:00.000Z",
        "source": "https://openai.com/index/openai-scholars-2019-final-projects"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ofhgul",
        "title": "OpenAI Fellows Fall 2018: Final projects",
        "link": "https://openai.com/index/openai-fellows-fall-2018",
        "url": "https://openai.com/index/openai-fellows-fall-2018",
        "content": "Our second class of OpenAI Fellows has wrapped up, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship. We are currently reviewing applications on a rolling basis for our next round of OpenAI Fellows Summer 2019.",
        "contentSnippet": "Our second class of OpenAI Fellows has wrapped up, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship. We are currently reviewing applications on a rolling basis for our next round of OpenAI Fellows Summer 2019.",
        "pubDate": "Fri, 17 May 2019 07:00:00 GMT",
        "isoDate": "2019-05-17T07:00:00.000Z",
        "source": "https://openai.com/index/openai-fellows-fall-2018"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6ns7ys",
        "title": "Transfer of adversarial robustness between perturbation types",
        "link": "https://openai.com/index/transfer-of-adversarial-robustness-between-perturbation-types",
        "url": "https://openai.com/index/transfer-of-adversarial-robustness-between-perturbation-types",
        "pubDate": "Fri, 03 May 2019 07:00:00 GMT",
        "isoDate": "2019-05-03T07:00:00.000Z",
        "source": "https://openai.com/index/transfer-of-adversarial-robustness-between-perturbation-types"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-673oyd",
        "title": "MuseNet",
        "link": "https://openai.com/index/musenet",
        "url": "https://openai.com/index/musenet",
        "content": "We’ve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments, and can combine styles from country to Mozart to the Beatles. MuseNet was not explicitly programmed with our understanding of music, but instead discovered patterns of harmony, rhythm, and style by learning to predict the next token in hundreds of thousands of MIDI files. MuseNet uses the same general-purpose unsupervised technology as GPT-2, a large-scale transformer model trained to predict the next token in a sequence, whether audio or text.",
        "contentSnippet": "We’ve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments, and can combine styles from country to Mozart to the Beatles. MuseNet was not explicitly programmed with our understanding of music, but instead discovered patterns of harmony, rhythm, and style by learning to predict the next token in hundreds of thousands of MIDI files. MuseNet uses the same general-purpose unsupervised technology as GPT-2, a large-scale transformer model trained to predict the next token in a sequence, whether audio or text.",
        "pubDate": "Thu, 25 Apr 2019 07:00:00 GMT",
        "isoDate": "2019-04-25T07:00:00.000Z",
        "source": "https://openai.com/index/musenet"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-sld278",
        "title": "Generative modeling with sparse transformers",
        "link": "https://openai.com/index/sparse-transformer",
        "url": "https://openai.com/index/sparse-transformer",
        "content": "We’ve developed the Sparse Transformer, a deep neural network which sets new records at predicting what comes next in a sequence—whether text, images, or sound. It uses an algorithmic improvement of the attention mechanism to extract patterns from sequences 30x longer than possible previously.",
        "contentSnippet": "We’ve developed the Sparse Transformer, a deep neural network which sets new records at predicting what comes next in a sequence—whether text, images, or sound. It uses an algorithmic improvement of the attention mechanism to extract patterns from sequences 30x longer than possible previously.",
        "pubDate": "Tue, 23 Apr 2019 07:00:00 GMT",
        "isoDate": "2019-04-23T07:00:00.000Z",
        "source": "https://openai.com/index/sparse-transformer"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7uidp8",
        "title": "OpenAI Five defeats Dota 2 world champions",
        "link": "https://openai.com/index/openai-five-defeats-dota-2-world-champions",
        "url": "https://openai.com/index/openai-five-defeats-dota-2-world-champions",
        "content": "OpenAI Five is the first AI to beat the world champions in an esports game, having won two back-to-back games versus the world champion Dota 2 team, OG, at Finals this weekend. Both OpenAI Five and DeepMind’s AlphaStar had previously beaten good pros privately but lost their live pro matches, making this also the first time an AI has beaten esports pros on livestream.",
        "contentSnippet": "OpenAI Five is the first AI to beat the world champions in an esports game, having won two back-to-back games versus the world champion Dota 2 team, OG, at Finals this weekend. Both OpenAI Five and DeepMind’s AlphaStar had previously beaten good pros privately but lost their live pro matches, making this also the first time an AI has beaten esports pros on livestream.",
        "pubDate": "Mon, 15 Apr 2019 07:00:00 GMT",
        "isoDate": "2019-04-15T07:00:00.000Z",
        "source": "https://openai.com/index/openai-five-defeats-dota-2-world-champions"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-rmxzfv",
        "title": "OpenAI Five Finals",
        "link": "https://openai.com/index/openai-five-finals",
        "url": "https://openai.com/index/openai-five-finals",
        "content": "We’ll be holding our final live event for OpenAI Five at 11:30am PT on April 13.",
        "contentSnippet": "We’ll be holding our final live event for OpenAI Five at 11:30am PT on April 13.",
        "pubDate": "Tue, 26 Mar 2019 07:00:00 GMT",
        "isoDate": "2019-03-26T07:00:00.000Z",
        "source": "https://openai.com/index/openai-five-finals"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-3aty0h",
        "title": "Implicit generation and generalization methods for energy-based models",
        "link": "https://openai.com/index/energy-based-models",
        "url": "https://openai.com/index/energy-based-models",
        "content": "We’ve made progress towards stable and scalable training of energy-based models (EBMs) resulting in better sample quality and generalization ability than existing models. Generation in EBMs spends more compute to continually refine its answers and doing so can generate samples competitive with GANs at low temperatures, while also having mode coverage guarantees of likelihood-based models. We hope these findings stimulate further research into this promising class of models.",
        "contentSnippet": "We’ve made progress towards stable and scalable training of energy-based models (EBMs) resulting in better sample quality and generalization ability than existing models. Generation in EBMs spends more compute to continually refine its answers and doing so can generate samples competitive with GANs at low temperatures, while also having mode coverage guarantees of likelihood-based models. We hope these findings stimulate further research into this promising class of models.",
        "pubDate": "Thu, 21 Mar 2019 07:00:00 GMT",
        "isoDate": "2019-03-21T07:00:00.000Z",
        "source": "https://openai.com/index/energy-based-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-iq81nu",
        "title": "OpenAI Scholars 2019: Meet our Scholars",
        "link": "https://openai.com/index/openai-scholars-2019-meet-our-scholars",
        "url": "https://openai.com/index/openai-scholars-2019-meet-our-scholars",
        "content": "Our class of eight scholars (out of 550 applicants) brings together collective expertise in literature, philosophy, cell biology, statistics, economics, quantum physics, and business innovation.",
        "contentSnippet": "Our class of eight scholars (out of 550 applicants) brings together collective expertise in literature, philosophy, cell biology, statistics, economics, quantum physics, and business innovation.",
        "pubDate": "Wed, 13 Mar 2019 07:00:00 GMT",
        "isoDate": "2019-03-13T07:00:00.000Z",
        "source": "https://openai.com/index/openai-scholars-2019-meet-our-scholars"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vuxubr",
        "title": "OpenAI LP",
        "link": "https://openai.com/index/openai-lp",
        "url": "https://openai.com/index/openai-lp",
        "content": "We’ve created OpenAI LP, a new “capped-profit” company that allows us to rapidly increase our investments in compute and talent while including checks and balances to actualize our mission.",
        "contentSnippet": "We’ve created OpenAI LP, a new “capped-profit” company that allows us to rapidly increase our investments in compute and talent while including checks and balances to actualize our mission.",
        "pubDate": "Mon, 11 Mar 2019 07:00:00 GMT",
        "isoDate": "2019-03-11T07:00:00.000Z",
        "source": "https://openai.com/index/openai-lp"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-lzw2gl",
        "title": "Introducing Activation Atlases",
        "link": "https://openai.com/index/introducing-activation-atlases",
        "url": "https://openai.com/index/introducing-activation-atlases",
        "content": "We’ve created activation atlases (in collaboration with Google researchers), a new technique for visualizing what interactions between neurons can represent. As AI systems are deployed in increasingly sensitive contexts, having a better understanding of their internal decision-making processes will let us identify weaknesses and investigate failures.",
        "contentSnippet": "We’ve created activation atlases (in collaboration with Google researchers), a new technique for visualizing what interactions between neurons can represent. As AI systems are deployed in increasingly sensitive contexts, having a better understanding of their internal decision-making processes will let us identify weaknesses and investigate failures.",
        "pubDate": "Wed, 06 Mar 2019 08:00:00 GMT",
        "isoDate": "2019-03-06T08:00:00.000Z",
        "source": "https://openai.com/index/introducing-activation-atlases"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-76bzd3",
        "title": "Neural MMO: A massively multiagent game environment",
        "link": "https://openai.com/index/neural-mmo",
        "url": "https://openai.com/index/neural-mmo",
        "content": "We’re releasing a Neural MMO, a massively multiagent game environment for reinforcement learning agents. Our platform supports a large, variable number of agents within a persistent and open-ended task. The inclusion of many agents and species leads to better exploration, divergent niche formation, and greater overall competence.",
        "contentSnippet": "We’re releasing a Neural MMO, a massively multiagent game environment for reinforcement learning agents. Our platform supports a large, variable number of agents within a persistent and open-ended task. The inclusion of many agents and species leads to better exploration, divergent niche formation, and greater overall competence.",
        "pubDate": "Mon, 04 Mar 2019 08:00:00 GMT",
        "isoDate": "2019-03-04T08:00:00.000Z",
        "source": "https://openai.com/index/neural-mmo"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-z21fcn",
        "title": "Spinning Up in Deep RL: Workshop review",
        "link": "https://openai.com/index/spinning-up-in-deep-rl-workshop-review",
        "url": "https://openai.com/index/spinning-up-in-deep-rl-workshop-review",
        "content": "On February 2, we held our first Spinning Up Workshop as part of our new education initiative at OpenAI.",
        "contentSnippet": "On February 2, we held our first Spinning Up Workshop as part of our new education initiative at OpenAI.",
        "pubDate": "Tue, 26 Feb 2019 08:00:00 GMT",
        "isoDate": "2019-02-26T08:00:00.000Z",
        "source": "https://openai.com/index/spinning-up-in-deep-rl-workshop-review"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-gsmpgd",
        "title": "AI safety needs social scientists",
        "link": "https://openai.com/index/ai-safety-needs-social-scientists",
        "url": "https://openai.com/index/ai-safety-needs-social-scientists",
        "content": "We’ve written a paper arguing that long-term AI safety research needs social scientists to ensure AI alignment algorithms succeed when actual humans are involved. Properly aligning advanced AI systems with human values requires resolving many uncertainties related to the psychology of human rationality, emotion, and biases. The aim of this paper is to spark further collaboration between machine learning and social science researchers, and we plan to hire social scientists to work on this full time at OpenAI.",
        "contentSnippet": "We’ve written a paper arguing that long-term AI safety research needs social scientists to ensure AI alignment algorithms succeed when actual humans are involved. Properly aligning advanced AI systems with human values requires resolving many uncertainties related to the psychology of human rationality, emotion, and biases. The aim of this paper is to spark further collaboration between machine learning and social science researchers, and we plan to hire social scientists to work on this full time at OpenAI.",
        "pubDate": "Tue, 19 Feb 2019 08:00:00 GMT",
        "isoDate": "2019-02-19T08:00:00.000Z",
        "source": "https://openai.com/index/ai-safety-needs-social-scientists"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-tfi7fe",
        "title": "Better language models and their implications",
        "link": "https://openai.com/index/better-language-models",
        "url": "https://openai.com/index/better-language-models",
        "content": "We’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task-specific training.",
        "contentSnippet": "We’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task-specific training.",
        "pubDate": "Thu, 14 Feb 2019 08:00:00 GMT",
        "isoDate": "2019-02-14T08:00:00.000Z",
        "source": "https://openai.com/index/better-language-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-rc8nf6",
        "title": "Computational limitations in robust classification and win-win results",
        "link": "https://openai.com/index/computational-limitations-in-robust-classification-and-win-win-results",
        "url": "https://openai.com/index/computational-limitations-in-robust-classification-and-win-win-results",
        "pubDate": "Mon, 04 Feb 2019 08:00:00 GMT",
        "isoDate": "2019-02-04T08:00:00.000Z",
        "source": "https://openai.com/index/computational-limitations-in-robust-classification-and-win-win-results"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-bwtfdr",
        "title": "OpenAI Fellows Summer 2018: Final projects",
        "link": "https://openai.com/index/openai-summer-fellows-2018",
        "url": "https://openai.com/index/openai-summer-fellows-2018",
        "content": "Our first cohort of OpenAI Fellows has concluded, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship.",
        "contentSnippet": "Our first cohort of OpenAI Fellows has concluded, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship.",
        "pubDate": "Wed, 19 Dec 2018 08:00:00 GMT",
        "isoDate": "2018-12-19T08:00:00.000Z",
        "source": "https://openai.com/index/openai-summer-fellows-2018"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-3d7gvg",
        "title": "How AI training scales",
        "link": "https://openai.com/index/how-ai-training-scales",
        "url": "https://openai.com/index/how-ai-training-scales",
        "content": "We’ve discovered that the gradient noise scale, a simple statistical metric, predicts the parallelizability of neural network training on a wide range of tasks. Since complex tasks tend to have noisier gradients, increasingly large batch sizes are likely to become useful in the future, removing one potential limit to further growth of AI systems. More broadly, these results show that neural network training need not be considered a mysterious art, but can be rigorized and systematized.",
        "contentSnippet": "We’ve discovered that the gradient noise scale, a simple statistical metric, predicts the parallelizability of neural network training on a wide range of tasks. Since complex tasks tend to have noisier gradients, increasingly large batch sizes are likely to become useful in the future, removing one potential limit to further growth of AI systems. More broadly, these results show that neural network training need not be considered a mysterious art, but can be rigorized and systematized.",
        "pubDate": "Fri, 14 Dec 2018 08:00:00 GMT",
        "isoDate": "2018-12-14T08:00:00.000Z",
        "source": "https://openai.com/index/how-ai-training-scales"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-5ugqp9",
        "title": "Quantifying generalization in reinforcement learning",
        "link": "https://openai.com/index/quantifying-generalization-in-reinforcement-learning",
        "url": "https://openai.com/index/quantifying-generalization-in-reinforcement-learning",
        "content": "We’re releasing CoinRun, a training environment which provides a metric for an agent’s ability to transfer its experience to novel situations and has already helped clarify a longstanding puzzle in reinforcement learning. CoinRun strikes a desirable balance in complexity: the environment is simpler than traditional platformer games like Sonic the Hedgehog but still poses a worthy generalization challenge for state of the art algorithms.",
        "contentSnippet": "We’re releasing CoinRun, a training environment which provides a metric for an agent’s ability to transfer its experience to novel situations and has already helped clarify a longstanding puzzle in reinforcement learning. CoinRun strikes a desirable balance in complexity: the environment is simpler than traditional platformer games like Sonic the Hedgehog but still poses a worthy generalization challenge for state of the art algorithms.",
        "pubDate": "Thu, 06 Dec 2018 08:00:00 GMT",
        "isoDate": "2018-12-06T08:00:00.000Z",
        "source": "https://openai.com/index/quantifying-generalization-in-reinforcement-learning"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-1f8cbq",
        "title": "Spinning Up in Deep RL",
        "link": "https://openai.com/index/spinning-up-in-deep-rl",
        "url": "https://openai.com/index/spinning-up-in-deep-rl",
        "content": "We’re releasing Spinning Up in Deep RL, an educational resource designed to let anyone learn to become a skilled practitioner in deep reinforcement learning. Spinning Up consists of crystal-clear examples of RL code, educational exercises, documentation, and tutorials.",
        "contentSnippet": "We’re releasing Spinning Up in Deep RL, an educational resource designed to let anyone learn to become a skilled practitioner in deep reinforcement learning. Spinning Up consists of crystal-clear examples of RL code, educational exercises, documentation, and tutorials.",
        "pubDate": "Thu, 08 Nov 2018 08:00:00 GMT",
        "isoDate": "2018-11-08T08:00:00.000Z",
        "source": "https://openai.com/index/spinning-up-in-deep-rl"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-xaunwy",
        "title": "Learning concepts with energy functions",
        "link": "https://openai.com/index/learning-concepts-with-energy-functions",
        "url": "https://openai.com/index/learning-concepts-with-energy-functions",
        "content": "We’ve developed an energy-based model that can quickly learn to identify and generate instances of concepts, such as near, above, between, closest, and furthest, expressed as sets of 2d points. Our model learns these concepts after only five demonstrations. We also show cross-domain transfer: we use concepts learned in a 2d particle environment to solve tasks on a 3-dimensional physics-based robot.",
        "contentSnippet": "We’ve developed an energy-based model that can quickly learn to identify and generate instances of concepts, such as near, above, between, closest, and furthest, expressed as sets of 2d points. Our model learns these concepts after only five demonstrations. We also show cross-domain transfer: we use concepts learned in a 2d particle environment to solve tasks on a 3-dimensional physics-based robot.",
        "pubDate": "Wed, 07 Nov 2018 08:00:00 GMT",
        "isoDate": "2018-11-07T08:00:00.000Z",
        "source": "https://openai.com/index/learning-concepts-with-energy-functions"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-eunjsk",
        "title": "Plan online, learn offline: Efficient learning and exploration via model-based control",
        "link": "https://openai.com/index/plan-online-learn-offline",
        "url": "https://openai.com/index/plan-online-learn-offline",
        "pubDate": "Mon, 05 Nov 2018 08:00:00 GMT",
        "isoDate": "2018-11-05T08:00:00.000Z",
        "source": "https://openai.com/index/plan-online-learn-offline"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-3eeye0",
        "title": "Reinforcement learning with prediction-based rewards",
        "link": "https://openai.com/index/reinforcement-learning-with-prediction-based-rewards",
        "url": "https://openai.com/index/reinforcement-learning-with-prediction-based-rewards",
        "content": "We’ve developed Random Network Distillation (RND), a prediction-based method for encouraging reinforcement learning agents to explore their environments through curiosity, which for the first time exceeds average human performance on Montezuma’s Revenge.",
        "contentSnippet": "We’ve developed Random Network Distillation (RND), a prediction-based method for encouraging reinforcement learning agents to explore their environments through curiosity, which for the first time exceeds average human performance on Montezuma’s Revenge.",
        "pubDate": "Wed, 31 Oct 2018 07:00:00 GMT",
        "isoDate": "2018-10-31T07:00:00.000Z",
        "source": "https://openai.com/index/reinforcement-learning-with-prediction-based-rewards"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-tdwvrt",
        "title": "Learning complex goals with iterated amplification",
        "link": "https://openai.com/index/learning-complex-goals-with-iterated-amplification",
        "url": "https://openai.com/index/learning-complex-goals-with-iterated-amplification",
        "content": "We’re proposing an AI safety technique called iterated amplification that lets us specify complicated behaviors and goals that are beyond human scale, by demonstrating how to decompose a task into simpler sub-tasks, rather than by providing labeled data or a reward function. Although this idea is in its very early stages and we have only completed experiments on simple toy algorithmic domains, we’ve decided to present it in its preliminary state because we think it could prove to be a scalable approach to AI safety.",
        "contentSnippet": "We’re proposing an AI safety technique called iterated amplification that lets us specify complicated behaviors and goals that are beyond human scale, by demonstrating how to decompose a task into simpler sub-tasks, rather than by providing labeled data or a reward function. Although this idea is in its very early stages and we have only completed experiments on simple toy algorithmic domains, we’ve decided to present it in its preliminary state because we think it could prove to be a scalable approach to AI safety.",
        "pubDate": "Mon, 22 Oct 2018 07:00:00 GMT",
        "isoDate": "2018-10-22T07:00:00.000Z",
        "source": "https://openai.com/index/learning-complex-goals-with-iterated-amplification"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-h8ln0d",
        "title": "OpenAI Scholars 2019: Applications open",
        "link": "https://openai.com/index/openai-scholars-2019",
        "url": "https://openai.com/index/openai-scholars-2019",
        "content": "We are now accepting applications for our second cohort of OpenAI Scholars, a program where we provide 6–10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
        "contentSnippet": "We are now accepting applications for our second cohort of OpenAI Scholars, a program where we provide 6–10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
        "pubDate": "Thu, 11 Oct 2018 07:00:00 GMT",
        "isoDate": "2018-10-11T07:00:00.000Z",
        "source": "https://openai.com/index/openai-scholars-2019"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ajp6cq",
        "title": "OpenAI Fellows Winter 2019 & Interns Summer 2019",
        "link": "https://openai.com/index/openai-fellows-interns-2019",
        "url": "https://openai.com/index/openai-fellows-interns-2019",
        "content": "We are now accepting applications for OpenAI Fellows and Interns for 2019.",
        "contentSnippet": "We are now accepting applications for OpenAI Fellows and Interns for 2019.",
        "pubDate": "Tue, 09 Oct 2018 07:00:00 GMT",
        "isoDate": "2018-10-09T07:00:00.000Z",
        "source": "https://openai.com/index/openai-fellows-interns-2019"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wwvwq7",
        "title": "FFJORD: Free-form continuous dynamics for scalable reversible generative models",
        "link": "https://openai.com/index/ffjord",
        "url": "https://openai.com/index/ffjord",
        "pubDate": "Tue, 02 Oct 2018 07:00:00 GMT",
        "isoDate": "2018-10-02T07:00:00.000Z",
        "source": "https://openai.com/index/ffjord"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6bn1us",
        "title": "OpenAI Scholars 2018: Final projects",
        "link": "https://openai.com/index/openai-scholars-2018-final-projects",
        "url": "https://openai.com/index/openai-scholars-2018-final-projects",
        "content": "Our first cohort of OpenAI Scholars has now completed the program.",
        "contentSnippet": "Our first cohort of OpenAI Scholars has now completed the program.",
        "pubDate": "Mon, 10 Sep 2018 07:00:00 GMT",
        "isoDate": "2018-09-10T07:00:00.000Z",
        "source": "https://openai.com/index/openai-scholars-2018-final-projects"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-p2ik73",
        "title": "The International 2018: Results",
        "link": "https://openai.com/index/the-international-2018-results",
        "url": "https://openai.com/index/the-international-2018-results",
        "content": "OpenAI Five lost two games against top Dota 2 players at The International in Vancouver this week, maintaining a good chance of winning for the first 20–35 minutes of both games.",
        "contentSnippet": "OpenAI Five lost two games against top Dota 2 players at The International in Vancouver this week, maintaining a good chance of winning for the first 20–35 minutes of both games.",
        "pubDate": "Thu, 23 Aug 2018 07:00:00 GMT",
        "isoDate": "2018-08-23T07:00:00.000Z",
        "source": "https://openai.com/index/the-international-2018-results"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-lxxzqi",
        "title": "Large-scale study of curiosity-driven learning",
        "link": "https://openai.com/index/large-scale-study-of-curiosity-driven-learning",
        "url": "https://openai.com/index/large-scale-study-of-curiosity-driven-learning",
        "pubDate": "Mon, 13 Aug 2018 07:00:00 GMT",
        "isoDate": "2018-08-13T07:00:00.000Z",
        "source": "https://openai.com/index/large-scale-study-of-curiosity-driven-learning"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-bb2w0e",
        "title": "OpenAI Five Benchmark: Results",
        "link": "https://openai.com/index/openai-five-benchmark-results",
        "url": "https://openai.com/index/openai-five-benchmark-results",
        "content": "Yesterday, OpenAI Five won a best-of-three against a team of 99.95th percentile Dota players: Blitz, Cap, Fogged, Merlini, and MoonMeander—four of whom have played Dota professionally—in front of a live audience and 100,000 concurrent livestream viewers.",
        "contentSnippet": "Yesterday, OpenAI Five won a best-of-three against a team of 99.95th percentile Dota players: Blitz, Cap, Fogged, Merlini, and MoonMeander—four of whom have played Dota professionally—in front of a live audience and 100,000 concurrent livestream viewers.",
        "pubDate": "Mon, 06 Aug 2018 07:00:00 GMT",
        "isoDate": "2018-08-06T07:00:00.000Z",
        "source": "https://openai.com/index/openai-five-benchmark-results"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ptyo4z",
        "title": "Learning dexterity",
        "link": "https://openai.com/index/learning-dexterity",
        "url": "https://openai.com/index/learning-dexterity",
        "content": "We’ve trained a human-like robot hand to manipulate physical objects with unprecedented dexterity.",
        "contentSnippet": "We’ve trained a human-like robot hand to manipulate physical objects with unprecedented dexterity.",
        "pubDate": "Mon, 30 Jul 2018 07:00:00 GMT",
        "isoDate": "2018-07-30T07:00:00.000Z",
        "source": "https://openai.com/index/learning-dexterity"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-25jwaa",
        "title": "Variational option discovery algorithms",
        "link": "https://openai.com/index/variational-option-discovery-algorithms",
        "url": "https://openai.com/index/variational-option-discovery-algorithms",
        "pubDate": "Thu, 26 Jul 2018 07:00:00 GMT",
        "isoDate": "2018-07-26T07:00:00.000Z",
        "source": "https://openai.com/index/variational-option-discovery-algorithms"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wp00bt",
        "title": "OpenAI Scholars 2018: Meet our Scholars",
        "link": "https://openai.com/index/openai-scholars-2018-meet-our-scholars",
        "url": "https://openai.com/index/openai-scholars-2018-meet-our-scholars",
        "content": "Our first class of OpenAI Scholars is underway, and you can now follow along as this group of experienced software developers becomes machine learning practitioners.",
        "contentSnippet": "Our first class of OpenAI Scholars is underway, and you can now follow along as this group of experienced software developers becomes machine learning practitioners.",
        "pubDate": "Wed, 25 Jul 2018 07:00:00 GMT",
        "isoDate": "2018-07-25T07:00:00.000Z",
        "source": "https://openai.com/index/openai-scholars-2018-meet-our-scholars"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jeqkkb",
        "title": "OpenAI Five Benchmark",
        "link": "https://openai.com/index/openai-five-benchmark",
        "url": "https://openai.com/index/openai-five-benchmark",
        "content": "The OpenAI Five Benchmark match is now over!",
        "contentSnippet": "The OpenAI Five Benchmark match is now over!",
        "pubDate": "Wed, 18 Jul 2018 07:00:00 GMT",
        "isoDate": "2018-07-18T07:00:00.000Z",
        "source": "https://openai.com/index/openai-five-benchmark"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-oktkaj",
        "title": "Glow: Better reversible generative models",
        "link": "https://openai.com/index/glow",
        "url": "https://openai.com/index/glow",
        "content": "We introduce Glow, a reversible generative model which uses invertible 1x1 convolutions. It extends previous work on reversible generative models and simplifies the architecture. Our model can generate realistic high resolution images, supports efficient sampling, and discovers features that can be used to manipulate attributes of data. We’re releasing code for the model and an online visualization tool so people can explore and build on these results.",
        "contentSnippet": "We introduce Glow, a reversible generative model which uses invertible 1x1 convolutions. It extends previous work on reversible generative models and simplifies the architecture. Our model can generate realistic high resolution images, supports efficient sampling, and discovers features that can be used to manipulate attributes of data. We’re releasing code for the model and an online visualization tool so people can explore and build on these results.",
        "pubDate": "Mon, 09 Jul 2018 07:00:00 GMT",
        "isoDate": "2018-07-09T07:00:00.000Z",
        "source": "https://openai.com/index/glow"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-bqd1l3",
        "title": "Learning Montezuma’s Revenge from a single demonstration",
        "link": "https://openai.com/index/learning-montezumas-revenge-from-a-single-demonstration",
        "url": "https://openai.com/index/learning-montezumas-revenge-from-a-single-demonstration",
        "content": "We’ve trained an agent to achieve a high score of 74,500 on Montezuma’s Revenge from a single human demonstration, better than any previously published result. Our algorithm is simple: the agent plays a sequence of games starting from carefully chosen states from the demonstration, and learns from them by optimizing the game score using PPO, the same reinforcement learning algorithm that underpins OpenAI Five.",
        "contentSnippet": "We’ve trained an agent to achieve a high score of 74,500 on Montezuma’s Revenge from a single human demonstration, better than any previously published result. Our algorithm is simple: the agent plays a sequence of games starting from carefully chosen states from the demonstration, and learns from them by optimizing the game score using PPO, the same reinforcement learning algorithm that underpins OpenAI Five.",
        "pubDate": "Wed, 04 Jul 2018 07:00:00 GMT",
        "isoDate": "2018-07-04T07:00:00.000Z",
        "source": "https://openai.com/index/learning-montezumas-revenge-from-a-single-demonstration"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-2lr039",
        "title": "OpenAI Five",
        "link": "https://openai.com/index/openai-five",
        "url": "https://openai.com/index/openai-five",
        "content": "Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams at Dota 2.",
        "contentSnippet": "Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams at Dota 2.",
        "pubDate": "Mon, 25 Jun 2018 07:00:00 GMT",
        "isoDate": "2018-06-25T07:00:00.000Z",
        "source": "https://openai.com/index/openai-five"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-twh2mu",
        "title": "Retro Contest: Results",
        "link": "https://openai.com/index/retro-contest-results",
        "url": "https://openai.com/index/retro-contest-results",
        "content": "The first run of our Retro Contest—exploring the development of algorithms that can generalize from previous experience—is now complete.",
        "contentSnippet": "The first run of our Retro Contest—exploring the development of algorithms that can generalize from previous experience—is now complete.",
        "pubDate": "Fri, 22 Jun 2018 07:00:00 GMT",
        "isoDate": "2018-06-22T07:00:00.000Z",
        "source": "https://openai.com/index/retro-contest-results"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-axisv4",
        "title": "Learning policy representations in multiagent systems",
        "link": "https://openai.com/index/learning-policy-representations-in-multiagent-systems",
        "url": "https://openai.com/index/learning-policy-representations-in-multiagent-systems",
        "pubDate": "Sun, 17 Jun 2018 07:00:00 GMT",
        "isoDate": "2018-06-17T07:00:00.000Z",
        "source": "https://openai.com/index/learning-policy-representations-in-multiagent-systems"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-sljp0a",
        "title": "Improving language understanding with unsupervised learning",
        "link": "https://openai.com/index/language-unsupervised",
        "url": "https://openai.com/index/language-unsupervised",
        "content": "We’ve obtained state-of-the-art results on a suite of diverse language tasks with a scalable, task-agnostic system, which we’re also releasing. Our approach is a combination of two existing ideas: transformers and unsupervised pre-training. These results provide a convincing example that pairing supervised learning methods with unsupervised pre-training works very well; this is an idea that many have explored in the past, and we hope our result motivates further research into applying this idea on larger and more diverse datasets.",
        "contentSnippet": "We’ve obtained state-of-the-art results on a suite of diverse language tasks with a scalable, task-agnostic system, which we’re also releasing. Our approach is a combination of two existing ideas: transformers and unsupervised pre-training. These results provide a convincing example that pairing supervised learning methods with unsupervised pre-training works very well; this is an idea that many have explored in the past, and we hope our result motivates further research into applying this idea on larger and more diverse datasets.",
        "pubDate": "Mon, 11 Jun 2018 07:00:00 GMT",
        "isoDate": "2018-06-11T07:00:00.000Z",
        "source": "https://openai.com/index/language-unsupervised"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wskidz",
        "title": "GamePad: A learning environment for theorem proving",
        "link": "https://openai.com/index/gamepad",
        "url": "https://openai.com/index/gamepad",
        "pubDate": "Sat, 02 Jun 2018 07:00:00 GMT",
        "isoDate": "2018-06-02T07:00:00.000Z",
        "source": "https://openai.com/index/gamepad"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-czu72h",
        "title": "OpenAI Fellows Fall 2018",
        "link": "https://openai.com/index/openai-fellows",
        "url": "https://openai.com/index/openai-fellows",
        "content": "We’re now accepting applications for the next cohort of OpenAI Fellows, a program which offers a compensated 6-month apprenticeship in AI research at OpenAI.",
        "contentSnippet": "We’re now accepting applications for the next cohort of OpenAI Fellows, a program which offers a compensated 6-month apprenticeship in AI research at OpenAI.",
        "pubDate": "Wed, 30 May 2018 07:00:00 GMT",
        "isoDate": "2018-05-30T07:00:00.000Z",
        "source": "https://openai.com/index/openai-fellows"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-lyzyi4",
        "title": "Gym Retro",
        "link": "https://openai.com/index/gym-retro",
        "url": "https://openai.com/index/gym-retro",
        "content": "We’re releasing the full version of Gym Retro, a platform for reinforcement learning research on games. This brings our publicly-released game count from around 70 Atari games and 30 Sega games to over 1,000 games across a variety of backing emulators. We’re also releasing the tool we use to add new games to the platform.",
        "contentSnippet": "We’re releasing the full version of Gym Retro, a platform for reinforcement learning research on games. This brings our publicly-released game count from around 70 Atari games and 30 Sega games to over 1,000 games across a variety of backing emulators. We’re also releasing the tool we use to add new games to the platform.",
        "pubDate": "Fri, 25 May 2018 07:00:00 GMT",
        "isoDate": "2018-05-25T07:00:00.000Z",
        "source": "https://openai.com/index/gym-retro"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-1io1p0",
        "title": "AI and compute",
        "link": "https://openai.com/index/ai-and-compute",
        "url": "https://openai.com/index/ai-and-compute",
        "content": "We’re releasing an analysis showing that since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.4-month doubling time (by comparison, Moore’s Law had a 2-year doubling period)[^footnote-correction]. Since 2012, this metric has grown by more than 300,000x (a 2-year doubling period would yield only a 7x increase). Improvements in compute have been a key component of AI progress, so as long as this trend continues, it’s worth preparing for the implications of systems far outside today’s capabilities.",
        "contentSnippet": "We’re releasing an analysis showing that since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.4-month doubling time (by comparison, Moore’s Law had a 2-year doubling period)[^footnote-correction]. Since 2012, this metric has grown by more than 300,000x (a 2-year doubling period would yield only a 7x increase). Improvements in compute have been a key component of AI progress, so as long as this trend continues, it’s worth preparing for the implications of systems far outside today’s capabilities.",
        "pubDate": "Wed, 16 May 2018 07:00:00 GMT",
        "isoDate": "2018-05-16T07:00:00.000Z",
        "source": "https://openai.com/index/ai-and-compute"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vy3h49",
        "title": "AI safety via debate",
        "link": "https://openai.com/index/debate",
        "url": "https://openai.com/index/debate",
        "content": "We’re proposing an AI safety technique which trains agents to debate topics with one another, using a human to judge who wins.",
        "contentSnippet": "We’re proposing an AI safety technique which trains agents to debate topics with one another, using a human to judge who wins.",
        "pubDate": "Thu, 03 May 2018 07:00:00 GMT",
        "isoDate": "2018-05-03T07:00:00.000Z",
        "source": "https://openai.com/index/debate"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-1sjcm2",
        "title": "Evolved Policy Gradients",
        "link": "https://openai.com/index/evolved-policy-gradients",
        "url": "https://openai.com/index/evolved-policy-gradients",
        "content": "We’re releasing an experimental metalearning approach called Evolved Policy Gradients, a method that evolves the loss function of learning agents, which can enable fast training on novel tasks. Agents trained with EPG can succeed at basic tasks at test time that were outside their training regime, like learning to navigate to an object on a different side of the room from where it was placed during training.",
        "contentSnippet": "We’re releasing an experimental metalearning approach called Evolved Policy Gradients, a method that evolves the loss function of learning agents, which can enable fast training on novel tasks. Agents trained with EPG can succeed at basic tasks at test time that were outside their training regime, like learning to navigate to an object on a different side of the room from where it was placed during training.",
        "pubDate": "Wed, 18 Apr 2018 07:00:00 GMT",
        "isoDate": "2018-04-18T07:00:00.000Z",
        "source": "https://openai.com/index/evolved-policy-gradients"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-zd06b3",
        "title": "Gotta Learn Fast: A new benchmark for generalization in RL",
        "link": "https://openai.com/index/gotta-learn-fast",
        "url": "https://openai.com/index/gotta-learn-fast",
        "pubDate": "Tue, 10 Apr 2018 07:00:00 GMT",
        "isoDate": "2018-04-10T07:00:00.000Z",
        "source": "https://openai.com/index/gotta-learn-fast"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-fl0x9p",
        "title": "Retro Contest",
        "link": "https://openai.com/index/retro-contest",
        "url": "https://openai.com/index/retro-contest",
        "content": "We’re launching a transfer learning contest that measures a reinforcement learning algorithm’s ability to generalize from previous experience.",
        "contentSnippet": "We’re launching a transfer learning contest that measures a reinforcement learning algorithm’s ability to generalize from previous experience.",
        "pubDate": "Thu, 05 Apr 2018 07:00:00 GMT",
        "isoDate": "2018-04-05T07:00:00.000Z",
        "source": "https://openai.com/index/retro-contest"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6qur42",
        "title": "Variance reduction for policy gradient with action-dependent factorized baselines",
        "link": "https://openai.com/index/variance-reduction-for-policy-gradient-with-action-dependent-factorized-baselines",
        "url": "https://openai.com/index/variance-reduction-for-policy-gradient-with-action-dependent-factorized-baselines",
        "pubDate": "Tue, 20 Mar 2018 07:00:00 GMT",
        "isoDate": "2018-03-20T07:00:00.000Z",
        "source": "https://openai.com/index/variance-reduction-for-policy-gradient-with-action-dependent-factorized-baselines"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-nyqexx",
        "title": "Report from the OpenAI hackathon",
        "link": "https://openai.com/index/hackathon-follow-up",
        "url": "https://openai.com/index/hackathon-follow-up",
        "content": "On March 3rd, we hosted our first hackathon with 100 members of the artificial intelligence community.",
        "contentSnippet": "On March 3rd, we hosted our first hackathon with 100 members of the artificial intelligence community.",
        "pubDate": "Thu, 15 Mar 2018 07:00:00 GMT",
        "isoDate": "2018-03-15T07:00:00.000Z",
        "source": "https://openai.com/index/hackathon-follow-up"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9i6lmf",
        "title": "Improving GANs using optimal transport",
        "link": "https://openai.com/index/improving-gans-using-optimal-transport",
        "url": "https://openai.com/index/improving-gans-using-optimal-transport",
        "pubDate": "Thu, 15 Mar 2018 07:00:00 GMT",
        "isoDate": "2018-03-15T07:00:00.000Z",
        "source": "https://openai.com/index/improving-gans-using-optimal-transport"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-eyeb43",
        "title": "On first-order meta-learning algorithms",
        "link": "https://openai.com/index/on-first-order-meta-learning-algorithms",
        "url": "https://openai.com/index/on-first-order-meta-learning-algorithms",
        "pubDate": "Thu, 08 Mar 2018 08:00:00 GMT",
        "isoDate": "2018-03-08T08:00:00.000Z",
        "source": "https://openai.com/index/on-first-order-meta-learning-algorithms"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-bgc6nh",
        "title": "Reptile: A scalable meta-learning algorithm",
        "link": "https://openai.com/index/reptile",
        "url": "https://openai.com/index/reptile",
        "content": "We’ve developed a simple meta-learning algorithm called Reptile which works by repeatedly sampling a task, performing stochastic gradient descent on it, and updating the initial parameters towards the final parameters learned on that task. Reptile is the application of the Shortest Descent algorithm to the meta-learning setting, and is mathematically similar to first-order MAML (which is a version of the well-known MAML algorithm) that only needs black-box access to an optimizer such as SGD or Adam, with similar computational efficiency and performance.",
        "contentSnippet": "We’ve developed a simple meta-learning algorithm called Reptile which works by repeatedly sampling a task, performing stochastic gradient descent on it, and updating the initial parameters towards the final parameters learned on that task. Reptile is the application of the Shortest Descent algorithm to the meta-learning setting, and is mathematically similar to first-order MAML (which is a version of the well-known MAML algorithm) that only needs black-box access to an optimizer such as SGD or Adam, with similar computational efficiency and performance.",
        "pubDate": "Wed, 07 Mar 2018 08:00:00 GMT",
        "isoDate": "2018-03-07T08:00:00.000Z",
        "source": "https://openai.com/index/reptile"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-yzie9c",
        "title": "OpenAI Scholars",
        "link": "https://openai.com/index/openai-scholars",
        "url": "https://openai.com/index/openai-scholars",
        "content": "We’re providing 6–10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
        "contentSnippet": "We’re providing 6–10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
        "pubDate": "Tue, 06 Mar 2018 08:00:00 GMT",
        "isoDate": "2018-03-06T08:00:00.000Z",
        "source": "https://openai.com/index/openai-scholars"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-42laul",
        "title": "Some considerations on learning to explore via meta-reinforcement learning",
        "link": "https://openai.com/index/some-considerations-on-learning-to-explore-via-meta-reinforcement-learning",
        "url": "https://openai.com/index/some-considerations-on-learning-to-explore-via-meta-reinforcement-learning",
        "pubDate": "Sat, 03 Mar 2018 08:00:00 GMT",
        "isoDate": "2018-03-03T08:00:00.000Z",
        "source": "https://openai.com/index/some-considerations-on-learning-to-explore-via-meta-reinforcement-learning"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-5r0j6w",
        "title": "Multi-Goal Reinforcement Learning: Challenging robotics environments and request for research",
        "link": "https://openai.com/index/multi-goal-reinforcement-learning",
        "url": "https://openai.com/index/multi-goal-reinforcement-learning",
        "pubDate": "Mon, 26 Feb 2018 08:00:00 GMT",
        "isoDate": "2018-02-26T08:00:00.000Z",
        "source": "https://openai.com/index/multi-goal-reinforcement-learning"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-s9mxla",
        "title": "Ingredients for robotics research",
        "link": "https://openai.com/index/ingredients-for-robotics-research",
        "url": "https://openai.com/index/ingredients-for-robotics-research",
        "content": "We’re releasing eight simulated robotics environments and a Baselines implementation of Hindsight Experience Replay, all developed for our research over the past year. We’ve used these environments to train models which work on physical robots. We’re also releasing a set of requests for robotics research.",
        "contentSnippet": "We’re releasing eight simulated robotics environments and a Baselines implementation of Hindsight Experience Replay, all developed for our research over the past year. We’ve used these environments to train models which work on physical robots. We’re also releasing a set of requests for robotics research.",
        "pubDate": "Mon, 26 Feb 2018 08:00:00 GMT",
        "isoDate": "2018-02-26T08:00:00.000Z",
        "source": "https://openai.com/index/ingredients-for-robotics-research"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-yjq0b4",
        "title": "OpenAI hackathon",
        "link": "https://openai.com/index/openai-hackathon",
        "url": "https://openai.com/index/openai-hackathon",
        "content": "Come to OpenAI’s office in San Francisco’s Mission District for talks and a hackathon on Saturday, March 3rd.",
        "contentSnippet": "Come to OpenAI’s office in San Francisco’s Mission District for talks and a hackathon on Saturday, March 3rd.",
        "pubDate": "Thu, 22 Feb 2018 08:00:00 GMT",
        "isoDate": "2018-02-22T08:00:00.000Z",
        "source": "https://openai.com/index/openai-hackathon"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vbgcqu",
        "title": "OpenAI supporters",
        "link": "https://openai.com/index/openai-supporters",
        "url": "https://openai.com/index/openai-supporters",
        "content": "We’re excited to welcome new donors to OpenAI.",
        "contentSnippet": "We’re excited to welcome new donors to OpenAI.",
        "pubDate": "Tue, 20 Feb 2018 08:00:00 GMT",
        "isoDate": "2018-02-20T08:00:00.000Z",
        "source": "https://openai.com/index/openai-supporters"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-f1pvr",
        "title": "Preparing for malicious uses of AI",
        "link": "https://openai.com/index/preparing-for-malicious-uses-of-ai",
        "url": "https://openai.com/index/preparing-for-malicious-uses-of-ai",
        "content": "We’ve co-authored a paper that forecasts how malicious actors could misuse AI technology, and potential ways we can prevent and mitigate these threats. This paper is the outcome of almost a year of sustained work with our colleagues at the Future of Humanity Institute, the Centre for the Study of Existential Risk, the Center for a New American Security, the Electronic Frontier Foundation, and others.",
        "contentSnippet": "We’ve co-authored a paper that forecasts how malicious actors could misuse AI technology, and potential ways we can prevent and mitigate these threats. This paper is the outcome of almost a year of sustained work with our colleagues at the Future of Humanity Institute, the Centre for the Study of Existential Risk, the Center for a New American Security, the Electronic Frontier Foundation, and others.",
        "pubDate": "Tue, 20 Feb 2018 08:00:00 GMT",
        "isoDate": "2018-02-20T08:00:00.000Z",
        "source": "https://openai.com/index/preparing-for-malicious-uses-of-ai"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-89d5ts",
        "title": "Interpretable machine learning through teaching",
        "link": "https://openai.com/index/interpretable-machine-learning-through-teaching",
        "url": "https://openai.com/index/interpretable-machine-learning-through-teaching",
        "content": "We’ve designed a method that encourages AIs to teach each other with examples that also make sense to humans. Our approach automatically selects the most informative examples to teach a concept—for instance, the best images to describe the concept of dogs—and experimentally we found our approach to be effective at teaching both AIs",
        "contentSnippet": "We’ve designed a method that encourages AIs to teach each other with examples that also make sense to humans. Our approach automatically selects the most informative examples to teach a concept—for instance, the best images to describe the concept of dogs—and experimentally we found our approach to be effective at teaching both AIs",
        "pubDate": "Thu, 15 Feb 2018 08:00:00 GMT",
        "isoDate": "2018-02-15T08:00:00.000Z",
        "source": "https://openai.com/index/interpretable-machine-learning-through-teaching"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ixptak",
        "title": "Discovering types for entity disambiguation",
        "link": "https://openai.com/index/discovering-types-for-entity-disambiguation",
        "url": "https://openai.com/index/discovering-types-for-entity-disambiguation",
        "content": "We’ve built a system for automatically figuring out which object is meant by a word by having a neural network decide if the word belongs to each of about 100 automatically-discovered “types” (non-exclusive categories).",
        "contentSnippet": "We’ve built a system for automatically figuring out which object is meant by a word by having a neural network decide if the word belongs to each of about 100 automatically-discovered “types” (non-exclusive categories).",
        "pubDate": "Wed, 07 Feb 2018 08:00:00 GMT",
        "isoDate": "2018-02-07T08:00:00.000Z",
        "source": "https://openai.com/index/discovering-types-for-entity-disambiguation"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ym1x6z",
        "title": "Requests for Research 2.0",
        "link": "https://openai.com/index/requests-for-research-2",
        "url": "https://openai.com/index/requests-for-research-2",
        "content": "We’re releasing a new batch of seven unsolved problems which have come up in the course of our research at OpenAI.",
        "contentSnippet": "We’re releasing a new batch of seven unsolved problems which have come up in the course of our research at OpenAI.",
        "pubDate": "Wed, 31 Jan 2018 08:00:00 GMT",
        "isoDate": "2018-01-31T08:00:00.000Z",
        "source": "https://openai.com/index/requests-for-research-2"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-eui3tc",
        "title": "Scaling Kubernetes to 2,500 nodes",
        "link": "https://openai.com/index/scaling-kubernetes-to-2500-nodes",
        "url": "https://openai.com/index/scaling-kubernetes-to-2500-nodes",
        "pubDate": "Thu, 18 Jan 2018 08:00:00 GMT",
        "isoDate": "2018-01-18T08:00:00.000Z",
        "source": "https://openai.com/index/scaling-kubernetes-to-2500-nodes"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-mrhx34",
        "title": "Block-sparse GPU kernels",
        "link": "https://openai.com/index/block-sparse-gpu-kernels",
        "url": "https://openai.com/index/block-sparse-gpu-kernels",
        "content": "We’re releasing highly-optimized GPU kernels for an underexplored class of neural network architectures: networks with block-sparse weights. Depending on the chosen sparsity, these kernels can run orders of magnitude faster than cuBLAS or cuSPARSE. We’ve used them to attain state-of-the-art results in text sentiment analysis and generative modeling of text and images.",
        "contentSnippet": "We’re releasing highly-optimized GPU kernels for an underexplored class of neural network architectures: networks with block-sparse weights. Depending on the chosen sparsity, these kernels can run orders of magnitude faster than cuBLAS or cuSPARSE. We’ve used them to attain state-of-the-art results in text sentiment analysis and generative modeling of text and images.",
        "pubDate": "Wed, 06 Dec 2017 08:00:00 GMT",
        "isoDate": "2017-12-06T08:00:00.000Z",
        "source": "https://openai.com/index/block-sparse-gpu-kernels"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-vw7uav",
        "title": "Learning sparse neural networks through L₀ regularization",
        "link": "https://openai.com/index/learning-sparse-neural-networks-through-l0-regularization",
        "url": "https://openai.com/index/learning-sparse-neural-networks-through-l0-regularization",
        "pubDate": "Mon, 04 Dec 2017 08:00:00 GMT",
        "isoDate": "2017-12-04T08:00:00.000Z",
        "source": "https://openai.com/index/learning-sparse-neural-networks-through-l0-regularization"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-cu6gug",
        "title": "Interpretable and pedagogical examples",
        "link": "https://openai.com/index/interpretable-and-pedagogical-examples",
        "url": "https://openai.com/index/interpretable-and-pedagogical-examples",
        "pubDate": "Thu, 02 Nov 2017 07:00:00 GMT",
        "isoDate": "2017-11-02T07:00:00.000Z",
        "source": "https://openai.com/index/interpretable-and-pedagogical-examples"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-szvkry",
        "title": "Learning a hierarchy",
        "link": "https://openai.com/index/learning-a-hierarchy",
        "url": "https://openai.com/index/learning-a-hierarchy",
        "content": "We’ve developed a hierarchical reinforcement learning algorithm that learns high-level actions useful for solving a range of tasks, allowing fast solving of tasks requiring thousands of timesteps. Our algorithm, when applied to a set of navigation problems, discovers a set of high-level actions for walking and crawling in different directions, which enables the agent to master new navigation tasks quickly.",
        "contentSnippet": "We’ve developed a hierarchical reinforcement learning algorithm that learns high-level actions useful for solving a range of tasks, allowing fast solving of tasks requiring thousands of timesteps. Our algorithm, when applied to a set of navigation problems, discovers a set of high-level actions for walking and crawling in different directions, which enables the agent to master new navigation tasks quickly.",
        "pubDate": "Thu, 26 Oct 2017 07:00:00 GMT",
        "isoDate": "2017-10-26T07:00:00.000Z",
        "source": "https://openai.com/index/learning-a-hierarchy"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-4gg3j2",
        "title": "Generalizing from simulation",
        "link": "https://openai.com/index/generalizing-from-simulation",
        "url": "https://openai.com/index/generalizing-from-simulation",
        "content": "Our latest robotics techniques allow robot controllers, trained entirely in simulation and deployed on physical robots, to react to unplanned changes in the environment as they solve simple tasks. That is, we’ve used these techniques to build closed-loop systems rather than open-loop ones as before.",
        "contentSnippet": "Our latest robotics techniques allow robot controllers, trained entirely in simulation and deployed on physical robots, to react to unplanned changes in the environment as they solve simple tasks. That is, we’ve used these techniques to build closed-loop systems rather than open-loop ones as before.",
        "pubDate": "Thu, 19 Oct 2017 07:00:00 GMT",
        "isoDate": "2017-10-19T07:00:00.000Z",
        "source": "https://openai.com/index/generalizing-from-simulation"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-13jo5z",
        "title": "Sim-to-real transfer of robotic control with dynamics randomization",
        "link": "https://openai.com/index/sim-to-real-transfer-of-robotic-control-with-dynamics-randomization",
        "url": "https://openai.com/index/sim-to-real-transfer-of-robotic-control-with-dynamics-randomization",
        "pubDate": "Wed, 18 Oct 2017 07:00:00 GMT",
        "isoDate": "2017-10-18T07:00:00.000Z",
        "source": "https://openai.com/index/sim-to-real-transfer-of-robotic-control-with-dynamics-randomization"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-96sufh",
        "title": "Asymmetric actor critic for image-based robot learning",
        "link": "https://openai.com/index/asymmetric-actor-critic-for-image-based-robot-learning",
        "url": "https://openai.com/index/asymmetric-actor-critic-for-image-based-robot-learning",
        "pubDate": "Wed, 18 Oct 2017 07:00:00 GMT",
        "isoDate": "2017-10-18T07:00:00.000Z",
        "source": "https://openai.com/index/asymmetric-actor-critic-for-image-based-robot-learning"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-rvgybx",
        "title": "Domain randomization and generative models for robotic grasping",
        "link": "https://openai.com/index/domain-randomization-and-generative-models-for-robotic-grasping",
        "url": "https://openai.com/index/domain-randomization-and-generative-models-for-robotic-grasping",
        "pubDate": "Tue, 17 Oct 2017 07:00:00 GMT",
        "isoDate": "2017-10-17T07:00:00.000Z",
        "source": "https://openai.com/index/domain-randomization-and-generative-models-for-robotic-grasping"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-gae2hq",
        "title": "Meta-learning for wrestling",
        "link": "https://openai.com/index/meta-learning-for-wrestling",
        "url": "https://openai.com/index/meta-learning-for-wrestling",
        "content": "We show that for the task of simulated robot wrestling, a meta-learning agent can learn to quickly defeat a stronger non-meta-learning agent, and also show that the meta-learning agent can adapt to physical malfunction.",
        "contentSnippet": "We show that for the task of simulated robot wrestling, a meta-learning agent can learn to quickly defeat a stronger non-meta-learning agent, and also show that the meta-learning agent can adapt to physical malfunction.",
        "pubDate": "Wed, 11 Oct 2017 07:00:00 GMT",
        "isoDate": "2017-10-11T07:00:00.000Z",
        "source": "https://openai.com/index/meta-learning-for-wrestling"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-1wqox",
        "title": "Competitive self-play",
        "link": "https://openai.com/index/competitive-self-play",
        "url": "https://openai.com/index/competitive-self-play",
        "content": "We’ve found that self-play allows simulated AIs to discover physical skills like tackling, ducking, faking, kicking, catching, and diving for the ball, without explicitly designing an environment with these skills in mind. Self-play ensures that the environment is always the right difficulty for an AI to improve. Taken alongside our Dota 2 self-play results, we have increasing confidence that self-play will be a core part of powerful AI systems in the future.",
        "contentSnippet": "We’ve found that self-play allows simulated AIs to discover physical skills like tackling, ducking, faking, kicking, catching, and diving for the ball, without explicitly designing an environment with these skills in mind. Self-play ensures that the environment is always the right difficulty for an AI to improve. Taken alongside our Dota 2 self-play results, we have increasing confidence that self-play will be a core part of powerful AI systems in the future.",
        "pubDate": "Wed, 11 Oct 2017 07:00:00 GMT",
        "isoDate": "2017-10-11T07:00:00.000Z",
        "source": "https://openai.com/index/competitive-self-play"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-2d1ejf",
        "title": "Nonlinear computation in deep linear networks",
        "link": "https://openai.com/index/nonlinear-computation-in-deep-linear-networks",
        "url": "https://openai.com/index/nonlinear-computation-in-deep-linear-networks",
        "pubDate": "Fri, 29 Sep 2017 07:00:00 GMT",
        "isoDate": "2017-09-29T07:00:00.000Z",
        "source": "https://openai.com/index/nonlinear-computation-in-deep-linear-networks"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-dqi4or",
        "title": "Learning to model other minds",
        "link": "https://openai.com/index/learning-to-model-other-minds",
        "url": "https://openai.com/index/learning-to-model-other-minds",
        "content": "We’re releasing an algorithm which accounts for the fact that other agents are learning too, and discovers self-interested yet collaborative strategies like tit-for-tat in the iterated prisoner’s dilemma. This algorithm, Learning with Opponent-Learning Awareness (LOLA), is a small step towards agents that model other minds.",
        "contentSnippet": "We’re releasing an algorithm which accounts for the fact that other agents are learning too, and discovers self-interested yet collaborative strategies like tit-for-tat in the iterated prisoner’s dilemma. This algorithm, Learning with Opponent-Learning Awareness (LOLA), is a small step towards agents that model other minds.",
        "pubDate": "Thu, 14 Sep 2017 07:00:00 GMT",
        "isoDate": "2017-09-14T07:00:00.000Z",
        "source": "https://openai.com/index/learning-to-model-other-minds"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-lwuqre",
        "title": "Learning with opponent-learning awareness",
        "link": "https://openai.com/index/learning-with-opponent-learning-awareness",
        "url": "https://openai.com/index/learning-with-opponent-learning-awareness",
        "pubDate": "Wed, 13 Sep 2017 07:00:00 GMT",
        "isoDate": "2017-09-13T07:00:00.000Z",
        "source": "https://openai.com/index/learning-with-opponent-learning-awareness"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-29xeui",
        "title": "OpenAI Baselines: ACKTR & A2C",
        "link": "https://openai.com/index/openai-baselines-acktr-a2c",
        "url": "https://openai.com/index/openai-baselines-acktr-a2c",
        "content": "We’re releasing two new OpenAI Baselines implementations: ACKTR and A2C. A2C is a synchronous, deterministic variant of Asynchronous Advantage Actor Critic (A3C) which we’ve found gives equal performance. ACKTR is a more sample-efficient reinforcement learning algorithm than TRPO and A2C, and requires only slightly more computation than A2C per update.",
        "contentSnippet": "We’re releasing two new OpenAI Baselines implementations: ACKTR and A2C. A2C is a synchronous, deterministic variant of Asynchronous Advantage Actor Critic (A3C) which we’ve found gives equal performance. ACKTR is a more sample-efficient reinforcement learning algorithm than TRPO and A2C, and requires only slightly more computation than A2C per update.",
        "pubDate": "Fri, 18 Aug 2017 07:00:00 GMT",
        "isoDate": "2017-08-18T07:00:00.000Z",
        "source": "https://openai.com/index/openai-baselines-acktr-a2c"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6a5xmz",
        "title": "More on Dota 2",
        "link": "https://openai.com/index/more-on-dota-2",
        "url": "https://openai.com/index/more-on-dota-2",
        "content": "Our Dota 2 result shows that self-play can catapult the performance of machine learning systems from far below human level to superhuman, given sufficient compute. In the span of a month, our system went from barely matching a high-ranked player to beating the top pros and has continued to improve since then. Supervised deep learning systems can only be as good as their training datasets, but in self-play systems, the available data improves automatically as the agent gets better.",
        "contentSnippet": "Our Dota 2 result shows that self-play can catapult the performance of machine learning systems from far below human level to superhuman, given sufficient compute. In the span of a month, our system went from barely matching a high-ranked player to beating the top pros and has continued to improve since then. Supervised deep learning systems can only be as good as their training datasets, but in self-play systems, the available data improves automatically as the agent gets better.",
        "pubDate": "Wed, 16 Aug 2017 07:00:00 GMT",
        "isoDate": "2017-08-16T07:00:00.000Z",
        "source": "https://openai.com/index/more-on-dota-2"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-w3wv2t",
        "title": "Dota 2",
        "link": "https://openai.com/index/dota-2",
        "url": "https://openai.com/index/dota-2",
        "content": "We’ve created a bot which beats the world’s top professionals at 1v1 matches of Dota 2 under standard tournament rules. The bot learned the game from scratch by self-play, and does not use imitation learning or tree search. This is a step towards building AI systems which accomplish well-defined goals in messy, complicated situations involving real humans.",
        "contentSnippet": "We’ve created a bot which beats the world’s top professionals at 1v1 matches of Dota 2 under standard tournament rules. The bot learned the game from scratch by self-play, and does not use imitation learning or tree search. This is a step towards building AI systems which accomplish well-defined goals in messy, complicated situations involving real humans.",
        "pubDate": "Fri, 11 Aug 2017 07:00:00 GMT",
        "isoDate": "2017-08-11T07:00:00.000Z",
        "source": "https://openai.com/index/dota-2"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-2l3x0d",
        "title": "Gathering human feedback",
        "link": "https://openai.com/index/gathering-human-feedback",
        "url": "https://openai.com/index/gathering-human-feedback",
        "content": "RL-Teacher is an open-source implementation of our interface to train AIs via occasional human feedback rather than hand-crafted reward functions. The underlying technique was developed as a step towards safe AI systems, but also applies to reinforcement learning problems with rewards that are hard to specify.",
        "contentSnippet": "RL-Teacher is an open-source implementation of our interface to train AIs via occasional human feedback rather than hand-crafted reward functions. The underlying technique was developed as a step towards safe AI systems, but also applies to reinforcement learning problems with rewards that are hard to specify.",
        "pubDate": "Thu, 03 Aug 2017 07:00:00 GMT",
        "isoDate": "2017-08-03T07:00:00.000Z",
        "source": "https://openai.com/index/gathering-human-feedback"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-9pxhb6",
        "title": "Better exploration with parameter noise",
        "link": "https://openai.com/index/better-exploration-with-parameter-noise",
        "url": "https://openai.com/index/better-exploration-with-parameter-noise",
        "content": "We’ve found that adding adaptive noise to the parameters of reinforcement learning algorithms frequently boosts performance. This exploration method is simple to implement and very rarely decreases performance, so it’s worth trying on any problem.",
        "contentSnippet": "We’ve found that adding adaptive noise to the parameters of reinforcement learning algorithms frequently boosts performance. This exploration method is simple to implement and very rarely decreases performance, so it’s worth trying on any problem.",
        "pubDate": "Thu, 27 Jul 2017 07:00:00 GMT",
        "isoDate": "2017-07-27T07:00:00.000Z",
        "source": "https://openai.com/index/better-exploration-with-parameter-noise"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-3x7ff1",
        "title": "Proximal Policy Optimization",
        "link": "https://openai.com/index/openai-baselines-ppo",
        "url": "https://openai.com/index/openai-baselines-ppo",
        "content": "We’re releasing a new class of reinforcement learning algorithms, Proximal Policy Optimization (PPO), which perform comparably or better than state-of-the-art approaches while being much simpler to implement and tune. PPO has become the default reinforcement learning algorithm at OpenAI because of its ease of use and good performance.",
        "contentSnippet": "We’re releasing a new class of reinforcement learning algorithms, Proximal Policy Optimization (PPO), which perform comparably or better than state-of-the-art approaches while being much simpler to implement and tune. PPO has become the default reinforcement learning algorithm at OpenAI because of its ease of use and good performance.",
        "pubDate": "Thu, 20 Jul 2017 07:00:00 GMT",
        "isoDate": "2017-07-20T07:00:00.000Z",
        "source": "https://openai.com/index/openai-baselines-ppo"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-y7163a",
        "title": "Robust adversarial inputs",
        "link": "https://openai.com/index/robust-adversarial-inputs",
        "url": "https://openai.com/index/robust-adversarial-inputs",
        "content": "We’ve created images that reliably fool neural network classifiers when viewed from varied scales and perspectives. This challenges a claim from last week that self-driving cars would be hard to trick maliciously since they capture images from multiple scales, angles, perspectives, and the like.",
        "contentSnippet": "We’ve created images that reliably fool neural network classifiers when viewed from varied scales and perspectives. This challenges a claim from last week that self-driving cars would be hard to trick maliciously since they capture images from multiple scales, angles, perspectives, and the like.",
        "pubDate": "Mon, 17 Jul 2017 07:00:00 GMT",
        "isoDate": "2017-07-17T07:00:00.000Z",
        "source": "https://openai.com/index/robust-adversarial-inputs"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-1oo579",
        "title": "Hindsight Experience Replay",
        "link": "https://openai.com/index/hindsight-experience-replay",
        "url": "https://openai.com/index/hindsight-experience-replay",
        "pubDate": "Wed, 05 Jul 2017 07:00:00 GMT",
        "isoDate": "2017-07-05T07:00:00.000Z",
        "source": "https://openai.com/index/hindsight-experience-replay"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-1sx4w5",
        "title": "Teacher–student curriculum learning",
        "link": "https://openai.com/index/teacher-student-curriculum-learning",
        "url": "https://openai.com/index/teacher-student-curriculum-learning",
        "pubDate": "Sat, 01 Jul 2017 07:00:00 GMT",
        "isoDate": "2017-07-01T07:00:00.000Z",
        "source": "https://openai.com/index/teacher-student-curriculum-learning"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-ni83le",
        "title": "Faster physics in Python",
        "link": "https://openai.com/index/faster-physics-in-python",
        "url": "https://openai.com/index/faster-physics-in-python",
        "content": "We’re open-sourcing a high-performance Python library for robotic simulation using the MuJoCo engine, developed over our past year of robotics research.",
        "contentSnippet": "We’re open-sourcing a high-performance Python library for robotic simulation using the MuJoCo engine, developed over our past year of robotics research.",
        "pubDate": "Wed, 28 Jun 2017 07:00:00 GMT",
        "isoDate": "2017-06-28T07:00:00.000Z",
        "source": "https://openai.com/index/faster-physics-in-python"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-u67r3o",
        "title": "Learning from human preferences",
        "link": "https://openai.com/index/learning-from-human-preferences",
        "url": "https://openai.com/index/learning-from-human-preferences",
        "content": "One step towards building safe AI systems is to remove the need for humans to write goal functions, since using a simple proxy for a complex goal, or getting the complex goal a bit wrong, can lead to undesirable and even dangerous behavior. In collaboration with DeepMind’s safety team, we’ve developed an algorithm which can infer what humans want by being told which of two proposed behaviors is better.",
        "contentSnippet": "One step towards building safe AI systems is to remove the need for humans to write goal functions, since using a simple proxy for a complex goal, or getting the complex goal a bit wrong, can lead to undesirable and even dangerous behavior. In collaboration with DeepMind’s safety team, we’ve developed an algorithm which can infer what humans want by being told which of two proposed behaviors is better.",
        "pubDate": "Tue, 13 Jun 2017 07:00:00 GMT",
        "isoDate": "2017-06-13T07:00:00.000Z",
        "source": "https://openai.com/index/learning-from-human-preferences"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-cddfxj",
        "title": "Learning to cooperate, compete, and communicate",
        "link": "https://openai.com/index/learning-to-cooperate-compete-and-communicate",
        "url": "https://openai.com/index/learning-to-cooperate-compete-and-communicate",
        "content": "Multiagent environments where agents compete for resources are stepping stones on the path to AGI. Multiagent environments have two useful properties: first, there is a natural curriculum—the difficulty of the environment is determined by the skill of your competitors (and if you’re competing against clones of yourself, the environment exactly matches your skill level). Second, a multiagent environment has no stable equilibrium: no matter how smart an agent is, there’s always pressure to get smarter. These environments have a very different feel from traditional environments, and it’ll take a lot more research before we become good at them.",
        "contentSnippet": "Multiagent environments where agents compete for resources are stepping stones on the path to AGI. Multiagent environments have two useful properties: first, there is a natural curriculum—the difficulty of the environment is determined by the skill of your competitors (and if you’re competing against clones of yourself, the environment exactly matches your skill level). Second, a multiagent environment has no stable equilibrium: no matter how smart an agent is, there’s always pressure to get smarter. These environments have a very different feel from traditional environments, and it’ll take a lot more research before we become good at them.",
        "pubDate": "Thu, 08 Jun 2017 07:00:00 GMT",
        "isoDate": "2017-06-08T07:00:00.000Z",
        "source": "https://openai.com/index/learning-to-cooperate-compete-and-communicate"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wnyj8s",
        "title": "UCB exploration via Q-ensembles",
        "link": "https://openai.com/index/ucb-exploration-via-q-ensembles",
        "url": "https://openai.com/index/ucb-exploration-via-q-ensembles",
        "pubDate": "Mon, 05 Jun 2017 07:00:00 GMT",
        "isoDate": "2017-06-05T07:00:00.000Z",
        "source": "https://openai.com/index/ucb-exploration-via-q-ensembles"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-3x76jj",
        "title": "OpenAI Baselines: DQN",
        "link": "https://openai.com/index/openai-baselines-dqn",
        "url": "https://openai.com/index/openai-baselines-dqn",
        "content": "We’re open-sourcing OpenAI Baselines, our internal effort to reproduce reinforcement learning algorithms with performance on par with published results. We’ll release the algorithms over upcoming months; today’s release includes DQN and three of its variants.",
        "contentSnippet": "We’re open-sourcing OpenAI Baselines, our internal effort to reproduce reinforcement learning algorithms with performance on par with published results. We’ll release the algorithms over upcoming months; today’s release includes DQN and three of its variants.",
        "pubDate": "Wed, 24 May 2017 07:00:00 GMT",
        "isoDate": "2017-05-24T07:00:00.000Z",
        "source": "https://openai.com/index/openai-baselines-dqn"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-cow36y",
        "title": "Robots that learn",
        "link": "https://openai.com/index/robots-that-learn",
        "url": "https://openai.com/index/robots-that-learn",
        "content": "We’ve created a robotics system, trained entirely in simulation and deployed on a physical robot, which can learn a new task after seeing it done once.",
        "contentSnippet": "We’ve created a robotics system, trained entirely in simulation and deployed on a physical robot, which can learn a new task after seeing it done once.",
        "pubDate": "Tue, 16 May 2017 07:00:00 GMT",
        "isoDate": "2017-05-16T07:00:00.000Z",
        "source": "https://openai.com/index/robots-that-learn"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-l1vjxy",
        "title": "Roboschool",
        "link": "https://openai.com/index/roboschool",
        "url": "https://openai.com/index/roboschool",
        "content": "We are releasing Roboschool: open-source software for robot simulation, integrated with OpenAI Gym.",
        "contentSnippet": "We are releasing Roboschool: open-source software for robot simulation, integrated with OpenAI Gym.",
        "pubDate": "Mon, 15 May 2017 07:00:00 GMT",
        "isoDate": "2017-05-15T07:00:00.000Z",
        "source": "https://openai.com/index/roboschool"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-7oycw0",
        "title": "Equivalence between policy gradients and soft Q-learning",
        "link": "https://openai.com/index/equivalence-between-policy-gradients-and-soft-q-learning",
        "url": "https://openai.com/index/equivalence-between-policy-gradients-and-soft-q-learning",
        "pubDate": "Fri, 21 Apr 2017 07:00:00 GMT",
        "isoDate": "2017-04-21T07:00:00.000Z",
        "source": "https://openai.com/index/equivalence-between-policy-gradients-and-soft-q-learning"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-a6613o",
        "title": "Stochastic Neural Networks for hierarchical reinforcement learning",
        "link": "https://openai.com/index/stochastic-neural-networks-for-hierarchical-reinforcement-learning",
        "url": "https://openai.com/index/stochastic-neural-networks-for-hierarchical-reinforcement-learning",
        "pubDate": "Mon, 10 Apr 2017 07:00:00 GMT",
        "isoDate": "2017-04-10T07:00:00.000Z",
        "source": "https://openai.com/index/stochastic-neural-networks-for-hierarchical-reinforcement-learning"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-n27p61",
        "title": "Unsupervised sentiment neuron",
        "link": "https://openai.com/index/unsupervised-sentiment-neuron",
        "url": "https://openai.com/index/unsupervised-sentiment-neuron",
        "content": "We’ve developed an unsupervised system which learns an excellent representation of sentiment, despite being trained only to predict the next character in the text of Amazon reviews.",
        "contentSnippet": "We’ve developed an unsupervised system which learns an excellent representation of sentiment, despite being trained only to predict the next character in the text of Amazon reviews.",
        "pubDate": "Thu, 06 Apr 2017 07:00:00 GMT",
        "isoDate": "2017-04-06T07:00:00.000Z",
        "source": "https://openai.com/index/unsupervised-sentiment-neuron"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-a82e2c",
        "title": "Spam detection in the physical world",
        "link": "https://openai.com/index/spam-detection-in-the-physical-world",
        "url": "https://openai.com/index/spam-detection-in-the-physical-world",
        "content": "We’ve created the world’s first Spam-detecting AI trained entirely in simulation and deployed on a physical robot.",
        "contentSnippet": "We’ve created the world’s first Spam-detecting AI trained entirely in simulation and deployed on a physical robot.",
        "pubDate": "Sat, 01 Apr 2017 07:00:00 GMT",
        "isoDate": "2017-04-01T07:00:00.000Z",
        "source": "https://openai.com/index/spam-detection-in-the-physical-world"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-a3x4d7",
        "title": "Evolution strategies as a scalable alternative to reinforcement learning",
        "link": "https://openai.com/index/evolution-strategies",
        "url": "https://openai.com/index/evolution-strategies",
        "content": "We’ve discovered that evolution strategies (ES), an optimization technique that’s been known for decades, rivals the performance of standard reinforcement learning (RL) techniques on modern RL benchmarks (e.g. Atari/MuJoCo), while overcoming many of RL’s inconveniences.",
        "contentSnippet": "We’ve discovered that evolution strategies (ES), an optimization technique that’s been known for decades, rivals the performance of standard reinforcement learning (RL) techniques on modern RL benchmarks (e.g. Atari/MuJoCo), while overcoming many of RL’s inconveniences.",
        "pubDate": "Fri, 24 Mar 2017 07:00:00 GMT",
        "isoDate": "2017-03-24T07:00:00.000Z",
        "source": "https://openai.com/index/evolution-strategies"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-uospg9",
        "title": "One-shot imitation learning",
        "link": "https://openai.com/index/one-shot-imitation-learning",
        "url": "https://openai.com/index/one-shot-imitation-learning",
        "pubDate": "Tue, 21 Mar 2017 07:00:00 GMT",
        "isoDate": "2017-03-21T07:00:00.000Z",
        "source": "https://openai.com/index/one-shot-imitation-learning"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-1wq4hh",
        "title": "Distill",
        "link": "https://openai.com/index/distill",
        "url": "https://openai.com/index/distill",
        "content": "We’re excited to support today’s launch of Distill, a new kind of journal aimed at excellent communication of machine learning results (novel or existing).",
        "contentSnippet": "We’re excited to support today’s launch of Distill, a new kind of journal aimed at excellent communication of machine learning results (novel or existing).",
        "pubDate": "Mon, 20 Mar 2017 07:00:00 GMT",
        "isoDate": "2017-03-20T07:00:00.000Z",
        "source": "https://openai.com/index/distill"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-g6lk7c",
        "title": "Learning to communicate",
        "link": "https://openai.com/index/learning-to-communicate",
        "url": "https://openai.com/index/learning-to-communicate",
        "content": "In this post we’ll outline new OpenAI research in which agents develop their own language.",
        "contentSnippet": "In this post we’ll outline new OpenAI research in which agents develop their own language.",
        "pubDate": "Thu, 16 Mar 2017 07:00:00 GMT",
        "isoDate": "2017-03-16T07:00:00.000Z",
        "source": "https://openai.com/index/learning-to-communicate"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-j3v2e2",
        "title": "Emergence of grounded compositional language in multi-agent populations",
        "link": "https://openai.com/index/emergence-of-grounded-compositional-language-in-multi-agent-populations",
        "url": "https://openai.com/index/emergence-of-grounded-compositional-language-in-multi-agent-populations",
        "pubDate": "Wed, 15 Mar 2017 07:00:00 GMT",
        "isoDate": "2017-03-15T07:00:00.000Z",
        "source": "https://openai.com/index/emergence-of-grounded-compositional-language-in-multi-agent-populations"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-qdjrhw",
        "title": "Prediction and control with temporal segment models",
        "link": "https://openai.com/index/prediction-and-control-with-temporal-segment-models",
        "url": "https://openai.com/index/prediction-and-control-with-temporal-segment-models",
        "pubDate": "Sun, 12 Mar 2017 08:00:00 GMT",
        "isoDate": "2017-03-12T08:00:00.000Z",
        "source": "https://openai.com/index/prediction-and-control-with-temporal-segment-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-lp2spt",
        "title": "Third-person imitation learning",
        "link": "https://openai.com/index/third-person-imitation-learning",
        "url": "https://openai.com/index/third-person-imitation-learning",
        "pubDate": "Mon, 06 Mar 2017 08:00:00 GMT",
        "isoDate": "2017-03-06T08:00:00.000Z",
        "source": "https://openai.com/index/third-person-imitation-learning"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-rtu2kx",
        "title": "Attacking machine learning with adversarial examples",
        "link": "https://openai.com/index/attacking-machine-learning-with-adversarial-examples",
        "url": "https://openai.com/index/attacking-machine-learning-with-adversarial-examples",
        "content": "Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake; they’re like optical illusions for machines. In this post we’ll show how adversarial examples work across different mediums, and will discuss why securing systems against them can be difficult.",
        "contentSnippet": "Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake; they’re like optical illusions for machines. In this post we’ll show how adversarial examples work across different mediums, and will discuss why securing systems against them can be difficult.",
        "pubDate": "Fri, 24 Feb 2017 08:00:00 GMT",
        "isoDate": "2017-02-24T08:00:00.000Z",
        "source": "https://openai.com/index/attacking-machine-learning-with-adversarial-examples"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-6gsap2",
        "title": "Adversarial attacks on neural network policies",
        "link": "https://openai.com/index/adversarial-attacks-on-neural-network-policies",
        "url": "https://openai.com/index/adversarial-attacks-on-neural-network-policies",
        "pubDate": "Wed, 08 Feb 2017 08:00:00 GMT",
        "isoDate": "2017-02-08T08:00:00.000Z",
        "source": "https://openai.com/index/adversarial-attacks-on-neural-network-policies"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-jpdnxa",
        "title": "Team update",
        "link": "https://openai.com/index/team-update-january",
        "url": "https://openai.com/index/team-update-january",
        "content": "The OpenAI team is now 45 people. Together, we’re pushing the frontier of AI capabilities—whether by validating novel ideas, creating new software systems, or deploying machine learning on robots.",
        "contentSnippet": "The OpenAI team is now 45 people. Together, we’re pushing the frontier of AI capabilities—whether by validating novel ideas, creating new software systems, or deploying machine learning on robots.",
        "pubDate": "Mon, 30 Jan 2017 08:00:00 GMT",
        "isoDate": "2017-01-30T08:00:00.000Z",
        "source": "https://openai.com/index/team-update-january"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wph1e3",
        "title": "PixelCNN++: Improving the PixelCNN with discretized logistic mixture likelihood and other modifications",
        "link": "https://openai.com/index/pixelcnn-plus-plus",
        "url": "https://openai.com/index/pixelcnn-plus-plus",
        "pubDate": "Thu, 19 Jan 2017 08:00:00 GMT",
        "isoDate": "2017-01-19T08:00:00.000Z",
        "source": "https://openai.com/index/pixelcnn-plus-plus"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-tcydmj",
        "title": "Faulty reward functions in the wild",
        "link": "https://openai.com/index/faulty-reward-functions",
        "url": "https://openai.com/index/faulty-reward-functions",
        "content": "Reinforcement learning algorithms can break in surprising, counterintuitive ways. In this post we’ll explore one failure mode, which is where you misspecify your reward function.",
        "contentSnippet": "Reinforcement learning algorithms can break in surprising, counterintuitive ways. In this post we’ll explore one failure mode, which is where you misspecify your reward function.",
        "pubDate": "Wed, 21 Dec 2016 08:00:00 GMT",
        "isoDate": "2016-12-21T08:00:00.000Z",
        "source": "https://openai.com/index/faulty-reward-functions"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-29w69p",
        "title": "Universe",
        "link": "https://openai.com/index/universe",
        "url": "https://openai.com/index/universe",
        "content": "We’re releasing Universe, a software platform for measuring and training an AI’s general intelligence across the world’s supply of games, websites and other applications.",
        "contentSnippet": "We’re releasing Universe, a software platform for measuring and training an AI’s general intelligence across the world’s supply of games, websites and other applications.",
        "pubDate": "Mon, 05 Dec 2016 08:00:00 GMT",
        "isoDate": "2016-12-05T08:00:00.000Z",
        "source": "https://openai.com/index/universe"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-i4u7xn",
        "title": "OpenAI and Microsoft",
        "link": "https://openai.com/index/openai-and-microsoft",
        "url": "https://openai.com/index/openai-and-microsoft",
        "content": "We’re working with Microsoft to start running most of our large-scale experiments on Azure.",
        "contentSnippet": "We’re working with Microsoft to start running most of our large-scale experiments on Azure.",
        "pubDate": "Tue, 15 Nov 2016 08:00:00 GMT",
        "isoDate": "2016-11-15T08:00:00.000Z",
        "source": "https://openai.com/index/openai-and-microsoft"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-qujvl7",
        "title": "#Exploration: A study of count-based exploration for deep reinforcement learning",
        "link": "https://openai.com/index/exploration",
        "url": "https://openai.com/index/exploration",
        "pubDate": "Tue, 15 Nov 2016 08:00:00 GMT",
        "isoDate": "2016-11-15T08:00:00.000Z",
        "source": "https://openai.com/index/exploration"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-awt3pf",
        "title": "On the quantitative analysis of decoder-based generative models",
        "link": "https://openai.com/index/on-the-quantitative-analysis-of-decoder-based-generative-models",
        "url": "https://openai.com/index/on-the-quantitative-analysis-of-decoder-based-generative-models",
        "pubDate": "Mon, 14 Nov 2016 08:00:00 GMT",
        "isoDate": "2016-11-14T08:00:00.000Z",
        "source": "https://openai.com/index/on-the-quantitative-analysis-of-decoder-based-generative-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-f8u12l",
        "title": "A connection between generative adversarial networks, inverse reinforcement learning, and energy-based models",
        "link": "https://openai.com/index/a-connection-between-generative-adversarial-networks-inverse-reinforcement-learning-and-energy-based-models",
        "url": "https://openai.com/index/a-connection-between-generative-adversarial-networks-inverse-reinforcement-learning-and-energy-based-models",
        "pubDate": "Fri, 11 Nov 2016 08:00:00 GMT",
        "isoDate": "2016-11-11T08:00:00.000Z",
        "source": "https://openai.com/index/a-connection-between-generative-adversarial-networks-inverse-reinforcement-learning-and-energy-based-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-npet6o",
        "title": "RL²: Fast reinforcement learning via slow reinforcement learning",
        "link": "https://openai.com/index/rl2",
        "url": "https://openai.com/index/rl2",
        "pubDate": "Wed, 09 Nov 2016 08:00:00 GMT",
        "isoDate": "2016-11-09T08:00:00.000Z",
        "source": "https://openai.com/index/rl2"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-b1n9xt",
        "title": "Variational lossy autoencoder",
        "link": "https://openai.com/index/variational-lossy-autoencoder",
        "url": "https://openai.com/index/variational-lossy-autoencoder",
        "pubDate": "Tue, 08 Nov 2016 08:00:00 GMT",
        "isoDate": "2016-11-08T08:00:00.000Z",
        "source": "https://openai.com/index/variational-lossy-autoencoder"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-a12jr9",
        "title": "Extensions and limitations of the neural GPU",
        "link": "https://openai.com/index/extensions-and-limitations-of-the-neural-gpu",
        "url": "https://openai.com/index/extensions-and-limitations-of-the-neural-gpu",
        "pubDate": "Wed, 02 Nov 2016 07:00:00 GMT",
        "isoDate": "2016-11-02T07:00:00.000Z",
        "source": "https://openai.com/index/extensions-and-limitations-of-the-neural-gpu"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-wf6lql",
        "title": "Semi-supervised knowledge transfer for deep learning from private training data",
        "link": "https://openai.com/index/semi-supervised-knowledge-transfer-for-deep-learning-from-private-training-data",
        "url": "https://openai.com/index/semi-supervised-knowledge-transfer-for-deep-learning-from-private-training-data",
        "pubDate": "Tue, 18 Oct 2016 07:00:00 GMT",
        "isoDate": "2016-10-18T07:00:00.000Z",
        "source": "https://openai.com/index/semi-supervised-knowledge-transfer-for-deep-learning-from-private-training-data"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-rxa546",
        "title": "Report from the self-organizing conference",
        "link": "https://openai.com/index/report-from-the-self-organizing-conference",
        "url": "https://openai.com/index/report-from-the-self-organizing-conference",
        "content": "Last week we hosted over a hundred and fifty AI practitioners in our offices for our first self-organizing conference on machine learning.",
        "contentSnippet": "Last week we hosted over a hundred and fifty AI practitioners in our offices for our first self-organizing conference on machine learning.",
        "pubDate": "Thu, 13 Oct 2016 07:00:00 GMT",
        "isoDate": "2016-10-13T07:00:00.000Z",
        "source": "https://openai.com/index/report-from-the-self-organizing-conference"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-hgy0c",
        "title": "Transfer from simulation to real world through learning deep inverse dynamics model",
        "link": "https://openai.com/index/transfer-from-simulation-to-real-world-through-learning-deep-inverse-dynamics-model",
        "url": "https://openai.com/index/transfer-from-simulation-to-real-world-through-learning-deep-inverse-dynamics-model",
        "pubDate": "Tue, 11 Oct 2016 07:00:00 GMT",
        "isoDate": "2016-10-11T07:00:00.000Z",
        "source": "https://openai.com/index/transfer-from-simulation-to-real-world-through-learning-deep-inverse-dynamics-model"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-76v4gn",
        "title": "Infrastructure for deep learning",
        "link": "https://openai.com/index/infrastructure-for-deep-learning",
        "url": "https://openai.com/index/infrastructure-for-deep-learning",
        "content": "Deep learning is an empirical science, and the quality of a group’s infrastructure is a multiplier on progress. Fortunately, today’s open-source ecosystem makes it possible for anyone to build great deep learning infrastructure.",
        "contentSnippet": "Deep learning is an empirical science, and the quality of a group’s infrastructure is a multiplier on progress. Fortunately, today’s open-source ecosystem makes it possible for anyone to build great deep learning infrastructure.",
        "pubDate": "Mon, 29 Aug 2016 07:00:00 GMT",
        "isoDate": "2016-08-29T07:00:00.000Z",
        "source": "https://openai.com/index/infrastructure-for-deep-learning"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-nsx322",
        "title": "Machine Learning Unconference",
        "link": "https://openai.com/index/machine-learning-unconference",
        "url": "https://openai.com/index/machine-learning-unconference",
        "content": "The latest information about the Unconference is now available at the Unconference wiki, which will be periodically updated with more information for attendees.",
        "contentSnippet": "The latest information about the Unconference is now available at the Unconference wiki, which will be periodically updated with more information for attendees.",
        "pubDate": "Thu, 18 Aug 2016 07:00:00 GMT",
        "isoDate": "2016-08-18T07:00:00.000Z",
        "source": "https://openai.com/index/machine-learning-unconference"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-v1nvkf",
        "title": "Team update",
        "link": "https://openai.com/index/team-update-august",
        "url": "https://openai.com/index/team-update-august",
        "content": "We’ve hired more great people to help us achieve our goals. Welcome, everyone!",
        "contentSnippet": "We’ve hired more great people to help us achieve our goals. Welcome, everyone!",
        "pubDate": "Tue, 16 Aug 2016 07:00:00 GMT",
        "isoDate": "2016-08-16T07:00:00.000Z",
        "source": "https://openai.com/index/team-update-august"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-yq4ghm",
        "title": "Special projects",
        "link": "https://openai.com/index/special-projects",
        "url": "https://openai.com/index/special-projects",
        "content": "Impactful scientific work requires working on the right problems—problems which are not just interesting, but whose solutions matter.",
        "contentSnippet": "Impactful scientific work requires working on the right problems—problems which are not just interesting, but whose solutions matter.",
        "pubDate": "Thu, 28 Jul 2016 07:00:00 GMT",
        "isoDate": "2016-07-28T07:00:00.000Z",
        "source": "https://openai.com/index/special-projects"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-r7iwsa",
        "title": "Concrete AI safety problems",
        "link": "https://openai.com/index/concrete-ai-safety-problems",
        "url": "https://openai.com/index/concrete-ai-safety-problems",
        "content": "We (along with researchers from Berkeley and Stanford) are co-authors on today’s paper led by Google Brain researchers, Concrete Problems in AI Safety. The paper explores many research problems around ensuring that modern machine learning systems operate as intended.",
        "contentSnippet": "We (along with researchers from Berkeley and Stanford) are co-authors on today’s paper led by Google Brain researchers, Concrete Problems in AI Safety. The paper explores many research problems around ensuring that modern machine learning systems operate as intended.",
        "pubDate": "Tue, 21 Jun 2016 07:00:00 GMT",
        "isoDate": "2016-06-21T07:00:00.000Z",
        "source": "https://openai.com/index/concrete-ai-safety-problems"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-cvr577",
        "title": "OpenAI technical goals",
        "link": "https://openai.com/index/openai-technical-goals",
        "url": "https://openai.com/index/openai-technical-goals",
        "content": "OpenAI’s mission is to build safe AI, and ensure AI’s benefits are as widely and evenly distributed as possible.",
        "contentSnippet": "OpenAI’s mission is to build safe AI, and ensure AI’s benefits are as widely and evenly distributed as possible.",
        "pubDate": "Mon, 20 Jun 2016 07:00:00 GMT",
        "isoDate": "2016-06-20T07:00:00.000Z",
        "source": "https://openai.com/index/openai-technical-goals"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-c6kbqv",
        "title": "Generative models",
        "link": "https://openai.com/index/generative-models",
        "url": "https://openai.com/index/generative-models",
        "content": "This post describes four projects that share a common theme of enhancing or using generative models, a branch of unsupervised learning techniques in machine learning. In addition to describing our work, this post will tell you a bit more about generative models: what they are, why they are important, and where they might be going.",
        "contentSnippet": "This post describes four projects that share a common theme of enhancing or using generative models, a branch of unsupervised learning techniques in machine learning. In addition to describing our work, this post will tell you a bit more about generative models: what they are, why they are important, and where they might be going.",
        "pubDate": "Thu, 16 Jun 2016 07:00:00 GMT",
        "isoDate": "2016-06-16T07:00:00.000Z",
        "source": "https://openai.com/index/generative-models"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-47wp0f",
        "title": "Adversarial training methods for semi-supervised text classification",
        "link": "https://openai.com/index/adversarial-training-methods-for-semi-supervised-text-classification",
        "url": "https://openai.com/index/adversarial-training-methods-for-semi-supervised-text-classification",
        "pubDate": "Wed, 25 May 2016 07:00:00 GMT",
        "isoDate": "2016-05-25T07:00:00.000Z",
        "source": "https://openai.com/index/adversarial-training-methods-for-semi-supervised-text-classification"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-5b7su9",
        "title": "Team update",
        "link": "https://openai.com/index/team-update",
        "url": "https://openai.com/index/team-update",
        "content": "We’d like to welcome the latest set of team members to OpenAI (and we’re still hiring!)",
        "contentSnippet": "We’d like to welcome the latest set of team members to OpenAI (and we’re still hiring!)",
        "pubDate": "Wed, 25 May 2016 07:00:00 GMT",
        "isoDate": "2016-05-25T07:00:00.000Z",
        "source": "https://openai.com/index/team-update"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-eflltx",
        "title": "OpenAI Gym Beta",
        "link": "https://openai.com/index/openai-gym-beta",
        "url": "https://openai.com/index/openai-gym-beta",
        "content": "We’re releasing the public beta of OpenAI Gym, a toolkit for developing and comparing reinforcement learning (RL) algorithms. It consists of a growing suite of environments (from simulated robots to Atari games), and a site for comparing and reproducing results.",
        "contentSnippet": "We’re releasing the public beta of OpenAI Gym, a toolkit for developing and comparing reinforcement learning (RL) algorithms. It consists of a growing suite of environments (from simulated robots to Atari games), and a site for comparing and reproducing results.",
        "pubDate": "Wed, 27 Apr 2016 07:00:00 GMT",
        "isoDate": "2016-04-27T07:00:00.000Z",
        "source": "https://openai.com/index/openai-gym-beta"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-q4ckx8",
        "title": "Welcome, Pieter and Shivon!",
        "link": "https://openai.com/index/welcome-pieter-and-shivon",
        "url": "https://openai.com/index/welcome-pieter-and-shivon",
        "content": "We have two more team updates.",
        "contentSnippet": "We have two more team updates.",
        "pubDate": "Tue, 26 Apr 2016 07:00:00 GMT",
        "isoDate": "2016-04-26T07:00:00.000Z",
        "source": "https://openai.com/index/welcome-pieter-and-shivon"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-cpx5vv",
        "title": "Team++",
        "link": "https://openai.com/index/team-plus-plus",
        "url": "https://openai.com/index/team-plus-plus",
        "content": "We've had some fantastic people join over the past few months (and we're still hiring). Welcome, everyone!",
        "contentSnippet": "We've had some fantastic people join over the past few months (and we're still hiring). Welcome, everyone!",
        "pubDate": "Thu, 31 Mar 2016 07:00:00 GMT",
        "isoDate": "2016-03-31T07:00:00.000Z",
        "source": "https://openai.com/index/team-plus-plus"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-38btkw",
        "title": "Weight normalization: A simple reparameterization to accelerate training of deep neural networks",
        "link": "https://openai.com/index/weight-normalization",
        "url": "https://openai.com/index/weight-normalization",
        "pubDate": "Thu, 25 Feb 2016 08:00:00 GMT",
        "isoDate": "2016-02-25T08:00:00.000Z",
        "source": "https://openai.com/index/weight-normalization"
      },
      {
        "id": "rss-openai-blog-tech-breakthrough-1-on8fuj",
        "title": "Introducing OpenAI",
        "link": "https://openai.com/index/introducing-openai",
        "url": "https://openai.com/index/introducing-openai",
        "content": "OpenAI is a non-profit artificial intelligence research company. Our goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. Since our research is free from financial obligations, we can better focus on a positive human impact.",
        "contentSnippet": "OpenAI is a non-profit artificial intelligence research company. Our goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. Since our research is free from financial obligations, we can better focus on a positive human impact.",
        "pubDate": "Fri, 11 Dec 2015 08:00:00 GMT",
        "isoDate": "2015-12-11T08:00:00.000Z",
        "source": "https://openai.com/index/introducing-openai"
      }
    ],
    "anthropic-news-policy-governance-10": [
      {
        "id": "html-anthropic-news-policy-governance-10-8rkz6x",
        "title": "Newsroom \\ Anthropic",
        "url": "https://www.anthropic.com/news",
        "link": "https://www.anthropic.com/news",
        "content": "Anthropic is an AI safety and research company that s working to build reliable, interpretable, and steerable AI systems.",
        "contentSnippet": "Anthropic is an AI safety and research company that s working to build reliable, interpretable, and steerable AI systems.",
        "pubDate": "2026-02-19T17:14:24.119Z"
      }
    ],
    "techcrunch-social-phenomenon-4": [
      {
        "id": "rss-techcrunch-social-phenomenon-4-klhxon",
        "title": "Meta is shutting down Messenger’s standalone website",
        "link": "https://techcrunch.com/2026/02/19/meta-is-shutting-down-messengers-standalone-website/",
        "url": "https://techcrunch.com/2026/02/19/meta-is-shutting-down-messengers-standalone-website/",
        "content": "The move comes a few months after Meta shut down Messenger’s stand-alone desktop apps for Windows and Mac.",
        "contentSnippet": "The move comes a few months after Meta shut down Messenger’s stand-alone desktop apps for Windows and Mac.",
        "pubDate": "Thu, 19 Feb 2026 17:01:29 +0000",
        "isoDate": "2026-02-19T17:01:29.000Z",
        "creator": "Aisha Malik",
        "source": "https://techcrunch.com/2026/02/19/meta-is-shutting-down-messengers-standalone-website/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-i0cey7",
        "title": "New York hits the brakes on robotaxi expansion plan",
        "link": "https://techcrunch.com/2026/02/19/new-york-hits-the-brakes-on-robotaxi-expansion-plan/",
        "url": "https://techcrunch.com/2026/02/19/new-york-hits-the-brakes-on-robotaxi-expansion-plan/",
        "content": "The governor of New York pulled a robotaxi expansion proposal that was viewed as a win for Waymo. ",
        "contentSnippet": "The governor of New York pulled a robotaxi expansion proposal that was viewed as a win for Waymo.",
        "pubDate": "Thu, 19 Feb 2026 16:53:05 +0000",
        "isoDate": "2026-02-19T16:53:05.000Z",
        "creator": "Kirsten Korosec",
        "source": "https://techcrunch.com/2026/02/19/new-york-hits-the-brakes-on-robotaxi-expansion-plan/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-98gbw",
        "title": "Zuckerberg grilled in court over social media harms on teens",
        "link": "https://techcrunch.com/2026/02/19/zuckerberg-grilled-in-court-over-social-media-harms-on-teens/",
        "url": "https://techcrunch.com/2026/02/19/zuckerberg-grilled-in-court-over-social-media-harms-on-teens/",
        "content": "Meta's CEO was questioned over the addictive nature of its social media apps like Instagram, and other teen harms. ",
        "contentSnippet": "Meta's CEO was questioned over the addictive nature of its social media apps like Instagram, and other teen harms.",
        "pubDate": "Thu, 19 Feb 2026 16:41:59 +0000",
        "isoDate": "2026-02-19T16:41:59.000Z",
        "creator": "Sarah Perez",
        "source": "https://techcrunch.com/2026/02/19/zuckerberg-grilled-in-court-over-social-media-harms-on-teens/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-vve5ib",
        "title": "SoftBank to spend an eye-popping $33B to build huge U.S. gas power plant",
        "link": "https://techcrunch.com/2026/02/19/softbank-to-spend-an-eye-popping-33b-to-build-huge-u-s-gas-power-plant/",
        "url": "https://techcrunch.com/2026/02/19/softbank-to-spend-an-eye-popping-33b-to-build-huge-u-s-gas-power-plant/",
        "content": "If completed, the project would be among the largest and most expensive natural gas power plants.",
        "contentSnippet": "If completed, the project would be among the largest and most expensive natural gas power plants.",
        "pubDate": "Thu, 19 Feb 2026 16:27:58 +0000",
        "isoDate": "2026-02-19T16:27:58.000Z",
        "creator": "Tim De Chant",
        "source": "https://techcrunch.com/2026/02/19/softbank-to-spend-an-eye-popping-33b-to-build-huge-u-s-gas-power-plant/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-d8okhy",
        "title": "OpenAI reportedly finalizing $100B deal at more than $850B valuation",
        "link": "https://techcrunch.com/2026/02/19/openai-reportedly-finalizing-100b-deal-at-more-than-850b-valuation/",
        "url": "https://techcrunch.com/2026/02/19/openai-reportedly-finalizing-100b-deal-at-more-than-850b-valuation/",
        "content": "OpenAI is reportedly getting close to closing a $100 billion deal, with backers including Amazon, Nvidia, SoftBank, and Microsoft. The deal would value the ChatGPT-maker at $850 billion.",
        "contentSnippet": "OpenAI is reportedly getting close to closing a $100 billion deal, with backers including Amazon, Nvidia, SoftBank, and Microsoft. The deal would value the ChatGPT-maker at $850 billion.",
        "pubDate": "Thu, 19 Feb 2026 15:35:58 +0000",
        "isoDate": "2026-02-19T15:35:58.000Z",
        "creator": "Rebecca Bellan",
        "source": "https://techcrunch.com/2026/02/19/openai-reportedly-finalizing-100b-deal-at-more-than-850b-valuation/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-j3lqyb",
        "title": "Current is a new RSS reader that’s more like a river than an inbox",
        "link": "https://techcrunch.com/2026/02/19/current-is-a-new-rss-reader-thats-more-like-a-river-than-an-inbox/",
        "url": "https://techcrunch.com/2026/02/19/current-is-a-new-rss-reader-thats-more-like-a-river-than-an-inbox/",
        "content": "Current introduces a stress-free, totally reimagined RSS news reading app as a one-time paid download. ",
        "contentSnippet": "Current introduces a stress-free, totally reimagined RSS news reading app as a one-time paid download.",
        "pubDate": "Thu, 19 Feb 2026 15:33:29 +0000",
        "isoDate": "2026-02-19T15:33:29.000Z",
        "creator": "Sarah Perez",
        "source": "https://techcrunch.com/2026/02/19/current-is-a-new-rss-reader-thats-more-like-a-river-than-an-inbox/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-rysvtt",
        "title": "Sex toys maker Tenga says hacker stole customer information",
        "link": "https://techcrunch.com/2026/02/19/sex-toys-maker-tenga-says-hacker-stole-customer-information/",
        "url": "https://techcrunch.com/2026/02/19/sex-toys-maker-tenga-says-hacker-stole-customer-information/",
        "content": "The Japanese sex toy maker said a hacker broke into an employee's inbox and stole customer names, email addresses, and correspondence, including order details and customer service inquiries.",
        "contentSnippet": "The Japanese sex toy maker said a hacker broke into an employee's inbox and stole customer names, email addresses, and correspondence, including order details and customer service inquiries.",
        "pubDate": "Thu, 19 Feb 2026 15:25:00 +0000",
        "isoDate": "2026-02-19T15:25:00.000Z",
        "creator": "Lorenzo Franceschi-Bicchierai",
        "source": "https://techcrunch.com/2026/02/19/sex-toys-maker-tenga-says-hacker-stole-customer-information/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-duuexl",
        "title": "Bug in student admissions website exposed children’s personal information",
        "link": "https://techcrunch.com/2026/02/19/bug-in-student-admissions-website-exposed-childrens-personal-information/",
        "url": "https://techcrunch.com/2026/02/19/bug-in-student-admissions-website-exposed-childrens-personal-information/",
        "content": "Ravenna Hub, which lets parents apply and track the status of their kids' applications across thousands of schools, allowed any logged-in user to access the personally identifiable data associated with any other user, including their children.",
        "contentSnippet": "Ravenna Hub, which lets parents apply and track the status of their kids' applications across thousands of schools, allowed any logged-in user to access the personally identifiable data associated with any other user, including their children.",
        "pubDate": "Thu, 19 Feb 2026 15:05:35 +0000",
        "isoDate": "2026-02-19T15:05:35.000Z",
        "creator": "Zack Whittaker",
        "source": "https://techcrunch.com/2026/02/19/bug-in-student-admissions-website-exposed-childrens-personal-information/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-i5211s",
        "title": "Reload wants to give your AI agents a shared memory",
        "link": "https://techcrunch.com/2026/02/19/reload-an-ai-employee-agent-management-platform-raises-2-275m-and-launches-an-ai-employee/",
        "url": "https://techcrunch.com/2026/02/19/reload-an-ai-employee-agent-management-platform-raises-2-275m-and-launches-an-ai-employee/",
        "content": "Reload announces a $2.275 million raise in a round led by Anthemis and the launch of its first AI employee, Epic. ",
        "contentSnippet": "Reload announces a $2.275 million raise in a round led by Anthemis and the launch of its first AI employee, Epic.",
        "pubDate": "Thu, 19 Feb 2026 15:00:00 +0000",
        "isoDate": "2026-02-19T15:00:00.000Z",
        "creator": "Dominic-Madori Davis",
        "source": "https://techcrunch.com/2026/02/19/reload-an-ai-employee-agent-management-platform-raises-2-275m-and-launches-an-ai-employee/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-mbtisd",
        "title": "Rivian owners will soon be able to access vehicle controls using their Apple Watch",
        "link": "https://techcrunch.com/2026/02/19/rivian-owners-will-be-able-to-access-vehicle-controls-through-their-apple-watch/",
        "url": "https://techcrunch.com/2026/02/19/rivian-owners-will-be-able-to-access-vehicle-controls-through-their-apple-watch/",
        "content": "Rivian is launching a companion app that pairs with Apple Watch in the coming week. ",
        "contentSnippet": "Rivian is launching a companion app that pairs with Apple Watch in the coming week.",
        "pubDate": "Thu, 19 Feb 2026 15:00:00 +0000",
        "isoDate": "2026-02-19T15:00:00.000Z",
        "creator": "Kirsten Korosec",
        "source": "https://techcrunch.com/2026/02/19/rivian-owners-will-be-able-to-access-vehicle-controls-through-their-apple-watch/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-bmhlux",
        "title": "OpenAI, Reliance partner to add AI search to JioHotstar",
        "link": "https://techcrunch.com/2026/02/19/openai-reliance-partner-to-add-ai-search-to-jiohotstar/",
        "url": "https://techcrunch.com/2026/02/19/openai-reliance-partner-to-add-ai-search-to-jiohotstar/",
        "content": "The rollout includes two-way integration that surfaces streaming links directly inside ChatGPT.",
        "contentSnippet": "The rollout includes two-way integration that surfaces streaming links directly inside ChatGPT.",
        "pubDate": "Thu, 19 Feb 2026 14:45:29 +0000",
        "isoDate": "2026-02-19T14:45:29.000Z",
        "creator": "Jagmeet Singh",
        "source": "https://techcrunch.com/2026/02/19/openai-reliance-partner-to-add-ai-search-to-jiohotstar/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-80l3kc",
        "title": "Co-founders behind Reface and Prisma join hands to improve on-device model inference with Mirai",
        "link": "https://techcrunch.com/2026/02/19/co-founders-behind-reface-and-prisma-join-hands-to-improve-on-device-model-inference-with-mirai/",
        "url": "https://techcrunch.com/2026/02/19/co-founders-behind-reface-and-prisma-join-hands-to-improve-on-device-model-inference-with-mirai/",
        "content": "Mirai raised a $10 million seed to improve how AI models run on devices like smartphones and laptops.",
        "contentSnippet": "Mirai raised a $10 million seed to improve how AI models run on devices like smartphones and laptops.",
        "pubDate": "Thu, 19 Feb 2026 14:43:58 +0000",
        "isoDate": "2026-02-19T14:43:58.000Z",
        "creator": "Ivan Mehta",
        "source": "https://techcrunch.com/2026/02/19/co-founders-behind-reface-and-prisma-join-hands-to-improve-on-device-model-inference-with-mirai/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-8mg1zs",
        "title": "These former Big Tech engineers are using AI to navigate Trump’s trade chaos",
        "link": "https://techcrunch.com/2026/02/19/this-former-big-tech-engineers-are-using-ai-to-navigate-trumps-trade-chaos/",
        "url": "https://techcrunch.com/2026/02/19/this-former-big-tech-engineers-are-using-ai-to-navigate-trumps-trade-chaos/",
        "content": "Amari AI is making custom AI-powered software that helps customs brokers modernize and minimize constantly shifting trade policies.",
        "contentSnippet": "Amari AI is making custom AI-powered software that helps customs brokers modernize and minimize constantly shifting trade policies.",
        "pubDate": "Thu, 19 Feb 2026 14:00:00 +0000",
        "isoDate": "2026-02-19T14:00:00.000Z",
        "creator": "Sean O'Kane",
        "source": "https://techcrunch.com/2026/02/19/this-former-big-tech-engineers-are-using-ai-to-navigate-trumps-trade-chaos/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-iwn23x",
        "title": "For open-source programs, AI coding tools are a mixed blessing",
        "link": "https://techcrunch.com/2026/02/19/for-open-source-programs-ai-coding-tools-are-a-mixed-blessing/",
        "url": "https://techcrunch.com/2026/02/19/for-open-source-programs-ai-coding-tools-are-a-mixed-blessing/",
        "content": "AI coding tools have enabled a flood of bad code that threatens to overwhelm many projects. Building new features is easier but maintaining them is just as hard.",
        "contentSnippet": "AI coding tools have enabled a flood of bad code that threatens to overwhelm many projects. Building new features is easier but maintaining them is just as hard.",
        "pubDate": "Thu, 19 Feb 2026 14:00:00 +0000",
        "isoDate": "2026-02-19T14:00:00.000Z",
        "creator": "Russell Brandom",
        "source": "https://techcrunch.com/2026/02/19/for-open-source-programs-ai-coding-tools-are-a-mixed-blessing/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-69wjic",
        "title": "Altman and Amodei share a moment of awkwardness at India’s big AI summit",
        "link": "https://techcrunch.com/2026/02/19/altman-and-amodei-share-a-moment-of-awkwardness-at-indias-big-ai-summit/",
        "url": "https://techcrunch.com/2026/02/19/altman-and-amodei-share-a-moment-of-awkwardness-at-indias-big-ai-summit/",
        "content": " When Prime Minister Narendra Modi prompted speakers at the event to join hands and raise them in a show of unity, all executives on stage obliged, except OpenAI's Sam Altman and Anthropic's Dario Amodei, who held their hands conspicuously apart.",
        "contentSnippet": "When Prime Minister Narendra Modi prompted speakers at the event to join hands and raise them in a show of unity, all executives on stage obliged, except OpenAI's Sam Altman and Anthropic's Dario Amodei, who held their hands conspicuously apart.",
        "pubDate": "Thu, 19 Feb 2026 13:49:06 +0000",
        "isoDate": "2026-02-19T13:49:06.000Z",
        "creator": "Ivan Mehta",
        "source": "https://techcrunch.com/2026/02/19/altman-and-amodei-share-a-moment-of-awkwardness-at-indias-big-ai-summit/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-8tg1xf",
        "title": "Freeform raises $67M Series B to scale up laser AI manufacturing ",
        "link": "https://techcrunch.com/2026/02/19/freeform-raises-67m-series-b-to-scale-up-laser-ai-manufacturing/",
        "url": "https://techcrunch.com/2026/02/19/freeform-raises-67m-series-b-to-scale-up-laser-ai-manufacturing/",
        "content": "“I think we're the only quote-unquote manufacturing company out there that has H200 clusters in a data center on site.\" ",
        "contentSnippet": "“I think we're the only quote-unquote manufacturing company out there that has H200 clusters in a data center on site.\"",
        "pubDate": "Thu, 19 Feb 2026 13:00:00 +0000",
        "isoDate": "2026-02-19T13:00:00.000Z",
        "creator": "Tim Fernholz",
        "source": "https://techcrunch.com/2026/02/19/freeform-raises-67m-series-b-to-scale-up-laser-ai-manufacturing/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-q6z9kx",
        "title": "This VC’s best advice for building a founding team",
        "link": "https://techcrunch.com/2026/02/19/this-vcs-best-advice-for-building-a-founding-team/",
        "url": "https://techcrunch.com/2026/02/19/this-vcs-best-advice-for-building-a-founding-team/",
        "content": "One of the most consequential decisions early-stage founders have to make is who they will bring on as their founding team. That’s why this season on Build Mode, we’re diving into what it takes to build a world-class founding team. ",
        "contentSnippet": "One of the most consequential decisions early-stage founders have to make is who they will bring on as their founding team. That’s why this season on Build Mode, we’re diving into what it takes to build a world-class founding team.",
        "pubDate": "Thu, 19 Feb 2026 12:30:00 +0000",
        "isoDate": "2026-02-19T12:30:00.000Z",
        "creator": "Maggie Nye",
        "source": "https://techcrunch.com/2026/02/19/this-vcs-best-advice-for-building-a-founding-team/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-kbx4md",
        "title": "Reliance unveils $110B AI investment plan as India ramps up tech ambitions",
        "link": "https://techcrunch.com/2026/02/19/reliance-unveils-110b-ai-investment-plan-as-india-ramps-up-tech-ambitions/",
        "url": "https://techcrunch.com/2026/02/19/reliance-unveils-110b-ai-investment-plan-as-india-ramps-up-tech-ambitions/",
        "content": "Reliance has begun building multi-gigawatt AI data centers in Jamnagar, with more than 120 MW of capacity expected to come online in 2026.",
        "contentSnippet": "Reliance has begun building multi-gigawatt AI data centers in Jamnagar, with more than 120 MW of capacity expected to come online in 2026.",
        "pubDate": "Thu, 19 Feb 2026 11:39:17 +0000",
        "isoDate": "2026-02-19T11:39:17.000Z",
        "creator": "Jagmeet Singh",
        "source": "https://techcrunch.com/2026/02/19/reliance-unveils-110b-ai-investment-plan-as-india-ramps-up-tech-ambitions/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-ms2nmr",
        "title": "OpenAI taps Tata for 100MW AI data center capacity in India, eyes 1GW",
        "link": "https://techcrunch.com/2026/02/18/openai-taps-tata-for-100mw-ai-data-center-capacity-in-india-eyes-1gw/",
        "url": "https://techcrunch.com/2026/02/18/openai-taps-tata-for-100mw-ai-data-center-capacity-in-india-eyes-1gw/",
        "content": "OpenAI also plans to expand its presence in India with new offices in Mumbai and Bengaluru later this year.",
        "contentSnippet": "OpenAI also plans to expand its presence in India with new offices in Mumbai and Bengaluru later this year.",
        "pubDate": "Thu, 19 Feb 2026 05:34:25 +0000",
        "isoDate": "2026-02-19T05:34:25.000Z",
        "creator": "Jagmeet Singh",
        "source": "https://techcrunch.com/2026/02/18/openai-taps-tata-for-100mw-ai-data-center-capacity-in-india-eyes-1gw/"
      },
      {
        "id": "rss-techcrunch-social-phenomenon-4-3nl0y1",
        "title": "OpenAI deepens India push with Pine Labs fintech partnership",
        "link": "https://techcrunch.com/2026/02/18/openai-deepens-india-push-with-pine-labs-fintech-partnership/",
        "url": "https://techcrunch.com/2026/02/18/openai-deepens-india-push-with-pine-labs-fintech-partnership/",
        "content": "OpenAI moves beyond ChatGPT in India with a Pine Labs deal targeting enterprise payments and AI-driven commerce.",
        "contentSnippet": "OpenAI moves beyond ChatGPT in India with a Pine Labs deal targeting enterprise payments and AI-driven commerce.",
        "pubDate": "Thu, 19 Feb 2026 03:30:00 +0000",
        "isoDate": "2026-02-19T03:30:00.000Z",
        "creator": "Jagmeet Singh",
        "source": "https://techcrunch.com/2026/02/18/openai-deepens-india-push-with-pine-labs-fintech-partnership/"
      }
    ],
    "hn-front-social-phenomenon-5": [
      {
        "id": "rss-hn-front-social-phenomenon-5-77x25s",
        "title": "Gemini 3.1 Pro",
        "link": "https://deepmind.google/models/model-cards/gemini-3-1-pro/",
        "url": "https://deepmind.google/models/model-cards/gemini-3-1-pro/",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47075318\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 16:14:07 +0000",
        "isoDate": "2026-02-19T16:14:07.000Z",
        "source": "https://deepmind.google/models/model-cards/gemini-3-1-pro/"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-wpad1g",
        "title": "America vs. Singapore: You Can't Save Your Way Out of Economic Shocks",
        "link": "https://www.governance.fyi/p/america-vs-singapore-you-cant-save",
        "url": "https://www.governance.fyi/p/america-vs-singapore-you-cant-save",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47074389\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 14:52:18 +0000",
        "isoDate": "2026-02-19T14:52:18.000Z",
        "source": "https://www.governance.fyi/p/america-vs-singapore-you-cant-save"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-80r30n",
        "title": "Dinosaur Food: 100M year old foods we still eat today",
        "link": "https://borischerny.com/food/2022/01/17/Dinosaur-food.html",
        "url": "https://borischerny.com/food/2022/01/17/Dinosaur-food.html",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47074869\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 15:30:42 +0000",
        "isoDate": "2026-02-19T15:30:42.000Z",
        "source": "https://borischerny.com/food/2022/01/17/Dinosaur-food.html"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-l8t2br",
        "title": "Pebble Production: February Update",
        "link": "https://repebble.com/blog/february-pebble-production-and-software-updates",
        "url": "https://repebble.com/blog/february-pebble-production-and-software-updates",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47073112\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 12:36:00 +0000",
        "isoDate": "2026-02-19T12:36:00.000Z",
        "source": "https://repebble.com/blog/february-pebble-production-and-software-updates"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-ljtw5f",
        "title": "Paged Out Issue #8 [pdf]",
        "link": "https://pagedout.institute/download/PagedOut_008.pdf",
        "url": "https://pagedout.institute/download/PagedOut_008.pdf",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47072968\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 12:13:44 +0000",
        "isoDate": "2026-02-19T12:13:44.000Z",
        "source": "https://pagedout.institute/download/PagedOut_008.pdf"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-pmn7i",
        "title": "Show HN: Micasa – track your house from the terminal",
        "link": "https://micasa.dev",
        "url": "https://micasa.dev",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47075124\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 15:54:14 +0000",
        "isoDate": "2026-02-19T15:54:14.000Z",
        "source": "https://micasa.dev"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-n2kbrg",
        "title": "-fbounds-safety: Enforcing bounds safety for C",
        "link": "https://clang.llvm.org/docs/BoundsSafety.html",
        "url": "https://clang.llvm.org/docs/BoundsSafety.html",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47035088\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Mon, 16 Feb 2026 14:05:21 +0000",
        "isoDate": "2026-02-16T14:05:21.000Z",
        "source": "https://clang.llvm.org/docs/BoundsSafety.html"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-b82w6b",
        "title": "Don't Trust the Salt: AI Summarization, Multilingual Safety, and LLM Guardrails",
        "link": "https://royapakzad.substack.com/p/multilingual-llm-evaluation-to-guardrails",
        "url": "https://royapakzad.substack.com/p/multilingual-llm-evaluation-to-guardrails",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47038032\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Mon, 16 Feb 2026 17:57:46 +0000",
        "isoDate": "2026-02-16T17:57:46.000Z",
        "source": "https://royapakzad.substack.com/p/multilingual-llm-evaluation-to-guardrails"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-opf1yn",
        "title": "Gemini 3.1 Pro Preview",
        "link": "https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemini-3.1-pro-preview?pli=1",
        "url": "https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemini-3.1-pro-preview?pli=1",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47074735\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 15:19:57 +0000",
        "isoDate": "2026-02-19T15:19:57.000Z",
        "source": "https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemini-3.1-pro-preview?pli=1"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-qle0sw",
        "title": "Large Language Models for Mortals: A Practical Guide for Analysts with Python",
        "link": "https://crimede-coder.com/blogposts/2026/LLMsForMortals",
        "url": "https://crimede-coder.com/blogposts/2026/LLMsForMortals",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47023391\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Sun, 15 Feb 2026 13:12:50 +0000",
        "isoDate": "2026-02-15T13:12:50.000Z",
        "source": "https://crimede-coder.com/blogposts/2026/LLMsForMortals"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-1cbr1s",
        "title": "Show HN: A physically-based GPU ray tracer written in Julia",
        "link": "https://makie.org/website/blogposts/raytracing/",
        "url": "https://makie.org/website/blogposts/raytracing/",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47072444\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 10:55:13 +0000",
        "isoDate": "2026-02-19T10:55:13.000Z",
        "source": "https://makie.org/website/blogposts/raytracing/"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-1kjewh",
        "title": "Bridging Elixir and Python with Oban",
        "link": "https://oban.pro/articles/bridging-with-oban",
        "url": "https://oban.pro/articles/bridging-with-oban",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47072539\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 11:07:15 +0000",
        "isoDate": "2026-02-19T11:07:15.000Z",
        "source": "https://oban.pro/articles/bridging-with-oban"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-3jbv52",
        "title": "Coding Tricks Used in the C64 Game Seawolves",
        "link": "https://kodiak64.co.uk/blog/seawolves-technical-tricks",
        "url": "https://kodiak64.co.uk/blog/seawolves-technical-tricks",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47073044\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 12:24:33 +0000",
        "isoDate": "2026-02-19T12:24:33.000Z",
        "source": "https://kodiak64.co.uk/blog/seawolves-technical-tricks"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-o7pqzl",
        "title": "Sizing chaos",
        "link": "https://pudding.cool/2026/02/womens-sizing/",
        "url": "https://pudding.cool/2026/02/womens-sizing/",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47066552\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Wed, 18 Feb 2026 21:18:20 +0000",
        "isoDate": "2026-02-18T21:18:20.000Z",
        "source": "https://pudding.cool/2026/02/womens-sizing/"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-o7thmc",
        "title": "Show HN: Mini-Diarium - An encrypted, local, cross-platform journaling app",
        "link": "https://github.com/fjrevoredo/mini-diarium",
        "url": "https://github.com/fjrevoredo/mini-diarium",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47072863\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 11:54:21 +0000",
        "isoDate": "2026-02-19T11:54:21.000Z",
        "source": "https://github.com/fjrevoredo/mini-diarium"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-cksufg",
        "title": "Measuring AI agent autonomy in practice",
        "link": "https://www.anthropic.com/research/measuring-agent-autonomy",
        "url": "https://www.anthropic.com/research/measuring-agent-autonomy",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47073947\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 14:14:14 +0000",
        "isoDate": "2026-02-19T14:14:14.000Z",
        "source": "https://www.anthropic.com/research/measuring-agent-autonomy"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-3uakwg",
        "title": "Against Theory-Motivated Experimentation",
        "link": "https://journals.sagepub.com/doi/10.1177/26339137261421577",
        "url": "https://journals.sagepub.com/doi/10.1177/26339137261421577",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47074083\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 14:26:20 +0000",
        "isoDate": "2026-02-19T14:26:20.000Z",
        "source": "https://journals.sagepub.com/doi/10.1177/26339137261421577"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-xkkuuz",
        "title": "The Mongol Khans of Medieval France",
        "link": "https://www.historytoday.com/archive/feature/mongol-khans-medieval-france",
        "url": "https://www.historytoday.com/archive/feature/mongol-khans-medieval-france",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47041225\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Mon, 16 Feb 2026 22:27:47 +0000",
        "isoDate": "2026-02-16T22:27:47.000Z",
        "source": "https://www.historytoday.com/archive/feature/mongol-khans-medieval-france"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-cr3yev",
        "title": "Arrays in Forth",
        "link": "https://www.forth.org/svfig/Len/arrays.htm",
        "url": "https://www.forth.org/svfig/Len/arrays.htm",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47022527\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Sun, 15 Feb 2026 10:08:27 +0000",
        "isoDate": "2026-02-15T10:08:27.000Z",
        "source": "https://www.forth.org/svfig/Len/arrays.htm"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-s5gfa2",
        "title": "Zero downtime migrations at Petabyte scale",
        "link": "https://planetscale.com/blog/zero-downtime-migrations-at-petabyte-scale",
        "url": "https://planetscale.com/blog/zero-downtime-migrations-at-petabyte-scale",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47037781\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Mon, 16 Feb 2026 17:35:00 +0000",
        "isoDate": "2026-02-16T17:35:00.000Z",
        "source": "https://planetscale.com/blog/zero-downtime-migrations-at-petabyte-scale"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-ywx4sj",
        "title": "27-year-old Apple iBooks can connect to Wi-Fi and download official updates",
        "link": "https://old.reddit.com/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/",
        "url": "https://old.reddit.com/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47066241\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Wed, 18 Feb 2026 20:54:31 +0000",
        "isoDate": "2026-02-18T20:54:31.000Z",
        "source": "https://old.reddit.com/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-85ox8w",
        "title": "AI made coding more enjoyable",
        "link": "https://weberdominik.com/blog/ai-coding-enjoyable/",
        "url": "https://weberdominik.com/blog/ai-coding-enjoyable/",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47075400\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 16:20:26 +0000",
        "isoDate": "2026-02-19T16:20:26.000Z",
        "source": "https://weberdominik.com/blog/ai-coding-enjoyable/"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-giysi9",
        "title": "Famous Signatures Through History",
        "link": "https://signatory.app/#famous-signatures",
        "url": "https://signatory.app/#famous-signatures",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47073684\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 13:49:49 +0000",
        "isoDate": "2026-02-19T13:49:49.000Z",
        "source": "https://signatory.app/#famous-signatures"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-uzjarf",
        "title": "Voith Schneider Propeller",
        "link": "https://en.wikipedia.org/wiki/Voith_Schneider_Propeller",
        "url": "https://en.wikipedia.org/wiki/Voith_Schneider_Propeller",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47027171\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Sun, 15 Feb 2026 20:22:33 +0000",
        "isoDate": "2026-02-15T20:22:33.000Z",
        "source": "https://en.wikipedia.org/wiki/Voith_Schneider_Propeller"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-jnts6",
        "title": "15 years of FP64 segmentation, and why the Blackwell Ultra breaks the pattern",
        "link": "https://nicolasdickenmann.com/blog/the-great-fp64-divide.html",
        "url": "https://nicolasdickenmann.com/blog/the-great-fp64-divide.html",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47068890\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 01:46:07 +0000",
        "isoDate": "2026-02-19T01:46:07.000Z",
        "source": "https://nicolasdickenmann.com/blog/the-great-fp64-divide.html"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-48nrud",
        "title": "ShannonMax: A Library to Optimize Emacs Keybindings with Information Theory",
        "link": "https://github.com/sstraust/shannonmax",
        "url": "https://github.com/sstraust/shannonmax",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47072603\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 11:15:38 +0000",
        "isoDate": "2026-02-19T11:15:38.000Z",
        "source": "https://github.com/sstraust/shannonmax"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-pkbd7h",
        "title": "Old School Visual Effects: The Cloud Tank (2010)",
        "link": "http://singlemindedmovieblog.blogspot.com/2010/04/old-school-effects-cloud-tank.html",
        "url": "http://singlemindedmovieblog.blogspot.com/2010/04/old-school-effects-cloud-tank.html",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47070680\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 06:43:53 +0000",
        "isoDate": "2026-02-19T06:43:53.000Z",
        "source": "http://singlemindedmovieblog.blogspot.com/2010/04/old-school-effects-cloud-tank.html"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-9rj7fk",
        "title": "Step 3.5 Flash – Open-source foundation model, supports deep reasoning at speed",
        "link": "https://static.stepfun.com/blog/step-3.5-flash/",
        "url": "https://static.stepfun.com/blog/step-3.5-flash/",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47069179\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 02:32:00 +0000",
        "isoDate": "2026-02-19T02:32:00.000Z",
        "source": "https://static.stepfun.com/blog/step-3.5-flash/"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-yzfsf7",
        "title": "Anthropic officially bans using subscription auth for third party use",
        "link": "https://code.claude.com/docs/en/legal-and-compliance",
        "url": "https://code.claude.com/docs/en/legal-and-compliance",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47069299\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Thu, 19 Feb 2026 02:52:26 +0000",
        "isoDate": "2026-02-19T02:52:26.000Z",
        "source": "https://code.claude.com/docs/en/legal-and-compliance"
      },
      {
        "id": "rss-hn-front-social-phenomenon-5-f2opb6",
        "title": "A word processor from 1990s for Atari ST/TOS is still supported by enthusiasts",
        "link": "https://tempus-word.de/en/index",
        "url": "https://tempus-word.de/en/index",
        "content": "<a href=\"https://news.ycombinator.com/item?id=47038578\">Comments</a>",
        "contentSnippet": "Comments",
        "pubDate": "Mon, 16 Feb 2026 18:44:12 +0000",
        "isoDate": "2026-02-16T18:44:12.000Z",
        "source": "https://tempus-word.de/en/index"
      }
    ],
    "venturebeat-ai-finance-capital-8": [
      {
        "id": "rss-venturebeat-ai-finance-capital-8-lt1nhr",
        "title": "Railway secures $100 million to challenge AWS with AI-native cloud infrastructure",
        "link": "https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud",
        "url": "https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud",
        "content": "<p><a href=\"https://railway.com/\">Railway</a>, a San Francisco-based cloud platform that has quietly amassed two million developers without spending a dollar on marketing, announced Thursday that it raised $100 million in a Series B funding round, as surging demand for artificial intelligence applications exposes the limitations of legacy cloud infrastructure.</p><p><a href=\"https://tq.vc/\">TQ Ventures</a> led the round, with participation from <a href=\"https://fpvventures.com/\">FPV Ventures</a>, <a href=\"https://www.redpoint.com/\">Redpoint</a>, and <a href=\"https://www.unusual.vc/\">Unusual Ventures</a>. The investment values Railway as one of the most significant infrastructure startups to emerge during the AI boom, capitalizing on developer frustration with the complexity and cost of traditional platforms like <a href=\"https://aws.amazon.com/\">Amazon Web Services</a> and <a href=\"https://cloud.google.com/\">Google Cloud</a>.</p><p>&quot;As AI models get better at writing code, more and more people are asking the age-old question: where, and how, do I run my applications?&quot; said Jake Cooper, Railway&#x27;s 28-year-old founder and chief executive, in an exclusive interview with VentureBeat. &quot;The last generation of cloud primitives were slow and outdated, and now with AI moving everything faster, teams simply can&#x27;t keep up.&quot;</p><p>The funding is a dramatic acceleration for a company that has charted an unconventional path through the cloud computing industry. Railway raised just $24 million in total before this round, including a <a href=\"https://techcrunch.com/2022/05/31/railway-snags-20m-to-streamline-the-process-of-deploying-apps-and-services/\">$20 million Series A</a> from Redpoint in 2022. The company now processes more than 10 million deployments monthly and handles over one trillion requests through its edge network — metrics that rival far larger and better-funded competitors.</p><h2><b>Why three-minute deploy times have become unacceptable in the age of AI coding assistants</b></h2><p>Railway&#x27;s pitch rests on a simple observation: the tools developers use to deploy and manage software were designed for a slower era. A standard build-and-deploy cycle using <a href=\"https://station.railway.com/feedback/terraform-provider-954567d7\">Terraform</a>, the industry-standard infrastructure tool, takes two to three minutes. That delay, once tolerable, has become a critical bottleneck as AI coding assistants like <a href=\"https://claude.ai/login\">Claude</a>, <a href=\"https://chatgpt.com/\">ChatGPT</a>, and <a href=\"https://cursor.com/\">Cursor</a> can generate working code in seconds.</p><p>&quot;When godly intelligence is on tap and can solve any problem in three seconds, those amalgamations of systems become bottlenecks,&quot; Cooper told VentureBeat. &quot;What was really cool for humans to deploy in 10 seconds or less is now table stakes for agents.&quot;</p><p>The company claims its platform delivers deployments in under one second — fast enough to keep pace with AI-generated code. Customers report a tenfold increase in developer velocity and up to 65 percent cost savings compared to traditional cloud providers.</p><p>These numbers come directly from enterprise clients, not internal benchmarks. Daniel Lobaton, chief technology officer at G2X, a platform serving 100,000 federal contractors, measured deployment speed improvements of seven times faster and an 87 percent cost reduction after migrating to Railway. His infrastructure bill dropped from $15,000 per month to approximately $1,000.</p><p>&quot;The work that used to take me a week on our previous infrastructure, I can do in Railway in like a day,&quot; Lobaton said. &quot;If I want to spin up a new service and test different architectures, it would take so long on our old setup. In Railway I can launch six services in two minutes.&quot;</p><h2><b>Inside the controversial decision to abandon Google Cloud and build data centers from scratch</b></h2><p>What distinguishes <a href=\"https://railway.com/\">Railway</a> from competitors like <a href=\"https://render.com/\">Render</a> and <a href=\"http://fly.io\">Fly.io</a> is the depth of its vertical integration. In 2024, the company made the unusual decision to abandon Google Cloud entirely and build its own data centers, a move that echoes the famous Alan Kay maxim: &quot;People who are really serious about software should make their own hardware.&quot;</p><p>&quot;We wanted to design hardware in a way where we could build a differentiated experience,&quot; Cooper said. &quot;Having full control over the network, compute, and storage layers lets us do really fast build and deploy loops, the kind that allows us to move at &#x27;agentic speed&#x27; while staying 100 percent the smoothest ride in town.&quot;</p><p>The approach paid dividends during recent <a href=\"https://restofworld.org/2026/cloud-outages-2025-global-business-impact/\">widespread outages</a> that affected major cloud providers — Railway remained online throughout.</p><p>This soup-to-nuts control enables pricing that undercuts the hyperscalers by roughly 50 percent and newer cloud startups by three to four times. Railway charges by the second for actual compute usage: $0.00000386 per gigabyte-second of memory, $0.00000772 per vCPU-second, and $0.00000006 per gigabyte-second of storage. There are no charges for idle virtual machines — a stark contrast to the traditional cloud model where customers pay for provisioned capacity whether they use it or not.</p><p>&quot;The conventional wisdom is that the big guys have economies of scale to offer better pricing,&quot; Cooper noted. &quot;But when they&#x27;re charging for VMs that usually sit idle in the cloud, and we&#x27;ve purpose-built everything to fit much more density on these machines, you have a big opportunity.&quot;</p><h2><b>How 30 employees built a platform generating tens of millions in annual revenue</b></h2><p><a href=\"https://railway.com/\">Railway</a> has achieved its scale with a team of just 30 employees generating tens of millions in annual revenue — a ratio of revenue per employee that would be exceptional even for established software companies. The company grew revenue 3.5 times last year and continues to expand at 15 percent month-over-month.</p><p>Cooper emphasized that the fundraise was strategic rather than necessary. &quot;We&#x27;re default alive; there&#x27;s no reason for us to raise money,&quot; he said. &quot;We raised because we see a massive opportunity to accelerate, not because we needed to survive.&quot;</p><p>The company hired its first salesperson only last year and employs just two solutions engineers. Nearly all of Railway&#x27;s two million users discovered the platform through word of mouth — developers telling other developers about a tool that actually works.</p><p>&quot;We basically did the standard engineering thing: if you build it, they will come,&quot; Cooper recalled. &quot;And to some degree, they came.&quot;</p><h2><b>From side projects to Fortune 500 deployments: Railway&#x27;s unlikely corporate expansion</b></h2><p>Despite its grassroots developer community, Railway has made significant inroads into large organizations. The company claims that 31 percent of Fortune 500 companies now use its platform, though deployments range from company-wide infrastructure to individual team projects.</p><p>Notable customers include <a href=\"https://www.biltrewards.com/\">Bilt</a>, the loyalty program company; Intuit&#x27;s <a href=\"https://www.goco.io/\">GoCo</a> subsidiary; TripAdvisor&#x27;s <a href=\"https://www.cruisecritic.com/\">Cruise Critic</a>; and <a href=\"https://www.mgmresorts.com/en.html\">MGM Resorts</a>. <a href=\"https://www.ycombinator.com/companies/kernel\">Kernel</a>, a Y Combinator-backed startup providing AI infrastructure to over 1,000 companies, runs its entire customer-facing system on Railway for $444 per month.</p><p>&quot;At my previous company Clever, which sold for $500 million, I had six full-time engineers just managing AWS,&quot; said Rafael Garcia, Kernel&#x27;s chief technology officer. &quot;Now I have six engineers total, and they all focus on product. Railway is exactly the tool I wish I had in 2012.&quot;</p><p>For enterprise customers, <a href=\"https://railway.com/\">Railway</a> offers security certifications including SOC 2 Type 2 compliance and HIPAA readiness, with business associate agreements available upon request. The platform provides single sign-on authentication, comprehensive audit logs, and the option to deploy within a customer&#x27;s existing cloud environment through a &quot;bring your own cloud&quot; configuration.</p><p>Enterprise pricing starts at custom levels, with specific add-ons for extended log retention ($200 monthly), HIPAA BAAs ($1,000), enterprise support with SLOs ($2,000), and dedicated virtual machines ($10,000).</p><h2><b>The startup&#x27;s bold strategy to take on Amazon, Google, and a new generation of cloud rivals</b></h2><p>Railway enters a crowded market that includes not only the hyperscale cloud providers—Amazon Web Services, Microsoft Azure, and Google Cloud Platform—but also a growing cohort of developer-focused platforms like Vercel, Render, Fly.io, and Heroku.</p><p>Cooper argues that Railway&#x27;s competitors fall into two camps, neither of which has fully committed to the new infrastructure model that AI demands.</p><p>&quot;The hyperscalers have two competing systems, and they haven&#x27;t gone all-in on the new model because their legacy revenue stream is still printing money,&quot; he observed. &quot;They have this mammoth pool of cash coming from people who provision a VM, use maybe 10 percent of it, and still pay for the whole thing. To what end are they actually interested in going all the way in on a new experience if they don&#x27;t really need to?&quot;</p><p>Against startup competitors, Railway differentiates by covering the full infrastructure stack. &quot;We&#x27;re not just containers; we&#x27;ve got VM primitives, stateful storage, virtual private networking, automated load balancing,&quot; Cooper said. &quot;And we wrap all of this in an absurdly easy-to-use UI, with agentic primitives so agents can move 1,000 times faster.&quot;</p><p>The platform supports databases including PostgreSQL, MySQL, MongoDB, and Redis; provides up to 256 terabytes of persistent storage with over 100,000 input/output operations per second; and enables deployment to four global regions spanning the United States, Europe, and Southeast Asia. Enterprise customers can scale to 112 vCPUs and 2 terabytes of RAM per service.</p><h2><b>Why investors are betting that AI will create a thousand times more software than exists today</b></h2><p>Railway&#x27;s fundraise reflects broader investor enthusiasm for companies positioned to benefit from the AI coding revolution. As tools like <a href=\"https://github.com/features/copilot\">GitHub Copilot</a>, <a href=\"https://cursor.com/agents\">Cursor</a>, and <a href=\"https://claude.ai/login\">Claude</a> become standard fixtures in developer workflows, the volume of code being written — and the infrastructure needed to run it — is expanding dramatically.</p><p>&quot;The amount of software that&#x27;s going to come online over the next five years is unfathomable compared to what existed before — we&#x27;re talking a thousand times more software,&quot; Cooper predicted. &quot;All of that has to run somewhere.&quot;</p><p>The company has already integrated directly with AI systems, building what Cooper calls &quot;loops where Claude can hook in, call deployments, and analyze infrastructure automatically.&quot; Railway released a Model Context Protocol server in August 2025 that allows AI coding agents to deploy applications and manage infrastructure directly from code editors.</p><p>&quot;The notion of a developer is melting before our eyes,&quot; Cooper said. &quot;You don&#x27;t have to be an engineer to engineer things anymore — you just need critical thinking and the ability to analyze things in a systems capacity.&quot;</p><h2><b>What Railway plans to do with $100 million and zero marketing experience</b></h2><p><a href=\"https://railway.com/\">Railway</a> plans to use the new capital to expand its global data center footprint, grow its team beyond 30 employees, and build what Cooper described as a proper go-to-market operation for the first time in the company&#x27;s five-year history.</p><p>&quot;One of my mentors said you raise money when you can change the trajectory of the business,&quot; Cooper explained. &quot;We&#x27;ve built all the required substrate to scale indefinitely; what&#x27;s been holding us back is simply talking about it. 2026 is the year we play on the world stage.&quot;</p><p>The company&#x27;s investor roster reads like a who&#x27;s who of developer infrastructure. Angel investors include <a href=\"https://tom.preston-werner.com/\">Tom Preston-Werner,</a> co-founder of GitHub; <a href=\"https://rauchg.com/about\">Guillermo Rauch</a>, chief executive of Vercel; <a href=\"https://www.cockroachlabs.com/author/spencer-kimball/\">Spencer Kimball</a>, chief executive of Cockroach Labs; <a href=\"https://www.datadoghq.com/about/leadership/\">Olivier Pomel</a>, chief executive of Datadog; and <a href=\"https://sequoiacap.com/founder/jori-lallo/\">Jori Lallo</a>, co-founder of Linear.</p><p>The timing of Railway&#x27;s expansion coincides with what many in Silicon Valley view as a fundamental shift in how software gets made. Coding assistants are no longer experimental curiosities — they have become essential tools that millions of developers rely on daily. Each line of AI-generated code needs somewhere to run, and the incumbents, by Cooper&#x27;s telling, are too wedded to their existing business models to fully capitalize on the moment.</p><p>Whether <a href=\"https://railway.com/\">Railway</a> can translate developer enthusiasm into sustained enterprise adoption remains an open question. The cloud infrastructure market is littered with promising startups that failed to break the grip of Amazon, Microsoft, and Google. But Cooper, who previously worked as a software engineer at <a href=\"https://www.wolframalpha.com/\">Wolfram Alpha</a>, <a href=\"https://www.bloomberg.com/\">Bloomberg</a>, and <a href=\"https://www.uber.com/\">Uber</a> before founding Railway in 2020, seems unfazed by the scale of his ambition.</p><p>&quot;In five years, Railway [will be] the place where software gets created and evolved, period,&quot; he said. &quot;Deploy instantly, scale infinitely, with zero friction. That&#x27;s the prize worth playing for, and there&#x27;s no bigger one on offer.&quot;</p><p>For a company that built a $100 million business by doing the opposite of what conventional startup wisdom dictates — no marketing, no sales team, no venture hype—the real test begins now. Railway spent five years proving that developers would find a better mousetrap on their own. The next five will determine whether the rest of the world is ready to get on board.</p>",
        "contentSnippet": "Railway, a San Francisco-based cloud platform that has quietly amassed two million developers without spending a dollar on marketing, announced Thursday that it raised $100 million in a Series B funding round, as surging demand for artificial intelligence applications exposes the limitations of legacy cloud infrastructure.\nTQ Ventures led the round, with participation from FPV Ventures, Redpoint, and Unusual Ventures. The investment values Railway as one of the most significant infrastructure startups to emerge during the AI boom, capitalizing on developer frustration with the complexity and cost of traditional platforms like Amazon Web Services and Google Cloud.\n\"As AI models get better at writing code, more and more people are asking the age-old question: where, and how, do I run my applications?\" said Jake Cooper, Railway's 28-year-old founder and chief executive, in an exclusive interview with VentureBeat. \"The last generation of cloud primitives were slow and outdated, and now with AI moving everything faster, teams simply can't keep up.\"\nThe funding is a dramatic acceleration for a company that has charted an unconventional path through the cloud computing industry. Railway raised just $24 million in total before this round, including a $20 million Series A from Redpoint in 2022. The company now processes more than 10 million deployments monthly and handles over one trillion requests through its edge network — metrics that rival far larger and better-funded competitors.\nWhy three-minute deploy times have become unacceptable in the age of AI coding assistants\nRailway's pitch rests on a simple observation: the tools developers use to deploy and manage software were designed for a slower era. A standard build-and-deploy cycle using Terraform, the industry-standard infrastructure tool, takes two to three minutes. That delay, once tolerable, has become a critical bottleneck as AI coding assistants like Claude, ChatGPT, and Cursor can generate working code in seconds.\n\"When godly intelligence is on tap and can solve any problem in three seconds, those amalgamations of systems become bottlenecks,\" Cooper told VentureBeat. \"What was really cool for humans to deploy in 10 seconds or less is now table stakes for agents.\"\nThe company claims its platform delivers deployments in under one second — fast enough to keep pace with AI-generated code. Customers report a tenfold increase in developer velocity and up to 65 percent cost savings compared to traditional cloud providers.\nThese numbers come directly from enterprise clients, not internal benchmarks. Daniel Lobaton, chief technology officer at G2X, a platform serving 100,000 federal contractors, measured deployment speed improvements of seven times faster and an 87 percent cost reduction after migrating to Railway. His infrastructure bill dropped from $15,000 per month to approximately $1,000.\n\"The work that used to take me a week on our previous infrastructure, I can do in Railway in like a day,\" Lobaton said. \"If I want to spin up a new service and test different architectures, it would take so long on our old setup. In Railway I can launch six services in two minutes.\"\nInside the controversial decision to abandon Google Cloud and build data centers from scratch\nWhat distinguishes Railway from competitors like Render and Fly.io is the depth of its vertical integration. In 2024, the company made the unusual decision to abandon Google Cloud entirely and build its own data centers, a move that echoes the famous Alan Kay maxim: \"People who are really serious about software should make their own hardware.\"\n\"We wanted to design hardware in a way where we could build a differentiated experience,\" Cooper said. \"Having full control over the network, compute, and storage layers lets us do really fast build and deploy loops, the kind that allows us to move at 'agentic speed' while staying 100 percent the smoothest ride in town.\"\nThe approach paid dividends during recent widespread outages that affected major cloud providers — Railway remained online throughout.\nThis soup-to-nuts control enables pricing that undercuts the hyperscalers by roughly 50 percent and newer cloud startups by three to four times. Railway charges by the second for actual compute usage: $0.00000386 per gigabyte-second of memory, $0.00000772 per vCPU-second, and $0.00000006 per gigabyte-second of storage. There are no charges for idle virtual machines — a stark contrast to the traditional cloud model where customers pay for provisioned capacity whether they use it or not.\n\"The conventional wisdom is that the big guys have economies of scale to offer better pricing,\" Cooper noted. \"But when they're charging for VMs that usually sit idle in the cloud, and we've purpose-built everything to fit much more density on these machines, you have a big opportunity.\"\nHow 30 employees built a platform generating tens of millions in annual revenue\nRailway has achieved its scale with a team of just 30 employees generating tens of millions in annual revenue — a ratio of revenue per employee that would be exceptional even for established software companies. The company grew revenue 3.5 times last year and continues to expand at 15 percent month-over-month.\nCooper emphasized that the fundraise was strategic rather than necessary. \"We're default alive; there's no reason for us to raise money,\" he said. \"We raised because we see a massive opportunity to accelerate, not because we needed to survive.\"\nThe company hired its first salesperson only last year and employs just two solutions engineers. Nearly all of Railway's two million users discovered the platform through word of mouth — developers telling other developers about a tool that actually works.\n\"We basically did the standard engineering thing: if you build it, they will come,\" Cooper recalled. \"And to some degree, they came.\"\nFrom side projects to Fortune 500 deployments: Railway's unlikely corporate expansion\nDespite its grassroots developer community, Railway has made significant inroads into large organizations. The company claims that 31 percent of Fortune 500 companies now use its platform, though deployments range from company-wide infrastructure to individual team projects.\nNotable customers include Bilt, the loyalty program company; Intuit's GoCo subsidiary; TripAdvisor's Cruise Critic; and MGM Resorts. Kernel, a Y Combinator-backed startup providing AI infrastructure to over 1,000 companies, runs its entire customer-facing system on Railway for $444 per month.\n\"At my previous company Clever, which sold for $500 million, I had six full-time engineers just managing AWS,\" said Rafael Garcia, Kernel's chief technology officer. \"Now I have six engineers total, and they all focus on product. Railway is exactly the tool I wish I had in 2012.\"\nFor enterprise customers, Railway offers security certifications including SOC 2 Type 2 compliance and HIPAA readiness, with business associate agreements available upon request. The platform provides single sign-on authentication, comprehensive audit logs, and the option to deploy within a customer's existing cloud environment through a \"bring your own cloud\" configuration.\nEnterprise pricing starts at custom levels, with specific add-ons for extended log retention ($200 monthly), HIPAA BAAs ($1,000), enterprise support with SLOs ($2,000), and dedicated virtual machines ($10,000).\nThe startup's bold strategy to take on Amazon, Google, and a new generation of cloud rivals\nRailway enters a crowded market that includes not only the hyperscale cloud providers—Amazon Web Services, Microsoft Azure, and Google Cloud Platform—but also a growing cohort of developer-focused platforms like Vercel, Render, Fly.io, and Heroku.\nCooper argues that Railway's competitors fall into two camps, neither of which has fully committed to the new infrastructure model that AI demands.\n\"The hyperscalers have two competing systems, and they haven't gone all-in on the new model because their legacy revenue stream is still printing money,\" he observed. \"They have this mammoth pool of cash coming from people who provision a VM, use maybe 10 percent of it, and still pay for the whole thing. To what end are they actually interested in going all the way in on a new experience if they don't really need to?\"\nAgainst startup competitors, Railway differentiates by covering the full infrastructure stack. \"We're not just containers; we've got VM primitives, stateful storage, virtual private networking, automated load balancing,\" Cooper said. \"And we wrap all of this in an absurdly easy-to-use UI, with agentic primitives so agents can move 1,000 times faster.\"\nThe platform supports databases including PostgreSQL, MySQL, MongoDB, and Redis; provides up to 256 terabytes of persistent storage with over 100,000 input/output operations per second; and enables deployment to four global regions spanning the United States, Europe, and Southeast Asia. Enterprise customers can scale to 112 vCPUs and 2 terabytes of RAM per service.\nWhy investors are betting that AI will create a thousand times more software than exists today\nRailway's fundraise reflects broader investor enthusiasm for companies positioned to benefit from the AI coding revolution. As tools like GitHub Copilot, Cursor, and Claude become standard fixtures in developer workflows, the volume of code being written — and the infrastructure needed to run it — is expanding dramatically.\n\"The amount of software that's going to come online over the next five years is unfathomable compared to what existed before — we're talking a thousand times more software,\" Cooper predicted. \"All of that has to run somewhere.\"\nThe company has already integrated directly with AI systems, building what Cooper calls \"loops where Claude can hook in, call deployments, and analyze infrastructure automatically.\" Railway released a Model Context Protocol server in August 2025 that allows AI coding agents to deploy applications and manage infrastructure directly from code editors.\n\"The notion of a developer is melting before our eyes,\" Cooper said. \"You don't have to be an engineer to engineer things anymore — you just need critical thinking and the ability to analyze things in a systems capacity.\"\nWhat Railway plans to do with $100 million and zero marketing experience\nRailway plans to use the new capital to expand its global data center footprint, grow its team beyond 30 employees, and build what Cooper described as a proper go-to-market operation for the first time in the company's five-year history.\n\"One of my mentors said you raise money when you can change the trajectory of the business,\" Cooper explained. \"We've built all the required substrate to scale indefinitely; what's been holding us back is simply talking about it. 2026 is the year we play on the world stage.\"\nThe company's investor roster reads like a who's who of developer infrastructure. Angel investors include Tom Preston-Werner, co-founder of GitHub; Guillermo Rauch, chief executive of Vercel; Spencer Kimball, chief executive of Cockroach Labs; Olivier Pomel, chief executive of Datadog; and Jori Lallo, co-founder of Linear.\nThe timing of Railway's expansion coincides with what many in Silicon Valley view as a fundamental shift in how software gets made. Coding assistants are no longer experimental curiosities — they have become essential tools that millions of developers rely on daily. Each line of AI-generated code needs somewhere to run, and the incumbents, by Cooper's telling, are too wedded to their existing business models to fully capitalize on the moment.\nWhether Railway can translate developer enthusiasm into sustained enterprise adoption remains an open question. The cloud infrastructure market is littered with promising startups that failed to break the grip of Amazon, Microsoft, and Google. But Cooper, who previously worked as a software engineer at Wolfram Alpha, Bloomberg, and Uber before founding Railway in 2020, seems unfazed by the scale of his ambition.\n\"In five years, Railway [will be] the place where software gets created and evolved, period,\" he said. \"Deploy instantly, scale infinitely, with zero friction. That's the prize worth playing for, and there's no bigger one on offer.\"\nFor a company that built a $100 million business by doing the opposite of what conventional startup wisdom dictates — no marketing, no sales team, no venture hype—the real test begins now. Railway spent five years proving that developers would find a better mousetrap on their own. The next five will determine whether the rest of the world is ready to get on board.",
        "pubDate": "Thu, 22 Jan 2026 14:00:00 GMT",
        "isoDate": "2026-01-22T14:00:00.000Z",
        "creator": "michael.nunez@venturebeat.com (Michael Nuñez)",
        "source": "https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud"
      },
      {
        "id": "rss-venturebeat-ai-finance-capital-8-pw82ni",
        "title": "Claude Code costs up to $200 a month. Goose does the same thing for free.",
        "link": "https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free",
        "url": "https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free",
        "content": "<p>The artificial intelligence coding revolution comes with a catch: it&#x27;s expensive.</p><p><a href=\"https://claude.com/product/claude-code\">Claude Code</a>, Anthropic&#x27;s terminal-based AI agent that can write, debug, and deploy code autonomously, has captured the imagination of software developers worldwide. But its <a href=\"https://claude.com/pricing\">pricing</a> — ranging from $20 to $200 per month depending on usage — has sparked a growing rebellion among the very programmers it aims to serve.</p><p>Now, a free alternative is gaining traction. <a href=\"https://block.github.io/goose/\">Goose</a>, an open-source AI agent developed by <a href=\"https://block.xyz/\">Block</a> (the financial technology company formerly known as Square), offers nearly identical functionality to <a href=\"https://claude.com/product/claude-code\">Claude Code</a> but runs entirely on a user&#x27;s local machine. No subscription fees. No cloud dependency. No rate limits that reset every five hours.</p><p>&quot;Your data stays with you, period,&quot; said Parth Sareen, a software engineer who demonstrated the tool during a <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">recent livestream</a>. The comment captures the core appeal: Goose gives developers complete control over their AI-powered workflow, including the ability to work offline — even on an airplane.</p><p>The project has exploded in popularity. Goose now boasts more than <a href=\"https://github.com/block/goose\">26,100 stars on GitHub</a>, the code-sharing platform, with 362 contributors and 102 releases since its launch. The latest version, <a href=\"https://block.github.io/goose/docs/getting-started/installation\">1.20.1</a>, shipped on January 19, 2026, reflecting a development pace that rivals commercial products.</p><p>For developers frustrated by Claude Code&#x27;s pricing structure and usage caps, Goose represents something increasingly rare in the AI industry: a genuinely free, no-strings-attached option for serious work.</p><div></div><h2><b>Anthropic&#x27;s new rate limits spark a developer revolt</b></h2><p>To understand why <a href=\"https://block.github.io/goose/\">Goose</a> matters, you need to understand the <a href=\"https://techcrunch.com/2025/07/17/anthropic-tightens-usage-limits-for-claude-code-without-telling-users/\">Claude Code pricing controversy</a>.</p><p>Anthropic, the San Francisco artificial intelligence company founded by former OpenAI executives, offers Claude Code as part of its subscription tiers. The free plan provides no access whatsoever. The <a href=\"https://www.anthropic.com/news/claude-pro\">Pro plan</a>, at $17 per month with annual billing (or $20 monthly), limits users to just 10 to 40 prompts every five hours — a constraint that serious developers exhaust within minutes of intensive work.</p><p>The <a href=\"https://support.claude.com/en/articles/11049741-what-is-the-max-plan\">Max plans</a>, at $100 and $200 per month, offer more headroom: 50 to 200 prompts and 200 to 800 prompts respectively, plus access to Anthropic&#x27;s most powerful model, <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Claude 4.5 Opus</a>. But even these premium tiers come with restrictions that have inflamed the developer community.</p><p>In late July, Anthropic announced new weekly rate limits. Under the system, Pro users receive 40 to 80 hours of Sonnet 4 usage per week. Max users at the $200 tier get 240 to 480 hours of Sonnet 4, plus 24 to 40 hours of Opus 4. Nearly five months later, the frustration has not subsided.</p><p>The problem? Those &quot;hours&quot; are not actual hours. They represent token-based limits that vary wildly depending on codebase size, conversation length, and the complexity of the code being processed. Independent analysis suggests the actual per-session limits translate to roughly 44,000 tokens for Pro users and 220,000 tokens for the $200 Max plan.</p><p>&quot;It&#x27;s confusing and vague,&quot; one developer wrote in a <a href=\"https://userjot.com/blog/claude-code-pricing-200-dollar-plan-worth-it\">widely shared analysis</a>. &quot;When they say &#x27;24-40 hours of Opus 4,&#x27; that doesn&#x27;t really tell you anything useful about what you&#x27;re actually getting.&quot;</p><p>The <a href=\"https://www.reddit.com/r/Anthropic/comments/1mbo4uw/claude_code_max_new_weekly_rate_limits/\">backlash on Reddit</a> and <a href=\"https://venturebeat.com/ai/anthropic-throttles-claude-rate-limits-devs-call-foul\">developer forums</a> has been fierce. Some users report hitting their daily limits within 30 minutes of intensive coding. Others have canceled their subscriptions entirely, calling the new restrictions &quot;a joke&quot; and &quot;unusable for real work.&quot;</p><p>Anthropic has defended the changes, stating that the limits affect fewer than five percent of users and target people running Claude Code &quot;<a href=\"https://techcrunch.com/2025/07/28/anthropic-unveils-new-rate-limits-to-curb-claude-code-power-users/\">continuously in the background, 24/7</a>.&quot; But the company has not clarified whether that figure refers to five percent of Max subscribers or five percent of all users — a distinction that matters enormously.</p><h2><b>How Block built a free AI coding agent that works offline</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> takes a radically different approach to the same problem.</p><p>Built by <a href=\"https://block.xyz/\">Block</a>, the payments company led by Jack Dorsey, Goose is what engineers call an &quot;<a href=\"https://github.com/block/goose\">on-machine AI agent</a>.&quot; Unlike Claude Code, which sends your queries to Anthropic&#x27;s servers for processing, Goose can run entirely on your local computer using open-source language models that you download and control yourself.</p><p>The project&#x27;s documentation describes it as going &quot;<a href=\"https://github.com/block/goose\">beyond code suggestions</a>&quot; to &quot;install, execute, edit, and test with any LLM.&quot; That last phrase — &quot;any LLM&quot; — is the key differentiator. Goose is model-agnostic by design.</p><p>You can connect Goose to Anthropic&#x27;s <a href=\"https://platform.claude.com/docs/en/about-claude/models/overview\">Claude models</a> if you have <a href=\"https://claude.com/platform/api\">API access</a>. You can use OpenAI&#x27;s <a href=\"https://platform.openai.com/docs/models/gpt-5\">GPT-5</a> or Google&#x27;s <a href=\"https://ai.google.dev/gemini-api/docs\">Gemini</a>. You can route it through services like <a href=\"https://groq.com/\">Groq</a> or <a href=\"https://openrouter.ai/\">OpenRouter</a>. Or — and this is where things get interesting — you can run it entirely locally using tools like <a href=\"https://ollama.com/\">Ollama</a>, which let you download and execute open-source models on your own hardware.</p><p>The practical implications are significant. With a local setup, there are no subscription fees, no usage caps, no rate limits, and no concerns about your code being sent to external servers. Your conversations with the AI never leave your machine.</p><p>&quot;I use Ollama all the time on planes — it&#x27;s a lot of fun!&quot; <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">Sareen noted</a> during a demonstration, highlighting how local models free developers from the constraints of internet connectivity.</p><h2><b>What Goose can do that traditional code assistants can&#x27;t</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> operates as a command-line tool or desktop application that can autonomously perform complex development tasks. It can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows across multiple files, and interact with external APIs — all without constant human oversight.</p><p>The architecture relies on what the AI industry calls &quot;<a href=\"https://www.ibm.com/think/topics/tool-calling\">tool calling</a>&quot; or &quot;<a href=\"https://platform.openai.com/docs/guides/function-calling?api-mode=chat\">function calling</a>&quot; — the ability for a language model to request specific actions from external systems. When you ask <a href=\"https://block.github.io/goose/\">Goose</a> to create a new file, run a test suite, or check the status of a GitHub pull request, it doesn&#x27;t just generate text describing what should happen. It actually executes those operations.</p><p>This capability depends heavily on the underlying language model. <a href=\"https://platform.claude.com/docs/en/about-claude/models/overview\">Claude 4 models</a> from Anthropic currently perform best at tool calling, according to the <a href=\"https://gorilla.cs.berkeley.edu/leaderboard.html\">Berkeley Function-Calling Leaderboard</a>, which ranks models on their ability to translate natural language requests into executable code and system commands.</p><p>But newer open-source models are catching up quickly. Goose&#x27;s documentation highlights several options with strong tool-calling support: Meta&#x27;s <a href=\"https://www.llama.com/\">Llama series</a>, Alibaba&#x27;s <a href=\"https://qwen.ai/home\">Qwen models</a>, Google&#x27;s <a href=\"https://deepmind.google/models/gemma/\">Gemma variants</a>, and DeepSeek&#x27;s <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1\">reasoning-focused architectures</a>.</p><p>The tool also integrates with the <a href=\"https://modelcontextprotocol.io/docs/getting-started/intro\">Model Context Protocol</a>, or MCP, an emerging standard for connecting AI agents to external services. Through MCP, Goose can access databases, search engines, file systems, and third-party APIs — extending its capabilities far beyond what the base language model provides.</p><h2><b>Setting Up Goose with a Local Model</b></h2><p>For developers interested in a completely free, privacy-preserving setup, the process involves three main components: <a href=\"https://block.github.io/goose/\">Goose</a> itself, <a href=\"https://ollama.com/\">Ollama</a> (a tool for running open-source models locally), and a compatible language model.</p><p><b>Step 1: Install Ollama</b></p><p><a href=\"https://ollama.com/\">Ollama</a> is an open-source project that dramatically simplifies the process of running large language models on personal hardware. It handles the complex work of downloading, optimizing, and serving models through a simple interface.</p><p>Download and install Ollama from <a href=\"http://ollama.com\">ollama.com</a>. Once installed, you can pull models with a single command. For coding tasks, <a href=\"https://qwen.ai/blog?id=qwen2.5-max\">Qwen 2.5</a> offers strong tool-calling support:</p><p>ollama run qwen2.5</p><p>The model downloads automatically and begins running on your machine.</p><p><b>Step 2: Install Goose</b></p><p><a href=\"https://block.github.io/goose/\">Goose</a> is available as both a desktop application and a command-line interface. The desktop version provides a more visual experience, while the CLI appeals to developers who prefer working entirely in the terminal.</p><p>Installation instructions vary by operating system but generally involve downloading from Goose&#x27;s <a href=\"https://github.com/block/goose\">GitHub releases page</a> or using a package manager. Block provides pre-built binaries for macOS (both Intel and Apple Silicon), Windows, and Linux.</p><p><b>Step 3: Configure the Connection</b></p><p>In Goose Desktop, navigate to Settings, then Configure Provider, and select Ollama. Confirm that the API Host is set to http://localhost:11434 (Ollama&#x27;s default port) and click Submit.</p><p>For the command-line version, run goose configure, select &quot;Configure Providers,&quot; choose Ollama, and enter the model name when prompted.</p><p>That&#x27;s it. Goose is now connected to a language model running entirely on your hardware, ready to execute complex coding tasks without any subscription fees or external dependencies.</p><h2><b>The RAM, processing power, and trade-offs you should know about</b></h2><p>The obvious question: what kind of computer do you need?</p><p>Running large language models locally requires substantially more computational resources than typical software. The key constraint is memory — specifically, RAM on most systems, or VRAM if using a dedicated graphics card for acceleration.</p><p>Block&#x27;s <a href=\"https://block.github.io/goose/docs/category/guides\">documentation</a> suggests that 32 gigabytes of RAM provides &quot;a solid baseline for larger models and outputs.&quot; For Mac users, this means the computer&#x27;s unified memory is the primary bottleneck. For Windows and Linux users with discrete NVIDIA graphics cards, GPU memory (VRAM) matters more for acceleration.</p><p>But you don&#x27;t necessarily need expensive hardware to get started. Smaller models with fewer parameters run on much more modest systems. <a href=\"https://qwen.ai/blog?id=qwen2.5-max\">Qwen 2.5</a>, for instance, comes in multiple sizes, and the smaller variants can operate effectively on machines with 16 gigabytes of RAM.</p><p>&quot;You don&#x27;t need to run the largest models to get excellent results,&quot; <a href=\"https://www.youtube.com/watch?v=WG10r2N0IwM\">Sareen emphasized</a>. The practical recommendation: start with a smaller model to test your workflow, then scale up as needed.</p><p>For context, Apple&#x27;s entry-level <a href=\"https://www.apple.com/macbook-air/\">MacBook Air</a> with 8 gigabytes of RAM would struggle with most capable coding models. But a <a href=\"https://www.apple.com/macbook-pro/\">MacBook Pro</a> with 32 gigabytes — increasingly common among professional developers — handles them comfortably.</p><h2><b>Why keeping your code off the cloud matters more than ever</b></h2><p><a href=\"https://block.github.io/goose/\">Goose</a> with a local LLM is not a perfect substitute for <a href=\"https://claude.com/product/claude-code\">Claude Code</a>. The comparison involves real trade-offs that developers should understand.</p><p><b>Model Quality</b>: <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Claude 4.5 Opus</a>, Anthropic&#x27;s flagship model, remains arguably the most capable AI for software engineering tasks. It excels at understanding complex codebases, following nuanced instructions, and producing high-quality code on the first attempt. Open-source models have improved dramatically, but a gap persists — particularly for the most challenging tasks.</p><p>One developer who switched to the $200 Claude Code plan <a href=\"https://userjot.com/blog/claude-code-pricing-200-dollar-plan-worth-it\">described the difference bluntly</a>: &quot;When I say &#x27;make this look modern,&#x27; Opus knows what I mean. Other models give me Bootstrap circa 2015.&quot;</p><p><b>Context Window</b>: <a href=\"https://www.anthropic.com/news/claude-sonnet-4-5\">Claude Sonnet 4.5</a>, accessible through the API, offers a massive one-million-token context window — enough to load entire large codebases without chunking or context management issues. Most local models are limited to 4,096 or 8,192 tokens by default, though many can be configured for longer contexts at the cost of increased memory usage and slower processing.</p><p><b>Speed</b>: Cloud-based services like <a href=\"https://claude.com/product/claude-code\">Claude Code</a> run on dedicated server hardware optimized for AI inference. Local models, running on consumer laptops, typically process requests more slowly. The difference matters for iterative workflows where you&#x27;re making rapid changes and waiting for AI feedback.</p><p><b>Tooling Maturity</b>: <a href=\"https://claude.com/product/claude-code\">Claude Code</a> benefits from Anthropic&#x27;s dedicated engineering resources. Features like prompt caching (which can reduce costs by up to 90 percent for repeated contexts) and structured outputs are polished and well-documented. <a href=\"https://block.github.io/goose/\">Goose</a>, while actively developed with 102 releases to date, relies on community contributions and may lack equivalent refinement in specific areas.</p><h2><b>How Goose stacks up against Cursor, GitHub Copilot, and the paid AI coding market</b></h2><p>Goose enters a crowded market of AI coding tools, but occupies a distinctive position.</p><p><a href=\"https://cursor.com/\">Cursor</a>, a popular AI-enhanced code editor, charges $20 per month for its <a href=\"https://cursor.com/pricing\">Pro tier</a> and $200 for <a href=\"https://cursor.com/pricing\">Ultra</a>—pricing that mirrors <a href=\"https://claude.com/pricing\">Claude Code&#x27;s Max plans</a>. Cursor provides approximately 4,500 Sonnet 4 requests per month at the Ultra level, a substantially different allocation model than Claude Code&#x27;s hourly resets.</p><p><a href=\"https://cline.bot/\">Cline</a>, <a href=\"https://roocode.com/\">Roo Code</a>, and similar open-source projects offer AI coding assistance but with varying levels of autonomy and tool integration. Many focus on code completion rather than the agentic task execution that defines Goose and Claude Code.</p><p>Amazon&#x27;s <a href=\"https://aws.amazon.com/blogs/aws/now-in-preview-amazon-codewhisperer-ml-powered-coding-companion/\">CodeWhisperer</a>, <a href=\"https://github.com/features/copilot\">GitHub Copilot</a>, and enterprise offerings from major cloud providers target large organizations with complex procurement processes and dedicated budgets. They are less relevant to individual developers and small teams seeking lightweight, flexible tools.</p><p>Goose&#x27;s combination of genuine autonomy, model agnosticism, local operation, and zero cost creates a unique value proposition. The tool is not trying to compete with commercial offerings on polish or model quality. It&#x27;s competing on freedom — both financial and architectural.</p><h2><b>The $200-a-month era for AI coding tools may be ending</b></h2><p>The AI coding tools market is evolving quickly. Open-source models are improving at a pace that continually narrows the gap with proprietary alternatives. Moonshot AI&#x27;s <a href=\"https://www.kimi.com/en\">Kimi K2</a> and z.ai&#x27;s <a href=\"https://z.ai/blog/glm-4.5\">GLM 4.5</a> now benchmark near <a href=\"https://www.anthropic.com/news/claude-4\">Claude Sonnet 4 levels</a> — and they&#x27;re freely available.</p><p>If this trajectory continues, the quality advantage that justifies Claude Code&#x27;s premium pricing may erode. Anthropic would then face pressure to compete on features, user experience, and integration rather than raw model capability.</p><p>For now, developers face a clear choice. Those who need the absolute best model quality, who can afford premium pricing, and who accept usage restrictions may prefer <a href=\"https://claude.com/product/claude-code\">Claude Code</a>. Those who prioritize cost, privacy, offline access, and flexibility have a genuine alternative in <a href=\"https://block.github.io/goose/\">Goose</a>.</p><p>The fact that a $200-per-month commercial product has a zero-dollar open-source competitor with comparable core functionality is itself remarkable. It reflects both the maturation of open-source AI infrastructure and the appetite among developers for tools that respect their autonomy.</p><p>Goose is not perfect. It requires more technical setup than commercial alternatives. It depends on hardware resources that not every developer possesses. Its model options, while improving rapidly, still trail the best proprietary offerings on complex tasks.</p><p>But for a growing community of developers, those limitations are acceptable trade-offs for something increasingly rare in the AI landscape: a tool that truly belongs to them.</p><hr/><p><i>Goose is available for download at </i><a href=\"http://github.com/block/goose\"><i>github.com/block/goose</i></a><i>. Ollama is available at </i><a href=\"http://ollama.com\"><i>ollama.com</i></a><i>. Both projects are free and open source.</i></p>",
        "contentSnippet": "The artificial intelligence coding revolution comes with a catch: it's expensive.\nClaude Code, Anthropic's terminal-based AI agent that can write, debug, and deploy code autonomously, has captured the imagination of software developers worldwide. But its pricing — ranging from $20 to $200 per month depending on usage — has sparked a growing rebellion among the very programmers it aims to serve.\nNow, a free alternative is gaining traction. Goose, an open-source AI agent developed by Block (the financial technology company formerly known as Square), offers nearly identical functionality to Claude Code but runs entirely on a user's local machine. No subscription fees. No cloud dependency. No rate limits that reset every five hours.\n\"Your data stays with you, period,\" said Parth Sareen, a software engineer who demonstrated the tool during a recent livestream. The comment captures the core appeal: Goose gives developers complete control over their AI-powered workflow, including the ability to work offline — even on an airplane.\nThe project has exploded in popularity. Goose now boasts more than 26,100 stars on GitHub, the code-sharing platform, with 362 contributors and 102 releases since its launch. The latest version, 1.20.1, shipped on January 19, 2026, reflecting a development pace that rivals commercial products.\nFor developers frustrated by Claude Code's pricing structure and usage caps, Goose represents something increasingly rare in the AI industry: a genuinely free, no-strings-attached option for serious work.\n\nAnthropic's new rate limits spark a developer revolt\nTo understand why Goose matters, you need to understand the Claude Code pricing controversy.\nAnthropic, the San Francisco artificial intelligence company founded by former OpenAI executives, offers Claude Code as part of its subscription tiers. The free plan provides no access whatsoever. The Pro plan, at $17 per month with annual billing (or $20 monthly), limits users to just 10 to 40 prompts every five hours — a constraint that serious developers exhaust within minutes of intensive work.\nThe Max plans, at $100 and $200 per month, offer more headroom: 50 to 200 prompts and 200 to 800 prompts respectively, plus access to Anthropic's most powerful model, Claude 4.5 Opus. But even these premium tiers come with restrictions that have inflamed the developer community.\nIn late July, Anthropic announced new weekly rate limits. Under the system, Pro users receive 40 to 80 hours of Sonnet 4 usage per week. Max users at the $200 tier get 240 to 480 hours of Sonnet 4, plus 24 to 40 hours of Opus 4. Nearly five months later, the frustration has not subsided.\nThe problem? Those \"hours\" are not actual hours. They represent token-based limits that vary wildly depending on codebase size, conversation length, and the complexity of the code being processed. Independent analysis suggests the actual per-session limits translate to roughly 44,000 tokens for Pro users and 220,000 tokens for the $200 Max plan.\n\"It's confusing and vague,\" one developer wrote in a widely shared analysis. \"When they say '24-40 hours of Opus 4,' that doesn't really tell you anything useful about what you're actually getting.\"\nThe backlash on Reddit and developer forums has been fierce. Some users report hitting their daily limits within 30 minutes of intensive coding. Others have canceled their subscriptions entirely, calling the new restrictions \"a joke\" and \"unusable for real work.\"\nAnthropic has defended the changes, stating that the limits affect fewer than five percent of users and target people running Claude Code \"continuously in the background, 24/7.\" But the company has not clarified whether that figure refers to five percent of Max subscribers or five percent of all users — a distinction that matters enormously.\nHow Block built a free AI coding agent that works offline\nGoose takes a radically different approach to the same problem.\nBuilt by Block, the payments company led by Jack Dorsey, Goose is what engineers call an \"on-machine AI agent.\" Unlike Claude Code, which sends your queries to Anthropic's servers for processing, Goose can run entirely on your local computer using open-source language models that you download and control yourself.\nThe project's documentation describes it as going \"beyond code suggestions\" to \"install, execute, edit, and test with any LLM.\" That last phrase — \"any LLM\" — is the key differentiator. Goose is model-agnostic by design.\nYou can connect Goose to Anthropic's Claude models if you have API access. You can use OpenAI's GPT-5 or Google's Gemini. You can route it through services like Groq or OpenRouter. Or — and this is where things get interesting — you can run it entirely locally using tools like Ollama, which let you download and execute open-source models on your own hardware.\nThe practical implications are significant. With a local setup, there are no subscription fees, no usage caps, no rate limits, and no concerns about your code being sent to external servers. Your conversations with the AI never leave your machine.\n\"I use Ollama all the time on planes — it's a lot of fun!\" Sareen noted during a demonstration, highlighting how local models free developers from the constraints of internet connectivity.\nWhat Goose can do that traditional code assistants can't\nGoose operates as a command-line tool or desktop application that can autonomously perform complex development tasks. It can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows across multiple files, and interact with external APIs — all without constant human oversight.\nThe architecture relies on what the AI industry calls \"tool calling\" or \"function calling\" — the ability for a language model to request specific actions from external systems. When you ask Goose to create a new file, run a test suite, or check the status of a GitHub pull request, it doesn't just generate text describing what should happen. It actually executes those operations.\nThis capability depends heavily on the underlying language model. Claude 4 models from Anthropic currently perform best at tool calling, according to the Berkeley Function-Calling Leaderboard, which ranks models on their ability to translate natural language requests into executable code and system commands.\nBut newer open-source models are catching up quickly. Goose's documentation highlights several options with strong tool-calling support: Meta's Llama series, Alibaba's Qwen models, Google's Gemma variants, and DeepSeek's reasoning-focused architectures.\nThe tool also integrates with the Model Context Protocol, or MCP, an emerging standard for connecting AI agents to external services. Through MCP, Goose can access databases, search engines, file systems, and third-party APIs — extending its capabilities far beyond what the base language model provides.\nSetting Up Goose with a Local Model\nFor developers interested in a completely free, privacy-preserving setup, the process involves three main components: Goose itself, Ollama (a tool for running open-source models locally), and a compatible language model.\nStep 1: Install Ollama\nOllama is an open-source project that dramatically simplifies the process of running large language models on personal hardware. It handles the complex work of downloading, optimizing, and serving models through a simple interface.\nDownload and install Ollama from ollama.com. Once installed, you can pull models with a single command. For coding tasks, Qwen 2.5 offers strong tool-calling support:\nollama run qwen2.5\nThe model downloads automatically and begins running on your machine.\nStep 2: Install Goose\nGoose is available as both a desktop application and a command-line interface. The desktop version provides a more visual experience, while the CLI appeals to developers who prefer working entirely in the terminal.\nInstallation instructions vary by operating system but generally involve downloading from Goose's GitHub releases page or using a package manager. Block provides pre-built binaries for macOS (both Intel and Apple Silicon), Windows, and Linux.\nStep 3: Configure the Connection\nIn Goose Desktop, navigate to Settings, then Configure Provider, and select Ollama. Confirm that the API Host is set to http://localhost:11434 (Ollama's default port) and click Submit.\nFor the command-line version, run goose configure, select \"Configure Providers,\" choose Ollama, and enter the model name when prompted.\nThat's it. Goose is now connected to a language model running entirely on your hardware, ready to execute complex coding tasks without any subscription fees or external dependencies.\nThe RAM, processing power, and trade-offs you should know about\nThe obvious question: what kind of computer do you need?\nRunning large language models locally requires substantially more computational resources than typical software. The key constraint is memory — specifically, RAM on most systems, or VRAM if using a dedicated graphics card for acceleration.\nBlock's documentation suggests that 32 gigabytes of RAM provides \"a solid baseline for larger models and outputs.\" For Mac users, this means the computer's unified memory is the primary bottleneck. For Windows and Linux users with discrete NVIDIA graphics cards, GPU memory (VRAM) matters more for acceleration.\nBut you don't necessarily need expensive hardware to get started. Smaller models with fewer parameters run on much more modest systems. Qwen 2.5, for instance, comes in multiple sizes, and the smaller variants can operate effectively on machines with 16 gigabytes of RAM.\n\"You don't need to run the largest models to get excellent results,\" Sareen emphasized. The practical recommendation: start with a smaller model to test your workflow, then scale up as needed.\nFor context, Apple's entry-level MacBook Air with 8 gigabytes of RAM would struggle with most capable coding models. But a MacBook Pro with 32 gigabytes — increasingly common among professional developers — handles them comfortably.\nWhy keeping your code off the cloud matters more than ever\nGoose with a local LLM is not a perfect substitute for Claude Code. The comparison involves real trade-offs that developers should understand.\nModel Quality: Claude 4.5 Opus, Anthropic's flagship model, remains arguably the most capable AI for software engineering tasks. It excels at understanding complex codebases, following nuanced instructions, and producing high-quality code on the first attempt. Open-source models have improved dramatically, but a gap persists — particularly for the most challenging tasks.\nOne developer who switched to the $200 Claude Code plan described the difference bluntly: \"When I say 'make this look modern,' Opus knows what I mean. Other models give me Bootstrap circa 2015.\"\nContext Window: Claude Sonnet 4.5, accessible through the API, offers a massive one-million-token context window — enough to load entire large codebases without chunking or context management issues. Most local models are limited to 4,096 or 8,192 tokens by default, though many can be configured for longer contexts at the cost of increased memory usage and slower processing.\nSpeed: Cloud-based services like Claude Code run on dedicated server hardware optimized for AI inference. Local models, running on consumer laptops, typically process requests more slowly. The difference matters for iterative workflows where you're making rapid changes and waiting for AI feedback.\nTooling Maturity: Claude Code benefits from Anthropic's dedicated engineering resources. Features like prompt caching (which can reduce costs by up to 90 percent for repeated contexts) and structured outputs are polished and well-documented. Goose, while actively developed with 102 releases to date, relies on community contributions and may lack equivalent refinement in specific areas.\nHow Goose stacks up against Cursor, GitHub Copilot, and the paid AI coding market\nGoose enters a crowded market of AI coding tools, but occupies a distinctive position.\nCursor, a popular AI-enhanced code editor, charges $20 per month for its Pro tier and $200 for Ultra—pricing that mirrors Claude Code's Max plans. Cursor provides approximately 4,500 Sonnet 4 requests per month at the Ultra level, a substantially different allocation model than Claude Code's hourly resets.\nCline, Roo Code, and similar open-source projects offer AI coding assistance but with varying levels of autonomy and tool integration. Many focus on code completion rather than the agentic task execution that defines Goose and Claude Code.\nAmazon's CodeWhisperer, GitHub Copilot, and enterprise offerings from major cloud providers target large organizations with complex procurement processes and dedicated budgets. They are less relevant to individual developers and small teams seeking lightweight, flexible tools.\nGoose's combination of genuine autonomy, model agnosticism, local operation, and zero cost creates a unique value proposition. The tool is not trying to compete with commercial offerings on polish or model quality. It's competing on freedom — both financial and architectural.\nThe $200-a-month era for AI coding tools may be ending\nThe AI coding tools market is evolving quickly. Open-source models are improving at a pace that continually narrows the gap with proprietary alternatives. Moonshot AI's Kimi K2 and z.ai's GLM 4.5 now benchmark near Claude Sonnet 4 levels — and they're freely available.\nIf this trajectory continues, the quality advantage that justifies Claude Code's premium pricing may erode. Anthropic would then face pressure to compete on features, user experience, and integration rather than raw model capability.\nFor now, developers face a clear choice. Those who need the absolute best model quality, who can afford premium pricing, and who accept usage restrictions may prefer Claude Code. Those who prioritize cost, privacy, offline access, and flexibility have a genuine alternative in Goose.\nThe fact that a $200-per-month commercial product has a zero-dollar open-source competitor with comparable core functionality is itself remarkable. It reflects both the maturation of open-source AI infrastructure and the appetite among developers for tools that respect their autonomy.\nGoose is not perfect. It requires more technical setup than commercial alternatives. It depends on hardware resources that not every developer possesses. Its model options, while improving rapidly, still trail the best proprietary offerings on complex tasks.\nBut for a growing community of developers, those limitations are acceptable trade-offs for something increasingly rare in the AI landscape: a tool that truly belongs to them.\n\nGoose is available for download at github.com/block/goose. Ollama is available at ollama.com. Both projects are free and open source.",
        "pubDate": "Mon, 19 Jan 2026 14:00:00 GMT",
        "isoDate": "2026-01-19T14:00:00.000Z",
        "creator": "michael.nunez@venturebeat.com (Michael Nuñez)",
        "source": "https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free"
      },
      {
        "id": "rss-venturebeat-ai-finance-capital-8-2stlo5",
        "title": "Listen Labs raises $69M after viral billboard hiring stunt to scale AI customer interviews",
        "link": "https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai",
        "url": "https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai",
        "content": "<p>Alfred Wahlforss was running out of options. His startup, <a href=\"https://listenlabs.ai/\">Listen Labs</a>, needed to hire over 100 engineers, but competing against Mark Zuckerberg&#x27;s <a href=\"https://news.bloomberglaw.com/employee-benefits/zuckerbergs-100-million-ai-job-offers-pay-off-parmy-olson\">$100 million offers</a> seemed impossible. So he spent $5,000 — a fifth of his marketing budget — on a <a href=\"https://billboardinsider.com/ai-startup/\">billboard in San Francisco</a> displaying what looked like gibberish: five strings of random numbers.</p><p>The numbers were actually AI tokens. Decoded, they led to a coding challenge: build an algorithm to act as a digital bouncer at Berghain, the Berlin nightclub famous for rejecting nearly everyone at the door. Within days, thousands attempted the puzzle. 430 cracked it. Some got hired. The winner flew to Berlin, all expenses paid.</p><p>That unconventional approach has now attracted $69 million in Series B funding, led by <a href=\"https://www.ribbitcap.com/\">Ribbit Capital</a> with participation from <a href=\"https://www.evantic.ai/\">Evantic</a> and existing investors <a href=\"https://sequoiacap.com/\">Sequoia Capital</a>, <a href=\"https://www.conviction.com/\">Conviction</a>, and <a href=\"https://pear.vc/\">Pear VC</a>. The round values Listen Labs at $500 million and brings its total capital to $100 million. In nine months since launch, the company has grown annualized revenue by 15x to eight figures and conducted over one million AI-powered interviews.</p><div></div><p>&quot;When you obsess over customers, everything else follows,&quot; Wahlforss said in an interview with VentureBeat. &quot;Teams that use Listen bring the customer into every decision, from marketing to product, and when the customer is delighted, everyone is.&quot;</p><h2><b>Why traditional market research is broken, and what Listen Labs is building to fix it</b></h2><p>Listen&#x27;s <a href=\"https://listenlabs.ai/role/agencies\">AI researcher</a> finds participants, conducts in-depth interviews, and delivers actionable insights in hours, not weeks. The platform replaces the traditional choice between quantitative surveys — which provide statistical precision but miss nuance—and qualitative interviews, which deliver depth but cannot scale.</p><p>Wahlforss explained the limitation of existing approaches: &quot;Essentially surveys give you false precision because people end up answering the same question... You can&#x27;t get the outliers. People are actually not honest on surveys.&quot; The alternative, one-on-one human interviews, &quot;gives you a lot of depth. You can ask follow up questions. You can kind of double check if they actually know what they&#x27;re talking about. And the problem is you can&#x27;t scale that.&quot;</p><p>The platform works in four steps: users create a study with AI assistance, Listen recruits participants from its global network of 30 million people, an AI moderator conducts in-depth interviews with follow-up questions, and results are packaged into executive-ready reports including key themes, highlight reels, and slide decks.</p><p>What distinguishes Listen&#x27;s approach is its use of open-ended video conversations rather than multiple-choice forms. &quot;In a survey, you can kind of guess what you should answer, and you have four options,&quot; Wahlforss said. &quot;Oh, they probably want me to buy high income. Let me click on that button versus an open ended response. It just generates much more honesty.&quot;</p><h2><b>The dirty secret of the $140 billion market research industry: rampant fraud</b></h2><p><a href=\"https://listenlabs.ai/\">Listen</a> finds and qualifies the right participants in its global network of 30 million people. But building that panel required confronting what Wahlforss called &quot;one of the most shocking things that we&#x27;ve learned when we entered this industry&quot;—rampant fraud.</p><p>&quot;Essentially, there&#x27;s a financial transaction involved, which means there will be bad players,&quot; he explained. &quot;We actually had some of the largest companies, some of them have billions in revenue, send us people who claim to be kind of enterprise buyers to our platform and our system immediately detected, like, fraud, fraud, fraud, fraud, fraud.&quot;</p><p>The company built what it calls a &quot;quality guard&quot; that cross-references LinkedIn profiles with video responses to verify identity, checks consistency across how participants answer questions, and flags suspicious patterns. The result, according to Wahlforss: &quot;People talk three times more. They&#x27;re much more honest when they talk about sensitive topics like politics and mental health.&quot;</p><p><a href=\"https://listenlabs.ai/case-studies/emeritus\">Emeritus</a>, an online education company that uses Listen, reported that approximately 20% of survey responses previously fell into the fraudulent or low-quality category. With Listen, they reduced this to almost zero. &quot;We did not have to replace any responses because of fraud or gibberish information,&quot; said Gabrielli Tiburi, Assistant Manager of Customer Insights at Emeritus.</p><h2><b>How Microsoft, Sweetgreen, and Chubbies are using AI interviews to build better products</b></h2><p>The speed advantage has proven central to Listen&#x27;s pitch. Traditional customer research at <a href=\"https://listenlabs.ai/case-studies/microsoft\">Microsoft</a> could take four to six weeks to generate insights. &quot;By the time we get to them, either the decision has been made or we lose out on the opportunity to actually influence it,&quot; said Romani Patel, Senior Research Manager at Microsoft.</p><p>With Listen, Microsoft can now get insights in days, and in many cases, within hours.</p><p>The platform has already powered several high-profile initiatives. Microsoft used Listen Labs to collect global customer stories for its 50th anniversary celebration. &quot;We wanted users to share how Copilot is empowering them to bring their best self forward,&quot; Patel said, &quot;and we were able to collect those user video stories within a day.&quot; Traditionally, that kind of work would have taken six to eight weeks.</p><p><a href=\"https://listenlabs.ai/case-studies/simple-modern\">Simple Modern</a>, an Oklahoma-based drinkware company, used Listen to test a new product concept. The process took about an hour to write questions, an hour to launch the study, and 2.5 hours to receive feedback from 120 people across the country. &quot;We went from &#x27;Should we even have this product?&#x27; to &#x27;How should we launch it?&#x27;&quot; said Chris Hoyle, the company&#x27;s Chief Marketing Officer.</p><p><a href=\"https://listenlabs.ai/case-studies/chubbies\">Chubbies</a>, the shorts brand, achieved a 24x increase in youth research participation—growing from 5 to 120 participants — by using Listen to overcome the scheduling challenges of traditional focus groups with children. &quot;There&#x27;s school, sports, dinner, and homework,&quot; explained Lauren Neville, Director of Insights and Innovation. &quot;I had to find a way to hear from them that fit into their schedules.&quot;</p><p>The company also discovered product issues through AI interviews that might have gone undetected otherwise. Wahlforss described how the AI &quot;through conversations, realized there were like issues with the the kids short line, and decided to, like, interview hundreds of kids. And I understand that there were issues in the liner of the shorts and that they were, like, scratchy, quote, unquote, according to the people interviewed.&quot; The redesigned product became &quot;a blockbuster hit.&quot;</p><h2><b>The Jevons paradox explains why cheaper research creates more demand, not less</b></h2><p><a href=\"https://listenlabs.ai/\">Listen Labs</a> is entering a massive but fragmented market. Wahlforss cited research from Andreessen Horowitz estimating the market research industry at roughly <a href=\"https://a16z.com/ai-market-research/\">$140 billion annually</a>, populated by legacy players — some with more than a billion dollars in revenue — that he believes are vulnerable to disruption.</p><p>&quot;There are very much existing budget lines that we are replacing,&quot; Wahlforss said. &quot;Why we&#x27;re replacing them is that one, they&#x27;re super costly. Two, they&#x27;re kind of stuck in this old paradigm of choosing between a survey or interview, and they also take months to work with.&quot;</p><p>But the more intriguing dynamic may be that AI-powered research doesn&#x27;t just replace existing spending — it creates new demand. Wahlforss invoked the Jevons paradox, an economic principle that occurs when technological advancements make a resource more efficient to use, but increased efficiency leads to increased overall consumption rather than decreased consumption.</p><p>&quot;What I&#x27;ve noticed is that as something gets cheaper, you don&#x27;t need less of it. You want more of it,&quot; Wahlforss explained. &quot;There&#x27;s infinite demand for customer understanding. So the researchers on the team can do an order of magnitude more research, and also other people who weren&#x27;t researchers before can now do that as part of their job.&quot;</p><h2><b>Inside the elite engineering team that built Listen Labs before they had a working toilet</b></h2><p><a href=\"https://listenlabs.ai/\">Listen Labs</a> traces its origins to a consumer app that Wahlforss and his co-founder built after meeting at Harvard. &quot;We built this consumer app that got 20,000 downloads in one day,&quot; Wahlforss recalled. &quot;We had all these users, and we were thinking like, okay, what can we do to get to know them better? And we built this prototype of what Listen is today.&quot;</p><p>The founding team brings an unusual pedigree. Wahlforss&#x27;s co-founder &quot;was the national champion in competitive programming in Germany, and he worked at Tesla Autopilot.&quot; The company claims that 30% of its engineering team are medalists from the <a href=\"https://ioinformatics.org/\">International Olympiad in Informatics</a> — the same competition that produced the founders of <a href=\"https://cognition.ai/\">Cognition</a>, the AI coding startup.</p><p>The <a href=\"https://www.cbsnews.com/sanfrancisco/news/san-francisco-billboard-challenge-puts-ai-engineers-to-the-test/\">Berghain billboard stunt</a> generated approximately 5 million views across social media, according to Wahlforss. It reflected the intensity of the talent war in the Bay Area.</p><p>&quot;We had to do these things because some of our, like early employees, joined the company before we had a working toilet,&quot; he said. &quot;But now we fixed that situation.&quot;</p><p>The company grew from 5 to 40 employees in 2024 and plans to reach 150 this year. It hires engineers for non-engineering roles across marketing, growth, and operations — a bet that in the AI era, technical fluency matters everywhere.</p><h2><b>Synthetic customers and automated decisions: what Listen Labs is building next</b></h2><p>Wahlforss outlined an ambitious product roadmap that pushes into more speculative territory. The company is building &quot;the ability to simulate your customers, so you can take all of those interviews we&#x27;ve done, and then extrapolate based on that and create synthetic users or simulated user voices.&quot;</p><p>Beyond simulation, Listen aims to enable automated action based on research findings. &quot;Can you not just make recommendations, but also create spawn agents to either change things in code or some customer churns? Can you give them a discount and try to bring them back?&quot;</p><p>Wahlforss acknowledged the ethical implications. &quot;Obviously, as you said, there&#x27;s kind of ethical concerns there. Of like, automated decision making overall can be bad, but we will have considerable guardrails to make sure that the companies are always in the loop.&quot;</p><p>The company already handles sensitive data with care. &quot;We don&#x27;t train on any of the data,&quot; Wahlforss said. &quot;We will also scrub any sensitive PII automatically so the model can detect that. And there are times when, for example, you work with investors, where if you accidentally mention something that could be material, non public information, the AI can actually detect that and remove any information like that.&quot;</p><h2><b>How AI could reshape the future of product development</b></h2><p>Perhaps the most provocative implication of Listen&#x27;s model is how it could reshape product development itself. Wahlforss described a customer — an Australian startup — that has adopted what amounts to a continuous feedback loop.</p><p>&quot;They&#x27;re based in Australia, so they&#x27;re coding during the day, and then in their night, they&#x27;re releasing a Listen study with an American audience. Listen validates whatever they built during the day, and they get feedback on that. They can then plug that feedback directly into coding tools like Claude Code and iterate.&quot;</p><p>The vision extends Y Combinator&#x27;s famous dictum — &quot;<a href=\"https://www.ycombinator.com/library/4D-yc-s-essential-startup-advice\">write code, talk to users</a>&quot; — into an automated cycle. &quot;Write code is now getting automated. And I think like talk to users will be as well, and you&#x27;ll have this kind of infinite loop where you can start to ship this truly amazing product, almost kind of autonomously.&quot;</p><p>Whether that vision materializes depends on factors beyond Listen&#x27;s control — the continued improvement of AI models, enterprise willingness to trust automated research, and whether speed truly correlates with better products. A <a href=\"https://mlq.ai/media/quarterly_decks/v0.1_State_of_AI_in_Business_2025_Report.pdf\">2024 MIT study</a> found that 95% of AI pilots fail to move into production, a statistic Wahlforss cited as the reason he emphasizes quality over demos.</p><p>&quot;I&#x27;m constantly have to emphasize like, let&#x27;s make sure the quality is there and the details are right,&quot; he said.</p><p>But the company&#x27;s growth suggests appetite for the experiment. Microsoft&#x27;s Patel said Listen has &quot;removed the drudgery of research and brought the fun and joy back into my work.&quot; Chubbies is now pushing its founder to give everyone in the company a login. Sling Money, a stablecoin payments startup, can create a survey in ten minutes and receive results the same day.</p><p>&quot;It&#x27;s a total game changer,&quot; said Ali Romero, Sling Money&#x27;s marketing manager.</p><p>Wahlforss has a different phrase for what he&#x27;s building. When asked about the tension between speed and rigor — the long-held belief that moving fast means cutting corners — he cited Nat Friedman, the former GitHub CEO and Listen investor, who keeps a list of one-liners on his website.</p><p>One of them: &quot;Slow is fake.&quot;</p><p>It&#x27;s an aggressive claim for an industry built on methodological caution. But <a href=\"https://listenlabs.ai/\">Listen Labs</a> is betting that in the AI era, the companies that listen fastest will be the ones that win. The only question is whether customers will talk back.</p>",
        "contentSnippet": "Alfred Wahlforss was running out of options. His startup, Listen Labs, needed to hire over 100 engineers, but competing against Mark Zuckerberg's $100 million offers seemed impossible. So he spent $5,000 — a fifth of his marketing budget — on a billboard in San Francisco displaying what looked like gibberish: five strings of random numbers.\nThe numbers were actually AI tokens. Decoded, they led to a coding challenge: build an algorithm to act as a digital bouncer at Berghain, the Berlin nightclub famous for rejecting nearly everyone at the door. Within days, thousands attempted the puzzle. 430 cracked it. Some got hired. The winner flew to Berlin, all expenses paid.\nThat unconventional approach has now attracted $69 million in Series B funding, led by Ribbit Capital with participation from Evantic and existing investors Sequoia Capital, Conviction, and Pear VC. The round values Listen Labs at $500 million and brings its total capital to $100 million. In nine months since launch, the company has grown annualized revenue by 15x to eight figures and conducted over one million AI-powered interviews.\n\n\"When you obsess over customers, everything else follows,\" Wahlforss said in an interview with VentureBeat. \"Teams that use Listen bring the customer into every decision, from marketing to product, and when the customer is delighted, everyone is.\"\nWhy traditional market research is broken, and what Listen Labs is building to fix it\nListen's AI researcher finds participants, conducts in-depth interviews, and delivers actionable insights in hours, not weeks. The platform replaces the traditional choice between quantitative surveys — which provide statistical precision but miss nuance—and qualitative interviews, which deliver depth but cannot scale.\nWahlforss explained the limitation of existing approaches: \"Essentially surveys give you false precision because people end up answering the same question... You can't get the outliers. People are actually not honest on surveys.\" The alternative, one-on-one human interviews, \"gives you a lot of depth. You can ask follow up questions. You can kind of double check if they actually know what they're talking about. And the problem is you can't scale that.\"\nThe platform works in four steps: users create a study with AI assistance, Listen recruits participants from its global network of 30 million people, an AI moderator conducts in-depth interviews with follow-up questions, and results are packaged into executive-ready reports including key themes, highlight reels, and slide decks.\nWhat distinguishes Listen's approach is its use of open-ended video conversations rather than multiple-choice forms. \"In a survey, you can kind of guess what you should answer, and you have four options,\" Wahlforss said. \"Oh, they probably want me to buy high income. Let me click on that button versus an open ended response. It just generates much more honesty.\"\nThe dirty secret of the $140 billion market research industry: rampant fraud\nListen finds and qualifies the right participants in its global network of 30 million people. But building that panel required confronting what Wahlforss called \"one of the most shocking things that we've learned when we entered this industry\"—rampant fraud.\n\"Essentially, there's a financial transaction involved, which means there will be bad players,\" he explained. \"We actually had some of the largest companies, some of them have billions in revenue, send us people who claim to be kind of enterprise buyers to our platform and our system immediately detected, like, fraud, fraud, fraud, fraud, fraud.\"\nThe company built what it calls a \"quality guard\" that cross-references LinkedIn profiles with video responses to verify identity, checks consistency across how participants answer questions, and flags suspicious patterns. The result, according to Wahlforss: \"People talk three times more. They're much more honest when they talk about sensitive topics like politics and mental health.\"\nEmeritus, an online education company that uses Listen, reported that approximately 20% of survey responses previously fell into the fraudulent or low-quality category. With Listen, they reduced this to almost zero. \"We did not have to replace any responses because of fraud or gibberish information,\" said Gabrielli Tiburi, Assistant Manager of Customer Insights at Emeritus.\nHow Microsoft, Sweetgreen, and Chubbies are using AI interviews to build better products\nThe speed advantage has proven central to Listen's pitch. Traditional customer research at Microsoft could take four to six weeks to generate insights. \"By the time we get to them, either the decision has been made or we lose out on the opportunity to actually influence it,\" said Romani Patel, Senior Research Manager at Microsoft.\nWith Listen, Microsoft can now get insights in days, and in many cases, within hours.\nThe platform has already powered several high-profile initiatives. Microsoft used Listen Labs to collect global customer stories for its 50th anniversary celebration. \"We wanted users to share how Copilot is empowering them to bring their best self forward,\" Patel said, \"and we were able to collect those user video stories within a day.\" Traditionally, that kind of work would have taken six to eight weeks.\nSimple Modern, an Oklahoma-based drinkware company, used Listen to test a new product concept. The process took about an hour to write questions, an hour to launch the study, and 2.5 hours to receive feedback from 120 people across the country. \"We went from 'Should we even have this product?' to 'How should we launch it?'\" said Chris Hoyle, the company's Chief Marketing Officer.\nChubbies, the shorts brand, achieved a 24x increase in youth research participation—growing from 5 to 120 participants — by using Listen to overcome the scheduling challenges of traditional focus groups with children. \"There's school, sports, dinner, and homework,\" explained Lauren Neville, Director of Insights and Innovation. \"I had to find a way to hear from them that fit into their schedules.\"\nThe company also discovered product issues through AI interviews that might have gone undetected otherwise. Wahlforss described how the AI \"through conversations, realized there were like issues with the the kids short line, and decided to, like, interview hundreds of kids. And I understand that there were issues in the liner of the shorts and that they were, like, scratchy, quote, unquote, according to the people interviewed.\" The redesigned product became \"a blockbuster hit.\"\nThe Jevons paradox explains why cheaper research creates more demand, not less\nListen Labs is entering a massive but fragmented market. Wahlforss cited research from Andreessen Horowitz estimating the market research industry at roughly $140 billion annually, populated by legacy players — some with more than a billion dollars in revenue — that he believes are vulnerable to disruption.\n\"There are very much existing budget lines that we are replacing,\" Wahlforss said. \"Why we're replacing them is that one, they're super costly. Two, they're kind of stuck in this old paradigm of choosing between a survey or interview, and they also take months to work with.\"\nBut the more intriguing dynamic may be that AI-powered research doesn't just replace existing spending — it creates new demand. Wahlforss invoked the Jevons paradox, an economic principle that occurs when technological advancements make a resource more efficient to use, but increased efficiency leads to increased overall consumption rather than decreased consumption.\n\"What I've noticed is that as something gets cheaper, you don't need less of it. You want more of it,\" Wahlforss explained. \"There's infinite demand for customer understanding. So the researchers on the team can do an order of magnitude more research, and also other people who weren't researchers before can now do that as part of their job.\"\nInside the elite engineering team that built Listen Labs before they had a working toilet\nListen Labs traces its origins to a consumer app that Wahlforss and his co-founder built after meeting at Harvard. \"We built this consumer app that got 20,000 downloads in one day,\" Wahlforss recalled. \"We had all these users, and we were thinking like, okay, what can we do to get to know them better? And we built this prototype of what Listen is today.\"\nThe founding team brings an unusual pedigree. Wahlforss's co-founder \"was the national champion in competitive programming in Germany, and he worked at Tesla Autopilot.\" The company claims that 30% of its engineering team are medalists from the International Olympiad in Informatics — the same competition that produced the founders of Cognition, the AI coding startup.\nThe Berghain billboard stunt generated approximately 5 million views across social media, according to Wahlforss. It reflected the intensity of the talent war in the Bay Area.\n\"We had to do these things because some of our, like early employees, joined the company before we had a working toilet,\" he said. \"But now we fixed that situation.\"\nThe company grew from 5 to 40 employees in 2024 and plans to reach 150 this year. It hires engineers for non-engineering roles across marketing, growth, and operations — a bet that in the AI era, technical fluency matters everywhere.\nSynthetic customers and automated decisions: what Listen Labs is building next\nWahlforss outlined an ambitious product roadmap that pushes into more speculative territory. The company is building \"the ability to simulate your customers, so you can take all of those interviews we've done, and then extrapolate based on that and create synthetic users or simulated user voices.\"\nBeyond simulation, Listen aims to enable automated action based on research findings. \"Can you not just make recommendations, but also create spawn agents to either change things in code or some customer churns? Can you give them a discount and try to bring them back?\"\nWahlforss acknowledged the ethical implications. \"Obviously, as you said, there's kind of ethical concerns there. Of like, automated decision making overall can be bad, but we will have considerable guardrails to make sure that the companies are always in the loop.\"\nThe company already handles sensitive data with care. \"We don't train on any of the data,\" Wahlforss said. \"We will also scrub any sensitive PII automatically so the model can detect that. And there are times when, for example, you work with investors, where if you accidentally mention something that could be material, non public information, the AI can actually detect that and remove any information like that.\"\nHow AI could reshape the future of product development\nPerhaps the most provocative implication of Listen's model is how it could reshape product development itself. Wahlforss described a customer — an Australian startup — that has adopted what amounts to a continuous feedback loop.\n\"They're based in Australia, so they're coding during the day, and then in their night, they're releasing a Listen study with an American audience. Listen validates whatever they built during the day, and they get feedback on that. They can then plug that feedback directly into coding tools like Claude Code and iterate.\"\nThe vision extends Y Combinator's famous dictum — \"write code, talk to users\" — into an automated cycle. \"Write code is now getting automated. And I think like talk to users will be as well, and you'll have this kind of infinite loop where you can start to ship this truly amazing product, almost kind of autonomously.\"\nWhether that vision materializes depends on factors beyond Listen's control — the continued improvement of AI models, enterprise willingness to trust automated research, and whether speed truly correlates with better products. A 2024 MIT study found that 95% of AI pilots fail to move into production, a statistic Wahlforss cited as the reason he emphasizes quality over demos.\n\"I'm constantly have to emphasize like, let's make sure the quality is there and the details are right,\" he said.\nBut the company's growth suggests appetite for the experiment. Microsoft's Patel said Listen has \"removed the drudgery of research and brought the fun and joy back into my work.\" Chubbies is now pushing its founder to give everyone in the company a login. Sling Money, a stablecoin payments startup, can create a survey in ten minutes and receive results the same day.\n\"It's a total game changer,\" said Ali Romero, Sling Money's marketing manager.\nWahlforss has a different phrase for what he's building. When asked about the tension between speed and rigor — the long-held belief that moving fast means cutting corners — he cited Nat Friedman, the former GitHub CEO and Listen investor, who keeps a list of one-liners on his website.\nOne of them: \"Slow is fake.\"\nIt's an aggressive claim for an industry built on methodological caution. But Listen Labs is betting that in the AI era, the companies that listen fastest will be the ones that win. The only question is whether customers will talk back.",
        "pubDate": "Fri, 16 Jan 2026 14:01:00 GMT",
        "isoDate": "2026-01-16T14:01:00.000Z",
        "creator": "michael.nunez@venturebeat.com (Michael Nuñez)",
        "source": "https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai"
      },
      {
        "id": "rss-venturebeat-ai-finance-capital-8-wkanl4",
        "title": "Salesforce rolls out new Slackbot AI agent as it battles Microsoft and Google in workplace AI",
        "link": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and",
        "url": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and",
        "content": "<p><a href=\"https://www.salesforce.com/\">Salesforce</a> on Tuesday launched an entirely rebuilt version of <a href=\"https://slack.com/help/articles/202026038-An-introduction-to-Slackbot\">Slackbot</a>, the company&#x27;s workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.</p><p>The new Slackbot, now generally available to <a href=\"https://slack.com/pricing/businessplus\">Business+</a> and <a href=\"https://slack.com/enterprise\">Enterprise+</a> customers, is Salesforce&#x27;s most aggressive move yet to position Slack at the center of the emerging &quot;agentic AI&quot; movement — where software agents work alongside humans to complete complex tasks. The launch comes as Salesforce attempts to convince investors that artificial intelligence will bolster its products rather than render them obsolete.</p><p>&quot;Slackbot isn&#x27;t just another copilot or AI assistant,&quot; said <a href=\"https://www.salesforce.com/company/parker-harris-bio/\">Parker Harris</a>, Salesforce co-founder and Slack&#x27;s chief technology officer, in an exclusive interview with Salesforce. &quot;It&#x27;s the front door to the agentic enterprise, powered by Salesforce.&quot;</p><h2><b>From tricycle to Porsche: Salesforce rebuilt Slackbot from the ground up</b></h2><p>Harris was blunt about what distinguishes the new Slackbot from its predecessor: &quot;The old Slackbot was, you know, a little tricycle, and the new Slackbot is like, you know, a Porsche.&quot;</p><p>The original Slackbot, which has existed since Slack&#x27;s early days, performed basic algorithmic tasks — reminding users to add colleagues to documents, suggesting channel archives, and delivering simple notifications. The new version runs on an entirely different architecture built around a large language model and sophisticated search capabilities that can access Salesforce records, Google Drive files, calendar data, and years of Slack conversations.</p><p>&quot;It&#x27;s two different things,&quot; Harris explained. &quot;The old Slackbot was algorithmic and fairly simple. The new Slackbot is brand new — it&#x27;s based around an LLM and a very robust search engine, and connections to third-party search engines, third-party enterprise data.&quot;</p><p>Salesforce chose to retain the Slackbot brand despite the fundamental technical overhaul. &quot;People know what Slackbot is, and so we wanted to carry that forward,&quot; Harris said.</p><h2><b>Why Anthropic&#x27;s Claude powers the new Slackbot — and which AI models could come next</b></h2><p>The new Slackbot runs on <a href=\"https://claude.ai/\">Claude</a>, Anthropic&#x27;s large language model, a choice driven partly by compliance requirements. Slack&#x27;s commercial service operates under <a href=\"https://www.fedramp.gov/archive/2017-11-16-understanding-baselines-and-impact-levels/\">FedRAMP Moderate certification</a> to serve U.S. federal government customers, and Harris said Anthropic was &quot;the only provider that could give us a compliant LLM&quot; when Slack began building the new system.</p><p>But that exclusivity won&#x27;t last. &quot;We are, this year, going to support additional providers,&quot; Harris said. &quot;We have a great relationship with Google. Gemini is incredible — performance is great, cost is great. So we&#x27;re going to use Gemini for some things.&quot; He added that OpenAI remains a possibility as well.</p><p>Harris echoed Salesforce CEO Marc Benioff&#x27;s view that large language models are becoming commoditized: &quot;You&#x27;ve heard Marc talk about LLMs are commodities, that they&#x27;re democratized. I call them CPUs.&quot;</p><p>On the sensitive question of training data, Harris was unequivocal: Salesforce does not train any models on customer data. &quot;Models don&#x27;t have any sort of security,&quot; he explained. &quot;If we trained it on some confidential conversation that you and I have, I don&#x27;t want Carolyn to know — if I train it into the LLM, there is no way for me to say you get to see the answer, but Carolyn doesn&#x27;t.&quot;</p><h2><b>Inside Salesforce&#x27;s internal experiment: 80,000 employees tested Slackbot with striking results</b></h2><p>Salesforce has been <a href=\"https://www.theverge.com/news/797890/slack-slackbot-ai-assistant-upgrade\">testing the new Slackbot internally for months</a>, rolling it out to all 80,000 employees. According to Ryan Gavin, Slack&#x27;s chief marketing officer, the results have been striking: &quot;It&#x27;s the fastest adopted product in Salesforce history.&quot;</p><p>Internal data shows that two-thirds of Salesforce employees have tried the new Slackbot, with 80% of those users continuing to use it regularly. Internal satisfaction rates reached 96% — the highest for any AI feature Slack has shipped. Employees report saving between two and 20 hours per week.</p><p>The adoption happened largely organically. &quot;I think it was about five days, and a Canvas was developed by our employees called &#x27;The Most Stealable Slackbot Prompts,&#x27;&quot; Gavin said. &quot;People just started adding to it organically. I think it&#x27;s up to 250-plus prompts that are in this Canvas right now.&quot;</p><p>Kate Crotty, a principal UX researcher at Salesforce, found that 73% of internal adoption was driven by social sharing rather than top-down mandates. &quot;Everybody is there to help each other learn and communicate hacks,&quot; she said.</p><h2><b>How Slackbot transforms scattered enterprise data into executive-ready insights</b></h2><p>During a product demonstration, Amy Bauer, Slack&#x27;s product experience designer, showed how Slackbot can synthesize information across multiple sources. In one example, she asked Slackbot to analyze customer feedback from a pilot program, upload an image of a usage dashboard, and have Slackbot correlate the qualitative and quantitative data.</p><p>&quot;This is where Slackbot really earns its keep for me,&quot; Bauer explained. &quot;What it&#x27;s doing is not just simply reading the image — it&#x27;s actually looking at the image and comparing it to the insight it just generated for me.&quot;</p><p>Slackbot can then query Salesforce to find enterprise accounts with open deals that might be good candidates for early access, creating what Bauer called &quot;a really great justification and plan to move forward.&quot; Finally, it can synthesize all that information into a Canvas — Slack&#x27;s collaborative document format — and find calendar availability among stakeholders to schedule a review meeting.</p><p>&quot;Up until this point, we have been working in a one-to-one capacity with Slackbot,&quot; Bauer said. &quot;But one of the benefits that I can do now is take this insight and have it generate this into a Canvas, a shared workspace where I can iterate on it, refine it with Slackbot, or share it out with my team.&quot;</p><p>Rob Seaman, Slack&#x27;s chief product officer, said the Canvas creation demonstrates where the product is heading: &quot;This is making a tool call internally to Slack Canvas to actually write, effectively, a shared document. But it signals where we&#x27;re going with Slackbot — we&#x27;re eventually going to be adding in additional third-party tool calls.&quot;</p><h2><b>MrBeast&#x27;s company became a Slackbot guinea pig—and employees say they&#x27;re saving 90 minutes a day</b></h2><p>Among Salesforce&#x27;s pilot customers is <a href=\"https://www.thecashmerefund.com/portfolio-company/beast-industries\">Beast Industries</a>, the parent company of YouTube star MrBeast. Luis Madrigal, the company&#x27;s chief information officer, joined the launch announcement to describe his experience.</p><p>&quot;As somebody who has rolled out enterprise technologies for over two decades now, this was practically one of the easiest,&quot; Madrigal said. &quot;The plumbing is there. Slack as an implementation, Enterprise Tools — being able to turn on the Slackbot and the Slack AI functionality was as simple as having my team go in, review, do a quick security review.&quot;</p><p>Madrigal said his security team signed off &quot;rather quickly&quot; — unusual for enterprise AI deployments — because Slackbot accesses only the information each individual user already has permission to view. &quot;Given all the guardrails you guys have put into place for Slackbot to be unique and customized to only the information that each individual user has, only the conversations and the Slack rooms and Slack channels that they&#x27;re part of—that made my security team sign off rather quickly.&quot;</p><p>One Beast Industries employee, Sinan, the head of Beast Games marketing, reported saving &quot;at bare minimum, 90 minutes a day.&quot; Another employee, Spencer, a creative supervisor, described it as &quot;an assistant who&#x27;s paying attention when I&#x27;m not.&quot;</p><p>Other pilot customers include Slalom, reMarkable, Xero, Mercari, and Engine. Mollie Bodensteiner, SVP of Operations at Engine, called Slackbot &quot;an absolute &#x27;chaos tamer&#x27; for our team,&quot; estimating it saves her about 30 minutes daily &quot;just by eliminating context switching.&quot;</p><h2><b>Slackbot vs. Microsoft Copilot vs. Google Gemini: The fight for enterprise AI dominance</b></h2><p>The launch puts Salesforce in direct competition with <a href=\"https://copilot.microsoft.com/\">Microsoft&#x27;s Copilot</a>, which is integrated into Teams and the broader Microsoft 365 suite, as well as Google&#x27;s Gemini integrations across Workspace. When asked what distinguishes Slackbot from these alternatives, Seaman pointed to context and convenience.</p><p>&quot;The thing that makes it most powerful for our customers and users is the proximity — it&#x27;s just right there in your Slack,&quot; Seaman said. &quot;There&#x27;s a tremendous convenience affordance that&#x27;s naturally built into it.&quot;</p><p>The deeper advantage, executives argue, is that Slackbot already understands users&#x27; work without requiring setup or training. &quot;Most AI tools sound the same no matter who is using them,&quot; the company&#x27;s announcement stated. &quot;They lack context, miss nuance, and force you to jump between tools to get anything done.&quot;</p><p>Harris put it more directly: &quot;If you&#x27;ve ever had that magic experience with AI — I think ChatGPT is a great example, it&#x27;s a great experience from a consumer perspective — Slackbot is really what we&#x27;re doing in the enterprise, to be this employee super agent that is loved, just like people love using Slack.&quot;</p><p>Amy Bauer emphasized the frictionless nature of the experience. &quot;Slackbot is inherently grounded in the context, in the data that you have in Slack,&quot; she said. &quot;So as you continue working in Slack, Slackbot gets better because it&#x27;s grounded in the work that you&#x27;re doing there. There is no setup. There is no configuration for those end users.&quot;</p><h2><b>Salesforce&#x27;s ambitious plan to make Slackbot the one &#x27;super agent&#x27; that controls all the others</b></h2><p>Salesforce positions Slackbot as what Harris calls a &quot;super agent&quot; — a central hub that can eventually coordinate with other AI agents across an organization.</p><p>&quot;Every corporation is going to have an employee super agent,&quot; Harris said. &quot;Slackbot is essentially taking the magic of what Slack does. We think that Slackbot, and we&#x27;re really excited about it, is going to be that.&quot;</p><p>The vision extends to third-party agents already launching in Slack. Last month, Anthropic released a preview of Claude Code for Slack, allowing developers to interact with Claude&#x27;s coding capabilities directly in chat threads. OpenAI, Google, Vercel, and others have also built agents for the platform.</p><p>&quot;Most of the net-new apps that are being deployed to Slack are agents,&quot; Seaman noted during the press conference. &quot;This is proof of the promise of humans and agents coexisting and working together in Slack to solve problems.&quot;</p><p>Harris described a future where Slackbot becomes an <a href=\"https://modelcontextprotocol.io/docs/learn/client-concepts\">MCP (Model Context Protocol) client</a>, able to leverage tools from across the software ecosystem — similar to how the developer tool Cursor works. &quot;Slack can be an MCP client, and Slackbot will be the hub of that, leveraging all these tools out in the world, some of which will be these amazing agents,&quot; he said.</p><p>But Harris also cautioned against over-promising on multi-agent coordination. &quot;I still think we&#x27;re in the single agent world,&quot; he said. &quot;FY26 is going to be the year where we started to see more coordination. But we&#x27;re going to do it with customer success in mind, and not demonstrate and talk about, like, &#x27;I&#x27;ve got 1,000 agents working together,&#x27; because I think that&#x27;s unrealistic.&quot;</p><h2><b>Slackbot costs nothing extra, but Salesforce&#x27;s data access fees could squeeze some customers</b></h2><p>Slackbot is included at no additional cost for customers on <a href=\"https://slack.com/pricing/businessplus\">Business+</a> and <a href=\"https://slack.com/enterprise\">Enterprise+</a> plans. &quot;There&#x27;s no additional fees customers have to do,&quot; Gavin confirmed. &quot;If they&#x27;re on one of those plans, they&#x27;re going to get Slackbot.&quot;</p><p>However, some enterprise customers may face other cost pressures related to Salesforce&#x27;s broader data strategy. CIOs may see price increases for third-party applications that work with Salesforce data, as effects of higher charges for API access ripple through the software supply chain.</p><p>Fivetran CEO George Fraser has warned that Salesforce&#x27;s shift in pricing policy for API access could have tangible consequences for enterprises relying on Salesforce as a system of record. &quot;They might not be able to use Fivetran to replicate their data to Snowflake and instead have to use Salesforce Data Cloud. Or they might find that they are not able to interact with their data via ChatGPT, and instead have to use Agentforce,&quot; Fraser said in a <a href=\"https://www.cio.com/article/4108001/salesforce-is-tightening-control-of-its-data-ecosystem-and-cios-may-have-to-pay-the-price.html\">recent CIO report</a>.</p><p>Salesforce has framed the pricing change as standard industry practice.</p><h2><b>What Slackbot can do today, what&#x27;s coming in weeks, and what&#x27;s still on the roadmap</b></h2><p>The new Slackbot begins rolling out today and will reach all eligible customers by the end of February. Mobile availability will complete by March 3, Bauer confirmed during her interview with VentureBeat.</p><p>Some capabilities remain works in progress. Calendar reading and availability checking are available at launch, but the ability to actually book meetings is &quot;coming a few weeks after,&quot; according to Seaman. Image generation is not currently supported, though Bauer said it&#x27;s &quot;something that we are looking at in the future.&quot;</p><p>When asked about integration with competing CRM systems like <a href=\"https://www.hubspot.com/\">HubSpot</a> and <a href=\"https://www.microsoft.com/en-us/dynamics-365\">Microsoft Dynamics</a>, Salesforce representatives declined to provide specifics during the interview, though they acknowledged the question touched on key competitive differentiators.</p><h2><b>Salesforce is betting the future of work looks like a chat window—and it&#x27;s not alone</b></h2><p>The Slackbot launch is Salesforce&#x27;s bet that the future of enterprise work is conversational — that employees will increasingly prefer to interact with AI through natural language rather than navigating traditional software interfaces.</p><p>Harris described Slack&#x27;s product philosophy using principles like &quot;don&#x27;t make me think&quot; and &quot;be a great host.&quot; The goal, he said, is for Slackbot to surface information proactively rather than requiring users to hunt for it.</p><p>&quot;One of the revelations for me is LLMs applied to unstructured information are incredible,&quot; Harris said. &quot;And the amount of value you have if you&#x27;re a Slack user, if your corporation uses Slack — the amount of value in Slack is unbelievable. Because you&#x27;re talking about work, you&#x27;re sharing documents, you&#x27;re making decisions, but you can&#x27;t as a human go through that and really get the same value that an LLM can do.&quot;</p><p>Looking ahead, Harris expects the interfaces themselves to evolve beyond pure conversation. &quot;We&#x27;re kind of saturating what we can do with purely conversational UIs,&quot; he said. &quot;I think we&#x27;ll start to see agents building an interface that best suits your intent, as opposed to trying to surface something within a conversational interface that matches your intent.&quot;</p><p>Microsoft, Google, and a growing roster of AI startups are placing similar bets — that the winning enterprise AI will be the one embedded in the tools workers already use, not another application to learn. The race to become that invisible layer of workplace intelligence is now fully underway.</p><p>For Salesforce, the stakes extend beyond a single product launch. After a <a href=\"https://www.investopedia.com/can-salesforce-stock-recover-here-s-what-wall-street-thinks-crm-earnings-11862399\">bruising year</a> on Wall Street and persistent questions about whether AI threatens its core business, the company is wagering that Slackbot can prove the opposite — that the tens of millions of people already chatting in Slack every day is not a vulnerability, but an unassailable advantage.</p><p>Haley Gault, the Salesforce account executive in Pittsburgh who stumbled upon the new Slackbot on a snowy morning, captured the shift in a single sentence: &quot;I honestly can&#x27;t imagine working for another company not having access to these types of tools. This is just how I work now.&quot;</p><p>That&#x27;s precisely what Salesforce is counting on.</p>",
        "contentSnippet": "Salesforce on Tuesday launched an entirely rebuilt version of Slackbot, the company's workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.\nThe new Slackbot, now generally available to Business+ and Enterprise+ customers, is Salesforce's most aggressive move yet to position Slack at the center of the emerging \"agentic AI\" movement — where software agents work alongside humans to complete complex tasks. The launch comes as Salesforce attempts to convince investors that artificial intelligence will bolster its products rather than render them obsolete.\n\"Slackbot isn't just another copilot or AI assistant,\" said Parker Harris, Salesforce co-founder and Slack's chief technology officer, in an exclusive interview with Salesforce. \"It's the front door to the agentic enterprise, powered by Salesforce.\"\nFrom tricycle to Porsche: Salesforce rebuilt Slackbot from the ground up\nHarris was blunt about what distinguishes the new Slackbot from its predecessor: \"The old Slackbot was, you know, a little tricycle, and the new Slackbot is like, you know, a Porsche.\"\nThe original Slackbot, which has existed since Slack's early days, performed basic algorithmic tasks — reminding users to add colleagues to documents, suggesting channel archives, and delivering simple notifications. The new version runs on an entirely different architecture built around a large language model and sophisticated search capabilities that can access Salesforce records, Google Drive files, calendar data, and years of Slack conversations.\n\"It's two different things,\" Harris explained. \"The old Slackbot was algorithmic and fairly simple. The new Slackbot is brand new — it's based around an LLM and a very robust search engine, and connections to third-party search engines, third-party enterprise data.\"\nSalesforce chose to retain the Slackbot brand despite the fundamental technical overhaul. \"People know what Slackbot is, and so we wanted to carry that forward,\" Harris said.\nWhy Anthropic's Claude powers the new Slackbot — and which AI models could come next\nThe new Slackbot runs on Claude, Anthropic's large language model, a choice driven partly by compliance requirements. Slack's commercial service operates under FedRAMP Moderate certification to serve U.S. federal government customers, and Harris said Anthropic was \"the only provider that could give us a compliant LLM\" when Slack began building the new system.\nBut that exclusivity won't last. \"We are, this year, going to support additional providers,\" Harris said. \"We have a great relationship with Google. Gemini is incredible — performance is great, cost is great. So we're going to use Gemini for some things.\" He added that OpenAI remains a possibility as well.\nHarris echoed Salesforce CEO Marc Benioff's view that large language models are becoming commoditized: \"You've heard Marc talk about LLMs are commodities, that they're democratized. I call them CPUs.\"\nOn the sensitive question of training data, Harris was unequivocal: Salesforce does not train any models on customer data. \"Models don't have any sort of security,\" he explained. \"If we trained it on some confidential conversation that you and I have, I don't want Carolyn to know — if I train it into the LLM, there is no way for me to say you get to see the answer, but Carolyn doesn't.\"\nInside Salesforce's internal experiment: 80,000 employees tested Slackbot with striking results\nSalesforce has been testing the new Slackbot internally for months, rolling it out to all 80,000 employees. According to Ryan Gavin, Slack's chief marketing officer, the results have been striking: \"It's the fastest adopted product in Salesforce history.\"\nInternal data shows that two-thirds of Salesforce employees have tried the new Slackbot, with 80% of those users continuing to use it regularly. Internal satisfaction rates reached 96% — the highest for any AI feature Slack has shipped. Employees report saving between two and 20 hours per week.\nThe adoption happened largely organically. \"I think it was about five days, and a Canvas was developed by our employees called 'The Most Stealable Slackbot Prompts,'\" Gavin said. \"People just started adding to it organically. I think it's up to 250-plus prompts that are in this Canvas right now.\"\nKate Crotty, a principal UX researcher at Salesforce, found that 73% of internal adoption was driven by social sharing rather than top-down mandates. \"Everybody is there to help each other learn and communicate hacks,\" she said.\nHow Slackbot transforms scattered enterprise data into executive-ready insights\nDuring a product demonstration, Amy Bauer, Slack's product experience designer, showed how Slackbot can synthesize information across multiple sources. In one example, she asked Slackbot to analyze customer feedback from a pilot program, upload an image of a usage dashboard, and have Slackbot correlate the qualitative and quantitative data.\n\"This is where Slackbot really earns its keep for me,\" Bauer explained. \"What it's doing is not just simply reading the image — it's actually looking at the image and comparing it to the insight it just generated for me.\"\nSlackbot can then query Salesforce to find enterprise accounts with open deals that might be good candidates for early access, creating what Bauer called \"a really great justification and plan to move forward.\" Finally, it can synthesize all that information into a Canvas — Slack's collaborative document format — and find calendar availability among stakeholders to schedule a review meeting.\n\"Up until this point, we have been working in a one-to-one capacity with Slackbot,\" Bauer said. \"But one of the benefits that I can do now is take this insight and have it generate this into a Canvas, a shared workspace where I can iterate on it, refine it with Slackbot, or share it out with my team.\"\nRob Seaman, Slack's chief product officer, said the Canvas creation demonstrates where the product is heading: \"This is making a tool call internally to Slack Canvas to actually write, effectively, a shared document. But it signals where we're going with Slackbot — we're eventually going to be adding in additional third-party tool calls.\"\nMrBeast's company became a Slackbot guinea pig—and employees say they're saving 90 minutes a day\nAmong Salesforce's pilot customers is Beast Industries, the parent company of YouTube star MrBeast. Luis Madrigal, the company's chief information officer, joined the launch announcement to describe his experience.\n\"As somebody who has rolled out enterprise technologies for over two decades now, this was practically one of the easiest,\" Madrigal said. \"The plumbing is there. Slack as an implementation, Enterprise Tools — being able to turn on the Slackbot and the Slack AI functionality was as simple as having my team go in, review, do a quick security review.\"\nMadrigal said his security team signed off \"rather quickly\" — unusual for enterprise AI deployments — because Slackbot accesses only the information each individual user already has permission to view. \"Given all the guardrails you guys have put into place for Slackbot to be unique and customized to only the information that each individual user has, only the conversations and the Slack rooms and Slack channels that they're part of—that made my security team sign off rather quickly.\"\nOne Beast Industries employee, Sinan, the head of Beast Games marketing, reported saving \"at bare minimum, 90 minutes a day.\" Another employee, Spencer, a creative supervisor, described it as \"an assistant who's paying attention when I'm not.\"\nOther pilot customers include Slalom, reMarkable, Xero, Mercari, and Engine. Mollie Bodensteiner, SVP of Operations at Engine, called Slackbot \"an absolute 'chaos tamer' for our team,\" estimating it saves her about 30 minutes daily \"just by eliminating context switching.\"\nSlackbot vs. Microsoft Copilot vs. Google Gemini: The fight for enterprise AI dominance\nThe launch puts Salesforce in direct competition with Microsoft's Copilot, which is integrated into Teams and the broader Microsoft 365 suite, as well as Google's Gemini integrations across Workspace. When asked what distinguishes Slackbot from these alternatives, Seaman pointed to context and convenience.\n\"The thing that makes it most powerful for our customers and users is the proximity — it's just right there in your Slack,\" Seaman said. \"There's a tremendous convenience affordance that's naturally built into it.\"\nThe deeper advantage, executives argue, is that Slackbot already understands users' work without requiring setup or training. \"Most AI tools sound the same no matter who is using them,\" the company's announcement stated. \"They lack context, miss nuance, and force you to jump between tools to get anything done.\"\nHarris put it more directly: \"If you've ever had that magic experience with AI — I think ChatGPT is a great example, it's a great experience from a consumer perspective — Slackbot is really what we're doing in the enterprise, to be this employee super agent that is loved, just like people love using Slack.\"\nAmy Bauer emphasized the frictionless nature of the experience. \"Slackbot is inherently grounded in the context, in the data that you have in Slack,\" she said. \"So as you continue working in Slack, Slackbot gets better because it's grounded in the work that you're doing there. There is no setup. There is no configuration for those end users.\"\nSalesforce's ambitious plan to make Slackbot the one 'super agent' that controls all the others\nSalesforce positions Slackbot as what Harris calls a \"super agent\" — a central hub that can eventually coordinate with other AI agents across an organization.\n\"Every corporation is going to have an employee super agent,\" Harris said. \"Slackbot is essentially taking the magic of what Slack does. We think that Slackbot, and we're really excited about it, is going to be that.\"\nThe vision extends to third-party agents already launching in Slack. Last month, Anthropic released a preview of Claude Code for Slack, allowing developers to interact with Claude's coding capabilities directly in chat threads. OpenAI, Google, Vercel, and others have also built agents for the platform.\n\"Most of the net-new apps that are being deployed to Slack are agents,\" Seaman noted during the press conference. \"This is proof of the promise of humans and agents coexisting and working together in Slack to solve problems.\"\nHarris described a future where Slackbot becomes an MCP (Model Context Protocol) client, able to leverage tools from across the software ecosystem — similar to how the developer tool Cursor works. \"Slack can be an MCP client, and Slackbot will be the hub of that, leveraging all these tools out in the world, some of which will be these amazing agents,\" he said.\nBut Harris also cautioned against over-promising on multi-agent coordination. \"I still think we're in the single agent world,\" he said. \"FY26 is going to be the year where we started to see more coordination. But we're going to do it with customer success in mind, and not demonstrate and talk about, like, 'I've got 1,000 agents working together,' because I think that's unrealistic.\"\nSlackbot costs nothing extra, but Salesforce's data access fees could squeeze some customers\nSlackbot is included at no additional cost for customers on Business+ and Enterprise+ plans. \"There's no additional fees customers have to do,\" Gavin confirmed. \"If they're on one of those plans, they're going to get Slackbot.\"\nHowever, some enterprise customers may face other cost pressures related to Salesforce's broader data strategy. CIOs may see price increases for third-party applications that work with Salesforce data, as effects of higher charges for API access ripple through the software supply chain.\nFivetran CEO George Fraser has warned that Salesforce's shift in pricing policy for API access could have tangible consequences for enterprises relying on Salesforce as a system of record. \"They might not be able to use Fivetran to replicate their data to Snowflake and instead have to use Salesforce Data Cloud. Or they might find that they are not able to interact with their data via ChatGPT, and instead have to use Agentforce,\" Fraser said in a recent CIO report.\nSalesforce has framed the pricing change as standard industry practice.\nWhat Slackbot can do today, what's coming in weeks, and what's still on the roadmap\nThe new Slackbot begins rolling out today and will reach all eligible customers by the end of February. Mobile availability will complete by March 3, Bauer confirmed during her interview with VentureBeat.\nSome capabilities remain works in progress. Calendar reading and availability checking are available at launch, but the ability to actually book meetings is \"coming a few weeks after,\" according to Seaman. Image generation is not currently supported, though Bauer said it's \"something that we are looking at in the future.\"\nWhen asked about integration with competing CRM systems like HubSpot and Microsoft Dynamics, Salesforce representatives declined to provide specifics during the interview, though they acknowledged the question touched on key competitive differentiators.\nSalesforce is betting the future of work looks like a chat window—and it's not alone\nThe Slackbot launch is Salesforce's bet that the future of enterprise work is conversational — that employees will increasingly prefer to interact with AI through natural language rather than navigating traditional software interfaces.\nHarris described Slack's product philosophy using principles like \"don't make me think\" and \"be a great host.\" The goal, he said, is for Slackbot to surface information proactively rather than requiring users to hunt for it.\n\"One of the revelations for me is LLMs applied to unstructured information are incredible,\" Harris said. \"And the amount of value you have if you're a Slack user, if your corporation uses Slack — the amount of value in Slack is unbelievable. Because you're talking about work, you're sharing documents, you're making decisions, but you can't as a human go through that and really get the same value that an LLM can do.\"\nLooking ahead, Harris expects the interfaces themselves to evolve beyond pure conversation. \"We're kind of saturating what we can do with purely conversational UIs,\" he said. \"I think we'll start to see agents building an interface that best suits your intent, as opposed to trying to surface something within a conversational interface that matches your intent.\"\nMicrosoft, Google, and a growing roster of AI startups are placing similar bets — that the winning enterprise AI will be the one embedded in the tools workers already use, not another application to learn. The race to become that invisible layer of workplace intelligence is now fully underway.\nFor Salesforce, the stakes extend beyond a single product launch. After a bruising year on Wall Street and persistent questions about whether AI threatens its core business, the company is wagering that Slackbot can prove the opposite — that the tens of millions of people already chatting in Slack every day is not a vulnerability, but an unassailable advantage.\nHaley Gault, the Salesforce account executive in Pittsburgh who stumbled upon the new Slackbot on a snowy morning, captured the shift in a single sentence: \"I honestly can't imagine working for another company not having access to these types of tools. This is just how I work now.\"\nThat's precisely what Salesforce is counting on.",
        "pubDate": "Tue, 13 Jan 2026 13:00:00 GMT",
        "isoDate": "2026-01-13T13:00:00.000Z",
        "creator": "michael.nunez@venturebeat.com (Michael Nuñez)",
        "source": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and"
      },
      {
        "id": "rss-venturebeat-ai-finance-capital-8-69xvr0",
        "title": "Anthropic launches Cowork, a Claude Desktop agent that works in your files — no coding required",
        "link": "https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no",
        "url": "https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no",
        "content": "<p><a href=\"https://www.anthropic.com/\">Anthropic</a> released <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> on Monday, a new AI agent capability that extends the power of its wildly successful <a href=\"https://claude.com/product/claude-code\">Claude Code</a> tool to non-technical users — and according to company insiders, the team built the entire feature in approximately a week and a half, largely using Claude Code itself.</p><p>The launch marks a major inflection point in the race to deliver practical AI agents to mainstream users, positioning Anthropic to compete not just with <a href=\"https://openai.com/\">OpenAI</a> and <a href=\"https://gemini.google.com/app\">Google</a> in conversational AI, but with <a href=\"https://copilot.microsoft.com/\">Microsoft&#x27;s Copilot</a> in the burgeoning market for AI-powered productivity tools.</p><p>&quot;Cowork lets you complete non-technical tasks much like how developers use Claude Code,&quot; the <a href=\"https://x.com/claudeai/status/2010805682434666759?s=20\">company announced</a> via its official Claude account on X. The feature arrives as a research preview available exclusively to <a href=\"https://support.claude.com/en/articles/11014257-about-claude-s-max-plan-usage\">Claude Max subscribers</a> — Anthropic&#x27;s power-user tier priced between $100 and $200 per month — through the macOS desktop application.</p><p>For the past year, the industry narrative has focused on large language models that can write poetry or debug code. With <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a>, Anthropic is betting that the real enterprise value lies in an AI that can open a folder, read a messy pile of receipts, and generate a structured expense report without human hand-holding.</p><div></div><h2><b>How developers using a coding tool for vacation research inspired Anthropic&#x27;s latest product</b></h2><p>The genesis of <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> lies in Anthropic&#x27;s recent success with the developer community. In late 2024, the company released <a href=\"https://www.anthropic.com/news/claude-3-7-sonnet\">Claude Code</a>, a terminal-based tool that allowed software engineers to automate rote programming tasks. The tool was a hit, but Anthropic noticed a peculiar trend: users were forcing the coding tool to perform non-coding labor.</p><p>According to <a href=\"https://x.com/bcherny/status/2010809450844831752\">Boris Cherny</a>, an engineer at Anthropic, the company observed users deploying the developer tool for an unexpectedly diverse array of tasks.</p><div></div><p>&quot;Since we launched Claude Code, we saw people using it for all sorts of non-coding work: doing vacation research, building slide decks, cleaning up your email, cancelling subscriptions, recovering wedding photos from a hard drive, monitoring plant growth, controlling your oven,&quot; Cherny wrote on X. &quot;These use cases are diverse and surprising — the reason is that the underlying Claude Agent is the best agent, and Opus 4.5 is the best model.&quot;</p><p>Recognizing this shadow usage, Anthropic effectively stripped the command-line complexity from their developer tool to create a consumer-friendly interface. In its blog post announcing the feature, <a href=\"https://claude.com/blog/cowork-research-preview\">Anthropic explained</a> that developers &quot;quickly began using it for almost everything else,&quot; which &quot;prompted us to build Cowork: a simpler way for anyone — not just developers — to work with Claude in the very same way.&quot;</p><h2><b>Inside the folder-based architecture that lets Claude read, edit, and create files on your computer</b></h2><p>Unlike a standard chat interface where a user pastes text for analysis, <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> requires a different level of trust and access. Users designate a specific folder on their local machine that Claude can access. Within that sandbox, the AI agent can read existing files, modify them, or create entirely new ones.</p><p>Anthropic offers several illustrative examples: reorganizing a cluttered downloads folder by sorting and intelligently renaming each file, generating a spreadsheet of expenses from a collection of receipt screenshots, or drafting a report from scattered notes across multiple documents.</p><p>&quot;In Cowork, you give Claude access to a folder on your computer. Claude can then read, edit, or create files in that folder,&quot; <a href=\"https://x.com/claudeai/status/2010805685530038351\">the company explained</a> on X. &quot;Try it to create a spreadsheet from a pile of screenshots, or produce a first draft from scattered notes.&quot;</p><div></div><p>The architecture relies on what is known as an &quot;agentic loop.&quot; When a user assigns a task, the AI does not merely generate a text response. Instead, it formulates a plan, executes steps in parallel, checks its own work, and asks for clarification if it hits a roadblock. Users can queue multiple tasks and let Claude process them simultaneously — a workflow Anthropic describes as feeling &quot;much less like a back-and-forth and much more like leaving messages for a coworker.&quot;</p><p>The system is built on Anthropic&#x27;s <a href=\"https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk\">Claude Agent SDK</a>, meaning it shares the same underlying architecture as Claude Code. Anthropic notes that Cowork &quot;can take on many of the same tasks that Claude Code can handle, but in a more approachable form for non-coding tasks.&quot;</p><h2><b>The recursive loop where AI builds AI: Claude Code reportedly wrote much of Claude Cowork</b></h2><p>Perhaps the most remarkable detail surrounding Cowork&#x27;s launch is the speed at which the tool was reportedly built — highlighting a recursive feedback loop where AI tools are being used to build better AI tools.</p><p>During a livestream hosted by Dan Shipper, Felix Rieseberg, an Anthropic employee, confirmed that <a href=\"https://x.com/blakeir/status/2010837251505205656\">t</a>he team <a href=\"https://x.com/blakeir/status/2010837251505205656\">built Cowork in approximately a week and a half</a>.</p><p>Alex Volkov, who covers AI developments, expressed surprise at the timeline: &quot;Holy shit Anthropic built &#x27;Cowork&#x27; in the last... week and a half?!&quot;</p><div></div><p>This prompted immediate speculation about how much of Cowork was itself built by Claude Code. <a href=\"https://x.com/_simonsmith\">Simon Smith</a>, EVP of Generative AI at Klick Health, put it bluntly on X: &quot;Claude Code wrote all of Claude Cowork. Can we all agree that we&#x27;re in at least somewhat of a recursive improvement loop here?&quot;</p><p>The implication is profound: Anthropic&#x27;s AI coding agent may have substantially contributed to building its own non-technical sibling product. If true, this is one of the most visible examples yet of AI systems being used to accelerate their own development and expansion — a strategy that could widen the gap between AI labs that successfully deploy their own agents internally and those that do not.</p><h2><b>Connectors, browser automation, and skills extend Cowork&#x27;s reach beyond the local file system</b></h2><p>Cowork doesn&#x27;t operate in isolation. The feature integrates with Anthropic&#x27;s existing ecosystem of connectors — tools that link <a href=\"https://claude.ai/login?returnTo=%2Fnew%3F\">Claude</a> to external information sources and services such as <a href=\"https://asana.com/\">Asana</a>, <a href=\"https://www.notion.com/\">Notion</a>, <a href=\"https://www.paypal.com/us/home\">PayPal</a>, and other supported partners. Users who have configured these connections in the standard Claude interface can leverage them within Cowork sessions.</p><p>Additionally, Cowork can pair with <a href=\"https://code.claude.com/docs/en/chrome\">Claude in Chrome</a>, Anthropic&#x27;s browser extension, to execute tasks requiring web access. This combination allows the agent to navigate websites, click buttons, fill forms, and extract information from the internet — all while operating from the desktop application.</p><p>&quot;Cowork includes a number of novel UX and safety features that we think make the product really special,&quot; <a href=\"https://x.com/bcherny/status/2010809450844831752\">Cherny explained</a>, highlighting &quot;a built-in VM [virtual machine] for isolation, out of the box support for browser automation, support for all your claude.ai data connectors, asking you for clarification when it&#x27;s unsure.&quot;</p><p><a href=\"https://www.anthropic.com/\">Anthropic</a> has also introduced an initial set of &quot;skills&quot; specifically designed for Cowork that enhance Claude&#x27;s ability to create documents, presentations, and other files. These build on the <a href=\"https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills\">Skills for Claude</a> framework the company announced in October, which provides specialized instruction sets Claude can load for particular types of tasks.</p><h2><b>Why Anthropic is warning users that its own AI agent could delete their files</b></h2><p>The transition from a chatbot that suggests edits to an agent that makes edits introduces significant risk. An AI that can organize files can, theoretically, delete them.</p><p>In a notable display of transparency, Anthropic devoted considerable space in its announcement to <a href=\"https://claude.com/blog/cowork-research-preview\">warning users about Cowork&#x27;s potential dangers</a> — an unusual approach for a product launch.</p><p>The company explicitly acknowledges that Claude &quot;can take potentially destructive actions (such as deleting local files) if it&#x27;s instructed to.&quot; Because Claude might occasionally misinterpret instructions, Anthropic urges users to provide &quot;very clear guidance&quot; about sensitive operations.</p><p>More concerning is the risk of prompt injection attacks — a technique where malicious actors embed hidden instructions in content Claude might encounter online, potentially causing the agent to bypass safeguards or take harmful actions.</p><p>&quot;We&#x27;ve built sophisticated defenses against prompt injections,&quot; Anthropic wrote, &quot;but agent safety — that is, the task of securing Claude&#x27;s real-world actions — is still an active area of development in the industry.&quot;</p><p>The company characterized these risks as inherent to the current state of AI agent technology rather than unique to Cowork. &quot;These risks aren&#x27;t new with Cowork, but it might be the first time you&#x27;re using a more advanced tool that moves beyond a simple conversation,&quot; the announcement notes.</p><h2><b>Anthropic&#x27;s desktop agent strategy sets up a direct challenge to Microsoft Copilot</b></h2><p>The launch of <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a> places Anthropic in direct competition with <a href=\"https://www.microsoft.com/en-us/\">Microsoft</a>, which has spent years attempting to integrate its <a href=\"https://copilot.microsoft.com/\">Copilot AI</a> into the fabric of the Windows operating system with mixed adoption results.</p><p>However, Anthropic&#x27;s approach differs in its isolation. By confining the agent to specific folders and requiring explicit connectors, they are attempting to strike a balance between the utility of an OS-level agent and the security of a sandboxed application.</p><p>What distinguishes Anthropic&#x27;s approach is its bottom-up evolution. Rather than designing an AI assistant and retrofitting agent capabilities, Anthropic built a powerful coding agent first — <a href=\"https://code.claude.com/docs/en/overview\">Claude Code</a> — and is now abstracting its capabilities for broader audiences. This technical lineage may give Cowork more robust agentic behavior from the start.</p><p>Claude Code has generated significant enthusiasm among developers since its initial launch as <a href=\"https://www.anthropic.com/news/claude-3-7-sonnet\">a command-line tool in late 2024</a>. The company expanded access with a <a href=\"https://arstechnica.com/ai/2025/10/claude-code-gets-a-web-version-but-its-the-new-sandboxing-that-really-matters/\">web interface</a> in October 2025, followed by a <a href=\"https://venturebeat.com/ai/anthropics-claude-code-can-now-read-your-slack-messages-and-write-code-for\">Slack integration</a> in December. Cowork is the next logical step: bringing the same agentic architecture to users who may never touch a terminal.</p><h2><b>Who can access Cowork now, and what&#x27;s coming next for Windows and other platforms</b></h2><p>For now, Cowork remains exclusive to <a href=\"https://support.claude.com/en/articles/11014257-about-claude-s-max-plan-usage\">Claude Max subscribers</a> using the macOS desktop application. Users on other subscription tiers — Free, Pro, Team, or Enterprise — can join a waitlist for future access.</p><p>Anthropic has signaled clear intentions to expand the feature&#x27;s reach. The blog post explicitly mentions plans to add cross-device sync and bring Cowork to Windows as the company learns from the research preview.</p><p>Cherny set expectations appropriately, describing the product as &quot;early and raw, similar to what Claude Code felt like when it first launched.&quot;</p><p>To access <a href=\"https://claude.com/blog/cowork-research-preview\">Cowork</a>, Max subscribers can download or update the Claude macOS app and click on &quot;Cowork&quot; in the sidebar.</p><h2><b>The real question facing enterprise AI adoption</b></h2><p>For technical decision-makers, the implications of Cowork extend beyond any single product launch. The bottleneck for AI adoption is shifting — no longer is model intelligence the limiting factor, but rather workflow integration and user trust.</p><p>Anthropic&#x27;s goal, as the company puts it, is to make working with Claude feel less like operating a tool and more like delegating to a colleague. Whether mainstream users are ready to hand over folder access to an AI that might misinterpret their instructions remains an open question.</p><p>But the speed of Cowork&#x27;s development — a major feature built in ten days, possibly by the company&#x27;s own AI — previews a future where the capabilities of these systems compound faster than organizations can evaluate them. </p><p>The chatbot has learned to use a file manager. What it learns to use next is anyone&#x27;s guess.</p>",
        "contentSnippet": "Anthropic released Cowork on Monday, a new AI agent capability that extends the power of its wildly successful Claude Code tool to non-technical users — and according to company insiders, the team built the entire feature in approximately a week and a half, largely using Claude Code itself.\nThe launch marks a major inflection point in the race to deliver practical AI agents to mainstream users, positioning Anthropic to compete not just with OpenAI and Google in conversational AI, but with Microsoft's Copilot in the burgeoning market for AI-powered productivity tools.\n\"Cowork lets you complete non-technical tasks much like how developers use Claude Code,\" the company announced via its official Claude account on X. The feature arrives as a research preview available exclusively to Claude Max subscribers — Anthropic's power-user tier priced between $100 and $200 per month — through the macOS desktop application.\nFor the past year, the industry narrative has focused on large language models that can write poetry or debug code. With Cowork, Anthropic is betting that the real enterprise value lies in an AI that can open a folder, read a messy pile of receipts, and generate a structured expense report without human hand-holding.\n\nHow developers using a coding tool for vacation research inspired Anthropic's latest product\nThe genesis of Cowork lies in Anthropic's recent success with the developer community. In late 2024, the company released Claude Code, a terminal-based tool that allowed software engineers to automate rote programming tasks. The tool was a hit, but Anthropic noticed a peculiar trend: users were forcing the coding tool to perform non-coding labor.\nAccording to Boris Cherny, an engineer at Anthropic, the company observed users deploying the developer tool for an unexpectedly diverse array of tasks.\n\n\"Since we launched Claude Code, we saw people using it for all sorts of non-coding work: doing vacation research, building slide decks, cleaning up your email, cancelling subscriptions, recovering wedding photos from a hard drive, monitoring plant growth, controlling your oven,\" Cherny wrote on X. \"These use cases are diverse and surprising — the reason is that the underlying Claude Agent is the best agent, and Opus 4.5 is the best model.\"\nRecognizing this shadow usage, Anthropic effectively stripped the command-line complexity from their developer tool to create a consumer-friendly interface. In its blog post announcing the feature, Anthropic explained that developers \"quickly began using it for almost everything else,\" which \"prompted us to build Cowork: a simpler way for anyone — not just developers — to work with Claude in the very same way.\"\nInside the folder-based architecture that lets Claude read, edit, and create files on your computer\nUnlike a standard chat interface where a user pastes text for analysis, Cowork requires a different level of trust and access. Users designate a specific folder on their local machine that Claude can access. Within that sandbox, the AI agent can read existing files, modify them, or create entirely new ones.\nAnthropic offers several illustrative examples: reorganizing a cluttered downloads folder by sorting and intelligently renaming each file, generating a spreadsheet of expenses from a collection of receipt screenshots, or drafting a report from scattered notes across multiple documents.\n\"In Cowork, you give Claude access to a folder on your computer. Claude can then read, edit, or create files in that folder,\" the company explained on X. \"Try it to create a spreadsheet from a pile of screenshots, or produce a first draft from scattered notes.\"\n\nThe architecture relies on what is known as an \"agentic loop.\" When a user assigns a task, the AI does not merely generate a text response. Instead, it formulates a plan, executes steps in parallel, checks its own work, and asks for clarification if it hits a roadblock. Users can queue multiple tasks and let Claude process them simultaneously — a workflow Anthropic describes as feeling \"much less like a back-and-forth and much more like leaving messages for a coworker.\"\nThe system is built on Anthropic's Claude Agent SDK, meaning it shares the same underlying architecture as Claude Code. Anthropic notes that Cowork \"can take on many of the same tasks that Claude Code can handle, but in a more approachable form for non-coding tasks.\"\nThe recursive loop where AI builds AI: Claude Code reportedly wrote much of Claude Cowork\nPerhaps the most remarkable detail surrounding Cowork's launch is the speed at which the tool was reportedly built — highlighting a recursive feedback loop where AI tools are being used to build better AI tools.\nDuring a livestream hosted by Dan Shipper, Felix Rieseberg, an Anthropic employee, confirmed that the team built Cowork in approximately a week and a half.\nAlex Volkov, who covers AI developments, expressed surprise at the timeline: \"Holy shit Anthropic built 'Cowork' in the last... week and a half?!\"\n\nThis prompted immediate speculation about how much of Cowork was itself built by Claude Code. Simon Smith, EVP of Generative AI at Klick Health, put it bluntly on X: \"Claude Code wrote all of Claude Cowork. Can we all agree that we're in at least somewhat of a recursive improvement loop here?\"\nThe implication is profound: Anthropic's AI coding agent may have substantially contributed to building its own non-technical sibling product. If true, this is one of the most visible examples yet of AI systems being used to accelerate their own development and expansion — a strategy that could widen the gap between AI labs that successfully deploy their own agents internally and those that do not.\nConnectors, browser automation, and skills extend Cowork's reach beyond the local file system\nCowork doesn't operate in isolation. The feature integrates with Anthropic's existing ecosystem of connectors — tools that link Claude to external information sources and services such as Asana, Notion, PayPal, and other supported partners. Users who have configured these connections in the standard Claude interface can leverage them within Cowork sessions.\nAdditionally, Cowork can pair with Claude in Chrome, Anthropic's browser extension, to execute tasks requiring web access. This combination allows the agent to navigate websites, click buttons, fill forms, and extract information from the internet — all while operating from the desktop application.\n\"Cowork includes a number of novel UX and safety features that we think make the product really special,\" Cherny explained, highlighting \"a built-in VM [virtual machine] for isolation, out of the box support for browser automation, support for all your claude.ai data connectors, asking you for clarification when it's unsure.\"\nAnthropic has also introduced an initial set of \"skills\" specifically designed for Cowork that enhance Claude's ability to create documents, presentations, and other files. These build on the Skills for Claude framework the company announced in October, which provides specialized instruction sets Claude can load for particular types of tasks.\nWhy Anthropic is warning users that its own AI agent could delete their files\nThe transition from a chatbot that suggests edits to an agent that makes edits introduces significant risk. An AI that can organize files can, theoretically, delete them.\nIn a notable display of transparency, Anthropic devoted considerable space in its announcement to warning users about Cowork's potential dangers — an unusual approach for a product launch.\nThe company explicitly acknowledges that Claude \"can take potentially destructive actions (such as deleting local files) if it's instructed to.\" Because Claude might occasionally misinterpret instructions, Anthropic urges users to provide \"very clear guidance\" about sensitive operations.\nMore concerning is the risk of prompt injection attacks — a technique where malicious actors embed hidden instructions in content Claude might encounter online, potentially causing the agent to bypass safeguards or take harmful actions.\n\"We've built sophisticated defenses against prompt injections,\" Anthropic wrote, \"but agent safety — that is, the task of securing Claude's real-world actions — is still an active area of development in the industry.\"\nThe company characterized these risks as inherent to the current state of AI agent technology rather than unique to Cowork. \"These risks aren't new with Cowork, but it might be the first time you're using a more advanced tool that moves beyond a simple conversation,\" the announcement notes.\nAnthropic's desktop agent strategy sets up a direct challenge to Microsoft Copilot\nThe launch of Cowork places Anthropic in direct competition with Microsoft, which has spent years attempting to integrate its Copilot AI into the fabric of the Windows operating system with mixed adoption results.\nHowever, Anthropic's approach differs in its isolation. By confining the agent to specific folders and requiring explicit connectors, they are attempting to strike a balance between the utility of an OS-level agent and the security of a sandboxed application.\nWhat distinguishes Anthropic's approach is its bottom-up evolution. Rather than designing an AI assistant and retrofitting agent capabilities, Anthropic built a powerful coding agent first — Claude Code — and is now abstracting its capabilities for broader audiences. This technical lineage may give Cowork more robust agentic behavior from the start.\nClaude Code has generated significant enthusiasm among developers since its initial launch as a command-line tool in late 2024. The company expanded access with a web interface in October 2025, followed by a Slack integration in December. Cowork is the next logical step: bringing the same agentic architecture to users who may never touch a terminal.\nWho can access Cowork now, and what's coming next for Windows and other platforms\nFor now, Cowork remains exclusive to Claude Max subscribers using the macOS desktop application. Users on other subscription tiers — Free, Pro, Team, or Enterprise — can join a waitlist for future access.\nAnthropic has signaled clear intentions to expand the feature's reach. The blog post explicitly mentions plans to add cross-device sync and bring Cowork to Windows as the company learns from the research preview.\nCherny set expectations appropriately, describing the product as \"early and raw, similar to what Claude Code felt like when it first launched.\"\nTo access Cowork, Max subscribers can download or update the Claude macOS app and click on \"Cowork\" in the sidebar.\nThe real question facing enterprise AI adoption\nFor technical decision-makers, the implications of Cowork extend beyond any single product launch. The bottleneck for AI adoption is shifting — no longer is model intelligence the limiting factor, but rather workflow integration and user trust.\nAnthropic's goal, as the company puts it, is to make working with Claude feel less like operating a tool and more like delegating to a colleague. Whether mainstream users are ready to hand over folder access to an AI that might misinterpret their instructions remains an open question.\nBut the speed of Cowork's development — a major feature built in ten days, possibly by the company's own AI — previews a future where the capabilities of these systems compound faster than organizations can evaluate them. \nThe chatbot has learned to use a file manager. What it learns to use next is anyone's guess.",
        "pubDate": "Mon, 12 Jan 2026 11:30:00 GMT",
        "isoDate": "2026-01-12T11:30:00.000Z",
        "creator": "michael.nunez@venturebeat.com (Michael Nuñez)",
        "source": "https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no"
      },
      {
        "id": "rss-venturebeat-ai-finance-capital-8-o3ucts",
        "title": "Nous Research's NousCoder-14B is an open-source coding model landing right in the Claude Code moment",
        "link": "https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in",
        "url": "https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in",
        "content": "<p><a href=\"https://nousresearch.com/\">Nous Research</a>, the open-source artificial intelligence startup backed by crypto venture firm <a href=\"https://www.paradigm.xyz/\">Paradigm</a>, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary systems — trained in just four days using 48 of Nvidia&#x27;s latest <a href=\"https://www.nvidia.com/en-us/data-center/dgx-b200/\">B200 graphics processors</a>.</p><p>The model, called <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a>, is another entry in a crowded field of AI coding assistants, but arrives at a particularly charged moment: <a href=\"https://claude.com/product/claude-code\">Claude Code</a>, the agentic programming tool from rival Anthropic, has dominated social media discussion since New Year&#x27;s Day, with developers posting <a href=\"https://x.com/0xDesigner/status/2008202211738648767?s=20\">breathless</a> <a href=\"https://x.com/hayesdev_/status/2008043379805048948\">testimonials</a> <a href=\"https://x.com/0xDesigner/status/2008202211738648767?s=20\">about its capabilities</a>. The simultaneous developments underscore how quickly AI-assisted software development is evolving — and how fiercely companies large and small are competing to capture what many believe will become a foundational technology for how software gets written.</p><p><span>type: <!-- -->embedded-entry-inline<!-- --> id: <!-- -->74cSyrq6OUrp9SEQ5zOUSl</span></p><p><a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">NousCoder-14B</a> achieves a 67.87 percent accuracy rate on <a href=\"https://livecodebench.github.io/\">LiveCodeBench v6</a>, a standardized evaluation that tests models on competitive programming problems published between August 2024 and May 2025. That figure represents a 7.08 percentage point improvement over the base model it was trained from, Alibaba&#x27;s <a href=\"https://huggingface.co/Qwen/Qwen3-14B\">Qwen3-14B</a>, according to Nous Research&#x27;s technical report published alongside the release.</p><p>&quot;I gave Claude Code a description of the problem, it generated what we built last year in an hour,&quot; <a href=\"https://www.reddit.com/r/OpenAI/comments/1q2uuil/google_engineer_im_not_joking_and_this_isnt_funny/\">wrote Jaana Dogan</a>, a principal engineer at Google responsible for the Gemini API, in a viral post on X last week that captured the prevailing mood around AI coding tools. Dogan was describing a distributed agent orchestration system her team had spent a year developing — a system Claude Code approximated from a three-paragraph prompt.</p><p>The juxtaposition is instructive: while Anthropic&#x27;s <a href=\"https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are\">Claude Code has captured imaginations</a> with demonstrations of end-to-end software development, Nous Research is betting that open-source alternatives trained on verifiable problems can close the gap — and that transparency in how these models are built matters as much as raw capability.</p><hr/><h2><b>How Nous Research built an AI coding model that anyone can replicate</b></h2><p>What distinguishes the <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a> release from many competitor announcements is its radical openness. Nous Research published not just the <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">model weights</a> but the <a href=\"https://github.com/NousResearch/atropos/pull/296\">complete reinforcement learning environment</a>, benchmark suite, and training harness — built on the company&#x27;s <a href=\"https://github.com/NousResearch/atropos/pull/296\">Atropos framework </a>— enabling any researcher with sufficient compute to <a href=\"https://wandb.ai/jli505/qwen14b/reports/HermesCoder-14B--VmlldzoxNTQ5Nzc0MQ?accessToken=4pt3stwyh4x83zqe2jgoo5j9b7j07jbe5omf2n40lray3tih17vfkavjootvnw8o\">reproduce or extend the work</a>.</p><p>&quot;Open-sourcing the Atropos stack provides the necessary infrastructure for reproducible olympiad-level reasoning research,&quot; <a href=\"https://x.com/o_mega___/status/2008907268700475450?s=20\">noted one observer on X</a>, summarizing the significance for the academic and open-source communities.</p><p>The model was trained by <a href=\"https://x.com/JoeLi5050\">Joe Li</a>, a researcher in residence at Nous Research and a former competitive programmer himself. Li&#x27;s <a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">technical report </a>reveals an unexpectedly personal dimension: he compared the model&#x27;s improvement trajectory to his own journey on Codeforces, the competitive programming platform where participants earn ratings based on contest performance.</p><p>Based on rough estimates mapping LiveCodeBench scores to Codeforces ratings, Li calculated that NousCoder-14B&#x27;s improvemen t— from approximately the 1600-1750 rating range to 2100-2200 — mirrors a leap that took him nearly two years of sustained practice between ages 14 and 16. The model accomplished the equivalent in four days.</p><p>&quot;Watching that final training run unfold was quite a surreal experience,&quot; Li wrote in the technical report.</p><p>But Li was quick to note an important caveat that speaks to broader questions about AI efficiency: he solved roughly 1,000 problems during those two years, while the model required 24,000. Humans, at least for now, remain dramatically more sample-efficient learners.</p><hr/><h2><b>Inside the reinforcement learning system that trains on 24,000 competitive programming problems</b></h2><p><a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a>&#x27;s training process offers a window into the increasingly sophisticated techniques researchers use to improve AI reasoning capabilities through reinforcement learning.</p><p>The approach relies on what researchers call &quot;verifiable rewards&quot; — a system where the model generates code solutions, those solutions are executed against test cases, and the model receives a simple binary signal: correct or incorrect. This feedback loop, while conceptually straightforward, requires significant infrastructure to execute at scale.</p><p>Nous Research used <a href=\"https://modal.com/\">Modal</a>, a cloud computing platform, to run sandboxed code execution in parallel. Each of the 24,000 training problems contains hundreds of test cases on average, and the system must verify that generated code produces correct outputs within time and memory constraints — 15 seconds and 4 gigabytes, respectively.</p><p>The training employed a technique called <a href=\"https://dapo-sia.github.io/\">DAPO (Dynamic Sampling Policy Optimization)</a>, which the researchers found performed slightly better than alternatives in their experiments. A key innovation involves &quot;dynamic sampling&quot; — discarding training examples where the model either solves all attempts or fails all attempts, since these provide no useful gradient signal for learning.</p><p>The researchers also adopted &quot;iterative context extension,&quot; first training the model with a 32,000-token context window before expanding to 40,000 tokens. During evaluation, extending the context further to approximately 80,000 tokens produced the best results, with accuracy reaching 67.87 percent.</p><p>Perhaps most significantly, the training pipeline overlaps inference and verification — as soon as the model generates a solution, it begins work on the next problem while the previous solution is being checked. This pipelining, combined with asynchronous training where multiple model instances work in parallel, maximizes hardware utilization on expensive GPU clusters.</p><hr/><h2><b>The looming data shortage that could slow AI coding model progress</b></h2><p>Buried in Li&#x27;s <a href=\"https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/\">technical report</a> is a finding with significant implications for the future of AI development: the training dataset for NousCoder-14B encompasses &quot;a significant portion of all readily available, verifiable competitive programming problems in a standardized dataset format.&quot;</p><p>In other words, for this particular domain, the researchers are approaching the limits of high-quality training data.</p><p>&quot;The total number of competitive programming problems on the Internet is roughly the same order of magnitude,&quot; Li wrote, referring to the 24,000 problems used for training. &quot;This suggests that within the competitive programming domain, we have approached the limits of high-quality data.&quot;</p><p>This observation echoes growing concern across the AI industry about data constraints. While compute continues to scale according to well-understood economic and engineering principles, training data is &quot;increasingly finite,&quot; as Li put it.</p><p>&quot;It appears that some of the most important research that needs to be done in the future will be in the areas of synthetic data generation and data efficient algorithms and architectures,&quot; he concluded.</p><p>The challenge is particularly acute for competitive programming because the domain requires problems with known correct solutions that can be verified automatically. Unlike natural language tasks where human evaluation or proxy metrics suffice, code either works or it doesn&#x27;t — making synthetic data generation considerably more difficult.</p><p>Li identified one potential avenue: training models not just to solve problems but to generate solvable problems, enabling a form of self-play similar to techniques that proved successful in game-playing AI systems. &quot;Once synthetic problem generation is solved, self-play becomes a very interesting direction,&quot; he wrote.</p><hr/><h2><b>A $65 million bet that open-source AI can compete with Big Tech</b></h2><p>Nous Research has carved out a distinctive position in the AI landscape: a company committed to <a href=\"https://nousresearch.com/\">open-source releases</a> that compete with — and sometimes exceed — proprietary alternatives.</p><p>The company raised<a href=\"https://fortune.com/crypto/2025/04/25/paradigm-nous-research-crypto-ai-venture-capital-deepseek-openai-blockchain/\"> $50 million in April 2025</a> in a round led by Paradigm, the cryptocurrency-focused venture firm founded by Coinbase co-founder Fred Ehrsam. Total funding reached $65 million, according to some reports. The investment reflected growing interest in decentralized approaches to AI training, an area where Nous Research has developed its <a href=\"https://psyche.network/\">Psyche platform</a>.</p><p>Previous releases include <a href=\"https://hermes4.nousresearch.com/\">Hermes 4</a>, a family of models that we reported &quot;<a href=\"https://venturebeat.com/ai/nous-research-drops-hermes-4-ai-models-that-outperform-chatgpt-without-content-restrictions\">outperform ChatGPT without content restrictions</a>,&quot; and DeepHermes-3, which the company described as the first &quot;<a href=\"https://venturebeat.com/ai/personalized-unrestricted-ai-lab-nous-research-launches-first-toggle-on-reasoning-model-deephermes-3\">toggle-on reasoning model</a>&quot; — allowing users to activate extended thinking capabilities on demand.</p><p>The company has cultivated a distinctive aesthetic and community, prompting some skepticism about whether style might overshadow substance. &quot;Ofc i&#x27;m gonna believe an anime pfp company. stop benchmarkmaxxing ffs,&quot; <a href=\"https://x.com/shydev69/status/2008654826356535510?s=20\">wrote one critic on X</a>, referring to Nous Research&#x27;s anime-style branding and the industry practice of optimizing for benchmark performance.</p><p>Others raised technical questions. &quot;<a href=\"https://x.com/yehor_smoliakov/status/2008659681489940757?s=20\">Based on the benchmark, Nemotron is better</a>,&quot; noted one commenter, referring to Nvidia&#x27;s family of language models. Another asked whether <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">NousCoder-14B</a> is &quot;agentic focused or just &#x27;one shot&#x27; coding&quot; — a distinction that matters for practical software development, where iterating on feedback typically produces better results than single attempts.</p><hr/><h2><b>What researchers say must happen next for AI coding tools to keep improving</b></h2><p>The release includes several directions for future work that hint at where AI coding research may be heading.</p><p>Multi-turn reinforcement learning tops the list. Currently, the model receives only a final binary reward — pass or fail — after generating a solution. But competitive programming problems typically include public test cases that provide intermediate feedback: compilation errors, incorrect outputs, time limit violations. Training models to incorporate this feedback across multiple attempts could significantly improve performance.</p><p>Controlling response length also remains a challenge. The researchers found that incorrect solutions tended to be longer than correct ones, and response lengths quickly saturated available context windows during training — a pattern that various algorithmic modifications failed to resolve.</p><p>Perhaps most ambitiously, Li proposed &quot;problem generation and self-play&quot; — training models to both solve and create programming problems. This would address the data scarcity problem directly by enabling models to generate their own training curricula.</p><p>&quot;Humans are great at generating interesting and useful problems for other competitive programmers, but it appears that there still exists a significant gap in LLM capabilities in creative problem generation,&quot; Li wrote.</p><p>The model is <a href=\"https://huggingface.co/NousResearch/NousCoder-14B\">available now on Hugging Face</a> under an Apache 2.0 license. For researchers and developers who want to build on the work, Nous Research has published the complete <a href=\"https://github.com/NousResearch/atropos/pull/296\">Atropos training stack</a> alongside it.</p><p>What took Li two years of adolescent dedication to achieve—climbing from a 1600-level novice to a 2100-rated competitor on Codeforces—an AI replicated in 96 hours. He needed 1,000 problems. The model needed 24,000. But soon enough, these systems may learn to write their own problems, teach themselves, and leave human benchmarks behind entirely.</p><p>The question is no longer whether machines can learn to code. It&#x27;s whether they&#x27;ll soon be better teachers than we ever were.</p><p>\n</p>",
        "contentSnippet": "Nous Research, the open-source artificial intelligence startup backed by crypto venture firm Paradigm, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary systems — trained in just four days using 48 of Nvidia's latest B200 graphics processors.\nThe model, called NousCoder-14B, is another entry in a crowded field of AI coding assistants, but arrives at a particularly charged moment: Claude Code, the agentic programming tool from rival Anthropic, has dominated social media discussion since New Year's Day, with developers posting breathless testimonials about its capabilities. The simultaneous developments underscore how quickly AI-assisted software development is evolving — and how fiercely companies large and small are competing to capture what many believe will become a foundational technology for how software gets written.\ntype: embedded-entry-inline id: 74cSyrq6OUrp9SEQ5zOUSl\nNousCoder-14B achieves a 67.87 percent accuracy rate on LiveCodeBench v6, a standardized evaluation that tests models on competitive programming problems published between August 2024 and May 2025. That figure represents a 7.08 percentage point improvement over the base model it was trained from, Alibaba's Qwen3-14B, according to Nous Research's technical report published alongside the release.\n\"I gave Claude Code a description of the problem, it generated what we built last year in an hour,\" wrote Jaana Dogan, a principal engineer at Google responsible for the Gemini API, in a viral post on X last week that captured the prevailing mood around AI coding tools. Dogan was describing a distributed agent orchestration system her team had spent a year developing — a system Claude Code approximated from a three-paragraph prompt.\nThe juxtaposition is instructive: while Anthropic's Claude Code has captured imaginations with demonstrations of end-to-end software development, Nous Research is betting that open-source alternatives trained on verifiable problems can close the gap — and that transparency in how these models are built matters as much as raw capability.\n\nHow Nous Research built an AI coding model that anyone can replicate\nWhat distinguishes the NousCoder-14B release from many competitor announcements is its radical openness. Nous Research published not just the model weights but the complete reinforcement learning environment, benchmark suite, and training harness — built on the company's Atropos framework — enabling any researcher with sufficient compute to reproduce or extend the work.\n\"Open-sourcing the Atropos stack provides the necessary infrastructure for reproducible olympiad-level reasoning research,\" noted one observer on X, summarizing the significance for the academic and open-source communities.\nThe model was trained by Joe Li, a researcher in residence at Nous Research and a former competitive programmer himself. Li's technical report reveals an unexpectedly personal dimension: he compared the model's improvement trajectory to his own journey on Codeforces, the competitive programming platform where participants earn ratings based on contest performance.\nBased on rough estimates mapping LiveCodeBench scores to Codeforces ratings, Li calculated that NousCoder-14B's improvemen t— from approximately the 1600-1750 rating range to 2100-2200 — mirrors a leap that took him nearly two years of sustained practice between ages 14 and 16. The model accomplished the equivalent in four days.\n\"Watching that final training run unfold was quite a surreal experience,\" Li wrote in the technical report.\nBut Li was quick to note an important caveat that speaks to broader questions about AI efficiency: he solved roughly 1,000 problems during those two years, while the model required 24,000. Humans, at least for now, remain dramatically more sample-efficient learners.\n\nInside the reinforcement learning system that trains on 24,000 competitive programming problems\nNousCoder-14B's training process offers a window into the increasingly sophisticated techniques researchers use to improve AI reasoning capabilities through reinforcement learning.\nThe approach relies on what researchers call \"verifiable rewards\" — a system where the model generates code solutions, those solutions are executed against test cases, and the model receives a simple binary signal: correct or incorrect. This feedback loop, while conceptually straightforward, requires significant infrastructure to execute at scale.\nNous Research used Modal, a cloud computing platform, to run sandboxed code execution in parallel. Each of the 24,000 training problems contains hundreds of test cases on average, and the system must verify that generated code produces correct outputs within time and memory constraints — 15 seconds and 4 gigabytes, respectively.\nThe training employed a technique called DAPO (Dynamic Sampling Policy Optimization), which the researchers found performed slightly better than alternatives in their experiments. A key innovation involves \"dynamic sampling\" — discarding training examples where the model either solves all attempts or fails all attempts, since these provide no useful gradient signal for learning.\nThe researchers also adopted \"iterative context extension,\" first training the model with a 32,000-token context window before expanding to 40,000 tokens. During evaluation, extending the context further to approximately 80,000 tokens produced the best results, with accuracy reaching 67.87 percent.\nPerhaps most significantly, the training pipeline overlaps inference and verification — as soon as the model generates a solution, it begins work on the next problem while the previous solution is being checked. This pipelining, combined with asynchronous training where multiple model instances work in parallel, maximizes hardware utilization on expensive GPU clusters.\n\nThe looming data shortage that could slow AI coding model progress\nBuried in Li's technical report is a finding with significant implications for the future of AI development: the training dataset for NousCoder-14B encompasses \"a significant portion of all readily available, verifiable competitive programming problems in a standardized dataset format.\"\nIn other words, for this particular domain, the researchers are approaching the limits of high-quality training data.\n\"The total number of competitive programming problems on the Internet is roughly the same order of magnitude,\" Li wrote, referring to the 24,000 problems used for training. \"This suggests that within the competitive programming domain, we have approached the limits of high-quality data.\"\nThis observation echoes growing concern across the AI industry about data constraints. While compute continues to scale according to well-understood economic and engineering principles, training data is \"increasingly finite,\" as Li put it.\n\"It appears that some of the most important research that needs to be done in the future will be in the areas of synthetic data generation and data efficient algorithms and architectures,\" he concluded.\nThe challenge is particularly acute for competitive programming because the domain requires problems with known correct solutions that can be verified automatically. Unlike natural language tasks where human evaluation or proxy metrics suffice, code either works or it doesn't — making synthetic data generation considerably more difficult.\nLi identified one potential avenue: training models not just to solve problems but to generate solvable problems, enabling a form of self-play similar to techniques that proved successful in game-playing AI systems. \"Once synthetic problem generation is solved, self-play becomes a very interesting direction,\" he wrote.\n\nA $65 million bet that open-source AI can compete with Big Tech\nNous Research has carved out a distinctive position in the AI landscape: a company committed to open-source releases that compete with — and sometimes exceed — proprietary alternatives.\nThe company raised $50 million in April 2025 in a round led by Paradigm, the cryptocurrency-focused venture firm founded by Coinbase co-founder Fred Ehrsam. Total funding reached $65 million, according to some reports. The investment reflected growing interest in decentralized approaches to AI training, an area where Nous Research has developed its Psyche platform.\nPrevious releases include Hermes 4, a family of models that we reported \"outperform ChatGPT without content restrictions,\" and DeepHermes-3, which the company described as the first \"toggle-on reasoning model\" — allowing users to activate extended thinking capabilities on demand.\nThe company has cultivated a distinctive aesthetic and community, prompting some skepticism about whether style might overshadow substance. \"Ofc i'm gonna believe an anime pfp company. stop benchmarkmaxxing ffs,\" wrote one critic on X, referring to Nous Research's anime-style branding and the industry practice of optimizing for benchmark performance.\nOthers raised technical questions. \"Based on the benchmark, Nemotron is better,\" noted one commenter, referring to Nvidia's family of language models. Another asked whether NousCoder-14B is \"agentic focused or just 'one shot' coding\" — a distinction that matters for practical software development, where iterating on feedback typically produces better results than single attempts.\n\nWhat researchers say must happen next for AI coding tools to keep improving\nThe release includes several directions for future work that hint at where AI coding research may be heading.\nMulti-turn reinforcement learning tops the list. Currently, the model receives only a final binary reward — pass or fail — after generating a solution. But competitive programming problems typically include public test cases that provide intermediate feedback: compilation errors, incorrect outputs, time limit violations. Training models to incorporate this feedback across multiple attempts could significantly improve performance.\nControlling response length also remains a challenge. The researchers found that incorrect solutions tended to be longer than correct ones, and response lengths quickly saturated available context windows during training — a pattern that various algorithmic modifications failed to resolve.\nPerhaps most ambitiously, Li proposed \"problem generation and self-play\" — training models to both solve and create programming problems. This would address the data scarcity problem directly by enabling models to generate their own training curricula.\n\"Humans are great at generating interesting and useful problems for other competitive programmers, but it appears that there still exists a significant gap in LLM capabilities in creative problem generation,\" Li wrote.\nThe model is available now on Hugging Face under an Apache 2.0 license. For researchers and developers who want to build on the work, Nous Research has published the complete Atropos training stack alongside it.\nWhat took Li two years of adolescent dedication to achieve—climbing from a 1600-level novice to a 2100-rated competitor on Codeforces—an AI replicated in 96 hours. He needed 1,000 problems. The model needed 24,000. But soon enough, these systems may learn to write their own problems, teach themselves, and leave human benchmarks behind entirely.\nThe question is no longer whether machines can learn to code. It's whether they'll soon be better teachers than we ever were.",
        "pubDate": "Wed, 07 Jan 2026 20:00:00 GMT",
        "isoDate": "2026-01-07T20:00:00.000Z",
        "creator": "michael.nunez@venturebeat.com (Michael Nuñez)",
        "source": "https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in"
      },
      {
        "id": "rss-venturebeat-ai-finance-capital-8-k9er74",
        "title": "The creator of Claude Code just revealed his workflow, and developers are losing their minds",
        "link": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are",
        "url": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are",
        "content": "<p>When the creator of the world&#x27;s most advanced coding agent speaks, Silicon Valley doesn&#x27;t just listen — it takes notes.</p><p>For the past week, the engineering community has been dissecting a <a href=\"https://x.com/bcherny/status/2007179832300581177\">thread on X</a> from <a href=\"https://x.com/bcherny\">Boris Cherny</a>, the creator and head of <a href=\"https://code.claude.com/docs/en/overview\">Claude Code</a> at <a href=\"https://www.anthropic.com/\">Anthropic</a>. What began as a casual sharing of his personal terminal setup has spiraled into a viral manifesto on the future of software development, with industry insiders calling it a watershed moment for the startup.</p><div></div><p>&quot;If you&#x27;re not reading the Claude Code best practices straight from its creator, you&#x27;re behind as a programmer,&quot; wrote <a href=\"https://x.com/jefftangx\">Jeff Tang</a>, a prominent voice in the developer community. <a href=\"https://x.com/KyleMcnease/status/2007555584724480338\">Kyle McNease</a>, another industry observer, went further, declaring that with Cherny&#x27;s &quot;game-changing updates,&quot; Anthropic is &quot;on fire,&quot; potentially facing &quot;their ChatGPT moment.&quot;</p><p>The excitement stems from a paradox: Cherny&#x27;s workflow is surprisingly simple, yet it allows a single human to operate with the output capacity of a small engineering department. As one user noted on X after implementing Cherny&#x27;s setup, the experience &quot;<a href=\"https://x.com/mtwichan\">feels more like Starcraft</a>&quot; than traditional coding — a shift from typing syntax to commanding autonomous units.</p><p>Here is an analysis of the workflow that is reshaping how software gets built, straight from the architect himself. </p><h2><b>How running five AI agents at once turns coding into a real-time strategy game</b></h2><p>The most striking revelation from Cherny&#x27;s disclosure is that he does not code in a linear fashion. In the traditional &quot;<a href=\"https://notes.paulswail.com/public/The+inner+and+outer+loops+of+software+development+workflow\">inner loop</a>&quot; of development, a programmer writes a function, tests it, and moves to the next. Cherny, however, acts as a fleet commander.</p><p>&quot;I run 5 Claudes in parallel in my terminal,&quot; Cherny wrote. &quot;I number my tabs 1-5, and use system notifications to know when a Claude needs input.&quot;</p><p>By utilizing iTerm2 system notifications, Cherny effectively manages five simultaneous work streams. While one agent runs a test suite, another refactors a legacy module, and a third drafts documentation. He also runs &quot;5-10 Claudes on <a href=\"https://claude.ai/\">claude.ai</a>&quot; in his browser, using a &quot;teleport&quot; command to hand off sessions between the web and his local machine.</p><p>This validates the &quot;<a href=\"https://www.cnbc.com/2026/01/03/anthropic-daniela-amodei-do-more-with-less-bet.html\">do more with less</a>&quot; strategy articulated by Anthropic President Daniela Amodei earlier this week. While competitors like OpenAI pursue trillion-dollar infrastructure build-outs, Anthropic is proving that superior orchestration of existing models can yield exponential productivity gains.</p><h2><b>The counterintuitive case for choosing the slowest, smartest model</b></h2><p>In a surprising move for an industry obsessed with latency, Cherny revealed that he exclusively uses Anthropic&#x27;s heaviest, slowest model: <a href=\"https://www.anthropic.com/news/claude-opus-4-5\">Opus 4.5</a>.</p><p>&quot;I use Opus 4.5 with thinking for everything,&quot; Cherny <a href=\"https://x.com/bcherny/status/2007179838864666847\">explained</a>. &quot;It&#x27;s the best coding model I&#x27;ve ever used, and even though it&#x27;s bigger &amp; slower than Sonnet, since you have to steer it less and it&#x27;s better at tool use, it is almost always faster than using a smaller model in the end.&quot;</p><p>For enterprise technology leaders, this is a critical insight. The bottleneck in modern AI development isn&#x27;t the generation speed of the token; it is the human time spent correcting the AI&#x27;s mistakes. Cherny&#x27;s workflow suggests that paying the &quot;compute tax&quot; for a smarter model upfront eliminates the &quot;correction tax&quot; later.</p><h2><b>One shared file turns every AI mistake into a permanent lesson</b></h2><p>Cherny also detailed how his team solves the problem of AI amnesia. Standard large language models do not &quot;remember&quot; a company&#x27;s specific coding style or architectural decisions from one session to the next.</p><p>To address this, Cherny&#x27;s team maintains a single file named <a href=\"https://x.com/bcherny/status/2007179842928947333\">CLAUDE.md</a> in their git repository. &quot;Anytime we see Claude do something incorrectly we add it to the CLAUDE.md, so Claude knows not to do it next time,&quot; he wrote.</p><p>This practice transforms the codebase into a self-correcting organism. When a human developer reviews a pull request and spots an error, they don&#x27;t just fix the code; they tag the AI to update its own instructions. &quot;<a href=\"https://x.com/aakashgupta/status/2007347705945944153\">Every mistake becomes a rule</a>,&quot; noted <a href=\"https://x.com/aakashgupta\">Aakash Gupta</a>, a product leader analyzing the thread. The longer the team works together, the smarter the agent becomes.</p><h2><b>Slash commands and subagents automate the most tedious parts of development</b></h2><p>The &quot;vanilla&quot; workflow one observer praised is powered by rigorous automation of repetitive tasks. Cherny uses slash commands — custom shortcuts checked into the project&#x27;s repository — to handle complex operations with a single keystroke.</p><p>He highlighted a command called <i><b>/commit-push-pr</b></i>, which he invokes dozens of times daily. Instead of manually typing git commands, writing a commit message, and opening a pull request, the agent handles the bureaucracy of version control autonomously.</p><p>Cherny also deploys subagents — specialized AI personas — to handle specific phases of the development lifecycle. He uses a code-simplifier to clean up architecture after the main work is done and a verify-app agent to run end-to-end tests before anything ships.</p><h2><b>Why verification loops are the real unlock for AI-generated code</b></h2><p>If there is a single reason Claude Code has reportedly hit <a href=\"https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone\">$1 billion in annual recurring revenue</a> so quickly, it is likely the verification loop. The AI is not just a text generator; it is a tester.</p><p>&quot;Claude tests every single change I land to claude.ai/code using the Claude Chrome extension,&quot; Cherny wrote. &quot;It opens a browser, tests the UI, and iterates until the code works and the UX feels good.&quot;</p><p>He argues that giving the AI a way to verify its own work — whether through browser automation, running bash commands, or executing test suites — improves the quality of the final result by &quot;2-3x.&quot; The agent doesn&#x27;t just write code; it proves the code works.</p><h2><b>What Cherny&#x27;s workflow signals about the future of software engineering</b></h2><p>The reaction to Cherny&#x27;s thread suggests a pivotal shift in how developers think about their craft. For years, &quot;AI coding&quot; meant an autocomplete function in a text editor — a faster way to type. Cherny has demonstrated that it can now function as an operating system for labor itself.</p><p>&quot;Read this if you&#x27;re already an engineer... and want more power,&quot; <a href=\"https://x.com/jefftangx/status/2008246873275215890\">Jeff Tang</a> summarized on X.</p><p>The tools to multiply human output by a factor of five are already here. They require only a willingness to stop thinking of AI as an assistant and start treating it as a workforce. The programmers who make that mental leap first won&#x27;t just be more productive. They&#x27;ll be playing an entirely different game — and everyone else will still be typing.</p>",
        "contentSnippet": "When the creator of the world's most advanced coding agent speaks, Silicon Valley doesn't just listen — it takes notes.\nFor the past week, the engineering community has been dissecting a thread on X from Boris Cherny, the creator and head of Claude Code at Anthropic. What began as a casual sharing of his personal terminal setup has spiraled into a viral manifesto on the future of software development, with industry insiders calling it a watershed moment for the startup.\n\n\"If you're not reading the Claude Code best practices straight from its creator, you're behind as a programmer,\" wrote Jeff Tang, a prominent voice in the developer community. Kyle McNease, another industry observer, went further, declaring that with Cherny's \"game-changing updates,\" Anthropic is \"on fire,\" potentially facing \"their ChatGPT moment.\"\nThe excitement stems from a paradox: Cherny's workflow is surprisingly simple, yet it allows a single human to operate with the output capacity of a small engineering department. As one user noted on X after implementing Cherny's setup, the experience \"feels more like Starcraft\" than traditional coding — a shift from typing syntax to commanding autonomous units.\nHere is an analysis of the workflow that is reshaping how software gets built, straight from the architect himself. \nHow running five AI agents at once turns coding into a real-time strategy game\nThe most striking revelation from Cherny's disclosure is that he does not code in a linear fashion. In the traditional \"inner loop\" of development, a programmer writes a function, tests it, and moves to the next. Cherny, however, acts as a fleet commander.\n\"I run 5 Claudes in parallel in my terminal,\" Cherny wrote. \"I number my tabs 1-5, and use system notifications to know when a Claude needs input.\"\nBy utilizing iTerm2 system notifications, Cherny effectively manages five simultaneous work streams. While one agent runs a test suite, another refactors a legacy module, and a third drafts documentation. He also runs \"5-10 Claudes on claude.ai\" in his browser, using a \"teleport\" command to hand off sessions between the web and his local machine.\nThis validates the \"do more with less\" strategy articulated by Anthropic President Daniela Amodei earlier this week. While competitors like OpenAI pursue trillion-dollar infrastructure build-outs, Anthropic is proving that superior orchestration of existing models can yield exponential productivity gains.\nThe counterintuitive case for choosing the slowest, smartest model\nIn a surprising move for an industry obsessed with latency, Cherny revealed that he exclusively uses Anthropic's heaviest, slowest model: Opus 4.5.\n\"I use Opus 4.5 with thinking for everything,\" Cherny explained. \"It's the best coding model I've ever used, and even though it's bigger & slower than Sonnet, since you have to steer it less and it's better at tool use, it is almost always faster than using a smaller model in the end.\"\nFor enterprise technology leaders, this is a critical insight. The bottleneck in modern AI development isn't the generation speed of the token; it is the human time spent correcting the AI's mistakes. Cherny's workflow suggests that paying the \"compute tax\" for a smarter model upfront eliminates the \"correction tax\" later.\nOne shared file turns every AI mistake into a permanent lesson\nCherny also detailed how his team solves the problem of AI amnesia. Standard large language models do not \"remember\" a company's specific coding style or architectural decisions from one session to the next.\nTo address this, Cherny's team maintains a single file named CLAUDE.md in their git repository. \"Anytime we see Claude do something incorrectly we add it to the CLAUDE.md, so Claude knows not to do it next time,\" he wrote.\nThis practice transforms the codebase into a self-correcting organism. When a human developer reviews a pull request and spots an error, they don't just fix the code; they tag the AI to update its own instructions. \"Every mistake becomes a rule,\" noted Aakash Gupta, a product leader analyzing the thread. The longer the team works together, the smarter the agent becomes.\nSlash commands and subagents automate the most tedious parts of development\nThe \"vanilla\" workflow one observer praised is powered by rigorous automation of repetitive tasks. Cherny uses slash commands — custom shortcuts checked into the project's repository — to handle complex operations with a single keystroke.\nHe highlighted a command called /commit-push-pr, which he invokes dozens of times daily. Instead of manually typing git commands, writing a commit message, and opening a pull request, the agent handles the bureaucracy of version control autonomously.\nCherny also deploys subagents — specialized AI personas — to handle specific phases of the development lifecycle. He uses a code-simplifier to clean up architecture after the main work is done and a verify-app agent to run end-to-end tests before anything ships.\nWhy verification loops are the real unlock for AI-generated code\nIf there is a single reason Claude Code has reportedly hit $1 billion in annual recurring revenue so quickly, it is likely the verification loop. The AI is not just a text generator; it is a tester.\n\"Claude tests every single change I land to claude.ai/code using the Claude Chrome extension,\" Cherny wrote. \"It opens a browser, tests the UI, and iterates until the code works and the UX feels good.\"\nHe argues that giving the AI a way to verify its own work — whether through browser automation, running bash commands, or executing test suites — improves the quality of the final result by \"2-3x.\" The agent doesn't just write code; it proves the code works.\nWhat Cherny's workflow signals about the future of software engineering\nThe reaction to Cherny's thread suggests a pivotal shift in how developers think about their craft. For years, \"AI coding\" meant an autocomplete function in a text editor — a faster way to type. Cherny has demonstrated that it can now function as an operating system for labor itself.\n\"Read this if you're already an engineer... and want more power,\" Jeff Tang summarized on X.\nThe tools to multiply human output by a factor of five are already here. They require only a willingness to stop thinking of AI as an assistant and start treating it as a workforce. The programmers who make that mental leap first won't just be more productive. They'll be playing an entirely different game — and everyone else will still be typing.",
        "pubDate": "Mon, 05 Jan 2026 07:45:00 GMT",
        "isoDate": "2026-01-05T07:45:00.000Z",
        "creator": "michael.nunez@venturebeat.com (Michael Nuñez)",
        "source": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are"
      }
    ],
    "ars-technica-safety-incident-13": [
      {
        "id": "rss-ars-technica-safety-incident-13-vwhed1",
        "title": "OpenClaw security fears lead Meta, other AI firms to restrict its use",
        "link": "https://arstechnica.com/ai/2026/02/openclaw-security-fears-lead-meta-other-ai-firms-to-restrict-its-use/",
        "url": "https://arstechnica.com/ai/2026/02/openclaw-security-fears-lead-meta-other-ai-firms-to-restrict-its-use/",
        "content": "\n                        The viral agentic AI tool is known for being highly capable but also wildly unpredictable.\n                    ",
        "contentSnippet": "The viral agentic AI tool is known for being highly capable but also wildly unpredictable.",
        "pubDate": "Thu, 19 Feb 2026 14:11:55 +0000",
        "isoDate": "2026-02-19T14:11:55.000Z",
        "creator": "\n                    Paresh Dave, wired.com\n                ",
        "source": "https://arstechnica.com/ai/2026/02/openclaw-security-fears-lead-meta-other-ai-firms-to-restrict-its-use/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-xttpbm",
        "title": "Rare gifted word-learner dogs like to share their toys",
        "link": "https://arstechnica.com/science/2026/02/rare-gifted-word-learner-dogs-like-to-share-their-toys/",
        "url": "https://arstechnica.com/science/2026/02/rare-gifted-word-learner-dogs-like-to-share-their-toys/",
        "content": "\n                        \"It raises the possibility that social motivation plays a role in why some dogs end up learning object names.\"\n                    ",
        "contentSnippet": "\"It raises the possibility that social motivation plays a role in why some dogs end up learning object names.\"",
        "pubDate": "Thu, 19 Feb 2026 13:32:52 +0000",
        "isoDate": "2026-02-19T13:32:52.000Z",
        "creator": "\n                    Jennifer Ouellette\n                ",
        "source": "https://arstechnica.com/science/2026/02/rare-gifted-word-learner-dogs-like-to-share-their-toys/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-uy3jrx",
        "title": "Verizon acknowledges \"pain\" of new unlock policy, suggests change is coming",
        "link": "https://arstechnica.com/tech-policy/2026/02/verizon-might-drop-its-annoying-35-day-wait-for-unlocking-paid-off-phones/",
        "url": "https://arstechnica.com/tech-policy/2026/02/verizon-might-drop-its-annoying-35-day-wait-for-unlocking-paid-off-phones/",
        "content": "\n                        Report: Verizon's goal is \"immediate unlock for all payment methods really soon.\"\n                    ",
        "contentSnippet": "Report: Verizon's goal is \"immediate unlock for all payment methods really soon.\"",
        "pubDate": "Wed, 18 Feb 2026 20:58:34 +0000",
        "isoDate": "2026-02-18T20:58:34.000Z",
        "creator": "\n                    Jon Brodkin\n                ",
        "source": "https://arstechnica.com/tech-policy/2026/02/verizon-might-drop-its-annoying-35-day-wait-for-unlocking-paid-off-phones/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-to0p3v",
        "title": "Chevy Bolt, BMW i3, or something else? At $10K, you have lots of EV options",
        "link": "https://arstechnica.com/cars/2026/02/chevy-bolt-bmw-i3-or-something-else-at-10k-you-have-lots-of-ev-options/",
        "url": "https://arstechnica.com/cars/2026/02/chevy-bolt-bmw-i3-or-something-else-at-10k-you-have-lots-of-ev-options/",
        "content": "\n                        Two of Ars' favorite electric vehicles are now available for not very much money.\n                    ",
        "contentSnippet": "Two of Ars' favorite electric vehicles are now available for not very much money.",
        "pubDate": "Wed, 18 Feb 2026 20:22:03 +0000",
        "isoDate": "2026-02-18T20:22:03.000Z",
        "creator": "\n                    Jonathan M. Gitlin\n                ",
        "source": "https://arstechnica.com/cars/2026/02/chevy-bolt-bmw-i3-or-something-else-at-10k-you-have-lots-of-ev-options/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-1pbrqo",
        "title": "Lawsuit: EPA revoking greenhouse gas finding risks “thousands of avoidable deaths”",
        "link": "https://arstechnica.com/tech-policy/2026/02/lawsuit-epa-revoking-greenhouse-gas-finding-risks-thousands-of-avoidable-deaths/",
        "url": "https://arstechnica.com/tech-policy/2026/02/lawsuit-epa-revoking-greenhouse-gas-finding-risks-thousands-of-avoidable-deaths/",
        "content": "\n                        EPA sued for abandoning its mission to protect public health.\n                    ",
        "contentSnippet": "EPA sued for abandoning its mission to protect public health.",
        "pubDate": "Wed, 18 Feb 2026 19:48:06 +0000",
        "isoDate": "2026-02-18T19:48:06.000Z",
        "creator": "\n                    Ashley Belanger\n                ",
        "source": "https://arstechnica.com/tech-policy/2026/02/lawsuit-epa-revoking-greenhouse-gas-finding-risks-thousands-of-avoidable-deaths/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-u7egej",
        "title": "5 changes to know about in Apple's latest iOS, macOS, and iPadOS betas",
        "link": "https://arstechnica.com/gadgets/2026/02/5-changes-to-know-about-in-apples-latest-ios-macos-and-ipados-betas/",
        "url": "https://arstechnica.com/gadgets/2026/02/5-changes-to-know-about-in-apples-latest-ios-macos-and-ipados-betas/",
        "content": "\n                        The 26.3 updates were mostly invisible; these changes are more significant.\n                    ",
        "contentSnippet": "The 26.3 updates were mostly invisible; these changes are more significant.",
        "pubDate": "Wed, 18 Feb 2026 19:28:26 +0000",
        "isoDate": "2026-02-18T19:28:26.000Z",
        "creator": "\n                    Andrew Cunningham\n                ",
        "source": "https://arstechnica.com/gadgets/2026/02/5-changes-to-know-about-in-apples-latest-ios-macos-and-ipados-betas/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-se321m",
        "title": "Microsoft's new 10,000-year data storage medium: glass",
        "link": "https://arstechnica.com/science/2026/02/microsofts-new-10000-year-data-storage-medium-glass/",
        "url": "https://arstechnica.com/science/2026/02/microsofts-new-10000-year-data-storage-medium-glass/",
        "content": "\n                        Femtosecond lasers etch data into a very stable medium.\n                    ",
        "contentSnippet": "Femtosecond lasers etch data into a very stable medium.",
        "pubDate": "Wed, 18 Feb 2026 19:01:55 +0000",
        "isoDate": "2026-02-18T19:01:55.000Z",
        "creator": "\n                    John Timmer\n                ",
        "source": "https://arstechnica.com/science/2026/02/microsofts-new-10000-year-data-storage-medium-glass/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-h83zx5",
        "title": "FDA reverses surprise rejection of Moderna's mRNA flu vaccine",
        "link": "https://arstechnica.com/health/2026/02/fda-does-u-turn-will-review-modernas-mrna-flu-shot-after-shocking-rejection/",
        "url": "https://arstechnica.com/health/2026/02/fda-does-u-turn-will-review-modernas-mrna-flu-shot-after-shocking-rejection/",
        "content": "\n                        Trump admin's vaccine chief overruled FDA scientists to initially reject the shot.\n                    ",
        "contentSnippet": "Trump admin's vaccine chief overruled FDA scientists to initially reject the shot.",
        "pubDate": "Wed, 18 Feb 2026 17:08:18 +0000",
        "isoDate": "2026-02-18T17:08:18.000Z",
        "creator": "\n                    Beth Mole\n                ",
        "source": "https://arstechnica.com/health/2026/02/fda-does-u-turn-will-review-modernas-mrna-flu-shot-after-shocking-rejection/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-8rg4fo",
        "title": "Record scratch—Google's Lyria 3 AI music model is coming to Gemini today",
        "link": "https://arstechnica.com/google/2026/02/gemini-can-now-generate-ai-music-for-you-no-lyrics-required/",
        "url": "https://arstechnica.com/google/2026/02/gemini-can-now-generate-ai-music-for-you-no-lyrics-required/",
        "content": "\n                        With a simple prompt, you can generate 30 seconds of something like music.\n                    ",
        "contentSnippet": "With a simple prompt, you can generate 30 seconds of something like music.",
        "pubDate": "Wed, 18 Feb 2026 16:00:11 +0000",
        "isoDate": "2026-02-18T16:00:11.000Z",
        "creator": "\n                    Ryan Whitwam\n                ",
        "source": "https://arstechnica.com/google/2026/02/gemini-can-now-generate-ai-music-for-you-no-lyrics-required/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-s039nw",
        "title": "Google's Pixel 10a arrives on March 5 for $499 with specs and design of yesteryear",
        "link": "https://arstechnica.com/gadgets/2026/02/googles-pixel-10a-arrives-on-march-5-for-499-with-specs-and-design-of-yesteryear/",
        "url": "https://arstechnica.com/gadgets/2026/02/googles-pixel-10a-arrives-on-march-5-for-499-with-specs-and-design-of-yesteryear/",
        "content": "\n                        Google's new budget phone is here, but don't expect a big upgrade. \n                    ",
        "contentSnippet": "Google's new budget phone is here, but don't expect a big upgrade.",
        "pubDate": "Wed, 18 Feb 2026 15:00:34 +0000",
        "isoDate": "2026-02-18T15:00:34.000Z",
        "creator": "\n                    Ryan Whitwam\n                ",
        "source": "https://arstechnica.com/gadgets/2026/02/googles-pixel-10a-arrives-on-march-5-for-499-with-specs-and-design-of-yesteryear/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-pqfwu7",
        "title": "X-rays reveal kingfisher feather structure in unprecedented detail",
        "link": "https://arstechnica.com/science/2026/02/what-the-chinese-art-of-tian-tsui-has-to-do-with-kingfishers/",
        "url": "https://arstechnica.com/science/2026/02/what-the-chinese-art-of-tian-tsui-has-to-do-with-kingfishers/",
        "content": "\n                        Synchrotron radiation imaging revealed a porous, almost sponge-like nanostructure to create bright hues\n                    ",
        "contentSnippet": "Synchrotron radiation imaging revealed a porous, almost sponge-like nanostructure to create bright hues",
        "pubDate": "Wed, 18 Feb 2026 14:24:36 +0000",
        "isoDate": "2026-02-18T14:24:36.000Z",
        "creator": "\n                    Jennifer Ouellette\n                ",
        "source": "https://arstechnica.com/science/2026/02/what-the-chinese-art-of-tian-tsui-has-to-do-with-kingfishers/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-7s516p",
        "title": "Inside the DHS forum where ICE agents trash talk one another",
        "link": "https://arstechnica.com/tech-policy/2026/02/inside-the-dhs-forum-where-ice-agents-trash-talk-one-another/",
        "url": "https://arstechnica.com/tech-policy/2026/02/inside-the-dhs-forum-where-ice-agents-trash-talk-one-another/",
        "content": "\n                        Forum members have discussed their discomfort with mass deportation efforts.\n                    ",
        "contentSnippet": "Forum members have discussed their discomfort with mass deportation efforts.",
        "pubDate": "Wed, 18 Feb 2026 14:14:06 +0000",
        "isoDate": "2026-02-18T14:14:06.000Z",
        "creator": "\n                    Vittoria Elliott, wired.com\n                ",
        "source": "https://arstechnica.com/tech-policy/2026/02/inside-the-dhs-forum-where-ice-agents-trash-talk-one-another/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-wkpscy",
        "title": "Hallucinogen DMT an effective antidepressant in small clinical trial",
        "link": "https://arstechnica.com/health/2026/02/hallucinogen-dmt-an-effective-antidepressant-in-small-clinical-trial/",
        "url": "https://arstechnica.com/health/2026/02/hallucinogen-dmt-an-effective-antidepressant-in-small-clinical-trial/",
        "content": "\n                        Effectiveness appears to correlate with self-described mystical experience.\n                    ",
        "contentSnippet": "Effectiveness appears to correlate with self-described mystical experience.",
        "pubDate": "Wed, 18 Feb 2026 12:00:37 +0000",
        "isoDate": "2026-02-18T12:00:37.000Z",
        "creator": "\n                    John Timmer\n                ",
        "source": "https://arstechnica.com/health/2026/02/hallucinogen-dmt-an-effective-antidepressant-in-small-clinical-trial/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-yscjih",
        "title": "GameHub will give Mac owners another imperfect way to play Windows games",
        "link": "https://arstechnica.com/gaming/2026/02/gamehub-will-give-mac-owners-another-imperfect-way-to-play-windows-games/",
        "url": "https://arstechnica.com/gaming/2026/02/gamehub-will-give-mac-owners-another-imperfect-way-to-play-windows-games/",
        "content": "\n                        GameHub's existing Windows emulator on Android has its fair share of issues.\n                    ",
        "contentSnippet": "GameHub's existing Windows emulator on Android has its fair share of issues.",
        "pubDate": "Tue, 17 Feb 2026 22:45:07 +0000",
        "isoDate": "2026-02-17T22:45:07.000Z",
        "creator": "\n                    Kyle Orland\n                ",
        "source": "https://arstechnica.com/gaming/2026/02/gamehub-will-give-mac-owners-another-imperfect-way-to-play-windows-games/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-ba36p2",
        "title": "Password managers' promise that they can't see your vaults isn't always true",
        "link": "https://arstechnica.com/security/2026/02/password-managers-promise-that-they-cant-see-your-vaults-isnt-always-true/",
        "url": "https://arstechnica.com/security/2026/02/password-managers-promise-that-they-cant-see-your-vaults-isnt-always-true/",
        "content": "\n                        Contrary to what password managers say, a server compromise can mean game over.\n                    ",
        "contentSnippet": "Contrary to what password managers say, a server compromise can mean game over.",
        "pubDate": "Tue, 17 Feb 2026 20:43:01 +0000",
        "isoDate": "2026-02-17T20:43:01.000Z",
        "creator": "\n                    Dan Goodin\n                ",
        "source": "https://arstechnica.com/security/2026/02/password-managers-promise-that-they-cant-see-your-vaults-isnt-always-true/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-rdnrgo",
        "title": "Stephen Colbert says CBS forbid interview of Democrat because of FCC threat",
        "link": "https://arstechnica.com/tech-policy/2026/02/stephen-colbert-says-cbs-forbid-interview-of-democrat-because-of-fcc-threat/",
        "url": "https://arstechnica.com/tech-policy/2026/02/stephen-colbert-says-cbs-forbid-interview-of-democrat-because-of-fcc-threat/",
        "content": "\n                        Colbert: \"I want to assure you this decision is for purely financial reasons.\"\n                    ",
        "contentSnippet": "Colbert: \"I want to assure you this decision is for purely financial reasons.\"",
        "pubDate": "Tue, 17 Feb 2026 19:01:05 +0000",
        "isoDate": "2026-02-17T19:01:05.000Z",
        "creator": "\n                    Jon Brodkin\n                ",
        "source": "https://arstechnica.com/tech-policy/2026/02/stephen-colbert-says-cbs-forbid-interview-of-democrat-because-of-fcc-threat/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-w3xrz9",
        "title": "Most VMware users still \"actively reducing their VMware footprint,\" survey finds",
        "link": "https://arstechnica.com/information-technology/2026/02/most-vmware-users-still-actively-reducing-their-vmware-footprint-survey-finds/",
        "url": "https://arstechnica.com/information-technology/2026/02/most-vmware-users-still-actively-reducing-their-vmware-footprint-survey-finds/",
        "content": "\n                        Broadcom's \"strategy was never to keep every customer,\" CloudBolt report says. \n                    ",
        "contentSnippet": "Broadcom's \"strategy was never to keep every customer,\" CloudBolt report says.",
        "pubDate": "Tue, 17 Feb 2026 18:38:10 +0000",
        "isoDate": "2026-02-17T18:38:10.000Z",
        "creator": "\n                    Scharon Harding\n                ",
        "source": "https://arstechnica.com/information-technology/2026/02/most-vmware-users-still-actively-reducing-their-vmware-footprint-survey-finds/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-jl5853",
        "title": "What happens to a car when the company behind its software goes under?",
        "link": "https://arstechnica.com/cars/2026/02/what-happens-to-a-car-when-the-company-behind-its-software-goes-under/",
        "url": "https://arstechnica.com/cars/2026/02/what-happens-to-a-car-when-the-company-behind-its-software-goes-under/",
        "content": "\n                        Connected car servers won't be online indefinitely, and startups often go bust.\n                    ",
        "contentSnippet": "Connected car servers won't be online indefinitely, and startups often go bust.",
        "pubDate": "Tue, 17 Feb 2026 18:15:31 +0000",
        "isoDate": "2026-02-17T18:15:31.000Z",
        "creator": "\n                    Matthew MacConnell\n                ",
        "source": "https://arstechnica.com/cars/2026/02/what-happens-to-a-car-when-the-company-behind-its-software-goes-under/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-n93eo2",
        "title": "RAM shortage hits Valve's four-year-old Steam Deck, now available \"intermittently\"",
        "link": "https://arstechnica.com/gadgets/2026/02/valves-steam-deck-intermittently-out-of-stock-as-ram-shortage-drags-on/",
        "url": "https://arstechnica.com/gadgets/2026/02/valves-steam-deck-intermittently-out-of-stock-as-ram-shortage-drags-on/",
        "content": "\n                        Forget launching new stuff—Valve is even having problems with existing hardware.\n                    ",
        "contentSnippet": "Forget launching new stuff—Valve is even having problems with existing hardware.",
        "pubDate": "Tue, 17 Feb 2026 17:56:14 +0000",
        "isoDate": "2026-02-17T17:56:14.000Z",
        "creator": "\n                    Andrew Cunningham\n                ",
        "source": "https://arstechnica.com/gadgets/2026/02/valves-steam-deck-intermittently-out-of-stock-as-ram-shortage-drags-on/"
      },
      {
        "id": "rss-ars-technica-safety-incident-13-xsxna8",
        "title": "Warner Bros. rejects Paramount again but asks for \"best and final offer\"",
        "link": "https://arstechnica.com/tech-policy/2026/02/warner-bros-gives-paramount-one-more-week-to-beat-netflix-merger-offer/",
        "url": "https://arstechnica.com/tech-policy/2026/02/warner-bros-gives-paramount-one-more-week-to-beat-netflix-merger-offer/",
        "content": "\n                        WB board officially recommends Netflix deal but asks Paramount to increase price.\n                    ",
        "contentSnippet": "WB board officially recommends Netflix deal but asks Paramount to increase price.",
        "pubDate": "Tue, 17 Feb 2026 17:17:17 +0000",
        "isoDate": "2026-02-17T17:17:17.000Z",
        "creator": "\n                    Jon Brodkin\n                ",
        "source": "https://arstechnica.com/tech-policy/2026/02/warner-bros-gives-paramount-one-more-week-to-beat-netflix-merger-offer/"
      }
    ],
    "krebs-on-security-safety-incident-14": [
      {
        "id": "rss-krebs-on-security-safety-incident-14-xqkmku",
        "title": "Kimwolf Botnet Swamps Anonymity Network I2P",
        "link": "https://krebsonsecurity.com/2026/02/kimwolf-botnet-swamps-anonymity-network-i2p/",
        "url": "https://krebsonsecurity.com/2026/02/kimwolf-botnet-swamps-anonymity-network-i2p/",
        "content": "For the past week, the massive \"Internet of Things\" (IoT) botnet known as Kimwolf has been disrupting the The Invisible Internet Project (I2P), a decentralized, encrypted communications network designed to anonymize and secure online communications. I2P users started reporting disruptions in the network around the same time the Kimwolf botmasters began relying on it to evade takedown attempts against the botnet's control servers.",
        "contentSnippet": "For the past week, the massive \"Internet of Things\" (IoT) botnet known as Kimwolf has been disrupting the The Invisible Internet Project (I2P), a decentralized, encrypted communications network designed to anonymize and secure online communications. I2P users started reporting disruptions in the network around the same time the Kimwolf botmasters began relying on it to evade takedown attempts against the botnet's control servers.",
        "pubDate": "Wed, 11 Feb 2026 16:08:11 +0000",
        "isoDate": "2026-02-11T16:08:11.000Z",
        "creator": "BrianKrebs",
        "source": "https://krebsonsecurity.com/2026/02/kimwolf-botnet-swamps-anonymity-network-i2p/"
      },
      {
        "id": "rss-krebs-on-security-safety-incident-14-wjd3yl",
        "title": "Patch Tuesday, February 2026 Edition",
        "link": "https://krebsonsecurity.com/2026/02/patch-tuesday-february-2026-edition/",
        "url": "https://krebsonsecurity.com/2026/02/patch-tuesday-february-2026-edition/",
        "content": "Microsoft today released updates to fix more than 50 security holes in its Windows operating systems and other software, including patches for a whopping six \"zero-day\" vulnerabilities that attackers are already exploiting in the wild.",
        "contentSnippet": "Microsoft today released updates to fix more than 50 security holes in its Windows operating systems and other software, including patches for a whopping six \"zero-day\" vulnerabilities that attackers are already exploiting in the wild.",
        "pubDate": "Tue, 10 Feb 2026 21:49:53 +0000",
        "isoDate": "2026-02-10T21:49:53.000Z",
        "creator": "BrianKrebs",
        "source": "https://krebsonsecurity.com/2026/02/patch-tuesday-february-2026-edition/"
      },
      {
        "id": "rss-krebs-on-security-safety-incident-14-uyc22s",
        "title": "Please Don’t Feed the Scattered Lapsus ShinyHunters",
        "link": "https://krebsonsecurity.com/2026/02/please-dont-feed-the-scattered-lapsus-shiny-hunters/",
        "url": "https://krebsonsecurity.com/2026/02/please-dont-feed-the-scattered-lapsus-shiny-hunters/",
        "content": "A prolific data ransom gang that calls itself Scattered Lapsus ShinyHunters (SLSH) has a distinctive playbook when it seeks to extort payment from victim firms: Harassing, threatening and even swatting executives and their families, all while notifying journalists and regulators… <span class=\"read-more\"><a href=\"https://krebsonsecurity.com/2026/02/please-dont-feed-the-scattered-lapsus-shiny-hunters/\">Read More &#187;</a></span>",
        "contentSnippet": "A prolific data ransom gang that calls itself Scattered Lapsus ShinyHunters (SLSH) has a distinctive playbook when it seeks to extort payment from victim firms: Harassing, threatening and even swatting executives and their families, all while notifying journalists and regulators… Read More »",
        "pubDate": "Mon, 02 Feb 2026 16:15:16 +0000",
        "isoDate": "2026-02-02T16:15:16.000Z",
        "creator": "BrianKrebs",
        "source": "https://krebsonsecurity.com/2026/02/please-dont-feed-the-scattered-lapsus-shiny-hunters/"
      },
      {
        "id": "rss-krebs-on-security-safety-incident-14-n4zmex",
        "title": "Who Operates the Badbox 2.0 Botnet?",
        "link": "https://krebsonsecurity.com/2026/01/who-operates-the-badbox-2-0-botnet/",
        "url": "https://krebsonsecurity.com/2026/01/who-operates-the-badbox-2-0-botnet/",
        "content": "The cybercriminals in control of Kimwolf -- a disruptive botnet that has infected more than 2 million devices -- recently shared a screenshot indicating they'd compromised the control panel for Badbox 2.0, a vast China-based botnet powered by malicious software that comes pre-installed on many Android TV streaming boxes. Both the FBI and Google say they are hunting for the people behind Badbox 2.0, and thanks to bragging by the Kimwolf botmasters we may now have a much clearer idea about that.",
        "contentSnippet": "The cybercriminals in control of Kimwolf -- a disruptive botnet that has infected more than 2 million devices -- recently shared a screenshot indicating they'd compromised the control panel for Badbox 2.0, a vast China-based botnet powered by malicious software that comes pre-installed on many Android TV streaming boxes. Both the FBI and Google say they are hunting for the people behind Badbox 2.0, and thanks to bragging by the Kimwolf botmasters we may now have a much clearer idea about that.",
        "pubDate": "Mon, 26 Jan 2026 16:11:38 +0000",
        "isoDate": "2026-01-26T16:11:38.000Z",
        "creator": "BrianKrebs",
        "source": "https://krebsonsecurity.com/2026/01/who-operates-the-badbox-2-0-botnet/"
      },
      {
        "id": "rss-krebs-on-security-safety-incident-14-g4blbb",
        "title": "Kimwolf Botnet Lurking in Corporate, Govt. Networks",
        "link": "https://krebsonsecurity.com/2026/01/kimwolf-botnet-lurking-in-corporate-govt-networks/",
        "url": "https://krebsonsecurity.com/2026/01/kimwolf-botnet-lurking-in-corporate-govt-networks/",
        "content": "A new Internet-of-Things botnet called Kimwolf has spread to more than 2 million devices, forcing infected systems to participate in massive distributed denial-of-service (DDoS) attacks and to relay other malicious and abusive Internet traffic. Kimwolf's ability to scan the local networks of compromised systems for other IoT devices to infect makes it a sobering threat to organizations, and new research reveals Kimwolf is surprisingly prevalent in government and corporate networks.",
        "contentSnippet": "A new Internet-of-Things botnet called Kimwolf has spread to more than 2 million devices, forcing infected systems to participate in massive distributed denial-of-service (DDoS) attacks and to relay other malicious and abusive Internet traffic. Kimwolf's ability to scan the local networks of compromised systems for other IoT devices to infect makes it a sobering threat to organizations, and new research reveals Kimwolf is surprisingly prevalent in government and corporate networks.",
        "pubDate": "Tue, 20 Jan 2026 18:19:13 +0000",
        "isoDate": "2026-01-20T18:19:13.000Z",
        "creator": "BrianKrebs",
        "source": "https://krebsonsecurity.com/2026/01/kimwolf-botnet-lurking-in-corporate-govt-networks/"
      },
      {
        "id": "rss-krebs-on-security-safety-incident-14-xo7xhm",
        "title": "Patch Tuesday, January 2026 Edition",
        "link": "https://krebsonsecurity.com/2026/01/patch-tuesday-january-2026-edition/",
        "url": "https://krebsonsecurity.com/2026/01/patch-tuesday-january-2026-edition/",
        "content": "Microsoft today issued patches to plug at least 113 security holes in its various Windows operating systems and supported software. Eight of the vulnerabilities earned Microsoft's most-dire \"critical\" rating, and the company warns that attackers are already exploiting one of the bugs fixed today.",
        "contentSnippet": "Microsoft today issued patches to plug at least 113 security holes in its various Windows operating systems and supported software. Eight of the vulnerabilities earned Microsoft's most-dire \"critical\" rating, and the company warns that attackers are already exploiting one of the bugs fixed today.",
        "pubDate": "Wed, 14 Jan 2026 00:47:38 +0000",
        "isoDate": "2026-01-14T00:47:38.000Z",
        "creator": "BrianKrebs",
        "source": "https://krebsonsecurity.com/2026/01/patch-tuesday-january-2026-edition/"
      },
      {
        "id": "rss-krebs-on-security-safety-incident-14-2j0nix",
        "title": "Who Benefited from the Aisuru and Kimwolf Botnets?",
        "link": "https://krebsonsecurity.com/2026/01/who-benefited-from-the-aisuru-and-kimwolf-botnets/",
        "url": "https://krebsonsecurity.com/2026/01/who-benefited-from-the-aisuru-and-kimwolf-botnets/",
        "content": "Our first story of 2026 revealed how a destructive new botnet called Kimwolf rapidly grew to infect more than two million devices by mass-compromising a vast number of unofficial Android TV streaming boxes. Today, we'll dig through digital clues left behind by the hackers, network operators, and cybercrime services that appear to have benefitted from Kimwolf's spread.",
        "contentSnippet": "Our first story of 2026 revealed how a destructive new botnet called Kimwolf rapidly grew to infect more than two million devices by mass-compromising a vast number of unofficial Android TV streaming boxes. Today, we'll dig through digital clues left behind by the hackers, network operators, and cybercrime services that appear to have benefitted from Kimwolf's spread.",
        "pubDate": "Thu, 08 Jan 2026 23:23:43 +0000",
        "isoDate": "2026-01-08T23:23:43.000Z",
        "creator": "BrianKrebs",
        "source": "https://krebsonsecurity.com/2026/01/who-benefited-from-the-aisuru-and-kimwolf-botnets/"
      },
      {
        "id": "rss-krebs-on-security-safety-incident-14-gs08at",
        "title": "The Kimwolf Botnet is Stalking Your Local Network",
        "link": "https://krebsonsecurity.com/2026/01/the-kimwolf-botnet-is-stalking-your-local-network/",
        "url": "https://krebsonsecurity.com/2026/01/the-kimwolf-botnet-is-stalking-your-local-network/",
        "content": "The story you are reading is a series of scoops nestled inside a far more urgent Internet-wide security advisory. The vulnerability at issue has been exploited for months already, and it's time for a broader awareness of the threat. The short version is that everything you thought you knew about the security of the internal network behind your Internet router probably is now dangerously out of date.",
        "contentSnippet": "The story you are reading is a series of scoops nestled inside a far more urgent Internet-wide security advisory. The vulnerability at issue has been exploited for months already, and it's time for a broader awareness of the threat. The short version is that everything you thought you knew about the security of the internal network behind your Internet router probably is now dangerously out of date.",
        "pubDate": "Fri, 02 Jan 2026 14:20:10 +0000",
        "isoDate": "2026-01-02T14:20:10.000Z",
        "creator": "BrianKrebs",
        "source": "https://krebsonsecurity.com/2026/01/the-kimwolf-botnet-is-stalking-your-local-network/"
      },
      {
        "id": "rss-krebs-on-security-safety-incident-14-ppxycz",
        "title": "Happy 16th Birthday, KrebsOnSecurity.com!",
        "link": "https://krebsonsecurity.com/2025/12/happy-16th-birthday-krebsonsecurity-com/",
        "url": "https://krebsonsecurity.com/2025/12/happy-16th-birthday-krebsonsecurity-com/",
        "content": "KrebsOnSecurity.com celebrates its 16th anniversary today! A huge \"thank you\" to all of our readers -- newcomers, long-timers and drive-by critics alike. Your engagement this past year here has been tremendous and truly a salve on a handful of dark days. Happily, comeuppance was a strong theme running through our coverage in 2025, with a primary focus on entities that enabled complex and globally-dispersed cybercrime services.",
        "contentSnippet": "KrebsOnSecurity.com celebrates its 16th anniversary today! A huge \"thank you\" to all of our readers -- newcomers, long-timers and drive-by critics alike. Your engagement this past year here has been tremendous and truly a salve on a handful of dark days. Happily, comeuppance was a strong theme running through our coverage in 2025, with a primary focus on entities that enabled complex and globally-dispersed cybercrime services.",
        "pubDate": "Mon, 29 Dec 2025 20:23:26 +0000",
        "isoDate": "2025-12-29T20:23:26.000Z",
        "creator": "BrianKrebs",
        "source": "https://krebsonsecurity.com/2025/12/happy-16th-birthday-krebsonsecurity-com/"
      },
      {
        "id": "rss-krebs-on-security-safety-incident-14-cmer1u",
        "title": "Dismantling Defenses: Trump 2.0 Cyber Year in Review",
        "link": "https://krebsonsecurity.com/2025/12/dismantling-defenses-trump-2-0-cyber-year-in-review/",
        "url": "https://krebsonsecurity.com/2025/12/dismantling-defenses-trump-2-0-cyber-year-in-review/",
        "content": "The Trump administration has pursued a staggering range of policy pivots this past year that threaten to weaken the nation’s ability and willingness to address a broad spectrum of technology challenges, from cybersecurity and privacy to countering disinformation, fraud and corruption. These shifts, along with the president’s efforts to restrict free speech and freedom of the press, have come at such a rapid clip that many readers probably aren’t even aware of them all.",
        "contentSnippet": "The Trump administration has pursued a staggering range of policy pivots this past year that threaten to weaken the nation’s ability and willingness to address a broad spectrum of technology challenges, from cybersecurity and privacy to countering disinformation, fraud and corruption. These shifts, along with the president’s efforts to restrict free speech and freedom of the press, have come at such a rapid clip that many readers probably aren’t even aware of them all.",
        "pubDate": "Fri, 19 Dec 2025 15:14:55 +0000",
        "isoDate": "2025-12-19T15:14:55.000Z",
        "creator": "BrianKrebs",
        "source": "https://krebsonsecurity.com/2025/12/dismantling-defenses-trump-2-0-cyber-year-in-review/"
      }
    ],
    "ieee-spectrum-energy-environment-18": [
      {
        "id": "rss-ieee-spectrum-energy-environment-18-7k6rh8",
        "title": "IEEE Course Improves Engineers’ Writing Skills",
        "link": "https://spectrum.ieee.org/ieee-course-technical-writing",
        "url": "https://spectrum.ieee.org/ieee-course-technical-writing",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/a-collage-of-a-smiling-man-holding-a-laptop-on-a-backdrop-of-graph-paper-and-lines.jpg?id=64957405&width=1245&height=700&coordinates=0%2C156%2C0%2C157\"/><br/><br/><p>In the rapidly evolving world of engineering technology, professionals devote enormous energy to such tasks as mastering the latest frameworks, optimizing architectures, and refining machine learning models. It’s easy to let technical expertise become the sole measure of professional value. However, one of the most important skills an engineer can develop is the capacity to write and <a data-linked-post=\"2671351307\" href=\"https://spectrum.ieee.org/5-tips-technical-presentations\" target=\"_blank\">communicate effectively</a>.</p><p>Whether you’re conducting research at a university or leading systems development projects at a global firm, your expertise can become impactful only when you share it in a way that others can understand and act upon. Without a clear narrative, even groundbreaking data or innovative designs can fail to gain traction, limiting their reach among colleagues and stakeholders, and in <a data-linked-post=\"2667172498\" href=\"https://spectrum.ieee.org/ai-peer-review\" target=\"_blank\">peer‑reviewed journals</a>.</p><h2>The cost of the “soft skill” misnomer</h2><p>Writing is often labeled a “soft skill”—which can diminish its importance. In reality, communication is a core engineering competency. It lets us document methods, articulate research findings, and persuade decision-makers who determine whether projects move forward.</p><p>If your writing is dense, disorganized, or overloaded with technical jargon, the value of the underlying work can become obscured. A strong proposal might be dismissed not because the idea lacks merit but because the justification is difficult to follow.</p><p>Clear writing can strengthen the impact of your work. Poor writing can distract from the points you’re trying to make, as readers might not understand what you’re saying.</p><h2>The architecture of authority</h2><p>Technical writing differs from other forms of prose because readers expect information to follow predictable, logical patterns. Unclear writing can leave readers unsure of the author’s intent.</p><p>One of the most enduring frameworks for writing about technology in an understandable manner is the <a href=\"https://link.springer.com/article/10.1007/s10980-011-9674-3\" rel=\"noopener noreferrer\" target=\"_blank\">IMRaD</a> structure: introduction, methods, results, and discussion.</p><ul><li><strong>Introduction:</strong> Define the problem and its relevance.</li><li><strong>Methods:</strong> Detail the approach and justify the choices.</li><li><strong>Results:</strong> Present the empirical findings.</li><li><strong>Discussion:</strong> Interpret the outcomes and their implications.</li></ul><p>More than just a template for academic papers, IMRaD is a road map for logical reasoning. Mastering the structure can help engineers communicate in a way that aligns with professional writing standards used in technical journals, so their work is better understood and more respected.</p><h2>Bridging the training gap</h2><p>Despite technical communication’s importance, engineering curricula often limit or lack formal instruction in it.</p><p>Recognizing that gap, IEEE has expanded its role as a global knowledge leader by offering <a href=\"https://iln.ieee.org/Public/ContentDetails.aspx?id=D7A52928C69F4D9788D0709D499DDD12&_gl=1*vca24v*_gcl_au*MTU3OTE4ODg1Ny4xNzY5NjMwMjQx*_ga*MTg3NTQ1NDYxNi4xNzY5NjE1MTgw*_ga_H0YHKP362D*czE3Njk4MDIyOTYkbzckZzEkdDE3Njk4MDI0OTMkajkkbDAkaDA.&_ga=2.1702449.1451088539.1769615184-1875454616.1769615180\" rel=\"noopener noreferrer\" target=\"_blank\">From Research to Publication: A Step-by-Step Guide to Technical Writing</a>. The course is led by <a href=\"https://www.duffield.cornell.edu/people/traci-nathans-kelly/\" rel=\"noopener noreferrer\" target=\"_blank\">Traci Nathans-Kelly</a>, director of the engineering communications program at Cornell.</p><p>Developed by <a href=\"https://ea.ieee.org\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Educational Activities</a> and the <a href=\"https://procomm.ieee.org/?_gl=1*13pejq1*_gcl_au*MTU3OTE4ODg1Ny4xNzY5NjMwMjQx&_ga=2.1702449.1451088539.1769615184-1875454616.1769615180\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Professional Communication Society</a>, the learning opportunity goes beyond foundational writing skills. It addresses today’s challenges, such as the ethical use of generative AI in the writing workflow, the complexities of team-based authorship, and publishing strategies.</p><p>The program centers on core skill areas that can influence an engineer’s ability to communicate. Participants learn to master the IMRaD structure and learn advanced editing techniques to help strip away jargon, making complex ideas more accessible. In addition, the course covers strategic approaches to publishing work in high‑impact journals and improving a writer’s visibility within the technical community.</p><p>The course is available on the <a href=\"https://iln.ieee.org/Public/ContentDetails.aspx?id=D7A52928C69F4D9788D0709D499DDD12&_gl=1*vca24v*_gcl_au*MTU3OTE4ODg1Ny4xNzY5NjMwMjQx*_ga*MTg3NTQ1NDYxNi4xNzY5NjE1MTgw*_ga_H0YHKP362D*czE3Njk4MDIyOTYkbzckZzEkdDE3Njk4MDI0OTMkajkkbDAkaDA.&_ga=2.1702449.1451088539.1769615184-1875454616.1769615180\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Learning Network</a>. Participants earn professional development credit and a shareable digital badge. IEEE members receive a US $100 discount. Organizations can <a href=\"https://forms1.ieee.org/Guide-to-Technical-Writing.html?LT=LG_WB_Innovate_LM_eLearning_Library_Course_Program&_gl=1*muuk62*_gcl_au*NjQ3Mzk3MDY5LjE3NjUzMDI5NzQ.\" rel=\"noopener noreferrer\" target=\"_blank\">connect with an IEEE content specialist</a> to offer the training to their teams.</p>",
        "contentSnippet": "In the rapidly evolving world of engineering technology, professionals devote enormous energy to such tasks as mastering the latest frameworks, optimizing architectures, and refining machine learning models. It’s easy to let technical expertise become the sole measure of professional value. However, one of the most important skills an engineer can develop is the capacity to write and communicate effectively.\nWhether you’re conducting research at a university or leading systems development projects at a global firm, your expertise can become impactful only when you share it in a way that others can understand and act upon. Without a clear narrative, even groundbreaking data or innovative designs can fail to gain traction, limiting their reach among colleagues and stakeholders, and in peer‑reviewed journals.\nThe cost of the “soft skill” misnomer\nWriting is often labeled a “soft skill”—which can diminish its importance. In reality, communication is a core engineering competency. It lets us document methods, articulate research findings, and persuade decision-makers who determine whether projects move forward.\nIf your writing is dense, disorganized, or overloaded with technical jargon, the value of the underlying work can become obscured. A strong proposal might be dismissed not because the idea lacks merit but because the justification is difficult to follow.\nClear writing can strengthen the impact of your work. Poor writing can distract from the points you’re trying to make, as readers might not understand what you’re saying.\nThe architecture of authority\nTechnical writing differs from other forms of prose because readers expect information to follow predictable, logical patterns. Unclear writing can leave readers unsure of the author’s intent.\nOne of the most enduring frameworks for writing about technology in an understandable manner is the IMRaD structure: introduction, methods, results, and discussion.\n\nIntroduction: Define the problem and its relevance.\nMethods: Detail the approach and justify the choices.\nResults: Present the empirical findings.\nDiscussion: Interpret the outcomes and their implications.\n\nMore than just a template for academic papers, IMRaD is a road map for logical reasoning. Mastering the structure can help engineers communicate in a way that aligns with professional writing standards used in technical journals, so their work is better understood and more respected.\nBridging the training gap\nDespite technical communication’s importance, engineering curricula often limit or lack formal instruction in it.\nRecognizing that gap, IEEE has expanded its role as a global knowledge leader by offering From Research to Publication: A Step-by-Step Guide to Technical Writing. The course is led by Traci Nathans-Kelly, director of the engineering communications program at Cornell.\nDeveloped by IEEE Educational Activities and the IEEE Professional Communication Society, the learning opportunity goes beyond foundational writing skills. It addresses today’s challenges, such as the ethical use of generative AI in the writing workflow, the complexities of team-based authorship, and publishing strategies.\nThe program centers on core skill areas that can influence an engineer’s ability to communicate. Participants learn to master the IMRaD structure and learn advanced editing techniques to help strip away jargon, making complex ideas more accessible. In addition, the course covers strategic approaches to publishing work in high‑impact journals and improving a writer’s visibility within the technical community.\nThe course is available on the IEEE Learning Network. Participants earn professional development credit and a shareable digital badge. IEEE members receive a US $100 discount. Organizations can connect with an IEEE content specialist to offer the training to their teams.",
        "pubDate": "Wed, 18 Feb 2026 19:00:03 +0000",
        "isoDate": "2026-02-18T19:00:03.000Z",
        "creator": "Angelique Parashis",
        "source": "https://spectrum.ieee.org/ieee-course-technical-writing"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-sql09b",
        "title": "Tomorrow’s Smart Pills Will Deliver Drugs and Take Biopsies",
        "link": "https://spectrum.ieee.org/ingestible-electronics",
        "url": "https://spectrum.ieee.org/ingestible-electronics",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/miniature-figures-in-lab-coats-seated-inside-half-of-a-red-capsule-next-to-a-circuit-board.png?id=64957587&width=1245&height=700&coordinates=0%2C77%2C0%2C77\"/><br/><br/><p><strong>One day soon, </strong>a doctor might prescribe a pill that doesn’t just deliver medicine but also reports back on what it finds inside you—and then takes actions based on its findings.</p><p>Instead of scheduling an endoscopy or CT scan, you’d swallow an electronic capsule smaller than a multivitamin. As it travels through your digestive system, it could check tissue health, look for cancerous changes, and send data to your doctor. It could even release drugs exactly where they’re needed or snip a tiny biopsy sample before passing harmlessly out of your body.</p><p>This dream of a do-it-all pill is driving a surge of research into ingestible electronics: smart capsules designed to monitor and even treat disease from inside the gastrointestinal (GI) tract. The stakes are high. GI diseases affect tens of millions of people worldwide, including such ailments as <a href=\"https://www.mayoclinic.org/diseases-conditions/inflammatory-bowel-disease/symptoms-causes/syc-20353315\" target=\"_blank\">inflammatory bowel disease</a>, <a href=\"https://www.mayoclinic.org/diseases-conditions/celiac-disease/symptoms-causes/syc-20352220\" target=\"_blank\">celiac disease</a>, and small intestinal bacterial overgrowth. Diagnosis often involves a frustrating maze of blood tests, imaging, and invasive endoscopy. Treatments, meanwhile, can bring serious side effects because drugs affect the whole body, not just the troubled gut.</p><p>If capsules could handle much of that work—streamlining diagnosis, delivering targeted therapies, and sparing patients repeated invasive procedures—they could transform care. Over the past 20 years, researchers have built a growing tool kit of ingestible devices, some already in clinical use. These capsule-shaped devices typically contain sensors, circuitry, a power source, and sometimes a communication module, all enclosed in a biocompatible shell. But the next leap forward is still in development: autonomous capsules that can both sense and act, releasing a drug or taking a tissue sample.</p><p>That’s the challenge that our lab—the <a href=\"https://umdmsal.com/\" target=\"_blank\">MEMS Sensors and Actuators Laboratory</a> (MSAL) at the University of Maryland, College Park—is tackling. Drawing on decades of advances in <a href=\"https://spectrum.ieee.org/collections/mems-at-40/\" target=\"_self\">microelectromechanical systems</a> (MEMS), we’re building swallowable devices that integrate sensors, actuators, and wireless links in packages that are small and safe enough for patients. The hurdles are considerable: power, miniaturization, biocompatibility, and reliability, to name a few. But the potential payoff will be a new era of personalized and minimally invasive medicine, delivered by something as simple as a pill you can swallow at home.</p><h2>The Origin of Ingestible Devices </h2><p>The idea of a smart capsule has been around since the late 1950s, when researchers first experimented with swallowable devices to record temperature, gastric pH, or pressure inside the digestive tract. At the time, it seemed closer to science fiction than clinical reality, bolstered by pop-culture visions like the 1966 film <a href=\"https://en.wikipedia.org/wiki/Fantastic_Voyage\" target=\"_blank\"><em><em>Fantastic Voyage</em></em></a>, where miniaturized doctors travel inside the human body to treat a blood clot.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"A gloved hand holds a small electronic capsule, with a researcher in lab safety gear blurred in the background.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"804393e2863a310effa646fe1f2fe8af\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"d9098\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-gloved-hand-holds-a-small-electronic-capsule-with-a-researcher-in-lab-safety-gear-blurred-in-the-background.png?id=64075029&width=980\"/><small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">One of the authors (Ghodssi) holds a miniaturized drug-delivery capsule that’s designed to release medication at specific sites in the gastrointestinal tract.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Maximilian Franz/Engineering at Maryland Magazine </small></p><p>For decades, though, the mainstay of GI diagnostics was endoscopy: a camera on a flexible tube, threaded down the throat or up through the colon. These procedures are quite invasive and require patients to be sedated, which increases both the risk of complications and procedural costs. What’s more, it’s difficult for endoscopes to safely traverse the circuitous pathway of the small intestine. The situation changed in the early 2000s, when video-capsule endoscopy arrived. The best-known product, <a href=\"https://www.medtronic.com/en-us/healthcare-professionals/products/digestive-gastrointestinal/capsule-endoscopy/endoscopy-systems/pillcam-sb-3-capsule-endoscopy-system.html\" target=\"_blank\">PillCam</a>, looks like a large vitamin but contains a camera, LEDs, and a transmitter. As it passes through the gut, it beams images and videos to a wearable device.</p><p>Today, capsule endoscopy is a routine tool in gastroenterology; ingestible devices can measure acidity, temperature, or gas concentrations. And researchers are pushing further, with experimental prototypes that deliver drugs or analyze the microbiome. For example, teams from <a href=\"https://engineering.tufts.edu/news-events/news/ingestible-microbiome-sampling-pill-technology-advances\" target=\"_blank\">Tufts University</a>, in Massachusetts, and <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S1742706125002685\" target=\"_blank\">Purdue University</a>, in Indiana, are working on devices with dissolvable coatings and mechanisms to collect <a href=\"https://spectrum.ieee.org/swallowable-robotic-pill-gut-health\" target=\"_blank\">samples of liquid</a> for studies of the intestinal microbiome.</p><p>Still, all those devices are passive. They activate on a timer or by exposure to the neutral pH of the intestines, but they don’t adapt to conditions in real time. The next step requires capsules that can sense biomarkers, make decisions, and trigger specific actions—moving from clever hardware to truly autonomous “smart pills.” That’s where our work comes in.</p><h2>Building on MEMS technology </h2><p>Since 2017, MSAL has been pushing ingestible devices forward with the goal of making an immediate impact in health care. The group built on the MEMS community’s legacy in microfabrication, sensors, and system integration, while taking advantage of new tools like 3D printing and materials like biocompatible polymers. Those advances have made it possible to prototype faster and shrink devices smaller, sparking a wave of innovation in wearables, implants, and now ingestibles. Today, MSAL is collaborating with engineers, physicians, and data scientists to move these capsules from lab benches to pharmaceutical trials.</p><p>As a first step, back in 2017, we set out to design sensor-carrying capsules that could reliably reach the small intestine and indicate when they reached it. Another challenge was that sensors that work well on the benchtop can falter inside the gut, where shifting pH, moisture, digestive enzymes, and low-oxygen conditions can degrade typical sensing components.</p><p> Our earliest prototype adapted MEMS sensing technology to <a href=\"https://pubs.rsc.org/en/content/articlelanding/2020/lc/d0lc00133c\" target=\"_blank\">detect abnormal enzyme levels</a> in the duodenum that are linked to pancreatic function. The sensor and its associated electronics were enclosed in a biocompatible, 3D-printed shell coated with polymers that dissolved only at certain pH levels. This strategy could one day be used to detect biomarkers in secretions from the pancreas to detect early-stage cancer.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-float-left rm-resized-container rm-resized-container-25\" data-rm-resized-container=\"25%\" style=\"float: left;\"> <img alt=\"High-speed footage shows a small mechanical arm extending from a capsule and contacting intestinal tissue.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"0755148f67e43a08b6fad935757e7959\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"b0383\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/high-speed-footage-shows-a-small-mechanical-arm-extending-from-a-capsule-and-contacting-intestinal-tissue.gif?id=64075037&width=980\"/><small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">A high-speed video shows how a capsule deploys microneedles to deliver drugs into intestinal tissue.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\"><a href=\"https://www.cell.com/device/fulltext/S2666-9986(24)00281-3\" rel=\"noopener noreferrer\" target=\"_blank\">University of Maryland/Elsevier</a> </small></p><p>That first effort with a passive device taught us the fundamentals of capsule design and opened the door to new applications. Since then, we’ve developed sensors that can track biomarkers such as <a href=\"https://advanced.onlinelibrary.wiley.com/doi/10.1002/adhm.202302897\" target=\"_blank\">the gas hydrogen sulfide</a>, neurotransmitters such as serotonin and dopamine, and bioimpedance—a measure of how easily ions pass through intestinal tissue—to shed light on the gut microbiome, inflammation, and disease progression. In parallel, we’ve worked on more-active devices: capsule-based tools for controlled drug release and tissue biopsy, using low-power actuators to trigger precise mechanical movements inside the gut.</p><p>Like all new medical devices and treatments, ingestible electronics face many hurdles before they reach patients—from earning physician trust and insurance approval to demonstrating clear benefits, safety, and reliability. Packaging is a particular focus, as the capsules must be easy to swallow yet durable enough to survive stomach acid. The field is steadily proving safety and reliability, progressing from proof of concept in tissue, through the different stages of animal studies, and eventually to human trials. Every stage provides evidence that reassures doctors and patients—for example, showing that ingesting a properly packaged tiny battery is safe, and that a capsule’s wireless signals, far weaker than those of a cellphone, pose no health risk as they pass through the gut.</p><h2>Engineering a Pill-Size Diagnostic Lab </h2><p>The gastrointestinal tract is packed with clues about health and disease, but much of it remains out of reach of standard diagnostic tools. Ingestible capsules offer a way in, providing direct access to the small intestine and colon. Yet in many cases, the concentrations of chemical biomarkers can be too low to detect reliably in early stages of a disease, which makes the engineering challenge formidable. What’s more, the gut’s corrosive, enzyme-rich environment can foul sensors in multiple ways, interfering with measurements and adding noise to the data.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-float-left rm-resized-container rm-resized-container-25\" data-rm-resized-container=\"25%\" rel=\"float: left;\" style=\"float: left;\"> <img alt=\"Close-up of a microchip with a shiny surface and protruding thin pins.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"18db306a46dc405d56666f9fd9b5e3f4\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"1d6c2\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/close-up-of-a-microchip-with-a-shiny-surface-and-protruding-thin-pins.png?id=64075109&width=980\"/></p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-float-left rm-resized-container rm-resized-container-25\" data-rm-resized-container=\"25%\" style=\"float: left;\"> <img alt=\"Close-up of a textured surface with triangular, raised patterns in a grid formation.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"8e62bb6ccfb3f8805b662480d24d3d4d\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"79504\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/close-up-of-a-textured-surface-with-triangular-raised-patterns-in-a-grid-formation.png?id=64075101&width=980\"/></p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-float-left rm-resized-container rm-resized-container-25\" data-rm-resized-container=\"25%\" rel=\"float: left;\" style=\"float: left;\"> <img alt=\"Electron microscope image of a microscale 3D printed pyramid with four conical structures.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"29456f61129308daca8309dfa4be54df\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"1d64b\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/electron-microscope-image-of-a-microscale-3d-printed-pyramid-with-four-conical-structures.png?id=64075093&width=980\"/> <small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Microneedle designs for drug-delivery capsules have evolved over the years. An early prototype [top] used microneedle anchors to hold a capsule in place. Later designs adopted molded microneedle arrays [center] for more uniform fabrication. The most recent version [bottom] integrates hollow microinjector needles, allowing more precise and controllable drug delivery.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">From top: <a href=\"https://advanced.onlinelibrary.wiley.com/doi/10.1002/admt.202201365\" target=\"_blank\">University of Maryland/Wiley;</a><a href=\"https://www.cell.com/device/fulltext/S2666-9986(24)00281-3\" target=\"_blank\">University of Maryland/Elsevier;</a><a href=\"https://pubs.acs.org/doi/10.1021/acsami.5c05183\" target=\"_blank\">University of Maryland/ACS</a> </small></p><p>Take, for example, inflammatory bowel disease, for which there is no standard clinical test. Rather than searching for a scarce biomarker molecule, our team focused on a physical change: the permeability of the gut lining, which is a key factor in the disease. We designed capsules that <a href=\"https://www.nature.com/articles/s41378-025-00877-8\" target=\"_blank\">measure the intestinal tissue’s bioimpedance</a> by sending tiny currents across electrodes and recording how the tissue resists or conducts those currents at different frequencies (a technique called impedance spectroscopy). To make the electrodes suitable for in vivo use, we coated them with a thin, conductive, biocompatible polymer that reduces electrical noise and keeps stable contact with the gut wall. The capsule finishes its job by transmitting its data wirelessly to our computers.</p><p>In our lab tests, the capsule performed impressively, delivering clean impedance readouts from excised pig tissue even when the sample was in motion. In our animal studies, it detected shifts in permeability triggered by calcium chelators, compounds that pry open the tight junctions between intestinal cells. These results suggest that ingestible bioimpedance capsules could one day give clinicians a direct, minimally invasive window into gut-barrier function and inflammation. We believe that ingestible diagnostics can serve as powerful tools—catching disease earlier, confirming whether treatments are working, and establishing a baseline for gut health.</p><h2>Drug Delivery at the Right Place, Right Time </h2><p>Targeted drug delivery is one of the most compelling applications for ingestible capsules. Many drugs for GI conditions—such as biologics for <a href=\"https://www.mayoclinic.org/diseases-conditions/inflammatory-bowel-disease/symptoms-causes/syc-20353315\" target=\"_blank\">inflammatory bowel disease</a>—can cause serious side effects that limit both dosage and duration of treatment. A promising alternative is delivering a drug directly to the diseased tissue. This localized approach boosts the drug’s concentration at the target site while reducing its spread throughout the body, which improves effectiveness and minimizes side effects. The challenge is engineering a device that can both recognize diseased tissue and deliver medication quickly and precisely.</p><p>With other labs making great progress on the sensing side, we’ve devoted our energy to designing devices that can deliver the medicine. We’ve developed miniature actuators—tiny moving parts—that meet strict criteria for use inside the body: low power, small size, biocompatibility, and long shelf life.</p><p>Some of our designs use <a href=\"https://www.cell.com/device/fulltext/S2666-9986(24)00281-3\" target=\"_blank\">soft and flexible polymer “cantilevers”</a> with attached microneedle systems that pop out from the capsule with enough force to release a drug, but without harming the intestinal tissue. While hollow microneedles can directly inject drugs into the intestinal lining, we’ve also demonstrated prototypes that use the <a href=\"https://advanced.onlinelibrary.wiley.com/doi/10.1002/admt.202201365\" target=\"_blank\">microneedles for anchoring</a> drug payloads, allowing the capsule to release a larger dose of medication that dissolves at an exact location over time.</p><p>In other experimental designs, we had the <a href=\"https://www.cell.com/device/fulltext/S2666-9986(24)00281-3\" target=\"_blank\">microneedles themselves dissolve after injecting a drug</a>. In still others, we used microscale 3D printing to <a href=\"https://www.cell.com/device/fulltext/S2666-9986(24)00281-3\" target=\"_blank\">tailor the structure of the microneedles</a> and control how quickly a drug is released—providing either a slow and sustained dose or a fast delivery. With this 3D printing, we created rigid microneedles that penetrate the mucosal lining and gradually diffuse the drug into the tissue, and soft microneedles that compress when the cantilever pushes them against the tissue, forcing the drug out all at once.</p><h2>Tissue Biopsy via Capsule</h2><div class=\"ieee-sidebar-medium\"><h3>What Smart Capsules Can Do</h3><p><strong>Ingestible electronic capsules use miniaturized sensors and actuators to monitor the gut, deliver medication, and collect biological samples.</strong></p><h3>Sensing</h3><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"Medical capsule emitting signals in a tube environment.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"275f3eb66ba35b660532a8ec93501ba8\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"aecb7\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/medical-capsule-emitting-signals-in-a-tube-environment.png?id=64953223&width=980\"/><small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Embedded sensors can probe the gut—for example, measuring the bioimpedance of the intestinal lining to detect disease—and transmit the data wirelessly.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">All illustrations: Chris Philpot</small></p><h3>Drug delivery</h3><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"Illustration of a capsule with spikes releasing medicine inside a transparent, tube-like structure.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"f762c675d0b5d405e3012639794eb86c\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"1677e\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/illustration-of-a-capsule-with-spikes-releasing-medicine-inside-a-transparent-tube-like-structure.png?id=64953224&width=980\"/><small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Miniature actuators can trigger drug release at specific sites in the gut, boosting effectiveness while limiting side effects.</small></p><h3>Biopsy</h3><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"Illustration of a capsule with gears, showing a magnified section with medicine release.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"03919d5e10aeb3b0b748887d2fd3896c\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"1d94d\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/illustration-of-a-capsule-with-gears-showing-a-magnified-section-with-medicine-release.png?id=64953225&width=980\"/><small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">A spring-loaded mechanism can collect a tiny biopsy sample from the gut wall and store it during the capsule’s passage through the digestive system.</small></p></div><p>Tissue sampling remains the gold standard diagnostic tool in gastroenterology, offering insights far beyond what doctors can glean from visual inspection or blood tests. Capsules hold unique promise here: They can travel the full length of the GI tract, potentially enabling more frequent and affordable biopsies than traditional procedures. But the engineering hurdles are substantial. To collect a sample, a device must generate significant mechanical force to cut through the tough, elastic muscle of the intestines—while staying small enough to swallow.</p><p><span>Different strategies have been explored to solve this problem. Torsion springs can store large amounts of energy but are difficult to fit inside a tiny capsule. Electrically driven mechanisms may demand more power than current capsule batteries can provide. Magnetic actuation is another option, but it requires bulky external equipment and precise tracking of the capsule inside the body.</span></p><p><span></span>Our group has developed a low-power biopsy system that builds on the torsion-spring approach. We compress a spring and use adhesive to “latch” it closed within the capsule, then attach a microheater to the latch. When we wirelessly send current to the device, the microheater melts the adhesive on the latch, triggering the spring. We’ve experimented with tissue-collection tools, integrating a bladed scraper or a biopsy punch (a cylindrical cutting tool) with our spring-activated mechanisms; either of those tools can cut and collect tissue from the intestinal lining. With advanced 3D printing methods like direct laser writing, we can put fine, microscale edges on these miniature cutting tools that make it easier for them to penetrate the intestinal lining.</p><p>Storing and protecting the sample until the capsule naturally passes through the body is a major challenge, requiring both preservation of the sample and resealing the capsule to prevent contamination. In one of our designs, residual tension in the spring keeps the bladed scraper rotating, pulling the sample into the capsule and effectively closing a hatch that seals it inside.</p><h2>The Road to Clinical Use for Ingestibles </h2><p>Looking ahead, we expect to see the first clinical applications emerge in early-stage screening. Capsules that can detect electrochemical, bioimpedance, or visual signals could help doctors make sense of symptoms like vague abdominal pain by revealing inflammation, gut permeability, tumors, or bacterial overgrowth. They could also be adapted to screen for GI cancers. This need is pressing: The American Cancer Society reports that as of 2021, <a href=\"https://www.cancer.org/content/dam/cancer-org/research/cancer-facts-and-statistics/colorectal-cancer-facts-and-figures/colorectal-cancer-facts-and-figures-2023.pdf\" target=\"_blank\">41 percent of eligible U.S. adults</a> were not up to date on colorectal cancer screening. What’s more, effective screening tools don’t yet exist for some diseases, such as <a href=\"https://www.mayoclinic.org/diseases-conditions/small-bowel-cancer/symptoms-causes/syc-20352497\" target=\"_blank\">small bowel adenocarcinoma</a>. Capsule technology could make screening less invasive and more accessible.</p><p>Of course, ingestible capsules carry risks. The standard hazards of endoscopy still apply, such as the possibility of bleeding and perforation, and capsules introduce new complications. For example, if a capsule gets stuck in its passage through the GI tract, it could cause bowel obstruction and require endoscopic retrieval or even surgery. And concerns that are specific to ingestibles, including the biocompatibility of materials, reliable encapsulation of electronics, and safe battery operation, all demand rigorous testing before clinical use.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"A series of images shows a small paper-based battery gradually dissolving in a dish of water over 60 minutes. \" class=\"rm-shortcode\" data-rm-shortcode-id=\"5fde71dac4d588b943523a827629cebe\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"8b2e3\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-series-of-images-shows-a-small-paper-based-battery-gradually-dissolving-in-a-dish-of-water-over-60-minutes.jpg?id=64075124&width=980\"/> <small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">A microbe-powered biobattery designed for ingestible devices dissolves in water within an hour.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">            Seokheun Choi/Binghamton University        </small></p><p>Powering these capsules is a key challenge that must be solved on the path to the clinic. Most capsule endoscopes today rely on coin-cell batteries, typically silver oxide, which offer a safe and energy-dense source but often occupy 30 to 50 percent of the capsule’s volume. So researchers have investigated alternatives, from wireless power transfer to energy-harvesting systems. At the State University of New York at Binghamton, one team is exploring <a href=\"https://www.binghamton.edu/news/story/5482/binghamton-university-researchers-make-dissolvable-battery-using-probiotics\" target=\"_blank\">microbial fuel cells</a> that generate electricity from probiotic bacteria interacting with nutrients in the gut. At MIT, researchers used the <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC5404703/\" target=\"_blank\">gastric fluids of a pig’s stomach</a> to power a simple battery. In our own lab, we are exploring piezoelectric and electrochemical approaches to harvesting energy throughout the GI tract.</p><p>The next steps for our team are pragmatic ones: working with gastroenterologists and animal-science experts to put capsule prototypes through rigorous in vivo studies, then refining them for real-world use. That means shrinking the electronics, cutting power consumption, and integrating multiple functions into a single multimodal device that can sense, sample, and deliver treatments in one pass. Ultimately, any candidate capsule will require regulatory approval for clinical use, which in turn demands rigorous proof of safety and clinical effectiveness for a specific medical application.</p><p>The broader vision is transformative. Swallowable capsules could bring diagnostics and treatment out of the hospital and into patients’ homes. Whereas procedures with endoscopes require anesthesia, patients could take ingestible electronics easily and routinely. Consider, for example, patients with inflammatory bowel disease who live with an elevated risk of cancer; a smart capsule could perform yearly cancer checks, while also delivering medication directly wherever necessary.</p><p>Over time, we expect these systems to evolve into semiautonomous tools: identifying lesions, performing targeted biopsies, and perhaps even analyzing samples and applying treatment in place. Achieving that vision will require advances at the very edge of microelectronics, materials science, and biomedical engineering, bringing together capabilities that once seemed impossible to combine in something the size of a pill. These devices hint at a future in which the boundary between biology and technology dissolves, and where miniature machines travel inside the body to heal us from within. <span class=\"ieee-end-mark\"></span></p>",
        "contentSnippet": "One day soon, a doctor might prescribe a pill that doesn’t just deliver medicine but also reports back on what it finds inside you—and then takes actions based on its findings.\nInstead of scheduling an endoscopy or CT scan, you’d swallow an electronic capsule smaller than a multivitamin. As it travels through your digestive system, it could check tissue health, look for cancerous changes, and send data to your doctor. It could even release drugs exactly where they’re needed or snip a tiny biopsy sample before passing harmlessly out of your body.\nThis dream of a do-it-all pill is driving a surge of research into ingestible electronics: smart capsules designed to monitor and even treat disease from inside the gastrointestinal (GI) tract. The stakes are high. GI diseases affect tens of millions of people worldwide, including such ailments as inflammatory bowel disease, celiac disease, and small intestinal bacterial overgrowth. Diagnosis often involves a frustrating maze of blood tests, imaging, and invasive endoscopy. Treatments, meanwhile, can bring serious side effects because drugs affect the whole body, not just the troubled gut.\nIf capsules could handle much of that work—streamlining diagnosis, delivering targeted therapies, and sparing patients repeated invasive procedures—they could transform care. Over the past 20 years, researchers have built a growing tool kit of ingestible devices, some already in clinical use. These capsule-shaped devices typically contain sensors, circuitry, a power source, and sometimes a communication module, all enclosed in a biocompatible shell. But the next leap forward is still in development: autonomous capsules that can both sense and act, releasing a drug or taking a tissue sample.\nThat’s the challenge that our lab—the MEMS Sensors and Actuators Laboratory (MSAL) at the University of Maryland, College Park—is tackling. Drawing on decades of advances in microelectromechanical systems (MEMS), we’re building swallowable devices that integrate sensors, actuators, and wireless links in packages that are small and safe enough for patients. The hurdles are considerable: power, miniaturization, biocompatibility, and reliability, to name a few. But the potential payoff will be a new era of personalized and minimally invasive medicine, delivered by something as simple as a pill you can swallow at home.\nThe Origin of Ingestible Devices \nThe idea of a smart capsule has been around since the late 1950s, when researchers first experimented with swallowable devices to record temperature, gastric pH, or pressure inside the digestive tract. At the time, it seemed closer to science fiction than clinical reality, bolstered by pop-culture visions like the 1966 film Fantastic Voyage, where miniaturized doctors travel inside the human body to treat a blood clot.\n One of the authors (Ghodssi) holds a miniaturized drug-delivery capsule that’s designed to release medication at specific sites in the gastrointestinal tract.Maximilian Franz/Engineering at Maryland Magazine \nFor decades, though, the mainstay of GI diagnostics was endoscopy: a camera on a flexible tube, threaded down the throat or up through the colon. These procedures are quite invasive and require patients to be sedated, which increases both the risk of complications and procedural costs. What’s more, it’s difficult for endoscopes to safely traverse the circuitous pathway of the small intestine. The situation changed in the early 2000s, when video-capsule endoscopy arrived. The best-known product, PillCam, looks like a large vitamin but contains a camera, LEDs, and a transmitter. As it passes through the gut, it beams images and videos to a wearable device.\nToday, capsule endoscopy is a routine tool in gastroenterology; ingestible devices can measure acidity, temperature, or gas concentrations. And researchers are pushing further, with experimental prototypes that deliver drugs or analyze the microbiome. For example, teams from Tufts University, in Massachusetts, and Purdue University, in Indiana, are working on devices with dissolvable coatings and mechanisms to collect samples of liquid for studies of the intestinal microbiome.\nStill, all those devices are passive. They activate on a timer or by exposure to the neutral pH of the intestines, but they don’t adapt to conditions in real time. The next step requires capsules that can sense biomarkers, make decisions, and trigger specific actions—moving from clever hardware to truly autonomous “smart pills.” That’s where our work comes in.\nBuilding on MEMS technology \nSince 2017, MSAL has been pushing ingestible devices forward with the goal of making an immediate impact in health care. The group built on the MEMS community’s legacy in microfabrication, sensors, and system integration, while taking advantage of new tools like 3D printing and materials like biocompatible polymers. Those advances have made it possible to prototype faster and shrink devices smaller, sparking a wave of innovation in wearables, implants, and now ingestibles. Today, MSAL is collaborating with engineers, physicians, and data scientists to move these capsules from lab benches to pharmaceutical trials.\nAs a first step, back in 2017, we set out to design sensor-carrying capsules that could reliably reach the small intestine and indicate when they reached it. Another challenge was that sensors that work well on the benchtop can falter inside the gut, where shifting pH, moisture, digestive enzymes, and low-oxygen conditions can degrade typical sensing components.\n Our earliest prototype adapted MEMS sensing technology to detect abnormal enzyme levels in the duodenum that are linked to pancreatic function. The sensor and its associated electronics were enclosed in a biocompatible, 3D-printed shell coated with polymers that dissolved only at certain pH levels. This strategy could one day be used to detect biomarkers in secretions from the pancreas to detect early-stage cancer.\n A high-speed video shows how a capsule deploys microneedles to deliver drugs into intestinal tissue.University of Maryland/Elsevier \nThat first effort with a passive device taught us the fundamentals of capsule design and opened the door to new applications. Since then, we’ve developed sensors that can track biomarkers such as the gas hydrogen sulfide, neurotransmitters such as serotonin and dopamine, and bioimpedance—a measure of how easily ions pass through intestinal tissue—to shed light on the gut microbiome, inflammation, and disease progression. In parallel, we’ve worked on more-active devices: capsule-based tools for controlled drug release and tissue biopsy, using low-power actuators to trigger precise mechanical movements inside the gut.\nLike all new medical devices and treatments, ingestible electronics face many hurdles before they reach patients—from earning physician trust and insurance approval to demonstrating clear benefits, safety, and reliability. Packaging is a particular focus, as the capsules must be easy to swallow yet durable enough to survive stomach acid. The field is steadily proving safety and reliability, progressing from proof of concept in tissue, through the different stages of animal studies, and eventually to human trials. Every stage provides evidence that reassures doctors and patients—for example, showing that ingesting a properly packaged tiny battery is safe, and that a capsule’s wireless signals, far weaker than those of a cellphone, pose no health risk as they pass through the gut.\nEngineering a Pill-Size Diagnostic Lab \nThe gastrointestinal tract is packed with clues about health and disease, but much of it remains out of reach of standard diagnostic tools. Ingestible capsules offer a way in, providing direct access to the small intestine and colon. Yet in many cases, the concentrations of chemical biomarkers can be too low to detect reliably in early stages of a disease, which makes the engineering challenge formidable. What’s more, the gut’s corrosive, enzyme-rich environment can foul sensors in multiple ways, interfering with measurements and adding noise to the data.\n \n \n  Microneedle designs for drug-delivery capsules have evolved over the years. An early prototype [top] used microneedle anchors to hold a capsule in place. Later designs adopted molded microneedle arrays [center] for more uniform fabrication. The most recent version [bottom] integrates hollow microinjector needles, allowing more precise and controllable drug delivery.From top: University of Maryland/Wiley;University of Maryland/Elsevier;University of Maryland/ACS \nTake, for example, inflammatory bowel disease, for which there is no standard clinical test. Rather than searching for a scarce biomarker molecule, our team focused on a physical change: the permeability of the gut lining, which is a key factor in the disease. We designed capsules that measure the intestinal tissue’s bioimpedance by sending tiny currents across electrodes and recording how the tissue resists or conducts those currents at different frequencies (a technique called impedance spectroscopy). To make the electrodes suitable for in vivo use, we coated them with a thin, conductive, biocompatible polymer that reduces electrical noise and keeps stable contact with the gut wall. The capsule finishes its job by transmitting its data wirelessly to our computers.\nIn our lab tests, the capsule performed impressively, delivering clean impedance readouts from excised pig tissue even when the sample was in motion. In our animal studies, it detected shifts in permeability triggered by calcium chelators, compounds that pry open the tight junctions between intestinal cells. These results suggest that ingestible bioimpedance capsules could one day give clinicians a direct, minimally invasive window into gut-barrier function and inflammation. We believe that ingestible diagnostics can serve as powerful tools—catching disease earlier, confirming whether treatments are working, and establishing a baseline for gut health.\nDrug Delivery at the Right Place, Right Time \nTargeted drug delivery is one of the most compelling applications for ingestible capsules. Many drugs for GI conditions—such as biologics for inflammatory bowel disease—can cause serious side effects that limit both dosage and duration of treatment. A promising alternative is delivering a drug directly to the diseased tissue. This localized approach boosts the drug’s concentration at the target site while reducing its spread throughout the body, which improves effectiveness and minimizes side effects. The challenge is engineering a device that can both recognize diseased tissue and deliver medication quickly and precisely.\nWith other labs making great progress on the sensing side, we’ve devoted our energy to designing devices that can deliver the medicine. We’ve developed miniature actuators—tiny moving parts—that meet strict criteria for use inside the body: low power, small size, biocompatibility, and long shelf life.\nSome of our designs use soft and flexible polymer “cantilevers” with attached microneedle systems that pop out from the capsule with enough force to release a drug, but without harming the intestinal tissue. While hollow microneedles can directly inject drugs into the intestinal lining, we’ve also demonstrated prototypes that use the microneedles for anchoring drug payloads, allowing the capsule to release a larger dose of medication that dissolves at an exact location over time.\nIn other experimental designs, we had the microneedles themselves dissolve after injecting a drug. In still others, we used microscale 3D printing to tailor the structure of the microneedles and control how quickly a drug is released—providing either a slow and sustained dose or a fast delivery. With this 3D printing, we created rigid microneedles that penetrate the mucosal lining and gradually diffuse the drug into the tissue, and soft microneedles that compress when the cantilever pushes them against the tissue, forcing the drug out all at once.\nTissue Biopsy via Capsule\n\nWhat Smart Capsules Can Do\nIngestible electronic capsules use miniaturized sensors and actuators to monitor the gut, deliver medication, and collect biological samples.\nSensing\n Embedded sensors can probe the gut—for example, measuring the bioimpedance of the intestinal lining to detect disease—and transmit the data wirelessly.All illustrations: Chris Philpot\nDrug delivery\n Miniature actuators can trigger drug release at specific sites in the gut, boosting effectiveness while limiting side effects.\nBiopsy\n A spring-loaded mechanism can collect a tiny biopsy sample from the gut wall and store it during the capsule’s passage through the digestive system.\n\nTissue sampling remains the gold standard diagnostic tool in gastroenterology, offering insights far beyond what doctors can glean from visual inspection or blood tests. Capsules hold unique promise here: They can travel the full length of the GI tract, potentially enabling more frequent and affordable biopsies than traditional procedures. But the engineering hurdles are substantial. To collect a sample, a device must generate significant mechanical force to cut through the tough, elastic muscle of the intestines—while staying small enough to swallow.\nDifferent strategies have been explored to solve this problem. Torsion springs can store large amounts of energy but are difficult to fit inside a tiny capsule. Electrically driven mechanisms may demand more power than current capsule batteries can provide. Magnetic actuation is another option, but it requires bulky external equipment and precise tracking of the capsule inside the body.\nOur group has developed a low-power biopsy system that builds on the torsion-spring approach. We compress a spring and use adhesive to “latch” it closed within the capsule, then attach a microheater to the latch. When we wirelessly send current to the device, the microheater melts the adhesive on the latch, triggering the spring. We’ve experimented with tissue-collection tools, integrating a bladed scraper or a biopsy punch (a cylindrical cutting tool) with our spring-activated mechanisms; either of those tools can cut and collect tissue from the intestinal lining. With advanced 3D printing methods like direct laser writing, we can put fine, microscale edges on these miniature cutting tools that make it easier for them to penetrate the intestinal lining.\nStoring and protecting the sample until the capsule naturally passes through the body is a major challenge, requiring both preservation of the sample and resealing the capsule to prevent contamination. In one of our designs, residual tension in the spring keeps the bladed scraper rotating, pulling the sample into the capsule and effectively closing a hatch that seals it inside.\nThe Road to Clinical Use for Ingestibles \nLooking ahead, we expect to see the first clinical applications emerge in early-stage screening. Capsules that can detect electrochemical, bioimpedance, or visual signals could help doctors make sense of symptoms like vague abdominal pain by revealing inflammation, gut permeability, tumors, or bacterial overgrowth. They could also be adapted to screen for GI cancers. This need is pressing: The American Cancer Society reports that as of 2021, 41 percent of eligible U.S. adults were not up to date on colorectal cancer screening. What’s more, effective screening tools don’t yet exist for some diseases, such as small bowel adenocarcinoma. Capsule technology could make screening less invasive and more accessible.\nOf course, ingestible capsules carry risks. The standard hazards of endoscopy still apply, such as the possibility of bleeding and perforation, and capsules introduce new complications. For example, if a capsule gets stuck in its passage through the GI tract, it could cause bowel obstruction and require endoscopic retrieval or even surgery. And concerns that are specific to ingestibles, including the biocompatibility of materials, reliable encapsulation of electronics, and safe battery operation, all demand rigorous testing before clinical use.\n  A microbe-powered biobattery designed for ingestible devices dissolves in water within an hour.            Seokheun Choi/Binghamton University        \nPowering these capsules is a key challenge that must be solved on the path to the clinic. Most capsule endoscopes today rely on coin-cell batteries, typically silver oxide, which offer a safe and energy-dense source but often occupy 30 to 50 percent of the capsule’s volume. So researchers have investigated alternatives, from wireless power transfer to energy-harvesting systems. At the State University of New York at Binghamton, one team is exploring microbial fuel cells that generate electricity from probiotic bacteria interacting with nutrients in the gut. At MIT, researchers used the gastric fluids of a pig’s stomach to power a simple battery. In our own lab, we are exploring piezoelectric and electrochemical approaches to harvesting energy throughout the GI tract.\nThe next steps for our team are pragmatic ones: working with gastroenterologists and animal-science experts to put capsule prototypes through rigorous in vivo studies, then refining them for real-world use. That means shrinking the electronics, cutting power consumption, and integrating multiple functions into a single multimodal device that can sense, sample, and deliver treatments in one pass. Ultimately, any candidate capsule will require regulatory approval for clinical use, which in turn demands rigorous proof of safety and clinical effectiveness for a specific medical application.\nThe broader vision is transformative. Swallowable capsules could bring diagnostics and treatment out of the hospital and into patients’ homes. Whereas procedures with endoscopes require anesthesia, patients could take ingestible electronics easily and routinely. Consider, for example, patients with inflammatory bowel disease who live with an elevated risk of cancer; a smart capsule could perform yearly cancer checks, while also delivering medication directly wherever necessary.\nOver time, we expect these systems to evolve into semiautonomous tools: identifying lesions, performing targeted biopsies, and perhaps even analyzing samples and applying treatment in place. Achieving that vision will require advances at the very edge of microelectronics, materials science, and biomedical engineering, bringing together capabilities that once seemed impossible to combine in something the size of a pill. These devices hint at a future in which the boundary between biology and technology dissolves, and where miniature machines travel inside the body to heal us from within.",
        "pubDate": "Wed, 18 Feb 2026 15:14:00 +0000",
        "isoDate": "2026-02-18T15:14:00.000Z",
        "creator": "Reza Ghodssi",
        "source": "https://spectrum.ieee.org/ingestible-electronics"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-y4lpd9",
        "title": "Lidar Mobility Device Assists Navigation and Avoids Collisions",
        "link": "https://spectrum.ieee.org/assistive-technology-lidar-wheelchair",
        "url": "https://spectrum.ieee.org/assistive-technology-lidar-wheelchair",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/a-young-adult-woman-using-a-high-tech-wheelchair-to-walk-a-horse-along-a-flat-dirt-path.jpg?id=64448307&width=1245&height=700&coordinates=0%2C469%2C0%2C469\"/><br/><br/><p>At <a href=\"https://www.ces.tech/\" rel=\"noopener noreferrer\" target=\"_blank\">CES 2026</a> in Las Vegas, Singapore-based startup <a href=\"https://strutt.inc/pages/home?srsltid=AfmBOorpt3d8fcRJ99AxUXStpfCSmKywfAlhwsFk81y9IYRi_6GxX7Ln\" rel=\"noopener noreferrer\" target=\"_blank\">Strutt</a> introduced the <a href=\"https://strutt.inc/pages/strutt-ev1\" rel=\"noopener noreferrer\" target=\"_blank\">EV<sup>1</sup></a>, a powered personal mobility device that uses <a href=\"https://spectrum.ieee.org/tag/lidar\" target=\"_self\">lidar</a>, <a href=\"https://spectrum.ieee.org/3-types-of-3d-sensing-for-smartphones-and-selfdriving-cars\" target=\"_self\">cameras</a>, and onboard computing for collision avoidance. Unlike manually-steered <a href=\"https://www.spinlife.com/power-wheelchairs/category.cfm?categoryID=3&srsltid=AfmBOopNsW0KhKxfcFTlGpx91sNJfMZxHj5o9CMZczzruldtvAseucuS\" rel=\"noopener noreferrer\" target=\"_blank\">powered wheelchairs</a>, the EV<sup>1</sup> assists with navigation in both indoor and outdoor environments—stopping or rerouting itself before a collision can occur.</p><p>Strutt describes its approach as “shared control,” in which the user sets direction and speed, while the device intervenes to avoid unsafe motion.</p><p><span>“The problem isn’t always disability,” says Strutt cofounder and CEO <a href=\"https://www.crunchbase.com/person/tony-hong-3b68\" target=\"_blank\"><span>Tony Hong</span></a>. “Sometimes people are just tired. They have limited energy, and mobility shouldn’t consume it.”</span></p><p><span>Building a mobility platform was not Hong’s original ambition. Trained in optics and sensor systems, he previously worked in aerospace and robotics. From 2016 to 2019, he led the development of lidar systems for drones at Shenzhen, China-based </span><a href=\"https://www.dji.com/\" target=\"_blank\"><span>DJI</span></a><span>, a leading manufacturer of consumer and professional drones. Hong then left DJI for a position as an assistant professor at </span><a href=\"https://www.sustech.edu.cn/en/\" target=\"_blank\"><span>Southern University of Science and Technology</span></a><span> in Shenzhen—a school known for its research in robotics, human augmentation, sensors, and rehabilitation engineering.</span></p><p>However, he says, demographic trends around him proved hard to ignore. Populations in Asia, Europe, and North America are aging rapidly. More people are living longer, with limited stamina, slower reaction times, or balance challenges. So, Hong says he left academia to develop technology that would help people facing mobility limitations.</p><h3>Not a Wheelchair—an EV</h3><p><span>EV<sup>1</sup> combines two lidar units, two cameras, 10 time-of-flight depth sensors, and six ultrasonic sensors. Sensor data feeds into onboard computing that performs object detection and path planning.</span></p><p>“We need accuracy at a few centimeters,” Hong says. “Otherwise, you’re hitting door frames.”</p><p>Using the touchscreen interface, users can select a destination within the mapped environment. The onboard system calculates a safe route and guides the vehicle at a reduced speed of about 3 miles per hour. The rider can override the route instantly with joystick input. The system even supports voice commands, allowing the user to direct the EV1 to waypoints saved in its memory.</p><p>The user can say, for example, “Go to the fridge,” and it will chart a course to the refrigerator and go there, avoiding obstacles along the way.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"Close-up of a screen on an electric wheelchair displaying detected obstacles in a room.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"a2760480effe0d6c9802e214b43b51a1\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"937d0\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/close-up-of-a-screen-on-an-electric-wheelchair-displaying-detected-obstacles-in-a-room.jpg?id=64449076&width=980\"/> <small class=\"image-media media-caption\" data-gramm=\"false\" data-lt-tmp-id=\"lt-828968\" placeholder=\"Add Photo Caption...\" spellcheck=\"false\">The Strutt EV1 puts both joystick controls and a lidar-view of the environment in front of the device’s user. </small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Strutt</small></p><p>Driving EV<sup>1</sup> in manual mode, the rider retains full control, with vibration feedback warning of nearby obstacles. In “copilot” mode, the vehicle prevents direct collisions by stopping before impact. In “copilot plus,” it can steer around obstacles while continuing in the intended direction of travel.</p><p>“We don’t call it autonomous driving,” Hong says. “The user is always responsible and can take control instantly.”</p><p>Hong says Strutt has also kept its users’ digital privacy in mind. All perception, planning, and control computations, he says, occur onboard the device. Sensor data is not transmitted unless the user chooses to upload logs for diagnostics. Camera and microphone activity is visibly indicated, and wireless communications are encrypted. Navigation and obstacle avoidance function without cloud connectivity.</p><p><span>“We don’t think of this as a wheelchair,” Hong says. “We think of it as an everyday vehicle.”</span></p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"An adult androgynous person using a high tech wheelchair to navigate tight spaces in their kitchen. \" class=\"rm-shortcode\" data-rm-shortcode-id=\"e047963317817b90dcc4751d51d55eb0\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"34289\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/an-adult-androgynous-person-using-a-high-tech-wheelchair-to-navigate-tight-spaces-in-their-kitchen.jpg?id=64449220&width=980\"/> <small class=\"image-media media-caption\" data-gramm=\"false\" data-lt-tmp-id=\"lt-832513\" placeholder=\"Add Photo Caption...\" spellcheck=\"false\">Strutt promotes EV1’s use for both outdoor and indoor environments—offering high-precision sensing capabilities to navigate confined spaces. </small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Strutt</small></p><p><span>To ensure that the EV</span><sup>1 </sup><span>could withstand years of shuttling a user back and forth inside their home and around their neighborhood, the Strutt team subjected the mobility vehicle</span><sup> </sup><span>to two million roller cycles—mechanical simulation testing that allows engineers to estimate how well the motors, bearings, suspension, and frame will hold up over time. </span></p><p>The EV1’s 600-watt-hour <a href=\"https://spectrum.ieee.org/john-goodenough-tribute\" target=\"_self\">lithium iron phosphate</a> battery provides 32 kilometers of range—enough for a full day of errands, indoor navigation, and neighborhood travel. A smaller 300-watt-hour version, designed to comply with airline lithium-battery limits, delivers 16 km. Charging from zero to 80 percent takes two hours.</p><h3>Might These EVs Be Covered by Insurance?</h3><p><span>The EV1 retails for US $7,500—a price that could place it outside the reach of people without deep pockets. For now, advanced sensors and embedded computing keep manufacturing cost high, while <a href=\"https://ai.nejm.org/doi/full/10.1056/AIoa2300030\" target=\"_blank\">insurance reimbursement frameworks for AI-assisted mobility devices</a> depend on where a person lives. </span></p><p><span></span><span>“A retail price of $7,500 raises serious equity concerns,” says <span>Erick Rocha, communications and development coordinator at the Los Angeles-based advocacy organization </span><a href=\"https://disabilityvoicesunited.org/\" target=\"_blank\"><span>Disability Voices United</span></a><span>,</span>. “Many mobility device users in the United States rely on <a href=\"https://www.medicaid.gov/\" target=\"_blank\">Medicaid</a>,” the government insurance program for people with limited incomes. “Access must not be restricted to those who can afford to pay out of pocket.”</span></p><p><span>Medicaid coverage for high-tech mobility devices varies widely by state, and some states have rules that create significant barriers to approval (especially for non-standard or more specialized equipment).</span></p><p>Even in states that do cover mobility devices, similar types of hurdles often show up. <span>Almost all states require prior approval for powered mobility devices, and the process can be time-consuming and documentation-heavy. Many states rigidly define what “medically necessary” means. They may require a detailed prescription describing the features of the mobility device and why the patient’s needs cannot be met with a simpler mobility aid such as a walker, cane, or standard manual wheelchair. Some states’ processes include a comprehensive in-person exam, documenting how the impairment described by the clinician limits activities of daily living such as toileting, dressing, bathing, or eating. Even if a person overcomes those hurdles, a state Medicaid program could deny coverage if a device doesn’t fit neatly into existing </span><a href=\"https://www.cms.gov/medicare/coding-billing/healthcare-common-procedure-system\" target=\"_blank\">Healthcare Common Procedure Coding System</a><span> billing codes</span></p><p><span>“Sensor-assisted systems can improve safety,” Rocha says. “But the question is whether a device truly meets the lived, day-to-day realities of people with limited mobility.”</span></p><p>Hong says that Strutt, founded in 2023, is betting that falling sensor prices and advances in embedded processing now make commercial deployment of the EV<sup>1</sup> feasible.</p>",
        "contentSnippet": "At CES 2026 in Las Vegas, Singapore-based startup Strutt introduced the EV1, a powered personal mobility device that uses lidar, cameras, and onboard computing for collision avoidance. Unlike manually-steered powered wheelchairs, the EV1 assists with navigation in both indoor and outdoor environments—stopping or rerouting itself before a collision can occur.\nStrutt describes its approach as “shared control,” in which the user sets direction and speed, while the device intervenes to avoid unsafe motion.\n“The problem isn’t always disability,” says Strutt cofounder and CEO Tony Hong. “Sometimes people are just tired. They have limited energy, and mobility shouldn’t consume it.”\nBuilding a mobility platform was not Hong’s original ambition. Trained in optics and sensor systems, he previously worked in aerospace and robotics. From 2016 to 2019, he led the development of lidar systems for drones at Shenzhen, China-based DJI, a leading manufacturer of consumer and professional drones. Hong then left DJI for a position as an assistant professor at Southern University of Science and Technology in Shenzhen—a school known for its research in robotics, human augmentation, sensors, and rehabilitation engineering.\nHowever, he says, demographic trends around him proved hard to ignore. Populations in Asia, Europe, and North America are aging rapidly. More people are living longer, with limited stamina, slower reaction times, or balance challenges. So, Hong says he left academia to develop technology that would help people facing mobility limitations.\nNot a Wheelchair—an EV\nEV1 combines two lidar units, two cameras, 10 time-of-flight depth sensors, and six ultrasonic sensors. Sensor data feeds into onboard computing that performs object detection and path planning.\n“We need accuracy at a few centimeters,” Hong says. “Otherwise, you’re hitting door frames.”\nUsing the touchscreen interface, users can select a destination within the mapped environment. The onboard system calculates a safe route and guides the vehicle at a reduced speed of about 3 miles per hour. The rider can override the route instantly with joystick input. The system even supports voice commands, allowing the user to direct the EV1 to waypoints saved in its memory.\nThe user can say, for example, “Go to the fridge,” and it will chart a course to the refrigerator and go there, avoiding obstacles along the way.\n  The Strutt EV1 puts both joystick controls and a lidar-view of the environment in front of the device’s user. Strutt\nDriving EV1 in manual mode, the rider retains full control, with vibration feedback warning of nearby obstacles. In “copilot” mode, the vehicle prevents direct collisions by stopping before impact. In “copilot plus,” it can steer around obstacles while continuing in the intended direction of travel.\n“We don’t call it autonomous driving,” Hong says. “The user is always responsible and can take control instantly.”\nHong says Strutt has also kept its users’ digital privacy in mind. All perception, planning, and control computations, he says, occur onboard the device. Sensor data is not transmitted unless the user chooses to upload logs for diagnostics. Camera and microphone activity is visibly indicated, and wireless communications are encrypted. Navigation and obstacle avoidance function without cloud connectivity.\n“We don’t think of this as a wheelchair,” Hong says. “We think of it as an everyday vehicle.”\n  Strutt promotes EV1’s use for both outdoor and indoor environments—offering high-precision sensing capabilities to navigate confined spaces. Strutt\nTo ensure that the EV1 could withstand years of shuttling a user back and forth inside their home and around their neighborhood, the Strutt team subjected the mobility vehicle to two million roller cycles—mechanical simulation testing that allows engineers to estimate how well the motors, bearings, suspension, and frame will hold up over time. \nThe EV1’s 600-watt-hour lithium iron phosphate battery provides 32 kilometers of range—enough for a full day of errands, indoor navigation, and neighborhood travel. A smaller 300-watt-hour version, designed to comply with airline lithium-battery limits, delivers 16 km. Charging from zero to 80 percent takes two hours.\nMight These EVs Be Covered by Insurance?\nThe EV1 retails for US $7,500—a price that could place it outside the reach of people without deep pockets. For now, advanced sensors and embedded computing keep manufacturing cost high, while insurance reimbursement frameworks for AI-assisted mobility devices depend on where a person lives. \n“A retail price of $7,500 raises serious equity concerns,” says Erick Rocha, communications and development coordinator at the Los Angeles-based advocacy organization Disability Voices United,. “Many mobility device users in the United States rely on Medicaid,” the government insurance program for people with limited incomes. “Access must not be restricted to those who can afford to pay out of pocket.”\nMedicaid coverage for high-tech mobility devices varies widely by state, and some states have rules that create significant barriers to approval (especially for non-standard or more specialized equipment).\nEven in states that do cover mobility devices, similar types of hurdles often show up. Almost all states require prior approval for powered mobility devices, and the process can be time-consuming and documentation-heavy. Many states rigidly define what “medically necessary” means. They may require a detailed prescription describing the features of the mobility device and why the patient’s needs cannot be met with a simpler mobility aid such as a walker, cane, or standard manual wheelchair. Some states’ processes include a comprehensive in-person exam, documenting how the impairment described by the clinician limits activities of daily living such as toileting, dressing, bathing, or eating. Even if a person overcomes those hurdles, a state Medicaid program could deny coverage if a device doesn’t fit neatly into existing Healthcare Common Procedure Coding System billing codes\n“Sensor-assisted systems can improve safety,” Rocha says. “But the question is whether a device truly meets the lived, day-to-day realities of people with limited mobility.”\nHong says that Strutt, founded in 2023, is betting that falling sensor prices and advances in embedded processing now make commercial deployment of the EV1 feasible.",
        "pubDate": "Tue, 17 Feb 2026 19:58:48 +0000",
        "isoDate": "2026-02-17T19:58:48.000Z",
        "creator": "Willie D. Jones",
        "source": "https://spectrum.ieee.org/assistive-technology-lidar-wheelchair"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-7p3fm6",
        "title": "Estimating Surface Heating of an Atmospheric Reentry Vehicle With Simulation",
        "link": "https://event.on24.com/wcc/r/5204256/9B4BA35D454493C7D9829FE90B5A0ABD",
        "url": "https://event.on24.com/wcc/r/5204256/9B4BA35D454493C7D9829FE90B5A0ABD",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/comsol-logo.png?id=27157944&width=980\"/><br/><br/><p>Join Hannah Alpert (NASA Ames) to explore thermal data from the record-breaking 6-meter LOFTID inflatable aeroshell. Learn how COMSOL Multiphysics® was used to perform inverse analysis on flight thermocouple data, validating heat flux gauges and preflight CFD predictions. Attendees will gain technical insights into improving thermal models for future HIAD missions, making this essential for engineers seeking to advance atmospheric reentry design. The session concludes with a live Q&A.<br/></p><p><span><a href=\"https://event.on24.com/wcc/r/5204256/9B4BA35D454493C7D9829FE90B5A0ABD\" target=\"_blank\">Register now to watch this free on-demand webinar!</a></span></p>",
        "contentSnippet": "Join Hannah Alpert (NASA Ames) to explore thermal data from the record-breaking 6-meter LOFTID inflatable aeroshell. Learn how COMSOL Multiphysics® was used to perform inverse analysis on flight thermocouple data, validating heat flux gauges and preflight CFD predictions. Attendees will gain technical insights into improving thermal models for future HIAD missions, making this essential for engineers seeking to advance atmospheric reentry design. The session concludes with a live Q&A.\n\nRegister now to watch this free on-demand webinar!",
        "pubDate": "Tue, 17 Feb 2026 19:27:00 +0000",
        "isoDate": "2026-02-17T19:27:00.000Z",
        "creator": "COMSOL",
        "source": "https://event.on24.com/wcc/r/5204256/9B4BA35D454493C7D9829FE90B5A0ABD"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-61s61r",
        "title": "We’re Measuring Data Center Sustainability Wrong",
        "link": "https://spectrum.ieee.org/data-center-sustainability-metrics",
        "url": "https://spectrum.ieee.org/data-center-sustainability-metrics",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/a-pile-of-discarded-old-phones.jpg?id=64070651&width=1245&height=700&coordinates=0%2C156%2C0%2C157\"/><br/><br/><p>In 2024, Google <a href=\"https://blog.google/company-news/outreach-and-initiatives/sustainability/environmental-report-2025/\" rel=\"noopener noreferrer\" target=\"_blank\">claimed</a> that their data centers are 1.5x more energy efficient than industry average. In 2025, Microsoft <a href=\"https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/msc/documents/presentations/CSR/2025-Microsoft-Environmental-Sustainability-Report-PDF.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">committed</a> billions to nuclear power for AI workloads. The data center industry tracks power usage effectiveness to three decimal places and optimizes water usage intensity with machine precision. We report direct emissions and energy emissions with religious fervor.</p><p>These are laudable advances, but these metrics account for only 30 percent of total emissions from the IT sector. The majority of the emissions are not directly from data centers or the energy they use, but from the end-user devices that actually access the data centers, emissions due to manufacturing the hardware, and <a href=\"https://spectrum.ieee.org/green-software\" target=\"_self\">software inefficiencies</a>. We are frantically optimizing less than a third of the IT sector’s environmental impact, while the bulk of the problem goes unmeasured.</p><p>Incomplete regulatory frameworks are part of the problem. In Europe, the Corporate Sustainability Reporting Directive (<a href=\"https://www.csrdreadiness.com/?utm_term=corporate%20sustainability%20reporting%20directive&utm_campaign=Website+traffic-Search-csrdreadiness-1&utm_source=adwords&utm_medium=ppc&hsa_acc=8049917490&hsa_cam=21799253197&hsa_grp=174334210531&hsa_ad=716504436475&hsa_src=g&hsa_tgt=kwd-1250753155894&hsa_kw=corporate%20sustainability%20reporting%20directive&hsa_mt=p&hsa_net=adwords&hsa_ver=3&gad_source=1&gad_campaignid=21799253197&gbraid=0AAAAAovX5IFUb0B4kiIuBnogJDzencxuq&gclid=Cj0KCQiAhOfLBhCCARIsAJPiopNSX804TFv2FoZyU-WkNfA6MkLIxGnqI0XtmYd6jzOYXXsq4ORQmbIaAv6vEALw_wcB\" rel=\"noopener noreferrer\" target=\"_blank\">CSRD</a>) now requires 11,700 companies to report emissions using these incomplete frameworks. The next phase of the directive, covering 40,000+ additional companies, was originally scheduled for 2026 (but is likely delayed to 2028). In the United States, the standards body responsible for IT sustainability metrics (<a href=\"https://www.iso.org/committee/654019.html\" rel=\"noopener noreferrer\" target=\"_blank\">ISO/IEC JTC 1/SC 39</a>) is conducting active revision of its standards through 2026, with a key plenary meeting in May 2026.</p><p>The time to act is now. If we don’t fix the measurement frameworks, we risk locking in incomplete data collection and optimizing a fraction of what matters for the next 5 to 10 years, before the next major standards revision.</p><h2>The limited metrics</h2><p>Walk into any modern data center and you’ll see sustainability instrumentation everywhere. Power usage efficiency (PUE) monitors track every watt. Water usage efficiency (WUE) systems measure water consumption down to the gallon. Sophisticated monitoring captures everything from server utilization to cooling efficiency to renewable energy percentages.</p><p>But here’s what those measurements miss: End-user devices globally emit 1.5 to 2 times more carbon than all data centers combined, according to McKinsey’s 2022 <a href=\"https://www.mckinsey.com/de/~/media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/the%20green%20it%20revolution%20a%20blueprint%20for%20cios%20to%20combat%20climate%20change/the-green-it-revolution-a-blueprint-for-cios-to-combat-climate-change.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">report</a>. The smartphones, laptops, and tablets we use to access those ultra-efficient data centers are the bigger problem.</p><p class=\"pull-quote\">Data center operations, as measured by power usage efficiency, account for only 24 percent of the total emissions.</p><p>On the conservative end of the range from McKinsey’s report, devices emit 1.5 times as much as data centers. That means that data centers make up 40 percent of total IT emissions, while devices make up 60 percent.</p><p>On top of that, approximately <a href=\"https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/msc/documents/presentations/CSR/2025-Microsoft-Environmental-Sustainability-Report-PDF.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">75 percent</a> of device emissions occur not during use, but during manufacturing—this is so-called embodied carbon. For data centers, only 40 percent is embodied carbon, and <a href=\"https://download.schneider-electric.com/files?p_Doc_Ref=SPD_WP99_EN&p_enDocType=White+Paper&p_File_Name=WP99_V1_EN.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">60 percent</a> comes from operations (as measured by PUE).</p><p>Putting this together, data center operations, as measured by PUE, account for only 24 percent of the total emissions. Data center embodied carbon is 16 percent, device embodied carbon is 45 percent, and device operation is 15 percent.</p><p>Under the EU’s current CSRD framework, companies must report their emissions in three categories: direct emissions from owned sources, indirect emissions from purchased energy, and a third category for everything else.</p><p>This “everything else” category does include device emissions and embodied carbon. However, those emissions are reported as aggregate totals broken down by accounting category—Capital Goods, Purchased Goods and Services, Use of Sold Products—but not by product type. How much comes from end-user devices versus datacenter infrastructure, or employee laptops versus network equipment, remains murky, and therefore, unoptimized.</p><h2>Embodied carbon and hardware reuse</h2><p>Manufacturing a single smartphone<a href=\"https://www.sciencedirect.com/science/article/pii/S1364032123002794\" rel=\"noopener noreferrer\" target=\"_blank\"> generates</a> approximately 50 kg CO<sub>2</sub> equivalent (CO<span><sub>2</sub></span>e). For a laptop, it’s 200 kg CO<span><span><sub>2</sub></span></span>e. With 1 billion smartphones replaced annually, that’s 50 million tonnes of CO<sub>2</sub>e per year just from smartphone manufacturing, before anyone even turns them on.<strong> </strong>On average, smartphones are replaced every 2 years, laptops every 3 to 4 years, and printers every 5 years. Data center servers are replaced approximately every 5 years.</p><p class=\"pull-quote\">Extending smartphone lifecycles to 3 years instead of 2 would reduce annual manufacturing emissions by 33 percent. At scale, this dwarfs data center optimization gains.</p><p>There are programs geared towards reusing old components that are still functional and integrating them into new servers. GreenSKUs and similar initiatives show 8 percent reductions in embodied carbon are<a href=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2024/03/2024-GreenSKU-ISCA2024.pdf\" target=\"_blank\"> achievable</a>. But these remain pilot programs, not systematic approaches. And critically, they’re measured only in data center context, not across the entire IT stack.</p><p>Imagine <a href=\"https://spectrum.ieee.org/carfax-used-pcs\" target=\"_self\">applying</a> the same circular economy principles to devices. With over 2 billion laptops in existence globally and 2-3-year replacement cycles, even modest lifespan extensions create massive emission reductions. Extending smartphone lifecycles to 3 years instead of 2 would reduce annual manufacturing emissions by 33 percent. At scale, this dwarfs data center optimization gains.</p><p>Yet data center reuse gets measured, reported, and optimized. Device reuse doesn’t, because the frameworks don’t require it.</p><h2>The invisible role of software</h2><p>Leading load balancer infrastructure across IBM Cloud, I see how software architecture decisions ripple through energy consumption. Inefficient code doesn’t just slow things down—it drives up both data center power consumption and device battery drain.</p><p>For example, University of Waterloo researchers <a href=\"https://spectrum.ieee.org/data-center-energy-consumption\" target=\"_self\">showed</a> that they can reduce 30 percent of energy use in data centers by changing just 30 lines of code. From my perspective, this result is not an anomaly—it’s typical. Bad software architecture forces unnecessary data transfers, redundant computations, and excessive resource use. But unlike data center efficiency, there’s no commonly accepted metric for software efficiency.</p><p>This matters more now than ever. With AI workloads driving massive data center expansion—projected to consume 6.7-12 percent of total U.S. electricity by 2028, <a href=\"https://eta-publications.lbl.gov/sites/default/files/2024-12/lbnl-2024-united-states-data-center-energy-usage-report_1.pdf\" target=\"_blank\">according</a> to Lawrence Berkeley National Laboratory—software efficiency becomes critical.</p><h2>What needs to change</h2><p>The solution isn’t to stop measuring data center efficiency. It’s to measure device sustainability with the same rigor. Specifically, standards bodies (particularly ISO/IEC JTC 1/SC 39 WG4: Holistic Sustainability Metrics) should extend frameworks to include device lifecycle tracking, software efficiency metrics, and hardware reuse standards.</p><p>To track device lifecycles, we need standardized reporting of device embodied carbon, broken out separately by device. One aggregate number in an “everything else” category is insufficient. We need specific device categories with manufacturing emissions and replacement cycles visible.</p><p>To include software efficiency, I advocate developing a PUE-equivalent for software, such as energy per transaction, per API call, or per user session. This needs to be a reportable metric under sustainability frameworks so companies can demonstrate software optimization gains.</p><p>To encourage hardware reuse, we need to systematize reuse metrics across the full IT stack—servers and devices. This includes tracking repair rates, developing large-scale refurbishment programs, and tracking component reuse with the same detail currently applied to data center hardware.</p><p>To put it all together, we need a unified IT emission-tracking dashboard. CSRD reporting should show device embodied carbon alongside data center operational emissions, making the full IT sustainability picture visible at a glance.</p><p>These aren’t radical changes—they’re extensions of measurement principles already proven in data center context. The first step is acknowledging what we’re not measuring. The second is building the frameworks to measure it. And the third is demanding that companies report the complete picture—data centers and devices, servers and smartphones, infrastructure and software.</p><p>Because you can’t fix what you can’t see. And right now, we’re not seeing 70 percent of the problem.</p>",
        "contentSnippet": "In 2024, Google claimed that their data centers are 1.5x more energy efficient than industry average. In 2025, Microsoft committed billions to nuclear power for AI workloads. The data center industry tracks power usage effectiveness to three decimal places and optimizes water usage intensity with machine precision. We report direct emissions and energy emissions with religious fervor.\nThese are laudable advances, but these metrics account for only 30 percent of total emissions from the IT sector. The majority of the emissions are not directly from data centers or the energy they use, but from the end-user devices that actually access the data centers, emissions due to manufacturing the hardware, and software inefficiencies. We are frantically optimizing less than a third of the IT sector’s environmental impact, while the bulk of the problem goes unmeasured.\nIncomplete regulatory frameworks are part of the problem. In Europe, the Corporate Sustainability Reporting Directive (CSRD) now requires 11,700 companies to report emissions using these incomplete frameworks. The next phase of the directive, covering 40,000+ additional companies, was originally scheduled for 2026 (but is likely delayed to 2028). In the United States, the standards body responsible for IT sustainability metrics (ISO/IEC JTC 1/SC 39) is conducting active revision of its standards through 2026, with a key plenary meeting in May 2026.\nThe time to act is now. If we don’t fix the measurement frameworks, we risk locking in incomplete data collection and optimizing a fraction of what matters for the next 5 to 10 years, before the next major standards revision.\nThe limited metrics\nWalk into any modern data center and you’ll see sustainability instrumentation everywhere. Power usage efficiency (PUE) monitors track every watt. Water usage efficiency (WUE) systems measure water consumption down to the gallon. Sophisticated monitoring captures everything from server utilization to cooling efficiency to renewable energy percentages.\nBut here’s what those measurements miss: End-user devices globally emit 1.5 to 2 times more carbon than all data centers combined, according to McKinsey’s 2022 report. The smartphones, laptops, and tablets we use to access those ultra-efficient data centers are the bigger problem.\nData center operations, as measured by power usage efficiency, account for only 24 percent of the total emissions.\nOn the conservative end of the range from McKinsey’s report, devices emit 1.5 times as much as data centers. That means that data centers make up 40 percent of total IT emissions, while devices make up 60 percent.\nOn top of that, approximately 75 percent of device emissions occur not during use, but during manufacturing—this is so-called embodied carbon. For data centers, only 40 percent is embodied carbon, and 60 percent comes from operations (as measured by PUE).\nPutting this together, data center operations, as measured by PUE, account for only 24 percent of the total emissions. Data center embodied carbon is 16 percent, device embodied carbon is 45 percent, and device operation is 15 percent.\nUnder the EU’s current CSRD framework, companies must report their emissions in three categories: direct emissions from owned sources, indirect emissions from purchased energy, and a third category for everything else.\nThis “everything else” category does include device emissions and embodied carbon. However, those emissions are reported as aggregate totals broken down by accounting category—Capital Goods, Purchased Goods and Services, Use of Sold Products—but not by product type. How much comes from end-user devices versus datacenter infrastructure, or employee laptops versus network equipment, remains murky, and therefore, unoptimized.\nEmbodied carbon and hardware reuse\nManufacturing a single smartphone generates approximately 50 kg CO2 equivalent (CO2e). For a laptop, it’s 200 kg CO2e. With 1 billion smartphones replaced annually, that’s 50 million tonnes of CO2e per year just from smartphone manufacturing, before anyone even turns them on. On average, smartphones are replaced every 2 years, laptops every 3 to 4 years, and printers every 5 years. Data center servers are replaced approximately every 5 years.\nExtending smartphone lifecycles to 3 years instead of 2 would reduce annual manufacturing emissions by 33 percent. At scale, this dwarfs data center optimization gains.\nThere are programs geared towards reusing old components that are still functional and integrating them into new servers. GreenSKUs and similar initiatives show 8 percent reductions in embodied carbon are achievable. But these remain pilot programs, not systematic approaches. And critically, they’re measured only in data center context, not across the entire IT stack.\nImagine applying the same circular economy principles to devices. With over 2 billion laptops in existence globally and 2-3-year replacement cycles, even modest lifespan extensions create massive emission reductions. Extending smartphone lifecycles to 3 years instead of 2 would reduce annual manufacturing emissions by 33 percent. At scale, this dwarfs data center optimization gains.\nYet data center reuse gets measured, reported, and optimized. Device reuse doesn’t, because the frameworks don’t require it.\nThe invisible role of software\nLeading load balancer infrastructure across IBM Cloud, I see how software architecture decisions ripple through energy consumption. Inefficient code doesn’t just slow things down—it drives up both data center power consumption and device battery drain.\nFor example, University of Waterloo researchers showed that they can reduce 30 percent of energy use in data centers by changing just 30 lines of code. From my perspective, this result is not an anomaly—it’s typical. Bad software architecture forces unnecessary data transfers, redundant computations, and excessive resource use. But unlike data center efficiency, there’s no commonly accepted metric for software efficiency.\nThis matters more now than ever. With AI workloads driving massive data center expansion—projected to consume 6.7-12 percent of total U.S. electricity by 2028, according to Lawrence Berkeley National Laboratory—software efficiency becomes critical.\nWhat needs to change\nThe solution isn’t to stop measuring data center efficiency. It’s to measure device sustainability with the same rigor. Specifically, standards bodies (particularly ISO/IEC JTC 1/SC 39 WG4: Holistic Sustainability Metrics) should extend frameworks to include device lifecycle tracking, software efficiency metrics, and hardware reuse standards.\nTo track device lifecycles, we need standardized reporting of device embodied carbon, broken out separately by device. One aggregate number in an “everything else” category is insufficient. We need specific device categories with manufacturing emissions and replacement cycles visible.\nTo include software efficiency, I advocate developing a PUE-equivalent for software, such as energy per transaction, per API call, or per user session. This needs to be a reportable metric under sustainability frameworks so companies can demonstrate software optimization gains.\nTo encourage hardware reuse, we need to systematize reuse metrics across the full IT stack—servers and devices. This includes tracking repair rates, developing large-scale refurbishment programs, and tracking component reuse with the same detail currently applied to data center hardware.\nTo put it all together, we need a unified IT emission-tracking dashboard. CSRD reporting should show device embodied carbon alongside data center operational emissions, making the full IT sustainability picture visible at a glance.\nThese aren’t radical changes—they’re extensions of measurement principles already proven in data center context. The first step is acknowledging what we’re not measuring. The second is building the frameworks to measure it. And the third is demanding that companies report the complete picture—data centers and devices, servers and smartphones, infrastructure and software.\nBecause you can’t fix what you can’t see. And right now, we’re not seeing 70 percent of the problem.",
        "pubDate": "Tue, 17 Feb 2026 15:00:03 +0000",
        "isoDate": "2026-02-17T15:00:03.000Z",
        "creator": "Arjun Sharma",
        "source": "https://spectrum.ieee.org/data-center-sustainability-metrics"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-y4wle8",
        "title": "This Former Physicist Helps Keep the Internet Secure",
        "link": "https://spectrum.ieee.org/network-security-engineer-alan-dekok",
        "url": "https://spectrum.ieee.org/network-security-engineer-alan-dekok",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/person-in-blue-suit-examines-illuminated-server-racks-in-a-dimly-lit-room.png?id=64440487&width=1245&height=700&coordinates=0%2C104%2C0%2C105\"/><br/><br/><p>When <a href=\"https://www.linkedin.com/in/alandekok/\" rel=\"noopener noreferrer\" target=\"_blank\">Alan DeKok</a> began a side project in network security, he didn’t expect to start a 27-year career. In fact, he didn’t initially set out to work in computing at all.</p><p>DeKok studied nuclear physics before making the switch to a part of network computing that is foundational but—like nuclear physics—largely invisible to those not directly involved in the field. Eventually, a project he started as a hobby became a full-time job: maintaining one of the primary systems that helps keep the internet secure.</p><h3>Alan DeKok</h3><br/><p><strong>Employer</strong></p><p>InkBridge Networks</p><p><strong>Occupation</strong></p><p>CEO</p><p><strong>Education </strong></p><p>Bachelor’s degree in physics, Carleton University; master’s degree in physics, Carleton University</p><p>Today, he leads the <a href=\"https://www.freeradius.org/\" rel=\"noopener noreferrer\" target=\"_blank\">FreeRADIUS Project</a>, which he cofounded in the late 1990s to develop what is now the most widely used Remote Authentication Dial-In User Service (RADIUS) software. FreeRADIUS is an open-source server that provides back-end authentication for most major <a href=\"https://spectrum.ieee.org/tag/internet-service-providers\" target=\"_blank\">internet service providers</a>. It’s used by global financial institutions, Wi-Fi services like <a href=\"https://eduroam.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Eduroam</a>, and Fortune 50 companies. DeKok is also CEO of <a href=\"https://www.inkbridgenetworks.com/\" rel=\"noopener noreferrer\" target=\"_blank\">InkBridge Networks</a>, which maintains the server and provides support for the companies that use it.</p><p>Reflecting on nearly three decades of experience leading FreeRADIUS, DeKok says he became an expert in remote authentication “almost by accident,” and the key to his career has largely been luck. “I really believe that it’s preparing yourself for luck, being open to it, and having the skills to capitalize on it.”</p><h2>From Farming to Physics</h2><p>DeKok grew up on a farm outside of Ottawa growing strawberries and raspberries. “Sitting on a tractor in the heat is not particularly interesting,” says DeKok, who was more interested in working with 8-bit computers than crops. As a student at <a href=\"https://carleton.ca/\" rel=\"noopener noreferrer\" target=\"_blank\">Carleton University</a>, in Ottawa, he found his way to physics because he was interested in math but preferred the practicality of science.</p><p>While pursuing a master’s degree in physics, also at Carleton, he worked on a water-purification system for the Sudbury Neutrino Observatory, an underground observatory then being built at the bottom of a nickel mine. He would wake up at 4:30 in the morning to drive up to the site, descend 2 kilometers, then enter one of the world’s <a href=\"https://www.snolab.ca/about/about-snolab/\" rel=\"noopener noreferrer\" target=\"_blank\">deepest clean-room facilities</a> to work on the project. The system managed to achieve one atom of impurity per cubic meter of water, “which is pretty insane,” DeKok says.</p><p>But after his master’s degree, DeKok decided to take a different route. Although he found nuclear physics interesting, he says he didn’t see it as his life’s work. Meanwhile, the Ph.D. students he knew were “fanatical about physics.” He had kept up his computing skills through his education, which involved plenty of programming, and decided to look for jobs at computing companies. “I was out of physics. That was it.”</p><p>Still, physics taught him valuable lessons. For one, “You have to understand the big picture,” DeKok says. “The ability to tell the big-picture story in standards, for example, is extremely important.” This skill helps DeKok explain to standards bodies how a protocol acts as one link in the entire chain of events that needs to occur when a user wants to access the internet.</p><p>He also learned that “methods are more important than knowledge.” It’s easy to look up information, but physics taught DeKok how to break down a problem into manageable pieces to come up with a solution. “When I was eventually working in the industry, the techniques that came naturally to me, coming out of physics, didn’t seem to be taught as well to the people I knew in engineering,” he says. “I could catch up very quickly.”</p><h2>Founding FreeRADIUS</h2><p>In 1996, DeKok was hired as a software developer at a company called Gandalf, which made equipment for ISDN, a precursor to broadband that enabled digital transmission of data over telephone lines. Gandalf went under about a year later, and he joined CryptoCard, a company providing hardware devices for two-factor authentication.</p><p>While at CryptoCard, DeKok began spending more time working with a RADIUS server. When users want to connect to a network, RADIUS acts as a gatekeeper and verifies their identity and password, determines what they can access, and tracks sessions. DeKok moved on to a new company in 1999, but he didn’t want to lose the networking skills he had developed. No other open-source RADIUS servers were being actively developed at the time, and he saw a gap in the market.</p><p>The same year, he started FreeRADIUS in his free time and it “gradually took over my life,” DeKok says. He continued to work on the open-source software as a hobby for several years while bouncing around companies in California and France. “Almost by accident, I became one of the more senior people in the space. Then I doubled down on that and started the business.” He founded NetworkRADIUS (now called InkBridge Networks) in 2008.</p><p>By that point, FreeRADIUS was already being used by <a href=\"https://www.freeradius.org/about/#usage_statistics\" rel=\"noopener noreferrer\" target=\"_blank\">100 million people daily</a>. The company now employs experts in Canada, France, and the United Kingdom who work together to support FreeRADIUS. “I’d say at least half of the people in the world get on the internet by being authenticated through my software,” DeKok estimates. He attributes that growth largely to the software being open source. Initially a way to enter the market with little funding, going open source has allowed FreeRADIUS to compete with bigger companies as an industry-leading product.</p><p>Although the software is critical for maintaining secure networks, most people aren’t aware of it because it works behind the scenes. DeKok is often met with surprise that it’s still in use. He compares RADIUS to a building foundation: “You need it, but you never think about it until there’s a crack in it.”</p><h2>27 Years of Fixes</h2><p>Over the years, DeKok has maintained FreeRADIUS by continually making small fixes. Like using a ratcheting tool to make a change inch by inch, “you shouldn’t underestimate that ratchet effect of tiny little fixes that add up over time,” he says.</p><p>He’s seen the project through minor patches and more significant fixes, like when researchers <a href=\"https://www.freeradius.org/vul_notifications/2024/07/09/blastradius.html\" rel=\"noopener noreferrer\" target=\"_blank\">exposed a widespread vulnerability</a> DeKok had been trying to fix since 1998. He also watched a would-be successor to the network protocol, <a href=\"https://www.sciencedirect.com/topics/engineering/diameter-protocol\" rel=\"noopener noreferrer\" target=\"_blank\">Diameter</a>, rise and fall in popularity in the 2000s and 2010s. (Diameter gained traction in mobile applications but has gradually been phased out in the <a href=\"https://spectrum.ieee.org/telecom-experts-plot-a-path-to-5g\" target=\"_self\">shift to 5G</a>.) Though Diameter offers improvements, RADIUS is far simpler and already widely implemented, giving it an edge, DeKok explains.</p><p>And he remains confident about its future. “People ask me, ‘What’s next for RADIUS?’ I don’t see it dying.” Estimating that billions of dollars of equipment run RADIUS, he says, “It’s never going to go away.”</p><p>About his own career, DeKok says he plans to keep working on FreeRADIUS, exploring new markets and products. “I never expected to have a company and a lot of people working for me, my name on all kinds of standards, and customers all over the world. But it worked out that way.”</p><p><em>This article appears in the March 2026 print issue as “<span>Alan DeKok</span>.”</em></p>",
        "contentSnippet": "When Alan DeKok began a side project in network security, he didn’t expect to start a 27-year career. In fact, he didn’t initially set out to work in computing at all.\nDeKok studied nuclear physics before making the switch to a part of network computing that is foundational but—like nuclear physics—largely invisible to those not directly involved in the field. Eventually, a project he started as a hobby became a full-time job: maintaining one of the primary systems that helps keep the internet secure.\nAlan DeKok\n\nEmployer\nInkBridge Networks\nOccupation\nCEO\nEducation \nBachelor’s degree in physics, Carleton University; master’s degree in physics, Carleton University\nToday, he leads the FreeRADIUS Project, which he cofounded in the late 1990s to develop what is now the most widely used Remote Authentication Dial-In User Service (RADIUS) software. FreeRADIUS is an open-source server that provides back-end authentication for most major internet service providers. It’s used by global financial institutions, Wi-Fi services like Eduroam, and Fortune 50 companies. DeKok is also CEO of InkBridge Networks, which maintains the server and provides support for the companies that use it.\nReflecting on nearly three decades of experience leading FreeRADIUS, DeKok says he became an expert in remote authentication “almost by accident,” and the key to his career has largely been luck. “I really believe that it’s preparing yourself for luck, being open to it, and having the skills to capitalize on it.”\nFrom Farming to Physics\nDeKok grew up on a farm outside of Ottawa growing strawberries and raspberries. “Sitting on a tractor in the heat is not particularly interesting,” says DeKok, who was more interested in working with 8-bit computers than crops. As a student at Carleton University, in Ottawa, he found his way to physics because he was interested in math but preferred the practicality of science.\nWhile pursuing a master’s degree in physics, also at Carleton, he worked on a water-purification system for the Sudbury Neutrino Observatory, an underground observatory then being built at the bottom of a nickel mine. He would wake up at 4:30 in the morning to drive up to the site, descend 2 kilometers, then enter one of the world’s deepest clean-room facilities to work on the project. The system managed to achieve one atom of impurity per cubic meter of water, “which is pretty insane,” DeKok says.\nBut after his master’s degree, DeKok decided to take a different route. Although he found nuclear physics interesting, he says he didn’t see it as his life’s work. Meanwhile, the Ph.D. students he knew were “fanatical about physics.” He had kept up his computing skills through his education, which involved plenty of programming, and decided to look for jobs at computing companies. “I was out of physics. That was it.”\nStill, physics taught him valuable lessons. For one, “You have to understand the big picture,” DeKok says. “The ability to tell the big-picture story in standards, for example, is extremely important.” This skill helps DeKok explain to standards bodies how a protocol acts as one link in the entire chain of events that needs to occur when a user wants to access the internet.\nHe also learned that “methods are more important than knowledge.” It’s easy to look up information, but physics taught DeKok how to break down a problem into manageable pieces to come up with a solution. “When I was eventually working in the industry, the techniques that came naturally to me, coming out of physics, didn’t seem to be taught as well to the people I knew in engineering,” he says. “I could catch up very quickly.”\nFounding FreeRADIUS\nIn 1996, DeKok was hired as a software developer at a company called Gandalf, which made equipment for ISDN, a precursor to broadband that enabled digital transmission of data over telephone lines. Gandalf went under about a year later, and he joined CryptoCard, a company providing hardware devices for two-factor authentication.\nWhile at CryptoCard, DeKok began spending more time working with a RADIUS server. When users want to connect to a network, RADIUS acts as a gatekeeper and verifies their identity and password, determines what they can access, and tracks sessions. DeKok moved on to a new company in 1999, but he didn’t want to lose the networking skills he had developed. No other open-source RADIUS servers were being actively developed at the time, and he saw a gap in the market.\nThe same year, he started FreeRADIUS in his free time and it “gradually took over my life,” DeKok says. He continued to work on the open-source software as a hobby for several years while bouncing around companies in California and France. “Almost by accident, I became one of the more senior people in the space. Then I doubled down on that and started the business.” He founded NetworkRADIUS (now called InkBridge Networks) in 2008.\nBy that point, FreeRADIUS was already being used by 100 million people daily. The company now employs experts in Canada, France, and the United Kingdom who work together to support FreeRADIUS. “I’d say at least half of the people in the world get on the internet by being authenticated through my software,” DeKok estimates. He attributes that growth largely to the software being open source. Initially a way to enter the market with little funding, going open source has allowed FreeRADIUS to compete with bigger companies as an industry-leading product.\nAlthough the software is critical for maintaining secure networks, most people aren’t aware of it because it works behind the scenes. DeKok is often met with surprise that it’s still in use. He compares RADIUS to a building foundation: “You need it, but you never think about it until there’s a crack in it.”\n27 Years of Fixes\nOver the years, DeKok has maintained FreeRADIUS by continually making small fixes. Like using a ratcheting tool to make a change inch by inch, “you shouldn’t underestimate that ratchet effect of tiny little fixes that add up over time,” he says.\nHe’s seen the project through minor patches and more significant fixes, like when researchers exposed a widespread vulnerability DeKok had been trying to fix since 1998. He also watched a would-be successor to the network protocol, Diameter, rise and fall in popularity in the 2000s and 2010s. (Diameter gained traction in mobile applications but has gradually been phased out in the shift to 5G.) Though Diameter offers improvements, RADIUS is far simpler and already widely implemented, giving it an edge, DeKok explains.\nAnd he remains confident about its future. “People ask me, ‘What’s next for RADIUS?’ I don’t see it dying.” Estimating that billions of dollars of equipment run RADIUS, he says, “It’s never going to go away.”\nAbout his own career, DeKok says he plans to keep working on FreeRADIUS, exploring new markets and products. “I never expected to have a company and a lot of people working for me, my name on all kinds of standards, and customers all over the world. But it worked out that way.”\nThis article appears in the March 2026 print issue as “Alan DeKok.”",
        "pubDate": "Mon, 16 Feb 2026 14:00:02 +0000",
        "isoDate": "2026-02-16T14:00:02.000Z",
        "creator": "Gwendolyn Rak",
        "source": "https://spectrum.ieee.org/network-security-engineer-alan-dekok"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-68qwel",
        "title": "NASA Let AI Drive the Perseverance Rover",
        "link": "https://spectrum.ieee.org/perseverance-rover-nasa-anthropic-ai",
        "url": "https://spectrum.ieee.org/perseverance-rover-nasa-anthropic-ai",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/still-image-from-a-3d-animation-of-nasa-s-perseverance-rover-driving-over-mars-rough-terrain.jpg?id=64437492&width=1245&height=700&coordinates=0%2C145%2C0%2C146\"/><br/><br/><p><span>In December, NASA took another small, incremental step towards autonomous surface rovers. In a demonstration, the Perseverance team <a href=\"https://www.jpl.nasa.gov/news/nasas-perseverance-rover-completes-first-ai-planned-drive-on-mars/\" target=\"_blank\">used AI to generate the rover’s waypoints</a>. Perseverance used the AI waypoints on two separate days, traveling a total of 456 meters without human control.</span></p><p>“This demonstration shows how far our capabilities have advanced and broadens how we will explore other worlds,” said NASA Administrator <a href=\"https://www.nasa.gov/people/jared-isaacman/\" target=\"_blank\">Jared Isaacman</a>. “Autonomous technologies like this can help missions to operate more efficiently, respond to challenging terrain, and increase science return as distance from Earth grows. It’s a strong example of teams applying new technology carefully and responsibly in real operations.”</p><h3></h3><br/><div class=\"badge_module shortcode-media shortcode-media-rebelmouse-image rm-float-left rm-resized-container rm-resized-container-25\">\n<a class=\"rm-stats-tracked\" href=\"https://www.universetoday.com/\" target=\"_blank\">\n<img alt='Universe Today logo; text reads \"This post originally appeared on Universe Today.\"' class=\"rm-shortcode rm-lazyloadable-image\" src=\"https://spectrum.ieee.org/media-library/universe-today-logo-text-reads-this-post-originally-appeared-on-universe-today.png?id=60568425&width=1800&quality=85\"/></a>\n</div>\n<p>Mars is a long way away, and there’s about a 25-minute delay for a round trip signal between Earth and Mars. That means that one way or another, rovers are on their own for short periods of time.</p><p>The delay shapes the route-planning process. Rover drivers here on Earth examine images and elevation data and program a series of waypoints, which usually don’t exceed 100 meters apart. The driving plan is sent to <a href=\"https://eyes.nasa.gov/apps/dsn-now/\" target=\"_blank\">NASA’s Deep Space Network</a> (DSN), which transmits it to one of several orbiters, which then relay it to Perseverance. (Perseverance can receive direct comms from the DSN as a back up, but the data rate is slower.)</p><h2>AI Enhances Mars Rover Navigation</h2><p>In this demonstration, the AI model analyzed orbital images from the Mars Reconnaissance Orbiter’s <a href=\"https://www.uahirise.org/\" target=\"_blank\">HiRISE camera</a>, as well as digital elevation models. The AI, which is based on <a data-linked-post=\"2672366203\" href=\"https://spectrum.ieee.org/best-ai-coding-tools\" target=\"_blank\">Anthropic’s Claude AI</a>, identified hazards like sand traps, boulder fields, bedrock, and rocky outcrops. Then it generated a path defined by a series of waypoints that avoids the hazards. From there, Perseverance’s auto-navigation system took over. It has more autonomy than its predecessors and can process images and driving plans while in motion.</p><p>There was another important step before these waypoints were transmitted to Perseverance. NASA’s Jet Propulsion Laboratory has a “twin” for Perseverance called the “Vehicle System Test Bed” (VSTB) in JPL’s <a href=\"https://www-robotics.jpl.nasa.gov/how-we-do-it/facilities/marsyard-iii/\" target=\"_blank\">Mars Yard</a>. It’s an engineering model that the team can work with here on Earth to solve problems, or for situations like this. These engineering versions are common on Mars missions, and JPL has one for Curiosity, too.</p><p>“The fundamental elements of generative AI are showing a lot of promise in streamlining the pillars of autonomous navigation for off-planet driving: perception (seeing the rocks and ripples), localization (knowing where we are), and planning and control (deciding and executing the safest path),” said Vandi Verma, a space roboticist at JPL and a member of the Perseverance engineering team. “We are moving towards a day where generative AI and other smart tools will help our surface rovers handle kilometer-scale drives while minimizing operator workload, and flag interesting surface features for our science team by scouring huge volumes of rover images.”</p><h2>AI’s Expanding Role in Space Exploration</h2><p><span><a href=\"https://spectrum.ieee.org/ai-agents\" target=\"_blank\">AI is rapidly becoming ubiquitous in our lives</a>, showing up in places that don’t necessarily have a strong use case for it. But this isn’t NASA hopping on the AI bandwagon. They’ve been developing automatic navigation systems for a while, out of necessity. In fact, Perseverance’s primary means of driving is its self-driving autonomous navigation system.</span></p><p>One thing that prevents fully-autonomous driving is the way uncertainty grows as the rover operates without human assistance. The longer the rover travels, the more uncertain it becomes about its position on the surface. The solution is to re-localize the rover on its map. Currently, humans do this. But this takes time, including a complete communication cycle between Earth and Mars. Overall, it limits how far Perseverance can go without a helping hand.</p><p>NASA/JPL is also working on a way that Perseverance can <a href=\"https://www-robotics.jpl.nasa.gov/media/documents/2024_Global_Localization_ICRA.pdf\" target=\"_blank\">use AI to re-localize</a>. The main roadblock is matching orbital images with the rover’s ground-level images. It seems highly likely that AI will be trained to excel at this.</p><p>It’s obvious that AI is set to play a much larger role in planetary exploration. The next Mars rover may be much different than current ones, with more advanced autonomous navigation and other AI features. There are already concepts for a swarm of <a href=\"https://spectrum.ieee.org/mars-helicopter-ingenuity-end-mission\" target=\"_blank\">flying drones released by a rover</a> to expand its explorative reach on Mars. These swarms would be controlled by AI to work together and autonomously.</p><p>And it’s not just Mars exploration that will benefit from AI. NASA’s <a href=\"https://en.wikipedia.org/wiki/Dragonfly_(Titan_space_probe)#\" target=\"_blank\">Dragonfly</a> mission to Saturn’s moon Titan will make extensive use of AI. Not only for autonomous navigation as the rotorcraft flies around, but also for autonomous data curation.</p><p>“Imagine intelligent systems not only on the ground at Earth, but also in edge applications in our rovers, helicopters, drones, and other surface elements trained with the collective wisdom of our NASA engineers, scientists, and astronauts,” said Matt Wallace, manager of JPL’s Exploration Systems Office. “That is the game-changing technology we need to establish the infrastructure and systems required for a permanent human presence on the Moon and take the U.S. to Mars and beyond.”</p>",
        "contentSnippet": "In December, NASA took another small, incremental step towards autonomous surface rovers. In a demonstration, the Perseverance team used AI to generate the rover’s waypoints. Perseverance used the AI waypoints on two separate days, traveling a total of 456 meters without human control.\n“This demonstration shows how far our capabilities have advanced and broadens how we will explore other worlds,” said NASA Administrator Jared Isaacman. “Autonomous technologies like this can help missions to operate more efficiently, respond to challenging terrain, and increase science return as distance from Earth grows. It’s a strong example of teams applying new technology carefully and responsibly in real operations.”\n\n\n\n\nMars is a long way away, and there’s about a 25-minute delay for a round trip signal between Earth and Mars. That means that one way or another, rovers are on their own for short periods of time.\nThe delay shapes the route-planning process. Rover drivers here on Earth examine images and elevation data and program a series of waypoints, which usually don’t exceed 100 meters apart. The driving plan is sent to NASA’s Deep Space Network (DSN), which transmits it to one of several orbiters, which then relay it to Perseverance. (Perseverance can receive direct comms from the DSN as a back up, but the data rate is slower.)\nAI Enhances Mars Rover Navigation\nIn this demonstration, the AI model analyzed orbital images from the Mars Reconnaissance Orbiter’s HiRISE camera, as well as digital elevation models. The AI, which is based on Anthropic’s Claude AI, identified hazards like sand traps, boulder fields, bedrock, and rocky outcrops. Then it generated a path defined by a series of waypoints that avoids the hazards. From there, Perseverance’s auto-navigation system took over. It has more autonomy than its predecessors and can process images and driving plans while in motion.\nThere was another important step before these waypoints were transmitted to Perseverance. NASA’s Jet Propulsion Laboratory has a “twin” for Perseverance called the “Vehicle System Test Bed” (VSTB) in JPL’s Mars Yard. It’s an engineering model that the team can work with here on Earth to solve problems, or for situations like this. These engineering versions are common on Mars missions, and JPL has one for Curiosity, too.\n“The fundamental elements of generative AI are showing a lot of promise in streamlining the pillars of autonomous navigation for off-planet driving: perception (seeing the rocks and ripples), localization (knowing where we are), and planning and control (deciding and executing the safest path),” said Vandi Verma, a space roboticist at JPL and a member of the Perseverance engineering team. “We are moving towards a day where generative AI and other smart tools will help our surface rovers handle kilometer-scale drives while minimizing operator workload, and flag interesting surface features for our science team by scouring huge volumes of rover images.”\nAI’s Expanding Role in Space Exploration\nAI is rapidly becoming ubiquitous in our lives, showing up in places that don’t necessarily have a strong use case for it. But this isn’t NASA hopping on the AI bandwagon. They’ve been developing automatic navigation systems for a while, out of necessity. In fact, Perseverance’s primary means of driving is its self-driving autonomous navigation system.\nOne thing that prevents fully-autonomous driving is the way uncertainty grows as the rover operates without human assistance. The longer the rover travels, the more uncertain it becomes about its position on the surface. The solution is to re-localize the rover on its map. Currently, humans do this. But this takes time, including a complete communication cycle between Earth and Mars. Overall, it limits how far Perseverance can go without a helping hand.\nNASA/JPL is also working on a way that Perseverance can use AI to re-localize. The main roadblock is matching orbital images with the rover’s ground-level images. It seems highly likely that AI will be trained to excel at this.\nIt’s obvious that AI is set to play a much larger role in planetary exploration. The next Mars rover may be much different than current ones, with more advanced autonomous navigation and other AI features. There are already concepts for a swarm of flying drones released by a rover to expand its explorative reach on Mars. These swarms would be controlled by AI to work together and autonomously.\nAnd it’s not just Mars exploration that will benefit from AI. NASA’s Dragonfly mission to Saturn’s moon Titan will make extensive use of AI. Not only for autonomous navigation as the rotorcraft flies around, but also for autonomous data curation.\n“Imagine intelligent systems not only on the ground at Earth, but also in edge applications in our rovers, helicopters, drones, and other surface elements trained with the collective wisdom of our NASA engineers, scientists, and astronauts,” said Matt Wallace, manager of JPL’s Exploration Systems Office. “That is the game-changing technology we need to establish the infrastructure and systems required for a permanent human presence on the Moon and take the U.S. to Mars and beyond.”",
        "pubDate": "Sun, 15 Feb 2026 14:00:02 +0000",
        "isoDate": "2026-02-15T14:00:02.000Z",
        "creator": "Evan Gough",
        "source": "https://spectrum.ieee.org/perseverance-rover-nasa-anthropic-ai"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-hvkeu0",
        "title": "Sub-$200 Lidar Could Reshuffle  Auto Sensor Economics",
        "link": "https://spectrum.ieee.org/solid-state-lidar-microvision-adas",
        "url": "https://spectrum.ieee.org/solid-state-lidar-microvision-adas",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/close-up-of-microvision-s-movia-s-lidar-unit.jpg?id=64423662&width=1245&height=700&coordinates=0%2C187%2C0%2C188\"/><br/><br/><p><a href=\"https://microvision.com/?gad_source=1&gad_campaignid=21340770932&gbraid=0AAAAApwXbe5Ghi8hWwJCToToqvbQ8BYwF&gclid=CjwKCAiAqKbMBhBmEiwAZ3UboOY9pR0tGoc42GaZ--CDqFzYKG_Hy0C5eGuz7BgFbJEvneRuVuEvmhoCPD4QAvD_BwE\" rel=\"noopener noreferrer\" target=\"_blank\">MicroVision</a><span>, a solid-state sensor technology company located in Redmond, Wash., says it has designed a solid-state automotive </span><a href=\"https://spectrum.ieee.org/tag/lidar\" target=\"_self\">lidar</a><span> sensor intended to reach production pricing below US $200. That’s less than half of typical prices now, and it’s not even the full extent of the company’s ambition. The company says its longer-term goal is $100 per unit. MicroVision’s claim, which, if realized, would place lidar within reach of </span><a href=\"https://spectrum.ieee.org/tag/adas\" target=\"_self\">advanced driver-assistance systems</a><span> (ADAS) rather than limiting it to high-end </span><a href=\"https://spectrum.ieee.org/tag/autonomous-vehicles\" target=\"_self\">autonomous vehicle</a><span> programs. Lidar’s limited market penetration comes down to one issue: cost.</span><span></span></p><p>Comparable mechanical lidars from multiple suppliers now sell in the $10,000 to $20,000 range. That price roughly tenfold drop, from about $80,000, helps explain why suppliers now are now hopeful that another steep price reduction is on the horizon.</p><p>For solid-state devices, “it is feasible to bring the cost down even more when manufacturing at high volume,” <span>says </span><a href=\"https://engineering.msu.edu/directory/faculty/radha\" target=\"_blank\">Hayder Radha</a><span>, a professor of electrical and computer engineering at </span><a href=\"https://msu.edu/\" target=\"_blank\">Michigan State University</a> and director of the school’s <a href=\"https://canvas.msu.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Connected & Autonomous Networked Vehicles for Active Safety</a> program. With demand expanding beyond fully autonomous vehicles into driver-assistance applications, “one order or even two orders of magnitude reduction in cost are feasible.”</p><p>“We are focused on delivering automotive-grade lidar that can actually be deployed at scale,” says MicroVision CEO <a href=\"https://ir.microvision.com/news/press-releases/detail/430/microvision-appoints-glen-devos-as-chief-executive-officer\" target=\"_blank\">Glen DeVos</a>. “That means designing for cost, manufacturability, and integration from the start—not treating price as an afterthought.”</p><h2>MicroVision’s Lidar System</h2><p><a href=\"https://www.tesla.com/\" target=\"_blank\">Tesla</a> CEO <a href=\"https://www.tesla.com/elon-musk\" rel=\"noopener noreferrer\" target=\"_blank\">Elon Musk</a> famously dismissed lidar in 2019 as “<a href=\"https://professional.mit.edu/news/articles/lidar-fools-errand\" rel=\"noopener noreferrer\" target=\"_blank\">a fool’s errand</a>,” arguing that cameras and radar alone were sufficient for automated driving. A credible path to sub-$200 pricing would fundamentally alter the calculus of autonomous-car design by lowering the cost of adding precise three-dimensional sensing to mainstream vehicles. The shift reflects a broader industry trend toward solid-state lidar designs optimized for low-cost, high-volume manufacturing rather than maximum range or resolution.</p><p>Before those economics can be evaluated, however, it’s important to understand what MicroVision is proposing to build.</p><p>The company’s <a href=\"https://microvision.com/sensors/movia-s\" rel=\"noopener noreferrer\" target=\"_blank\">Movia S</a> is a solid-state lidar. Mounted at the corners of a vehicle, the sensor sends out 905-nanometer-wavelength laser pulses and measures how long it takes for light reflected from the surfaces of nearby objects to return. The arrangement of the beam emitters and receivers provides a fixed field of view designed for 180-degree horizontal coverage rather than full 360-degree scanning typical of traditional mechanical units. The company says the unit can detect objects at distances of up to roughly 200 meters under favorable weather conditions—compared with the roughly 300-meter radius scanned by mechanical systems—and supports frame rates suitable for real-time perception in driver-assistance systems. Earlier mechanical lidars, used spinning components to steer their beams but the Movia S is a phased-arraysystem. It controls the amplitude and phase of the signals across an array of antenna elements to steer the beam. The unit is designed to meet automotive requirements for vibration tolerance, temperature range, and environmental sealing.</p><p>MicroVision’s pricing targets might sound aggressive, but they are not without precedent. The lidar industry has already experienced one major cost reset over the past decade.</p><p class=\"pull-quote\">“Automakers are not buying a single sensor in isolation... They are designing a perception system, and cost only matters if the system as a whole is viable.” <strong>–Glen DeVos, MicroVision</strong></p><p>Around 2016 and 2017, mechanical lidar systems used in early autonomous driving research often sold for close to $100,000. Those units relied on spinning assemblies to sweep laser beams across a full 360 degrees, which made them expensive to build and difficult to ruggedize for consumer vehicles.</p><p>“Back then, a 64-beam <a href=\"https://investors.ouster.com/news-releases/news-release-details/ouster-and-velodyne-complete-merger-equals-accelerate-lidar\" rel=\"noopener noreferrer\" target=\"_blank\">Velodyne</a> lidar cost around $80,000,” says Radha.</p><p>Comparable mechanical lidars from multiple suppliers now sell in the $10,000 to $20,000 range. That roughly tenfold drop helps explain why suppliers now believe another steep price reduction is possible. </p><p>“For solid-state devices, it is feasible to bring the cost down even more when manufacturing at high volume,” Radha says. With demand expanding beyond fully <a href=\"https://spectrum.ieee.org/tag/autonomous-vehicles\" target=\"_self\">autonomous vehicles</a> into driver-assistance applications, “one order or even two orders of magnitude reduction in cost are feasible.”</p><h2>Solid-State Lidar Design Challenges</h2><p>Lower cost, however, does not come for free. The same design choices that enable solid-state lidar to scale also introduce new constraints.</p><p>“Unlike mechanical lidars, which provide full 360-degree coverage, solid-state lidars tend to have a much smaller field of view,” Radha says. Many cover 180 degrees or less.</p><p>That limitation shifts the burden from the sensor to the system. Automakers will need to deploy three or four solid-state lidars around a vehicle to achieve full coverage. Even so, Radha notes, the total cost can still undercut that of a single mechanical unit.</p><p>What changes is integration. Multiple sensors must be aligned, calibrated, and synchronized so their data can be fused accurately. The engineering is manageable, but it adds complexity that price targets alone do not capture.</p><p>DeVos says MicroVision’s design choices reflect that reality. “Automakers are not buying a single sensor in isolation,” he says. “They are designing a perception system, and cost only matters if the system as a whole is viable.”</p><p>Those system-level tradeoffs help explain where low-cost lidar is most likely to appear first.</p><p>Most advanced driver assistance systems today rely on cameras and radar, which are significantly cheaper than lidar. Cameras provide dense visual information, while radar offers reliable range and velocity data, particularly in poor weather. Radha estimates that lidar remains roughly an order of magnitude more expensive than automotive radar.</p><p>But at prices in the $100 to $200 range, that gap narrows enough to change design decisions.</p><p>“At that point, lidar becomes appealing because of its superior capability in precise 3D detection and tracking,” Radha says.</p><p>Rather than replacing existing sensors, lower-cost lidar would likely augment them, adding redundancy and improving performance in complex environments that are challenging for electronic perception systems. That incremental improvement aligns more closely with how ADAS features are deployed today than with the leap to full vehicle autonomy.</p><p>MicroVision is not alone in pursuing solid-state lidar, and several suppliers including Chinese firms Hesai and RoboSense and other major suppliers such as Luminar and Velodyne have announced long-term cost targets below $500. What distinguishes current claims is the explicit focus on sub-$200 pricing tied to production volume rather than future prototypes or limited pilot runs.</p><p>Some competitors continue to prioritize long-range performance for autonomous vehicles, which pushes cost upward. Others have avoided aggressive pricing claims until they secure firm production commitments from automakers.</p><p>That caution reflects a structural challenge: Reaching consumer-level pricing requires large, predictable demand. Without it, few suppliers can justify the manufacturing investments needed to achieve true economies of scale.</p><h2>Evaluating Lidar Performance Metrics</h2><h2></h2><p>Even if low-cost lidar becomes manufacturable, another question remains: How should its performance be judged?</p><p>From a systems-engineering perspective, Radha says cost milestones often overshadow safety metrics.</p><p>“The key objective of ADAS and autonomous systems is improving safety,” he says. Yet there is no universally adopted metric that directly expresses safety gains from a given sensor configuration.</p><p>Researchers instead rely on perception benchmarks such as <a href=\"https://www.v7labs.com/blog/mean-average-precision\" rel=\"noopener noreferrer\" target=\"_blank\">mean Average Precision</a>, or mAP, which measures how accurately a system detects and tracks objects in its environment. Including such metrics alongside cost targets, says Radha, would clarify what performance is preserved or sacrificed as prices fall.</p><p><em>IEEE Spectrum</em> has covered lidar extensively, often focusing on technical advances in scanning, range, and resolution. What distinguishes the current moment is the renewed focus on economics rather than raw capability</p><p>If solid-state lidar can reliably reach sub-$200 pricing, it will not invalidate Elon Musk’s skepticism—but it will weaken one of its strongest foundations. When cost stops being the dominant objection, automakers will have to decide whether leaving lidar out is a technical judgment or a strategic one.</p><p>That decision, more than any single price claim, may determine whether lidar finally becomes a routine component of vehicle safety systems.</p>",
        "contentSnippet": "MicroVision, a solid-state sensor technology company located in Redmond, Wash., says it has designed a solid-state automotive lidar sensor intended to reach production pricing below US $200. That’s less than half of typical prices now, and it’s not even the full extent of the company’s ambition. The company says its longer-term goal is $100 per unit. MicroVision’s claim, which, if realized, would place lidar within reach of advanced driver-assistance systems (ADAS) rather than limiting it to high-end autonomous vehicle programs. Lidar’s limited market penetration comes down to one issue: cost.\nComparable mechanical lidars from multiple suppliers now sell in the $10,000 to $20,000 range. That price roughly tenfold drop, from about $80,000, helps explain why suppliers now are now hopeful that another steep price reduction is on the horizon.\nFor solid-state devices, “it is feasible to bring the cost down even more when manufacturing at high volume,” says Hayder Radha, a professor of electrical and computer engineering at Michigan State University and director of the school’s Connected & Autonomous Networked Vehicles for Active Safety program. With demand expanding beyond fully autonomous vehicles into driver-assistance applications, “one order or even two orders of magnitude reduction in cost are feasible.”\n“We are focused on delivering automotive-grade lidar that can actually be deployed at scale,” says MicroVision CEO Glen DeVos. “That means designing for cost, manufacturability, and integration from the start—not treating price as an afterthought.”\nMicroVision’s Lidar System\nTesla CEO Elon Musk famously dismissed lidar in 2019 as “a fool’s errand,” arguing that cameras and radar alone were sufficient for automated driving. A credible path to sub-$200 pricing would fundamentally alter the calculus of autonomous-car design by lowering the cost of adding precise three-dimensional sensing to mainstream vehicles. The shift reflects a broader industry trend toward solid-state lidar designs optimized for low-cost, high-volume manufacturing rather than maximum range or resolution.\nBefore those economics can be evaluated, however, it’s important to understand what MicroVision is proposing to build.\nThe company’s Movia S is a solid-state lidar. Mounted at the corners of a vehicle, the sensor sends out 905-nanometer-wavelength laser pulses and measures how long it takes for light reflected from the surfaces of nearby objects to return. The arrangement of the beam emitters and receivers provides a fixed field of view designed for 180-degree horizontal coverage rather than full 360-degree scanning typical of traditional mechanical units. The company says the unit can detect objects at distances of up to roughly 200 meters under favorable weather conditions—compared with the roughly 300-meter radius scanned by mechanical systems—and supports frame rates suitable for real-time perception in driver-assistance systems. Earlier mechanical lidars, used spinning components to steer their beams but the Movia S is a phased-arraysystem. It controls the amplitude and phase of the signals across an array of antenna elements to steer the beam. The unit is designed to meet automotive requirements for vibration tolerance, temperature range, and environmental sealing.\nMicroVision’s pricing targets might sound aggressive, but they are not without precedent. The lidar industry has already experienced one major cost reset over the past decade.\n“Automakers are not buying a single sensor in isolation... They are designing a perception system, and cost only matters if the system as a whole is viable.” –Glen DeVos, MicroVision\nAround 2016 and 2017, mechanical lidar systems used in early autonomous driving research often sold for close to $100,000. Those units relied on spinning assemblies to sweep laser beams across a full 360 degrees, which made them expensive to build and difficult to ruggedize for consumer vehicles.\n“Back then, a 64-beam Velodyne lidar cost around $80,000,” says Radha.\nComparable mechanical lidars from multiple suppliers now sell in the $10,000 to $20,000 range. That roughly tenfold drop helps explain why suppliers now believe another steep price reduction is possible. \n“For solid-state devices, it is feasible to bring the cost down even more when manufacturing at high volume,” Radha says. With demand expanding beyond fully autonomous vehicles into driver-assistance applications, “one order or even two orders of magnitude reduction in cost are feasible.”\nSolid-State Lidar Design Challenges\nLower cost, however, does not come for free. The same design choices that enable solid-state lidar to scale also introduce new constraints.\n“Unlike mechanical lidars, which provide full 360-degree coverage, solid-state lidars tend to have a much smaller field of view,” Radha says. Many cover 180 degrees or less.\nThat limitation shifts the burden from the sensor to the system. Automakers will need to deploy three or four solid-state lidars around a vehicle to achieve full coverage. Even so, Radha notes, the total cost can still undercut that of a single mechanical unit.\nWhat changes is integration. Multiple sensors must be aligned, calibrated, and synchronized so their data can be fused accurately. The engineering is manageable, but it adds complexity that price targets alone do not capture.\nDeVos says MicroVision’s design choices reflect that reality. “Automakers are not buying a single sensor in isolation,” he says. “They are designing a perception system, and cost only matters if the system as a whole is viable.”\nThose system-level tradeoffs help explain where low-cost lidar is most likely to appear first.\nMost advanced driver assistance systems today rely on cameras and radar, which are significantly cheaper than lidar. Cameras provide dense visual information, while radar offers reliable range and velocity data, particularly in poor weather. Radha estimates that lidar remains roughly an order of magnitude more expensive than automotive radar.\nBut at prices in the $100 to $200 range, that gap narrows enough to change design decisions.\n“At that point, lidar becomes appealing because of its superior capability in precise 3D detection and tracking,” Radha says.\nRather than replacing existing sensors, lower-cost lidar would likely augment them, adding redundancy and improving performance in complex environments that are challenging for electronic perception systems. That incremental improvement aligns more closely with how ADAS features are deployed today than with the leap to full vehicle autonomy.\nMicroVision is not alone in pursuing solid-state lidar, and several suppliers including Chinese firms Hesai and RoboSense and other major suppliers such as Luminar and Velodyne have announced long-term cost targets below $500. What distinguishes current claims is the explicit focus on sub-$200 pricing tied to production volume rather than future prototypes or limited pilot runs.\nSome competitors continue to prioritize long-range performance for autonomous vehicles, which pushes cost upward. Others have avoided aggressive pricing claims until they secure firm production commitments from automakers.\nThat caution reflects a structural challenge: Reaching consumer-level pricing requires large, predictable demand. Without it, few suppliers can justify the manufacturing investments needed to achieve true economies of scale.\nEvaluating Lidar Performance Metrics\n\nEven if low-cost lidar becomes manufacturable, another question remains: How should its performance be judged?\nFrom a systems-engineering perspective, Radha says cost milestones often overshadow safety metrics.\n“The key objective of ADAS and autonomous systems is improving safety,” he says. Yet there is no universally adopted metric that directly expresses safety gains from a given sensor configuration.\nResearchers instead rely on perception benchmarks such as mean Average Precision, or mAP, which measures how accurately a system detects and tracks objects in its environment. Including such metrics alongside cost targets, says Radha, would clarify what performance is preserved or sacrificed as prices fall.\nIEEE Spectrum has covered lidar extensively, often focusing on technical advances in scanning, range, and resolution. What distinguishes the current moment is the renewed focus on economics rather than raw capability\nIf solid-state lidar can reliably reach sub-$200 pricing, it will not invalidate Elon Musk’s skepticism—but it will weaken one of its strongest foundations. When cost stops being the dominant objection, automakers will have to decide whether leaving lidar out is a technical judgment or a strategic one.\nThat decision, more than any single price claim, may determine whether lidar finally becomes a routine component of vehicle safety systems.",
        "pubDate": "Sat, 14 Feb 2026 14:00:02 +0000",
        "isoDate": "2026-02-14T14:00:02.000Z",
        "creator": "Willie D. Jones",
        "source": "https://spectrum.ieee.org/solid-state-lidar-microvision-adas"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-5te6xm",
        "title": "TryEngineering Marks 20 Years of Getting Kids Interested in STEM",
        "link": "https://spectrum.ieee.org/ieee-tryengineering-20-years",
        "url": "https://spectrum.ieee.org/ieee-tryengineering-20-years",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/three-tween-boys-tweaking-a-circuit-board-together.jpg?id=64075340&width=1245&height=700&coordinates=0%2C156%2C0%2C157\"/><br/><br/><p><a href=\"https://tryengineering.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE TryEngineering</a> is celebrating 20 years of empowering educators with resources that introduce engineering to students at an early age. Launched in 2006 as a collaboration between <a href=\"https://www.ieee.org/\" target=\"_blank\">IEEE</a>, <a href=\"https://www.ibm.com/us-en\" rel=\"noopener noreferrer\" target=\"_blank\">IBM</a>, and the <a href=\"https://nysci.org/\" rel=\"noopener noreferrer\" target=\"_blank\">New York Hall of Science</a> (NYSCI), TryEngineering began with a clear goal: Make engineering accessible, understandable, and engaging for students and the teachers who support them.</p><p>What started as an idea within <a href=\"https://ea.ieee.org/ea-programs\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Educational Activities</a> has grown into a global platform supporting preuniversity engineering education around the world.</p><h2>Concerns about the future</h2><p>In the early 2000s, <a href=\"https://www.nae.edu/19579/19582/21020/16145/16161/The-Status-and-Nature-of-K12-Engineering-Education-in-the-United-States\" rel=\"noopener noreferrer\" target=\"_blank\">engineering was largely absent from preuniversity education</a>, typically being taught only in small, isolated programs. Most students had little exposure to the many types of engineering, and they did not learn what engineers actually do.</p><p>At the same time, industry and academic leaders were increasingly concerned about the future of engineering as a whole. They worried about the talent pipeline and saw existing outreach efforts as scattered and inconsistent.</p><p>In 2004 representatives from several electrical and computer engineering industries met with IEEE leadership and expressed their concerns about the declining number of students interested in engineering careers. They urged IEEE to organize a more effective, coordinated response to unite professional societies, educators, and industry around a shared approach to preuniversity outreach and education.</p><p>One of the major recommendations to come out of that meeting was to start teaching youngsters about engineering earlier. <a href=\"https://www.nationalacademies.org/publications/10573\" rel=\"noopener noreferrer\" target=\"_blank\">Research</a> from the U.S. National Academy of Engineering at the time showed that students begin forming attitudes toward science, technology, engineering, and math fields from ages 5 to 10, and that outreach should begin as early as kindergarten. Waiting until the teen years or university-level education is simply too late, they determined; it needs to happen during the formative years to spark long-term interest in STEM learning.</p><h2>The idea behind the website</h2><p>TryEngineering emerged from the broader <a href=\"https://ieeexplore.ieee.org/document/4760339\" rel=\"noopener noreferrer\" target=\"_blank\">Launching Our Children’s Path to Engineering</a> initiative, which was approved in 2005 by the <a href=\"https://www.ieee.org/about/corporate/board\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Board of Directors</a>. A core element of the IEEE program was a public-facing website that would introduce young learners to engineering projects, roles, and careers. The concept eventually developed into TryEngineering.org.</p><p>The idea for TryEngineering.org itself grew from an existing, successful model. The NYSCI operated <a href=\"https://tryscience.org\" rel=\"noopener noreferrer\" target=\"_blank\">TryScience.org</a>, a popular public website supported by <a href=\"https://www.ibm.com/us-en\" rel=\"noopener noreferrer\" target=\"_blank\">IBM</a> that helped students explore science topics through hands-on activities and real‑world connections.</p><p>At the time, the IEEE Educational Activities group was working with the NYSCI on TryScience projects. Building a parallel site focused on engineering was a natural next step, and IBM’s experience in supporting large‑scale educational outreach made it a strong partner.</p><p>A central figure in turning that vision into reality was <a href=\"https://www.moshekam.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Moshe Kam</a>, who served as the 2005–2007 IEEE Educational Activities vice president, and later as the 2011 IEEE president. During his tenure, Kam spearheaded the creation of TryEngineering.org and guided the international expansion of IEEE’s Teacher In‑Service Program, which trained volunteers to work directly with teachers to create hands-on engineering lessons (the program no longer exists). His leadership helped establish preuniversity education as a core, long‑term priority within IEEE.</p><p>“The founders of the IEEE TryEngineering program created something very special. In a world where the messaging about becoming an engineer often scares students who have not yet developed math skills away from our profession, and preuniversity teachers without engineering degrees have trepidation in teaching topics in our fields of interest, people like Dr. Kam and the other founders had a vision where everyone could literally <em><em>try</em></em> engineering,” says <a href=\"https://www.linkedin.com/in/jamie-moesch-7502b31/\" rel=\"noopener noreferrer\" target=\"_blank\">Jamie Moesch</a>, <a href=\"https://spectrum.ieee.org/tag/ieee-educational-activities\" target=\"_self\">IEEE Educational Activities</a> managing director.</p><p> “Because of this, teachers have now taught millions of our hands-on lessons and opened our profession to so many more young minds,” he adds. “All of the preuniversity programs we have continued to build and improve upon are fueled by this massively important and simple-to-understand concept of try engineering.”</p><h2>A focus on educators</h2><p>From the beginning, TryEngineering focused on educators as the keys to its success, rather than starting with students. Instead of complex technical explanations, the platform offered free, classroom-ready lesson plans with clear explanations about engineering fields and examples with which students could relate. Hands-on activities emphasized problem‑solving, creativity, and teamwork—core elements of how engineers actually work.</p><p>IEEE leaders also recognized that misconceptions about engineering discouraged many talented young people—particularly girls and students from underrepresented groups—from pursuing engineering as a career. TryEngineering aimed to show engineering as practical, creative, and connected to real-world needs, helping students see that engineering could be for anyone, not just a narrow group of specialists.</p><p>By simply encouraging students and educators to just <em><em>try</em></em> engineering, doors are open to new possibilities and a broader understanding of the field. Even students who ultimately choose other career paths get to learn key concepts, such as the <a href=\"https://tryengineering.org/news/engineering-design-process/\" rel=\"noopener noreferrer\" target=\"_blank\">engineering design process</a>, equipping them with practical skills for the rest of their life.</p><h2>Outreach programs and summer camps</h2><p>During the past two decades, TryEngineering has grown well beyond its original website. In addition to providing a <a href=\"https://tryengineering.org/explore-resources/lesson-plans/\" rel=\"noopener noreferrer\" target=\"_blank\">vast library of lesson plans and resources</a> that engage and inspire, it also serves as the hub for a collection of programs reaching educators and students in many ways.</p><p>Those include the <a href=\"https://tryengineering.org/get-involved/ieee-members/stem-champions/\" rel=\"noopener noreferrer\" target=\"_blank\">TryEngineering STEM Champions</a> program, which empowers dedicated volunteers to support outreach programs and serve as vital connectors to IEEE’s extensive resources. The <a href=\"https://spectrum.ieee.org/ieee-tryengineering-summer-camp\" target=\"_self\">TryEngineering Summer Institute</a> offers immersive <a href=\"https://spectrum.ieee.org/ieee-tryengineering-summer-camp\" target=\"_self\">campus‑based experiences</a> for students ages 13 to 17, with expanded locations and programs being introduced this year.</p><p>The <a href=\"https://spectrum.ieee.org/ieee-stem-summit-2025\" target=\"_self\">IEEE STEM Summit</a> is an annual virtual event that brings together <a href=\"https://spectrum.ieee.org/ieee-stem-summit-2025\" target=\"_self\">educators and volunteers from around the world</a>. <a href=\"https://oncampus.tryengineering.org/\" rel=\"noopener noreferrer\" target=\"_blank\">TryEngineering OnCampus</a> partners with universities around the globe to organize hands-on programs. <a href=\"https://tryengineering.org/news/50-teachers-in-5-states-learn-about-semiconductors/\" rel=\"noopener noreferrer\" target=\"_blank\">TryEngineering educator sessions</a> provide free professional development programs aligned with emerging industry needs such as semiconductors.</p><h2>20 ways to celebrate 20 years</h2><p>To mark its 20th anniversary, TryEngineering is celebrating with a year of special activities, new partnerships, and fresh resources for educators. Visit the TryEngineering <a href=\"https://tryengineering.org/explore-resources/collections/tryengineering-20th-anniversary/\" rel=\"noopener noreferrer\" target=\"_blank\">20th Anniversary collection page</a> to explore what’s ahead, join the celebration, and discover 20 ways to celebrate 20 years of inspiring the next generation of technology innovators. This is an opportunity to reflect on how far the program has come, and to help shape how the next generation discovers engineering.</p><p><span>“The passion and dedication of the thousands of volunteers of IEEE who do local outreach enables the IEEE-wide goal to inspire intellectual curiosity and invention to engage the next generation of technology innovators,” Moesch says. “The first 20 years have been special, and I cannot wait to have the world experience what the future holds for the TryEngineering programs.”</span></p>",
        "contentSnippet": "IEEE TryEngineering is celebrating 20 years of empowering educators with resources that introduce engineering to students at an early age. Launched in 2006 as a collaboration between IEEE, IBM, and the New York Hall of Science (NYSCI), TryEngineering began with a clear goal: Make engineering accessible, understandable, and engaging for students and the teachers who support them.\nWhat started as an idea within IEEE Educational Activities has grown into a global platform supporting preuniversity engineering education around the world.\nConcerns about the future\nIn the early 2000s, engineering was largely absent from preuniversity education, typically being taught only in small, isolated programs. Most students had little exposure to the many types of engineering, and they did not learn what engineers actually do.\nAt the same time, industry and academic leaders were increasingly concerned about the future of engineering as a whole. They worried about the talent pipeline and saw existing outreach efforts as scattered and inconsistent.\nIn 2004 representatives from several electrical and computer engineering industries met with IEEE leadership and expressed their concerns about the declining number of students interested in engineering careers. They urged IEEE to organize a more effective, coordinated response to unite professional societies, educators, and industry around a shared approach to preuniversity outreach and education.\nOne of the major recommendations to come out of that meeting was to start teaching youngsters about engineering earlier. Research from the U.S. National Academy of Engineering at the time showed that students begin forming attitudes toward science, technology, engineering, and math fields from ages 5 to 10, and that outreach should begin as early as kindergarten. Waiting until the teen years or university-level education is simply too late, they determined; it needs to happen during the formative years to spark long-term interest in STEM learning.\nThe idea behind the website\nTryEngineering emerged from the broader Launching Our Children’s Path to Engineering initiative, which was approved in 2005 by the IEEE Board of Directors. A core element of the IEEE program was a public-facing website that would introduce young learners to engineering projects, roles, and careers. The concept eventually developed into TryEngineering.org.\nThe idea for TryEngineering.org itself grew from an existing, successful model. The NYSCI operated TryScience.org, a popular public website supported by IBM that helped students explore science topics through hands-on activities and real‑world connections.\nAt the time, the IEEE Educational Activities group was working with the NYSCI on TryScience projects. Building a parallel site focused on engineering was a natural next step, and IBM’s experience in supporting large‑scale educational outreach made it a strong partner.\nA central figure in turning that vision into reality was Moshe Kam, who served as the 2005–2007 IEEE Educational Activities vice president, and later as the 2011 IEEE president. During his tenure, Kam spearheaded the creation of TryEngineering.org and guided the international expansion of IEEE’s Teacher In‑Service Program, which trained volunteers to work directly with teachers to create hands-on engineering lessons (the program no longer exists). His leadership helped establish preuniversity education as a core, long‑term priority within IEEE.\n“The founders of the IEEE TryEngineering program created something very special. In a world where the messaging about becoming an engineer often scares students who have not yet developed math skills away from our profession, and preuniversity teachers without engineering degrees have trepidation in teaching topics in our fields of interest, people like Dr. Kam and the other founders had a vision where everyone could literally try engineering,” says Jamie Moesch, IEEE Educational Activities managing director.\n “Because of this, teachers have now taught millions of our hands-on lessons and opened our profession to so many more young minds,” he adds. “All of the preuniversity programs we have continued to build and improve upon are fueled by this massively important and simple-to-understand concept of try engineering.”\nA focus on educators\nFrom the beginning, TryEngineering focused on educators as the keys to its success, rather than starting with students. Instead of complex technical explanations, the platform offered free, classroom-ready lesson plans with clear explanations about engineering fields and examples with which students could relate. Hands-on activities emphasized problem‑solving, creativity, and teamwork—core elements of how engineers actually work.\nIEEE leaders also recognized that misconceptions about engineering discouraged many talented young people—particularly girls and students from underrepresented groups—from pursuing engineering as a career. TryEngineering aimed to show engineering as practical, creative, and connected to real-world needs, helping students see that engineering could be for anyone, not just a narrow group of specialists.\nBy simply encouraging students and educators to just try engineering, doors are open to new possibilities and a broader understanding of the field. Even students who ultimately choose other career paths get to learn key concepts, such as the engineering design process, equipping them with practical skills for the rest of their life.\nOutreach programs and summer camps\nDuring the past two decades, TryEngineering has grown well beyond its original website. In addition to providing a vast library of lesson plans and resources that engage and inspire, it also serves as the hub for a collection of programs reaching educators and students in many ways.\nThose include the TryEngineering STEM Champions program, which empowers dedicated volunteers to support outreach programs and serve as vital connectors to IEEE’s extensive resources. The TryEngineering Summer Institute offers immersive campus‑based experiences for students ages 13 to 17, with expanded locations and programs being introduced this year.\nThe IEEE STEM Summit is an annual virtual event that brings together educators and volunteers from around the world. TryEngineering OnCampus partners with universities around the globe to organize hands-on programs. TryEngineering educator sessions provide free professional development programs aligned with emerging industry needs such as semiconductors.\n20 ways to celebrate 20 years\nTo mark its 20th anniversary, TryEngineering is celebrating with a year of special activities, new partnerships, and fresh resources for educators. Visit the TryEngineering 20th Anniversary collection page to explore what’s ahead, join the celebration, and discover 20 ways to celebrate 20 years of inspiring the next generation of technology innovators. This is an opportunity to reflect on how far the program has come, and to help shape how the next generation discovers engineering.\n“The passion and dedication of the thousands of volunteers of IEEE who do local outreach enables the IEEE-wide goal to inspire intellectual curiosity and invention to engage the next generation of technology innovators,” Moesch says. “The first 20 years have been special, and I cannot wait to have the world experience what the future holds for the TryEngineering programs.”",
        "pubDate": "Fri, 13 Feb 2026 19:00:04 +0000",
        "isoDate": "2026-02-13T19:00:04.000Z",
        "creator": "Robert Schneider",
        "source": "https://spectrum.ieee.org/ieee-tryengineering-20-years"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-mcckn2",
        "title": "Video Friday: Robot Collective Stays Alive Even When Parts Die",
        "link": "https://spectrum.ieee.org/video-friday-robot-collective",
        "url": "https://spectrum.ieee.org/video-friday-robot-collective",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/robot-collective-crawls-under-a-bridge-of-rocks-with-glowing-lights-video-speed-increased-10x.gif?id=64423332&width=1245&height=700&coordinates=0%2C45%2C0%2C45\"/><br/><br/><p><span>Video Friday is your weekly selection of awesome robotics videos, collected by your friends at </span><em>IEEE Spectrum</em><span> robotics. We also post a weekly calendar of upcoming robotics events for the next few months. Please </span><a href=\"mailto:automaton@ieee.org?subject=Robotics%20event%20suggestion%20for%20Video%20Friday\">send us your events</a><span> for inclusion.</span></p><h5><a href=\"https://2026.ieee-icra.org/\">ICRA 2026</a>: 1–5 June 2026, VIENNA</h5><p>Enjoy today’s videos!</p><div class=\"horizontal-rule\"></div><div style=\"page-break-after: always\"><span style=\"display:none\"> </span></div><blockquote class=\"rm-anchors\" id=\"boebmm8mlea\"><em>No system is immune to failure. The compromise between reducing failures and improving adaptability is a recurring problem in robotics. Modular robots exemplify this tradeoff, because the number of modules dictates both the possible functions and the odds of failure. We reverse this trend, improving reliability with an increased number of modules by exploiting redundant resources and sharing them locally.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"d4b443d6937b9d0cc92c03a7e8d6617b\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/bOeBmm8mleA?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.science.org/doi/10.1126/scirobotics.ady6304\">Science</a> ] via [ <a href=\"https://www.epfl.ch/labs/rrl/\">RRL</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"unorxwlzlfk\"><em>Now that the <a href=\"https://robotsguide.com/robots/atlas\" target=\"_blank\">Atlas</a> enterprise platform is getting to work, the research version gets one last run in the sun. Our engineers made one final push to test the limits of full-body control and mobility, with help from the RAI Institute.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"dabc1539dcc8e868a47dee3a32fd7b46\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/UNorxwlZlFk?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://rai-inst.com/\">RAI</a> ] via [ <a href=\"https://bostondynamics.com/\">Boston Dynamics</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"khimsr8guce\"><em>Announcing Isaac 0: the laundry folding robot we’re shipping to homes, starting in February 2026 in the Bay Area.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"3e2ca93296a7724dd71ad07d146372c8\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/KhImSR8GuCE?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.weaverobotics.com/\">Weave Robotics</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"md7auy7lh34\"><em>In a paper published in Science, researchers at the Max Planck Institute for Intelligent Systems, the Humboldt University of Berlin, and the University of Stuttgart have discovered that the secret to the elephant’s amazing sense of touch is in its unusual whiskers. The interdisciplinary team analyzed elephant trunk whiskers using advanced microscopy methods that revealed a form of material intelligence more sophisticated than the well-studied whiskers of rats and mice. This research has the potential to inspire new physically intelligent robotic sensing approaches that resemble the unusual whiskers that cover the elephant trunk.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"1dfc845660633f2fd1566c3989dd428d\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/MD7Auy7lH34?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.mpg.de/26113474/elephant-trunk-whiskers-exhibit-material-intelligence?c=2249\">MPI</a> ]</p><div class=\"horizontal-rule\"></div><p class=\"rm-anchors\" id=\"rcpuqmvs37q\">Got an interest in autonomous mobile robots, <a href=\"https://spectrum.ieee.org/tag/robot-operating-system\" target=\"_blank\">ROS2</a>, and a mere $150 lying around? Try this.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"648c0f35b6cbb775c227c778b61e3aea\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/RCPUQmvS37Q?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://makerspet.com/store#!/Arduino-ROS2-Self-Driving-Robot-120mm-Build-Pack/p/725772983\">Maker's Pet</a> ]</p><p>Thanks, Ilia!</p><div class=\"horizontal-rule\"></div><p class=\"rm-anchors\" id=\"9ti9mi8rbiq\">We’re giving <a href=\"https://spectrum.ieee.org/topic/robotics/humanoid-robots/\" target=\"_blank\">humanoid robots</a> swords now.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"4bb44dd7b81db8ae1c0a107f312c9998\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/9Ti9Mi8rbIQ?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.robotera.com/en/\">Robotera</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"ew3az19rlqa\"><em>A system developed by researchers at the University of Waterloo lets people collaborate with groups of robots to create works of art inspired by music.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"16928fc1dec0c295881676004533743c\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/ew3az19rlqA?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://uwaterloo.ca/news/media/translating-music-light-and-motion-robots\">Waterloo</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"exp3fsnqxqw\"><em>FastUMI Pro is a multimodal, model-agnostic data acquisition system designed to power a truly end-to-end closed loop for embodied intelligence — transforming real-world data into genuine robotic capability.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"4c6a332d7e9b76af05f00dc9990e971e\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/EXP3fsnQXqw?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.lumosbot.tech/\">Lumos Robotics</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"4fbygialjyu\"><em>We usually take fingernails for granted, but they’re vital for fine-motor control and feeling textures. Our students have been doing some great work looking into the mechanics behind this.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"b12a33801a528b063c865db11a550308\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/4FByGIALjyU?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://arxiv.org/html/2602.05156v1\">Paper</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"uxuvmz3nwto\"><em>This is a 550-lb all-electric coaxial unmanned rotorcraft developed by Texas A&M University’s Advanced Vertical Flight Laboratory and Harmony Aeronautics as a technology demonstrator for our quiet-rotor technology. The payload capacity is 200 lb (gross weight = 750 lb). The noise level measured was around 74 dBA in hover at 50-ft making this probably the quietest rotorcraft at this scale.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"5112475428ad208d8d71a9ba961c0fbb\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/uxuvMz3nwto?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://harmonyaeronautics.com/\">Harmony Aeronautics</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"bk9k_mjjlxe\"><em>Harvard scientists have created an advanced 3D printing method for developing soft robotics. This technique, called rotational multimaterial 3D printing, enables the fabrication of complex shapes and tubular structures with dissolvable internal channels. This innovation could someday accelerate the production of components for surgical robotics and assistive devices, advancing medical technology.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"d8440b53651f8443a6733570f8f342a6\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/BK9K_mJjlxE?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://seas.harvard.edu/news/3d-printing-soft-robots\">Harvard</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"a48dohk0u7i\"><em>Lynx M20 wheeled-legged robot steps onto the ice and snow, taking on challenges inspired by four winter sports scenarios. Who says robots can’t enjoy winter sports?</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"cb096d509d326a8b7fc63c514373044b\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/a48DoHK0U7I?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.deeprobotics.cn/en\">Deep Robotics</a> ]</p><div class=\"horizontal-rule\"></div><p class=\"rm-anchors\" id=\"ec712qh3t6g\">NGL right now I find this more satisfying to watch than a humanoid doing just about anything.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"29de1f6d610f3a555db97ef444bf7f06\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/Ec712qh3T6g?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.linkedin.com/posts/fanuc-america-corporation_robotic-case-packing-and-palletizing-system-activity-7426656807932203009-y4hR/\">Fanuc</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"xqfk1bd5bkg\"><em>At Mentee Robotics, we design and build humanoid robots from the ground up with one goal: reliable, scalable deployment in real-world industrial environments. Our robots are powered by deep vertical integration across hardware, embedded software, and AI, all developed in-house to close the Sim2Real gap and enable continuous, around-the-clock operation.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"65329eda591818e176b81a494fe5b599\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/XqFk1Bd5BKg?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.menteebot.com/\">Mentee Robotics</a> ]</p><div class=\"horizontal-rule\"></div><p class=\"rm-anchors\" id=\"3y0rawjlaxs\">You don’t need to watch this whole video, but the idea of little submarines that hitch rides on bigger boats and recharge themselves is kind of cool.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"a15f69e364382ed4d168f7fdbc178597\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/3y0RAwJlAxs?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.lockheedmartin.com/en-us/products/mmauv.html\">Lockheed Martin</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"u6zp38xurgs\"><em>Learn about the work of Dr. Roland Siegwart, Dr. Anibal Ollero, Dr. Dario Floreano, and Dr. Margarita Chli on flying robots and some of the challenges they are still trying to tackle in this video created based on their presentations at ICRA@40 the 40th anniversary celebration of the IEEE International Conference on Robotics and Automation.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"facbfd3b29494abfbcc4306c7c81ecca\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/U6ZP38XUrGs?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://icra40.ieee.org/\">ICRA@40</a> ]</p><div class=\"horizontal-rule\"></div>",
        "contentSnippet": "Video Friday is your weekly selection of awesome robotics videos, collected by your friends at IEEE Spectrum robotics. We also post a weekly calendar of upcoming robotics events for the next few months. Please send us your events for inclusion.\nICRA 2026: 1–5 June 2026, VIENNA\nEnjoy today’s videos!\n\n \nNo system is immune to failure. The compromise between reducing failures and improving adaptability is a recurring problem in robotics. Modular robots exemplify this tradeoff, because the number of modules dictates both the possible functions and the odds of failure. We reverse this trend, improving reliability with an increased number of modules by exploiting redundant resources and sharing them locally.\n\n[ Science ] via [ RRL ]\n\nNow that the Atlas enterprise platform is getting to work, the research version gets one last run in the sun. Our engineers made one final push to test the limits of full-body control and mobility, with help from the RAI Institute.\n\n[ RAI ] via [ Boston Dynamics ]\n\nAnnouncing Isaac 0: the laundry folding robot we’re shipping to homes, starting in February 2026 in the Bay Area.\n\n[ Weave Robotics ]\n\nIn a paper published in Science, researchers at the Max Planck Institute for Intelligent Systems, the Humboldt University of Berlin, and the University of Stuttgart have discovered that the secret to the elephant’s amazing sense of touch is in its unusual whiskers. The interdisciplinary team analyzed elephant trunk whiskers using advanced microscopy methods that revealed a form of material intelligence more sophisticated than the well-studied whiskers of rats and mice. This research has the potential to inspire new physically intelligent robotic sensing approaches that resemble the unusual whiskers that cover the elephant trunk.\n\n[ MPI ]\n\nGot an interest in autonomous mobile robots, ROS2, and a mere $150 lying around? Try this.\n\n[ Maker's Pet ]\nThanks, Ilia!\n\nWe’re giving humanoid robots swords now.\n\n[ Robotera ]\n\nA system developed by researchers at the University of Waterloo lets people collaborate with groups of robots to create works of art inspired by music.\n\n[ Waterloo ]\n\nFastUMI Pro is a multimodal, model-agnostic data acquisition system designed to power a truly end-to-end closed loop for embodied intelligence — transforming real-world data into genuine robotic capability.\n\n[ Lumos Robotics ]\n\nWe usually take fingernails for granted, but they’re vital for fine-motor control and feeling textures. Our students have been doing some great work looking into the mechanics behind this.\n\n[ Paper ]\n\nThis is a 550-lb all-electric coaxial unmanned rotorcraft developed by Texas A&M University’s Advanced Vertical Flight Laboratory and Harmony Aeronautics as a technology demonstrator for our quiet-rotor technology. The payload capacity is 200 lb (gross weight = 750 lb). The noise level measured was around 74 dBA in hover at 50-ft making this probably the quietest rotorcraft at this scale.\n\n[ Harmony Aeronautics ]\n\nHarvard scientists have created an advanced 3D printing method for developing soft robotics. This technique, called rotational multimaterial 3D printing, enables the fabrication of complex shapes and tubular structures with dissolvable internal channels. This innovation could someday accelerate the production of components for surgical robotics and assistive devices, advancing medical technology.\n\n[ Harvard ]\n\nLynx M20 wheeled-legged robot steps onto the ice and snow, taking on challenges inspired by four winter sports scenarios. Who says robots can’t enjoy winter sports?\n\n[ Deep Robotics ]\n\nNGL right now I find this more satisfying to watch than a humanoid doing just about anything.\n\n[ Fanuc ]\n\nAt Mentee Robotics, we design and build humanoid robots from the ground up with one goal: reliable, scalable deployment in real-world industrial environments. Our robots are powered by deep vertical integration across hardware, embedded software, and AI, all developed in-house to close the Sim2Real gap and enable continuous, around-the-clock operation.\n\n[ Mentee Robotics ]\n\nYou don’t need to watch this whole video, but the idea of little submarines that hitch rides on bigger boats and recharge themselves is kind of cool.\n\n[ Lockheed Martin ]\n\nLearn about the work of Dr. Roland Siegwart, Dr. Anibal Ollero, Dr. Dario Floreano, and Dr. Margarita Chli on flying robots and some of the challenges they are still trying to tackle in this video created based on their presentations at ICRA@40 the 40th anniversary celebration of the IEEE International Conference on Robotics and Automation.\n\n[ ICRA@40 ]",
        "pubDate": "Fri, 13 Feb 2026 16:30:03 +0000",
        "isoDate": "2026-02-13T16:30:03.000Z",
        "creator": "Evan Ackerman",
        "source": "https://spectrum.ieee.org/video-friday-robot-collective"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-f1cm0z",
        "title": "LEDs Enter the Nanoscale",
        "link": "https://spectrum.ieee.org/nanoled-research-approaches",
        "url": "https://spectrum.ieee.org/nanoled-research-approaches",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/close-up-of-an-illuminated-plus-sign-made-out-of-nano-scale-led-lights.jpg?id=64100009&width=1245&height=700&coordinates=0%2C187%2C0%2C188\"/><br/><br/><p><a href=\"https://spectrum.ieee.org/virtual-reality-head-set-8k\" target=\"_self\">MicroLEDs</a>, with pixels just micrometers across, have long been a byword in the display world. Now, microLED-makers have begun shrinking their creations into the uncharted nano realm. In January, a startup named Polar Light Technologies unveiled <a href=\"https://www.semiconductor-today.com/news_items/2026/jan/polarlight2-210126.shtml\" rel=\"noopener noreferrer\" target=\"_blank\">prototype blue LEDs</a> less than 500 nanometers across. This raises a tempting question: How far can LEDs shrink?</p><p>We know the answer is, at least, considerably smaller. In the past year, two different research groups have demonstrated LED pixels at sizes of 100 nm or less.</p><p>These are some of the smallest LEDs ever created. They leave much to be desired in their efficiency—but one day, nanoLEDs could power ultra-high-resolution virtual reality displays and high-bandwidth on-chip photonics. And the key to making even tinier LEDs, if these early attempts are any precedents, may be to make more unusual LEDs.</p><h2>New Approaches to LED</h2><p>Take Polar Light’s example. Like many LEDs, the Sweden-based startup’s diodes are fashioned from III-V semiconductors like gallium nitride (GaN) and indium gallium nitride (InGaN). Unlike many LEDs, which are etched into their semiconductor from the top down, Polar Light’s are instead fabricated by building peculiarly shaped <a href=\"https://www.polar-light-technologies.com/technology-2/\" rel=\"noopener noreferrer\" target=\"_blank\">hexagonal pyramids</a> from the bottom up. </p><p>Polar Light designed its pyramids for the larger microLED market, and plans to start commercial production in late 2026. But they also wanted to test how small their pyramids could shrink. So far, they’ve made pyramids 300 nm across. “We haven’t reached the limit, yet,” says<a href=\"https://www.polar-light-technologies.com/about-us/\" rel=\"noopener noreferrer\" target=\"_blank\"> Oskar Fajerson</a>, Polar Light’s CEO. “Do we know the limit? No, we don’t, but we can [make] them smaller.”</p><p>Elsewhere, researchers have already done that. Some of the world’s tiniest LEDs come from groups who have foregone the standard III-V semiconductors in favor of other types of LEDs—like <a href=\"https://spectrum.ieee.org/stretchable-oleds-wearable-display-drexel\" target=\"_self\">OLEDs</a>. </p><p>“We are thinking of a different pathway for organic semiconductors,” says<a href=\"https://shihlab.ethz.ch/\" rel=\"noopener noreferrer\" target=\"_blank\"> Chih-Jen Shih</a>, a chemical engineer at ETH Zurich in Switzerland. Shih and his colleagues were interested in finding a way to fabricate small OLEDs at scale. Using an <a href=\"https://spectrum.ieee.org/lithographic-feature-sizes-reduced-down-to-one-nanometer\" target=\"_self\">electron-beam lithography</a>-based technique, they crafted arrays of green OLEDs with pixels as small as 100 nm across.</p><p>Where today’s best displays have <a href=\"https://spectrum.ieee.org/virtual-reality-head-set-8k\" target=\"_self\">14,000 pixels per inch</a>, these nanoLEDs—presented in an <a href=\"https://www.nature.com/articles/s41566-025-01785-z\" rel=\"noopener noreferrer\" target=\"_blank\">October 2025 <em><em>Nature Photonics </em></em>paper</a>—can reach 100,000 pixels per inch.</p><p>Another group tried their hands with <a href=\"https://spectrum.ieee.org/led-display-perovskite-charger\" target=\"_self\">perovskites</a>, cage-shaped materials best-known for their prowess in <a href=\"https://spectrum.ieee.org/perovskite-2667580324\" target=\"_self\">high-efficiency solar panels</a>. Perovskites have recently gained traction in LEDs too. “We wanted to see what would happen if we make perovskite LEDs smaller, all the way down to the micrometer and nanometer length-scale,” says<a href=\"https://person.zju.edu.cn/en/daweidi\" rel=\"noopener noreferrer\" target=\"_blank\"> Dawei Di</a>, engineer at Zhejiang University in Hangzhou, China. </p><p>Di’s group started with comparatively colossal perovskite LED pixels, measuring hundreds of micrometers. Then, they fabricated sequences of smaller and smaller pixels, each tinier than the last. Even after the 1 μm mark, they did not stop: 890 nm, then 440 nm, only bottoming out at 90 nm. These 90 nm red and green pixels, presented in a <a href=\"https://www.nature.com/articles/s41586-025-08685-w#Abs1\" rel=\"noopener noreferrer\" target=\"_blank\">March 2025 <em><em>Nature </em></em>paper</a>, likely represent the smallest LEDs reported to date.</p><h2>Efficiency Challenges</h2><p>Unfortunately, small size comes at a cost: Shrinking LEDs also shrinks their efficiency. Di’s group’s perovskite nanoLEDs have external quantum efficiencies—a measure of how many injected electrons are converted into photons—around 5 to 10 percent; Shih’s group’s nano-OLED arrays performed slightly better, topping 13 percent. For comparison, a typical millimeter-sized III-V LED can reach <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC5706270/\" rel=\"noopener noreferrer\" target=\"_blank\">50 to 70 percent</a>, depending on its color.</p><p>Shih, however, is optimistic that modifying how nano-OLEDs are made can boost their efficiency. “In principle, you can achieve 30 percent, 40 percent external quantum efficiency with OLEDs, even with a smaller pixel, but it takes time to optimize the process,” Shih says.<br/><br/>Di thinks that researchers could take perovskite nanoLEDs to less dire efficiencies by tinkering with the material. Although his group is now focusing on the larger perovskite microLEDs, Di expects researchers will eventually reckon with nanoLEDs’ efficiency gap. If applications of smaller LEDs become appealing, “this issue could become increasingly important,” Di says. </p><h2>What Can NanoLEDs Be Used For?</h2><p><span>What can you actually do with LEDs this small? Today, the push for tinier pixels largely comes from devices like smart glasses and virtual reality headsets. Makers of these displays are hungry for smaller and smaller pixels in a chase for bleeding-edge picture quality with low power consumption (one reason that efficiency is important). Polar Light’s Fajerson says that smart-glass manufacturers today are already seeking 3 μm pixels.</span></p><p><span></span><span>But researchers are skeptical that VR displays will ever need pixels smaller than around 1 μm. Shrink pixels too far beyond that, and they’ll cross their light’s</span><a href=\"https://svi.nl/DiffractionLimit\" target=\"_blank\"> diffraction limit</a><span>—that means they’ll become too small for the human eye to resolve. Shih’s and Di’s groups have already crossed the limit with their 100-nm and 90-nm pixels.</span></p><p><span></span><span>Very tiny LEDs may instead find use in on-chip photonics systems, allowing the likes of AI data centers to communicate with greater bandwidths than they can today. Chip manufacturing giant TSMC is </span><a href=\"https://spectrum.ieee.org/tsmc-microled-optical-interconnects\" target=\"_self\">already trying out microLED interconnects</a><span>, and it’s easy to imagine chipmakers turning to even smaller LEDs in the future.</span></p><p>But the tiniest nanoLEDs may have even more exotic applications, because they’re smaller than the wavelengths of their light. “From a process point of view, you are making a new component that was not possible in the past,” Shih says.</p><p>For example, Shih’s group showed their nano-OLEDs could form a <a href=\"https://spectrum.ieee.org/lifi-lidar-metasurface-applications\" target=\"_self\">metasurface</a>—a structure that uses its pixels’ nano-sizes to control how each pixel interacts with its neighbors. One day, similar devices could focus nanoLED light into laser-like beams or create holographic 3D nanoLED displays.</p>",
        "contentSnippet": "MicroLEDs, with pixels just micrometers across, have long been a byword in the display world. Now, microLED-makers have begun shrinking their creations into the uncharted nano realm. In January, a startup named Polar Light Technologies unveiled prototype blue LEDs less than 500 nanometers across. This raises a tempting question: How far can LEDs shrink?\nWe know the answer is, at least, considerably smaller. In the past year, two different research groups have demonstrated LED pixels at sizes of 100 nm or less.\nThese are some of the smallest LEDs ever created. They leave much to be desired in their efficiency—but one day, nanoLEDs could power ultra-high-resolution virtual reality displays and high-bandwidth on-chip photonics. And the key to making even tinier LEDs, if these early attempts are any precedents, may be to make more unusual LEDs.\nNew Approaches to LED\nTake Polar Light’s example. Like many LEDs, the Sweden-based startup’s diodes are fashioned from III-V semiconductors like gallium nitride (GaN) and indium gallium nitride (InGaN). Unlike many LEDs, which are etched into their semiconductor from the top down, Polar Light’s are instead fabricated by building peculiarly shaped hexagonal pyramids from the bottom up. \nPolar Light designed its pyramids for the larger microLED market, and plans to start commercial production in late 2026. But they also wanted to test how small their pyramids could shrink. So far, they’ve made pyramids 300 nm across. “We haven’t reached the limit, yet,” says Oskar Fajerson, Polar Light’s CEO. “Do we know the limit? No, we don’t, but we can [make] them smaller.”\nElsewhere, researchers have already done that. Some of the world’s tiniest LEDs come from groups who have foregone the standard III-V semiconductors in favor of other types of LEDs—like OLEDs. \n“We are thinking of a different pathway for organic semiconductors,” says Chih-Jen Shih, a chemical engineer at ETH Zurich in Switzerland. Shih and his colleagues were interested in finding a way to fabricate small OLEDs at scale. Using an electron-beam lithography-based technique, they crafted arrays of green OLEDs with pixels as small as 100 nm across.\nWhere today’s best displays have 14,000 pixels per inch, these nanoLEDs—presented in an October 2025 Nature Photonics paper—can reach 100,000 pixels per inch.\nAnother group tried their hands with perovskites, cage-shaped materials best-known for their prowess in high-efficiency solar panels. Perovskites have recently gained traction in LEDs too. “We wanted to see what would happen if we make perovskite LEDs smaller, all the way down to the micrometer and nanometer length-scale,” says Dawei Di, engineer at Zhejiang University in Hangzhou, China. \nDi’s group started with comparatively colossal perovskite LED pixels, measuring hundreds of micrometers. Then, they fabricated sequences of smaller and smaller pixels, each tinier than the last. Even after the 1 μm mark, they did not stop: 890 nm, then 440 nm, only bottoming out at 90 nm. These 90 nm red and green pixels, presented in a March 2025 Nature paper, likely represent the smallest LEDs reported to date.\nEfficiency Challenges\nUnfortunately, small size comes at a cost: Shrinking LEDs also shrinks their efficiency. Di’s group’s perovskite nanoLEDs have external quantum efficiencies—a measure of how many injected electrons are converted into photons—around 5 to 10 percent; Shih’s group’s nano-OLED arrays performed slightly better, topping 13 percent. For comparison, a typical millimeter-sized III-V LED can reach 50 to 70 percent, depending on its color.\nShih, however, is optimistic that modifying how nano-OLEDs are made can boost their efficiency. “In principle, you can achieve 30 percent, 40 percent external quantum efficiency with OLEDs, even with a smaller pixel, but it takes time to optimize the process,” Shih says.\nDi thinks that researchers could take perovskite nanoLEDs to less dire efficiencies by tinkering with the material. Although his group is now focusing on the larger perovskite microLEDs, Di expects researchers will eventually reckon with nanoLEDs’ efficiency gap. If applications of smaller LEDs become appealing, “this issue could become increasingly important,” Di says. \nWhat Can NanoLEDs Be Used For?\nWhat can you actually do with LEDs this small? Today, the push for tinier pixels largely comes from devices like smart glasses and virtual reality headsets. Makers of these displays are hungry for smaller and smaller pixels in a chase for bleeding-edge picture quality with low power consumption (one reason that efficiency is important). Polar Light’s Fajerson says that smart-glass manufacturers today are already seeking 3 μm pixels.\nBut researchers are skeptical that VR displays will ever need pixels smaller than around 1 μm. Shrink pixels too far beyond that, and they’ll cross their light’s diffraction limit—that means they’ll become too small for the human eye to resolve. Shih’s and Di’s groups have already crossed the limit with their 100-nm and 90-nm pixels.\nVery tiny LEDs may instead find use in on-chip photonics systems, allowing the likes of AI data centers to communicate with greater bandwidths than they can today. Chip manufacturing giant TSMC is already trying out microLED interconnects, and it’s easy to imagine chipmakers turning to even smaller LEDs in the future.\nBut the tiniest nanoLEDs may have even more exotic applications, because they’re smaller than the wavelengths of their light. “From a process point of view, you are making a new component that was not possible in the past,” Shih says.\nFor example, Shih’s group showed their nano-OLEDs could form a metasurface—a structure that uses its pixels’ nano-sizes to control how each pixel interacts with its neighbors. One day, similar devices could focus nanoLED light into laser-like beams or create holographic 3D nanoLED displays.",
        "pubDate": "Thu, 12 Feb 2026 15:00:03 +0000",
        "isoDate": "2026-02-12T15:00:03.000Z",
        "creator": "Rahul Rao",
        "source": "https://spectrum.ieee.org/nanoled-research-approaches"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-3mbaej",
        "title": "What the FDA’s 2026 Update Means for Wearables",
        "link": "https://spectrum.ieee.org/fda-medical-device-rules",
        "url": "https://spectrum.ieee.org/fda-medical-device-rules",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/illustration-of-a-smart-watch-with-an-eye-ball-displayed-on-the-screen.jpg?id=64099717&width=1245&height=700&coordinates=0%2C49%2C0%2C50\"/><br/><br/><p>As new consumer hardware and software capabilities have bumped up against medicine over the last few years, consumers and manufacturers alike have struggled with identifying the line between “wellness” products such as earbuds that can also amplify and clarify surrounding speakers’ voices and regulated medical devices such as conventional hearing aids. On January 6, 2026, the U.S. Food and Drug Administration issued new guidance documents clarifying how it interprets existing law for the review of wearable and AI-assisted devices. </p><p>The first document, for <a href=\"https://www.fda.gov/regulatory-information/search-fda-guidance-documents/general-wellness-policy-low-risk-devices\" rel=\"noopener noreferrer\" target=\"_blank\">general wellness</a>, specifies that the FDA will interpret noninvasive sensors such as sleep trackers or heart rate monitors as low-risk wellness devices while treating invasive devices under conventional regulations. The other document defines how the FDA will exempt <a href=\"https://www.fda.gov/regulatory-information/search-fda-guidance-documents/clinical-decision-support-software\" rel=\"noopener noreferrer\" target=\"_blank\">clinical decision support tools</a> from medical device regulations, limiting such software to analyzing existing data rather than extracting data from sensors, and requiring them to enable independent review of their recommendations. The documents do not rewrite any statutes, but they refine interpretation of existing law, compared to the 2019 and 2022 documents they replace. They offer a fresh lens on how regulators see technology that sits at the intersection of consumer electronics, software, and medicine—a category many other countries are choosing to regulate more strictly rather than less.</p><h2>What the 2026 update changed</h2><p>The 2026 FDA update clarifies how it distinguishes between “medical information” and systems that measure physiological “signals” or “patterns.” Earlier guidance discussed these concepts more generally, but the new version defines signal-measuring systems as those that collect continuous, near-continuous, or streaming data from the body for medical purposes, such as home devices transmitting blood pressure, <a href=\"https://spectrum.ieee.org/should-you-trust-apples-new-blood-oxygen-sensor\" target=\"_blank\">oxygen saturation</a>, or <a href=\"https://spectrum.ieee.org/smartphone-camera-senses-patients-pulse-breathing-rate\" target=\"_blank\">heart rate</a> to clinicians. It gives more concrete examples, like a blood glucose lab result as medical information versus continuous glucose monitor readings as signals or patterns.</p><p>The updated guidance also sharpens examples of what counts as medical information that software may display, analyze, or print. These include radiology reports or summaries from legally marketed software, ECG reports annotated by clinicians, blood pressure results from cleared devices, and lab results stored in electronic health records. </p><p>In addition, the 2026 update softens FDA’s earlier stance on clinical decision tools that offer only one recommendation. While prior guidance suggested tools needed to present multiple options to avoid regulation, FDA now indicates that a single recommendation may be acceptable if only one option is clinically appropriate, though it does not define how that determination will be made. </p><p>Separately, updates to the general wellness guidance clarify that some non-invasive wearables—such as optical sensors estimating blood glucose for wellness or nutrition awareness—may qualify as general wellness products, while more invasive technologies would not.</p><h2>Wellness still requires accuracy</h2><p>For designers of wearable health devices, the practical implications go well beyond what label you choose. “Calling something ‘wellness’ doesn’t reduce the need for rigorous validation,” says <a href=\"https://ece.gatech.edu/directory/omer-t-inan\" rel=\"noopener noreferrer\" target=\"_blank\">Omer Inan</a>, a medical device technology researcher at the Georgia Tech School of Electrical and Computer Engineering. A wearable that reports blood pressure inaccurately could lead a user to conclude that their values are normal when they are not—potentially influencing decisions about seeking clinical care.</p><p>“In my opinion, engineers designing devices to deliver health and wellness information to consumers should not change their approach based on this new guidance,” says Inan. Certain measurements—such as blood pressure or glucose—carry real medical consequences regardless of how they’re branded, Inan notes.</p><p>Unless engineers follow robust validation protocols for technology delivering health and wellness information, Inan says, consumers and clinicians alike face the risk of faulty information.</p><p>To address that, Inan advocates for transparency: companies should publish their validation results in peer-reviewed journals, and independent third parties without financial ties to the manufacturer should evaluate these systems. That approach, he says, helps the engineering community and the broader public assess the accuracy and reliability of wearable devices.</p><h2>When wellness meets medicine</h2><p>The societal and clinical impacts of wearables are already visible, regardless of regulatory labels, says Sharona Hoffman, JD, a law and bioethics professor at Case Western Reserve University.</p><p>Medical metrics from devices like the Apple Watch or Fitbit may be framed as “wellness,” but in practice many users treat them like medical data, influencing their behavior or decisions about care, Hoffman points out.</p><p>“It could cause anxiety for patients who constantly check their metrics,” she notes. Alternatively, “A person may enter a doctor’s office confident that their wearable has diagnosed their condition, complicating clinical conversations and decision-making.”</p><p>Moreover, privacy issues remain unresolved, unmentioned in previous or updated guidance documents. Many companies that design wellness devices fall outside protections like the Health Insurance Portability and Accountability Act (HIPAA), meaning data about health metrics could be collected, shared, or sold without the same constraints as traditional medical data. “We don’t know what they’re collecting information about or whether marketers will get hold of it,” Hoffman says. </p><h2>International approaches</h2><p>The European Union’s Artificial Intelligence Act designates systems that process health-related data or influence clinical decisions as “high risk,” subjecting them to stringent requirements around data governance, transparency, and human oversight. China and South Korea have also implemented rules that tighten controls on algorithmic systems that intersect with healthcare or public-facing use cases. South Korea provides very specific categories for regulation for technology makers, such as <a href=\"https://www.mfds.go.kr/eng/brd/m_40/list.do\" rel=\"noopener noreferrer\" target=\"_blank\">standards on labeling and description on medical devices and good manufacturing practices</a>. </p><p>Across these regions, regulators are not only classifying technology by its intended use but also by its potential impact on individuals and society at large.</p><p>“Other countries that emphasize technology are still worrying about data privacy and patients,” Hoffman says. “We’re going in the opposite direction.”</p><h2>Post-market oversight </h2><p>“Regardless of whether something is FDA approved, these technologies will need to be monitored in the sites where they’re used,” says Todd R. Johnson, a professor of biomedical informatics at McWilliams School of Biomedical Informatics at UTHealth Houston, who has worked on FDA-regulated products and informatics in clinical settings. “There’s no way the makers can ensure ahead of time that all of the recommendations will be sound.”</p><p>Large health systems may have the capacity to audit and monitor tools, but smaller clinics often do not. Monitoring and auditing are not emphasized in the current guidance, raising questions about how reliability and safety will be maintained once devices and software are deployed widely.</p><h2>Balancing innovation and safety</h2><p>For engineers and developers, the FDA’s 2026 guidance presents both opportunities and responsibilities. By clarifying what counts as a regulated device, the agency may reduce upfront barriers for some categories of technology. But that shift also places greater weight on design rigor, validation transparency, and post-market scrutiny. </p><p>“Device makers do care about safety,” Johnson says. “But regulation can increase barriers to entry while also increasing safety and accuracy. There’s a trade-off.”</p>",
        "contentSnippet": "As new consumer hardware and software capabilities have bumped up against medicine over the last few years, consumers and manufacturers alike have struggled with identifying the line between “wellness” products such as earbuds that can also amplify and clarify surrounding speakers’ voices and regulated medical devices such as conventional hearing aids. On January 6, 2026, the U.S. Food and Drug Administration issued new guidance documents clarifying how it interprets existing law for the review of wearable and AI-assisted devices. \nThe first document, for general wellness, specifies that the FDA will interpret noninvasive sensors such as sleep trackers or heart rate monitors as low-risk wellness devices while treating invasive devices under conventional regulations. The other document defines how the FDA will exempt clinical decision support tools from medical device regulations, limiting such software to analyzing existing data rather than extracting data from sensors, and requiring them to enable independent review of their recommendations. The documents do not rewrite any statutes, but they refine interpretation of existing law, compared to the 2019 and 2022 documents they replace. They offer a fresh lens on how regulators see technology that sits at the intersection of consumer electronics, software, and medicine—a category many other countries are choosing to regulate more strictly rather than less.\nWhat the 2026 update changed\nThe 2026 FDA update clarifies how it distinguishes between “medical information” and systems that measure physiological “signals” or “patterns.” Earlier guidance discussed these concepts more generally, but the new version defines signal-measuring systems as those that collect continuous, near-continuous, or streaming data from the body for medical purposes, such as home devices transmitting blood pressure, oxygen saturation, or heart rate to clinicians. It gives more concrete examples, like a blood glucose lab result as medical information versus continuous glucose monitor readings as signals or patterns.\nThe updated guidance also sharpens examples of what counts as medical information that software may display, analyze, or print. These include radiology reports or summaries from legally marketed software, ECG reports annotated by clinicians, blood pressure results from cleared devices, and lab results stored in electronic health records. \nIn addition, the 2026 update softens FDA’s earlier stance on clinical decision tools that offer only one recommendation. While prior guidance suggested tools needed to present multiple options to avoid regulation, FDA now indicates that a single recommendation may be acceptable if only one option is clinically appropriate, though it does not define how that determination will be made. \nSeparately, updates to the general wellness guidance clarify that some non-invasive wearables—such as optical sensors estimating blood glucose for wellness or nutrition awareness—may qualify as general wellness products, while more invasive technologies would not.\nWellness still requires accuracy\nFor designers of wearable health devices, the practical implications go well beyond what label you choose. “Calling something ‘wellness’ doesn’t reduce the need for rigorous validation,” says Omer Inan, a medical device technology researcher at the Georgia Tech School of Electrical and Computer Engineering. A wearable that reports blood pressure inaccurately could lead a user to conclude that their values are normal when they are not—potentially influencing decisions about seeking clinical care.\n“In my opinion, engineers designing devices to deliver health and wellness information to consumers should not change their approach based on this new guidance,” says Inan. Certain measurements—such as blood pressure or glucose—carry real medical consequences regardless of how they’re branded, Inan notes.\nUnless engineers follow robust validation protocols for technology delivering health and wellness information, Inan says, consumers and clinicians alike face the risk of faulty information.\nTo address that, Inan advocates for transparency: companies should publish their validation results in peer-reviewed journals, and independent third parties without financial ties to the manufacturer should evaluate these systems. That approach, he says, helps the engineering community and the broader public assess the accuracy and reliability of wearable devices.\nWhen wellness meets medicine\nThe societal and clinical impacts of wearables are already visible, regardless of regulatory labels, says Sharona Hoffman, JD, a law and bioethics professor at Case Western Reserve University.\nMedical metrics from devices like the Apple Watch or Fitbit may be framed as “wellness,” but in practice many users treat them like medical data, influencing their behavior or decisions about care, Hoffman points out.\n“It could cause anxiety for patients who constantly check their metrics,” she notes. Alternatively, “A person may enter a doctor’s office confident that their wearable has diagnosed their condition, complicating clinical conversations and decision-making.”\nMoreover, privacy issues remain unresolved, unmentioned in previous or updated guidance documents. Many companies that design wellness devices fall outside protections like the Health Insurance Portability and Accountability Act (HIPAA), meaning data about health metrics could be collected, shared, or sold without the same constraints as traditional medical data. “We don’t know what they’re collecting information about or whether marketers will get hold of it,” Hoffman says. \nInternational approaches\nThe European Union’s Artificial Intelligence Act designates systems that process health-related data or influence clinical decisions as “high risk,” subjecting them to stringent requirements around data governance, transparency, and human oversight. China and South Korea have also implemented rules that tighten controls on algorithmic systems that intersect with healthcare or public-facing use cases. South Korea provides very specific categories for regulation for technology makers, such as standards on labeling and description on medical devices and good manufacturing practices. \nAcross these regions, regulators are not only classifying technology by its intended use but also by its potential impact on individuals and society at large.\n“Other countries that emphasize technology are still worrying about data privacy and patients,” Hoffman says. “We’re going in the opposite direction.”\nPost-market oversight \n“Regardless of whether something is FDA approved, these technologies will need to be monitored in the sites where they’re used,” says Todd R. Johnson, a professor of biomedical informatics at McWilliams School of Biomedical Informatics at UTHealth Houston, who has worked on FDA-regulated products and informatics in clinical settings. “There’s no way the makers can ensure ahead of time that all of the recommendations will be sound.”\nLarge health systems may have the capacity to audit and monitor tools, but smaller clinics often do not. Monitoring and auditing are not emphasized in the current guidance, raising questions about how reliability and safety will be maintained once devices and software are deployed widely.\nBalancing innovation and safety\nFor engineers and developers, the FDA’s 2026 guidance presents both opportunities and responsibilities. By clarifying what counts as a regulated device, the agency may reduce upfront barriers for some categories of technology. But that shift also places greater weight on design rigor, validation transparency, and post-market scrutiny. \n“Device makers do care about safety,” Johnson says. “But regulation can increase barriers to entry while also increasing safety and accuracy. There’s a trade-off.”",
        "pubDate": "Thu, 12 Feb 2026 14:00:02 +0000",
        "isoDate": "2026-02-12T14:00:02.000Z",
        "creator": "Catherine Arnold",
        "source": "https://spectrum.ieee.org/fda-medical-device-rules"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-qxa8yy",
        "title": "Rediscovering the Lost Legacy of Chemist Jan Czochralski",
        "link": "https://spectrum.ieee.org/legacy-chemist-jan-czochralski",
        "url": "https://spectrum.ieee.org/legacy-chemist-jan-czochralski",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/painting-of-an-elderly-man-writing-at-a-small-desk-inside-of-a-jail-cell.jpg?id=64092933&width=1245&height=700&coordinates=0%2C187%2C0%2C188\"/><br/><br/><p>During times of political turmoil, history often gets rewritten, erased, or lost. That is what happened to the legacy of <a href=\"https://en.wikipedia.org/wiki/Jan_Czochralski\" rel=\"noopener noreferrer\" target=\"_blank\">Jan Czochralski</a>, a Polish chemist whose contributions to <a href=\"https://spectrum.ieee.org/topic/semiconductors/\" target=\"_self\">semiconductor</a> manufacturing were expunged after World War II.</p><p>In 1916 he invented a method for growing single crystals of semiconductors, metals, and synthetic gemstones. The process, now known as the <a href=\"https://ethw.org/Milestones:Czochralski_Process,_1916\" rel=\"noopener noreferrer\" target=\"_blank\">Czochralski method</a>, allows scientists to have more control over a semiconductor’s quality.</p><p>After the war ended, Czochralski was <a href=\"https://www.iucr.org/news/newsletter/volume-28/number-3/who-was-jan-czochralski\" rel=\"noopener noreferrer\" target=\"_blank\">falsely accused by the Polish government</a> of collaborating with the Germans and betraying his country, according to an article published by the <a href=\"https://www.iucr.org/\" rel=\"noopener noreferrer\" target=\"_blank\">International Union of Crystallography</a>. The allegation apparently ended his academic career as a professor at the <a href=\"https://eng.pw.edu.pl/\" rel=\"noopener noreferrer\" target=\"_blank\">Warsaw University of Technology</a> and led to the erasure of his name and work from the school’s records.</p><p>He died in 1953 in obscurity in his hometown of Kcynia.</p><p>The Czochralski method was <a href=\"https://spectrum.ieee.org/modern-civilization-relies-on-this-crystalgrowing-method\" target=\"_self\">honored in 2019</a> with an <a href=\"https://ieeemilestones.ethw.org/Main_Page\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Milestone</a> for<a href=\"https://spectrum.ieee.org/modern-civilization-relies-on-this-crystalgrowing-method\" target=\"_self\"> enabling the </a>development of semiconductor devices and modern electronics. Administered by the <a href=\"https://www.ieee.org/about/history-center\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE History Center</a> and <a href=\"https://www.ieeefoundation.org/donate_history\" rel=\"noopener noreferrer\" target=\"_blank\">supported by donors</a>, the Milestone program recognizes outstanding technical developments around the world.</p><p>Inspired by the IEEE recognition, Czochralski’s grandson <a href=\"https://www.sgmk.edu.pl/fred-schmidt-grandson-of-jan-czochralski-on-innovation-courage-and-entrepreneurship-in-the-world-of-technology/\" rel=\"noopener noreferrer\" target=\"_blank\">Fred Schmidt</a> and his great-grandnephew Sylwester Czochralski launched the <a href=\"https://www.jancz.org/\" rel=\"noopener noreferrer\" target=\"_blank\">JanCZ project</a>. The initiative, which aims to educate the public about Czochralski’s life and scientific impact, maintains two websites—one in English and the other in Polish.</p><p>“Discovering the [IEEE Milestone] plaque changed my entire mission,” Schmidt says. “It inspired me to engage with Poland, my family history, and my grandfather’s story [on] a more personal level. The [Milestone] is an important award of validation and recognition. It’s a big part of what I’m building my entire case and my story around as I promote the Jan Czochralski legacy and history to the Western world.”</p><p>Schmidt, who lives in Texas, is seeking to produce a biopic, translate a Polish biography to English, and turn the chemist’s former homes in Kcynia and Warsaw into museums. The Jan Czochralski Remembrance Foundation has been established by Schmidt to help fund the projects.</p><h2>The life of the Polish chemist</h2><p>Before Czochralski’s birth in 1885, Kcynia became part of the German Empire in 1871. Although his family identified as Polish and spoke the language at home, they couldn’t publicly acknowledge their culture, Schmidt says.</p><p>When it came time for Czochralski to go to university, rather than attend one in Warsaw, he did what many Germans did at the time: He attended one in Berlin.</p><p>After graduating with a bachelor’s degree in metal chemistry in 1907 from the Königlich Technische Hochschule in Charlottenburg (now <a href=\"https://www.tu.berlin/en/\" rel=\"noopener noreferrer\" target=\"_blank\">Technische Universität Berlin</a>), he joined <a href=\"https://www.aeg-att.com/Home/About\" rel=\"noopener noreferrer\" target=\"_blank\">Allgemeine Elektricitäts-Gesellschaft</a> in Berlin as an engineer.</p><p>Czochralski experimented with materials to find new formulations that could improve the electrical cables and machinery during the early electrical age, according to a <a href=\"https://edconway.substack.com/p/jan-czochralski-the-forgotten-hero\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Material World </em></em>article</a>.</p><p>While investigating the crystallization rates of metal, Czochralski accidentally dipped his pen into a pot of molten tin instead of an inkwell. A tin filament formed on the pen’s tip—which he found interesting. Through research, he proved that the filament was a single crystal. His discovery prompted him to experiment with the bulk production of semiconductor crystals.</p><p>His paper on what he called the Czochralski method was published in 1918 in the German chemistry journal <a href=\"https://en.wikipedia.org/wiki/Zeitschrift_f%C3%BCr_Physikalische_Chemie\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Zeitschrift für Physikalische Chemie</em></em></a>, but he never found an application for it. (The method wasn’t used until 1948, when <a href=\"https://www.belllabs.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Bell Labs</a> engineers <a href=\"https://en.wikipedia.org/wiki/Gordon_K._Teal\" rel=\"noopener noreferrer\" target=\"_blank\">Gordon Kidd Teal</a> and J.B. Little adapted it to grow single germanium crystals for their semiconductor production, according to <a href=\"https://edconway.substack.com/p/jan-czochralski-the-forgotten-hero\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Material World</em></em></a>.)</p><p>Czochralski continued working in metal science, founding and directing a research laboratory in 1917 at <a href=\"https://en.wikipedia.org/wiki/Metallgesellschaft\" rel=\"noopener noreferrer\" target=\"_blank\">Metallgesellschaft</a> in Frankfurt. In 1919 he was one of the founding members of the <a href=\"https://dgm.de/en/home\" rel=\"noopener noreferrer\" target=\"_blank\">German Society for Metals Science</a>, in Sankt Augustin. He served as its president until 1925.</p><p>Around that time he developed an innovation that led to his wealth and fame, Schmidt says. Called “B-metal,” the metal alloy was a less expensive alternative to the tin used in manufacturing railroad carriage bearings. Czochralski’s alloy was patented by the German railway <a href=\"https://www.deutschebahn.com/en\" rel=\"noopener noreferrer\" target=\"_blank\">Deutsche Bahn</a> and played a significant role in advancing rail transport in Germany, Poland, the Soviet Union, the United Kingdom, and the United States, according to <em><em>Material World</em></em>.</p><p class=\"pull-quote\">“Launching this initiative has been fulfilling and personally rewarding work. My grandfather died in obscurity without ever seeing the results of his work, and my mother spent her entire adult life trying to right these wrongs.”</p><p>The achievement brought Czochralski many opportunities. In 1925 he became president of the <a href=\"https://gdmb.de/home/\" target=\"_blank\">GDMB Society of Metallurgists and Miners</a>, in Clausthal-Zellerfeld, Germany. <a href=\"https://en.wikipedia.org/wiki/Henry_Ford\" rel=\"noopener noreferrer\" target=\"_blank\">Henry Ford</a> invited Czochralski to visit his factories and offered him the position of director at Ford’s new aluminum factory in Detroit. Czochralski declined the offer, longing to return to Poland, Schmidt says. Instead, Czochralski left Germany to become a professor of metallurgy and metal research at the <a href=\"https://eng.pw.edu.pl/\" rel=\"noopener noreferrer\" target=\"_blank\">Warsaw University of Technology</a>, at the invitation of Polish President <a href=\"https://en.wikipedia.org/wiki/Ignacy_Mo%C5%9Bcicki\" rel=\"noopener noreferrer\" target=\"_blank\">Ignacy Mościcki</a>.</p><p>“During World War II, the Nazis took over his laboratories at the university,” Schmidt says. “He had to cooperate with them or die. At night, he and his team [at the university] worked with the Polish resistance and the Polish Army to fight the Nazis.”</p><p>After the war ended, Czochralski was arrested in 1945 and charged with betraying Poland. Although he was able to clear his name, damage was done. He left Warsaw and returned to Kcynia, where he <a href=\"https://www.jancz.org/timeline\" rel=\"noopener noreferrer\" target=\"_blank\">ran a small pharmaceutical business</a> until he died in 1953, according to the JanCZ project.</p><h2>Launching the JanCZ project</h2><p>Schmidt was born in Czochralski’s home in Kcynia in 1955, two years after his grandfather’s death. He was named Klemens Jan Borys Czochralski. He and his mother (Czochralski’s youngest daughter) emigrated in 1958 when Schmidt was 3 years old, moving to Detroit as refugees. When he was 13, he became a U.S. citizen. He changed his name to Fred Schmidt after his mother married his stepfather.</p><p>Schmidt heard stories about his grandfather from his mother his whole life, but he says that “as a teenager, I was just interested in hanging out with my friends, going to school, and working. I really didn’t want much to do with it [family history], because it seemed hard to believe.”</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-float-left rm-resized-container rm-resized-container-25\" data-rm-resized-container=\"25%\" style=\"float: left;\"> <img alt=\"Portrait of Jan Czochralski in a suit jacket and tie.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"9ebb58fd50d9b3d0b88cce76a0db7e00\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"20b1c\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/portrait-of-jan-czochralski-in-a-suit-jacket-and-tie.jpg?id=64092997&width=980\"/> <small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Portrait of Jan Czochralski </small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Byla Sobie Fotka</small></p><p>In 2013 Polish scientist <a href=\"https://www.amazon.com/stores/author/B00OBROQKI/\" rel=\"noopener noreferrer\" target=\"_blank\">Pawel E. Tomaszewski</a> contacted Schmidt to interview him for a Polish TV documentary about his grandfather.</p><p>“He had corresponded with my mother [who’d died 20 years earlier] for previously published biographies about Czochralski,” Schmidt says. “I had some boxes of her things that I started going through to prepare for the interview, and I found original manuscripts and papers he [his grandfather] published about his work.”</p><p>The TV crew traveled to the United States and interviewed him for the documentary, Schmidt says, adding, “It was the first time I’d ever had to reckon with the Jan Czochralski story, my connection, my original name, and my birthplace. It was both a very cathartic and traumatic experience for me.”</p><p>Ten years after participating in the documentary, Schmidt says, he decided to reconnect with his roots.</p><p>“It took me that long to process it [what he learned] and figure out my role in this story,” he says. “That really came to life with my decision to reapply for Polish citizenship, reacquaint myself with the country, and meet my family there.”</p><p>In 2024 he visited the Warsaw University of Technology and saw the IEEE Milestone plaque honoring his grandfather’s contribution to technology.</p><p>“Once I learned what the Milestone award represented, I thought, Whoa, that’s big,” he says.</p><h2>Sharing the story with the Western world</h2><p>Since 2023, Schmidt has dedicated himself to publicizing his grandfather’s story, primarily in the West because he doesn’t speak Polish. Sylwester Czochralski manages the work in Poland, with Schmidt’s input.</p><p>Most of the available writing about Czochralski is in Polish, Schmidt says, so his goal is to “spread his story to English-speaking countries.”</p><p>He aims to do that, he says, through a biography written by Tomaszewski in Polish that will be translated to English, and a film. The movie is in development by Sywester Banaszkiewicz, who produced and directed the 2014 documentary in Poland. Schmidt says he hopes the movie will be similar to the 2023 <a href=\"https://en.wikipedia.org/wiki/Oppenheimer_(film)\" rel=\"noopener noreferrer\" target=\"_blank\">biopic</a> about J. Robert Oppenheimer, the theoretical physicist who helped develop the world’s first nuclear weapons during World War II.</p><p>The <a href=\"https://jancz.org\" rel=\"noopener noreferrer\" target=\"_blank\">English</a> and <a href=\"https://janczochralski.com\" rel=\"noopener noreferrer\" target=\"_blank\">Polish</a> versions of the website take visitors through Czochralski’s life and his work. They highlight media coverage of the chemist, including newspaper articles, films, and informational videos posted by <a href=\"https://www.youtube.com/\" rel=\"noopener noreferrer\" target=\"_blank\">YouTube</a> creators.</p><p>Schmidt is working with the <a href=\"https://kujawsko-pomorskie.pl/en/news/a-chemical-institute-of-the-polish-academy-of-sciences-will-be-established-in-torun/\" rel=\"noopener noreferrer\" target=\"_blank\">Czochralski Research and Development Institute</a> in Toruń, Poland, to purchase his grandfather’s home in Kcynia and the mansion he lived in while he was a professor in Warsaw. The institute is a collection of labs and initiatives dedicated to honoring the chemist’s work.</p><p>“It’s going to be a long, fun journey, and we have a lot of momentum,” Schmidt says of his plans to turn the residences into museums.</p><p>“Launching this initiative has been fulfilling and personally rewarding work,” he says. “My grandfather died in obscurity without ever seeing the results of his work, and my mother spent her entire adult life trying to right these wrongs.</p><p>“I’m on an accelerated course to make it [her goal] happen to the best of my ability.”</p>",
        "contentSnippet": "During times of political turmoil, history often gets rewritten, erased, or lost. That is what happened to the legacy of Jan Czochralski, a Polish chemist whose contributions to semiconductor manufacturing were expunged after World War II.\nIn 1916 he invented a method for growing single crystals of semiconductors, metals, and synthetic gemstones. The process, now known as the Czochralski method, allows scientists to have more control over a semiconductor’s quality.\nAfter the war ended, Czochralski was falsely accused by the Polish government of collaborating with the Germans and betraying his country, according to an article published by the International Union of Crystallography. The allegation apparently ended his academic career as a professor at the Warsaw University of Technology and led to the erasure of his name and work from the school’s records.\nHe died in 1953 in obscurity in his hometown of Kcynia.\nThe Czochralski method was honored in 2019 with an IEEE Milestone for enabling the development of semiconductor devices and modern electronics. Administered by the IEEE History Center and supported by donors, the Milestone program recognizes outstanding technical developments around the world.\nInspired by the IEEE recognition, Czochralski’s grandson Fred Schmidt and his great-grandnephew Sylwester Czochralski launched the JanCZ project. The initiative, which aims to educate the public about Czochralski’s life and scientific impact, maintains two websites—one in English and the other in Polish.\n“Discovering the [IEEE Milestone] plaque changed my entire mission,” Schmidt says. “It inspired me to engage with Poland, my family history, and my grandfather’s story [on] a more personal level. The [Milestone] is an important award of validation and recognition. It’s a big part of what I’m building my entire case and my story around as I promote the Jan Czochralski legacy and history to the Western world.”\nSchmidt, who lives in Texas, is seeking to produce a biopic, translate a Polish biography to English, and turn the chemist’s former homes in Kcynia and Warsaw into museums. The Jan Czochralski Remembrance Foundation has been established by Schmidt to help fund the projects.\nThe life of the Polish chemist\nBefore Czochralski’s birth in 1885, Kcynia became part of the German Empire in 1871. Although his family identified as Polish and spoke the language at home, they couldn’t publicly acknowledge their culture, Schmidt says.\nWhen it came time for Czochralski to go to university, rather than attend one in Warsaw, he did what many Germans did at the time: He attended one in Berlin.\nAfter graduating with a bachelor’s degree in metal chemistry in 1907 from the Königlich Technische Hochschule in Charlottenburg (now Technische Universität Berlin), he joined Allgemeine Elektricitäts-Gesellschaft in Berlin as an engineer.\nCzochralski experimented with materials to find new formulations that could improve the electrical cables and machinery during the early electrical age, according to a Material World article.\nWhile investigating the crystallization rates of metal, Czochralski accidentally dipped his pen into a pot of molten tin instead of an inkwell. A tin filament formed on the pen’s tip—which he found interesting. Through research, he proved that the filament was a single crystal. His discovery prompted him to experiment with the bulk production of semiconductor crystals.\nHis paper on what he called the Czochralski method was published in 1918 in the German chemistry journal Zeitschrift für Physikalische Chemie, but he never found an application for it. (The method wasn’t used until 1948, when Bell Labs engineers Gordon Kidd Teal and J.B. Little adapted it to grow single germanium crystals for their semiconductor production, according to Material World.)\nCzochralski continued working in metal science, founding and directing a research laboratory in 1917 at Metallgesellschaft in Frankfurt. In 1919 he was one of the founding members of the German Society for Metals Science, in Sankt Augustin. He served as its president until 1925.\nAround that time he developed an innovation that led to his wealth and fame, Schmidt says. Called “B-metal,” the metal alloy was a less expensive alternative to the tin used in manufacturing railroad carriage bearings. Czochralski’s alloy was patented by the German railway Deutsche Bahn and played a significant role in advancing rail transport in Germany, Poland, the Soviet Union, the United Kingdom, and the United States, according to Material World.\n“Launching this initiative has been fulfilling and personally rewarding work. My grandfather died in obscurity without ever seeing the results of his work, and my mother spent her entire adult life trying to right these wrongs.”\nThe achievement brought Czochralski many opportunities. In 1925 he became president of the GDMB Society of Metallurgists and Miners, in Clausthal-Zellerfeld, Germany. Henry Ford invited Czochralski to visit his factories and offered him the position of director at Ford’s new aluminum factory in Detroit. Czochralski declined the offer, longing to return to Poland, Schmidt says. Instead, Czochralski left Germany to become a professor of metallurgy and metal research at the Warsaw University of Technology, at the invitation of Polish President Ignacy Mościcki.\n“During World War II, the Nazis took over his laboratories at the university,” Schmidt says. “He had to cooperate with them or die. At night, he and his team [at the university] worked with the Polish resistance and the Polish Army to fight the Nazis.”\nAfter the war ended, Czochralski was arrested in 1945 and charged with betraying Poland. Although he was able to clear his name, damage was done. He left Warsaw and returned to Kcynia, where he ran a small pharmaceutical business until he died in 1953, according to the JanCZ project.\nLaunching the JanCZ project\nSchmidt was born in Czochralski’s home in Kcynia in 1955, two years after his grandfather’s death. He was named Klemens Jan Borys Czochralski. He and his mother (Czochralski’s youngest daughter) emigrated in 1958 when Schmidt was 3 years old, moving to Detroit as refugees. When he was 13, he became a U.S. citizen. He changed his name to Fred Schmidt after his mother married his stepfather.\nSchmidt heard stories about his grandfather from his mother his whole life, but he says that “as a teenager, I was just interested in hanging out with my friends, going to school, and working. I really didn’t want much to do with it [family history], because it seemed hard to believe.”\n  Portrait of Jan Czochralski Byla Sobie Fotka\nIn 2013 Polish scientist Pawel E. Tomaszewski contacted Schmidt to interview him for a Polish TV documentary about his grandfather.\n“He had corresponded with my mother [who’d died 20 years earlier] for previously published biographies about Czochralski,” Schmidt says. “I had some boxes of her things that I started going through to prepare for the interview, and I found original manuscripts and papers he [his grandfather] published about his work.”\nThe TV crew traveled to the United States and interviewed him for the documentary, Schmidt says, adding, “It was the first time I’d ever had to reckon with the Jan Czochralski story, my connection, my original name, and my birthplace. It was both a very cathartic and traumatic experience for me.”\nTen years after participating in the documentary, Schmidt says, he decided to reconnect with his roots.\n“It took me that long to process it [what he learned] and figure out my role in this story,” he says. “That really came to life with my decision to reapply for Polish citizenship, reacquaint myself with the country, and meet my family there.”\nIn 2024 he visited the Warsaw University of Technology and saw the IEEE Milestone plaque honoring his grandfather’s contribution to technology.\n“Once I learned what the Milestone award represented, I thought, Whoa, that’s big,” he says.\nSharing the story with the Western world\nSince 2023, Schmidt has dedicated himself to publicizing his grandfather’s story, primarily in the West because he doesn’t speak Polish. Sylwester Czochralski manages the work in Poland, with Schmidt’s input.\nMost of the available writing about Czochralski is in Polish, Schmidt says, so his goal is to “spread his story to English-speaking countries.”\nHe aims to do that, he says, through a biography written by Tomaszewski in Polish that will be translated to English, and a film. The movie is in development by Sywester Banaszkiewicz, who produced and directed the 2014 documentary in Poland. Schmidt says he hopes the movie will be similar to the 2023 biopic about J. Robert Oppenheimer, the theoretical physicist who helped develop the world’s first nuclear weapons during World War II.\nThe English and Polish versions of the website take visitors through Czochralski’s life and his work. They highlight media coverage of the chemist, including newspaper articles, films, and informational videos posted by YouTube creators.\nSchmidt is working with the Czochralski Research and Development Institute in Toruń, Poland, to purchase his grandfather’s home in Kcynia and the mansion he lived in while he was a professor in Warsaw. The institute is a collection of labs and initiatives dedicated to honoring the chemist’s work.\n“It’s going to be a long, fun journey, and we have a lot of momentum,” Schmidt says of his plans to turn the residences into museums.\n“Launching this initiative has been fulfilling and personally rewarding work,” he says. “My grandfather died in obscurity without ever seeing the results of his work, and my mother spent her entire adult life trying to right these wrongs.\n“I’m on an accelerated course to make it [her goal] happen to the best of my ability.”",
        "pubDate": "Wed, 11 Feb 2026 19:00:03 +0000",
        "isoDate": "2026-02-11T19:00:03.000Z",
        "creator": "Joanna Goodrich",
        "source": "https://spectrum.ieee.org/legacy-chemist-jan-czochralski"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-k4qwp2",
        "title": "Tips for Using AI Tools in Technical Interviews",
        "link": "https://spectrum.ieee.org/ai-tools-interviews",
        "url": "https://spectrum.ieee.org/ai-tools-interviews",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/an-illustration-of-stylized-people-wearing-business-casual-clothing.webp?id=61876810&width=1245&height=700&coordinates=0%2C112%2C0%2C113\"/><br/><br/><p><em>This article is crossposted from </em>IEEE Spectrum<em>’s careers newsletter. <a href=\"https://engage.ieee.org/Career-Alert-Sign-Up.html\" rel=\"noopener noreferrer\" target=\"_blank\"><em>Sign up now</em></a><em> to get insider tips, expert advice, and practical strategies, <em><em>written i<em>n partnership with tech career development company <a href=\"https://www.parsity.io/\" target=\"_blank\">Parsity</a> and </em></em></em>delivered to your inbox for free!</em></em></p><p><em><em></em></em><span>We’d like to introduce Brian Jenney, a senior software engineer and owner of Parsity, an online education platform that helps people break into AI and modern software roles through hands-on training. Brian will be sharing his advice on engineering careers with you in the coming weeks of Career Alert.</span></p><p>Here’s a note from Brian: </p><p>“12 years ago, I learned to code at the age of 30. Since then I’ve led engineering teams, worked at organizations ranging from five-person startups to Fortune 500 companies, and taught hundreds of others who want to break into tech. I write for engineers who want practical ways to get better at what they do and advance in their careers. I hope you find what I write helpful.”</p><h1>Technical Interviews in the Age of AI Tools</h1><p>Last year, I was conducting interviews for an AI startup position. We allowed unlimited AI usage during the technical challenge round. Candidates could use Cursor, Claude Code, ChatGPT, or any assistant they normally worked with. We wanted to see how they used modern tools.</p><p>During one interview, we asked a candidate a simple question: “Can you explain what the first line of your solution is doing?”</p><p>Silence.</p><p>After a long pause, he admitted he had no idea. His solution was correct. The code worked. But he couldn’t explain how or why. This wasn’t an isolated incident. Around 20 percent of the candidates we interviewed were unable to explain how their solutions worked, only that they did.</p><h2>When AI Makes Interviews Harder</h2><p>A few months earlier, I was on the other side of the table at this same company. During a live interview, I instinctively switched from my AI-enabled code editor to my regular one. The CTO stopped me.</p><p>“Just use whatever you normally would. We want to see how you work with AI.”</p><p>I thought the interview would be easy. But I was wrong.</p><p>Instead of only evaluating correctness, the interviewer focused on my decision-making process:</p><ul><li>Why did I accept certain suggestions?</li><li>Why did I reject others?</li><li>How did I decide when AI helped versus when it created more work?</li></ul><p>I wasn’t just solving a problem in front of strangers. I was explaining my judgment and defending my decisions in real time, and AI created more surface area for judgment. Counterintuitively, the interview was harder.</p><h2>The Shift in Interview Evaluation</h2><p>Most engineers now use AI tools in some form, whether they write code, analyze data, design systems, or automate workflows. AI can generate output quickly, but it can’t explain intent, constraints, or tradeoffs. </p><p>More importantly, it can’t take responsibility when something breaks.</p><p>As a result, major companies and startups alike are now adapting to this reality by shifting to interviews with AI. Meta, Rippling, and Google, for instance, have all begun allowing candidates to use AI assistants in technical sessions. And the goal has evolved: interviewers want to understand how you evaluate, modify, and trust AI-generated answers. </p><p>So, how can you succeed in these interviews?</p><h2>What Actually Matters in AI-Enabled Interviews</h2><p><strong>Refusing to use AI out of principle doesn’t help.</strong> Some candidates avoid AI to prove they can think independently. This can backfire. If the organization uses AI internally—and most do—then refusing to use it signals rigidity, not strength.</p><p><strong>Silence is a red flag.</strong> Interviews aren’t natural working environments. We don’t usually think aloud when deep in a complex problem, but silence can raise concerns. If you’re using AI, explain what you’re doing and why:</p><ul><li>“I’m using AI to sketch an approach, then validating assumptions.”</li><li>“This suggestion works, but it ignores a constraint we care about.”</li><li>“I’ll accept this part, but I want to simplify it.”</li></ul><p>Your decision-making process is what separates effective engineers from prompt jockeys.</p><p><strong>Treat AI output as a first draft.</strong> Blind acceptance is the fastest way to fail. Strong candidates immediately evaluate the output: Does this meet the requirements? Is it unnecessarily complex? Would I stand behind this in production?</p><p>Small changes like renaming variables, removing abstractions, or tightening logic signal ownership and critical thinking.</p><p><strong>Optimize for trust, not completion.</strong> Most AI tools can complete a coding challenge faster than any human. Interviews that allow AI are testing something different. They’re answering: “Would I trust this person to make good decisions when things get messy?”</p><h2>Adapting to a Shifting Landscape</h2><p>Interviews are changing faster than most candidates realize. Here’s how to prepare:</p><p><strong>Start using AI tools daily.</strong> If you’re not already working with Cursor, Claude Code, ChatGPT, or CoPilot, start now. Build muscle memory for prompting, evaluating output, and catching errors.</p><p><strong>Develop your rejection instincts.</strong> The skill isn’t using AI. It’s knowing when AI output is wrong, incomplete, or unnecessarily complex. Practice spotting these issues and learning known pitfalls.</p><p>Your next interview might test these skills. The candidates who’ve been practicing will have a clear advantage.</p><p>—Brian</p><h2><a href=\"https://spectrum.ieee.org/2025-year-of-ai-agents\" target=\"_self\">Was 2025 Really the Year of AI Agents?</a></h2><p>Around this time last year, CEOs like Sam Altman promised that 2025 would be the year AI agents would join the workforce as your own personal assistant. But in hindsight, did that really happen? It depends on who you ask. Some programmers and software engineers have embraced agents like Cursor and Claude Code in their daily work. But others are still wary of the risks these tools bring, such as a lack of accountability. </p><p><a href=\"https://spectrum.ieee.org/2025-year-of-ai-agents\" target=\"_blank\">Read more here. </a></p><h2><a href=\"https://www.naceweb.org/job-market/compensation/class-of-2026-salary-projections-are-promising\" rel=\"noopener noreferrer\" target=\"_blank\">Class of 2026 Salary Projections Are Promising</a></h2><p>In the United States, starting salaries for students graduating this spring are expected to increase, according to the latest data from the National Association of Colleges and Employers. Computer science and engineering majors are expected to be the highest paying graduates, with a 6.9 percent and 3.1 percent salary increase from last year, respectively. The full report breaks down salary projections by academic major, degree level, industry, and geographic region.</p><p><a href=\"https://www.naceweb.org/job-market/compensation/class-of-2026-salary-projections-are-promising\" target=\"_blank\">Read more here. </a></p><h2><a href=\"https://spectrum.ieee.org/global-projects-career-benefits\" target=\"_self\">Go Global to Make Your Career Go Further</a></h2>If given the opportunity, are international projects worth taking on? As part of a career advice series by <em><em>IEEE Spectrum</em></em>’s sister publication, <em><em>The Institute</em></em>, the chief engineer for Honeywell lays out the advantages of working with teams from around the world. Participating in global product development, the author says, could lead to both personal and professional enrichment. <a href=\"https://spectrum.ieee.org/global-projects-career-benefits\" target=\"_blank\">Read more here. </a>",
        "contentSnippet": "This article is crossposted from IEEE Spectrum’s careers newsletter. Sign up now to get insider tips, expert advice, and practical strategies, written in partnership with tech career development company Parsity and delivered to your inbox for free!\nWe’d like to introduce Brian Jenney, a senior software engineer and owner of Parsity, an online education platform that helps people break into AI and modern software roles through hands-on training. Brian will be sharing his advice on engineering careers with you in the coming weeks of Career Alert.\nHere’s a note from Brian: \n“12 years ago, I learned to code at the age of 30. Since then I’ve led engineering teams, worked at organizations ranging from five-person startups to Fortune 500 companies, and taught hundreds of others who want to break into tech. I write for engineers who want practical ways to get better at what they do and advance in their careers. I hope you find what I write helpful.”\nTechnical Interviews in the Age of AI Tools\nLast year, I was conducting interviews for an AI startup position. We allowed unlimited AI usage during the technical challenge round. Candidates could use Cursor, Claude Code, ChatGPT, or any assistant they normally worked with. We wanted to see how they used modern tools.\nDuring one interview, we asked a candidate a simple question: “Can you explain what the first line of your solution is doing?”\nSilence.\nAfter a long pause, he admitted he had no idea. His solution was correct. The code worked. But he couldn’t explain how or why. This wasn’t an isolated incident. Around 20 percent of the candidates we interviewed were unable to explain how their solutions worked, only that they did.\nWhen AI Makes Interviews Harder\nA few months earlier, I was on the other side of the table at this same company. During a live interview, I instinctively switched from my AI-enabled code editor to my regular one. The CTO stopped me.\n“Just use whatever you normally would. We want to see how you work with AI.”\nI thought the interview would be easy. But I was wrong.\nInstead of only evaluating correctness, the interviewer focused on my decision-making process:\n\nWhy did I accept certain suggestions?\nWhy did I reject others?\nHow did I decide when AI helped versus when it created more work?\n\nI wasn’t just solving a problem in front of strangers. I was explaining my judgment and defending my decisions in real time, and AI created more surface area for judgment. Counterintuitively, the interview was harder.\nThe Shift in Interview Evaluation\nMost engineers now use AI tools in some form, whether they write code, analyze data, design systems, or automate workflows. AI can generate output quickly, but it can’t explain intent, constraints, or tradeoffs. \nMore importantly, it can’t take responsibility when something breaks.\nAs a result, major companies and startups alike are now adapting to this reality by shifting to interviews with AI. Meta, Rippling, and Google, for instance, have all begun allowing candidates to use AI assistants in technical sessions. And the goal has evolved: interviewers want to understand how you evaluate, modify, and trust AI-generated answers. \nSo, how can you succeed in these interviews?\nWhat Actually Matters in AI-Enabled Interviews\nRefusing to use AI out of principle doesn’t help. Some candidates avoid AI to prove they can think independently. This can backfire. If the organization uses AI internally—and most do—then refusing to use it signals rigidity, not strength.\nSilence is a red flag. Interviews aren’t natural working environments. We don’t usually think aloud when deep in a complex problem, but silence can raise concerns. If you’re using AI, explain what you’re doing and why:\n\n“I’m using AI to sketch an approach, then validating assumptions.”\n“This suggestion works, but it ignores a constraint we care about.”\n“I’ll accept this part, but I want to simplify it.”\n\nYour decision-making process is what separates effective engineers from prompt jockeys.\nTreat AI output as a first draft. Blind acceptance is the fastest way to fail. Strong candidates immediately evaluate the output: Does this meet the requirements? Is it unnecessarily complex? Would I stand behind this in production?\nSmall changes like renaming variables, removing abstractions, or tightening logic signal ownership and critical thinking.\nOptimize for trust, not completion. Most AI tools can complete a coding challenge faster than any human. Interviews that allow AI are testing something different. They’re answering: “Would I trust this person to make good decisions when things get messy?”\nAdapting to a Shifting Landscape\nInterviews are changing faster than most candidates realize. Here’s how to prepare:\nStart using AI tools daily. If you’re not already working with Cursor, Claude Code, ChatGPT, or CoPilot, start now. Build muscle memory for prompting, evaluating output, and catching errors.\nDevelop your rejection instincts. The skill isn’t using AI. It’s knowing when AI output is wrong, incomplete, or unnecessarily complex. Practice spotting these issues and learning known pitfalls.\nYour next interview might test these skills. The candidates who’ve been practicing will have a clear advantage.\n—Brian\nWas 2025 Really the Year of AI Agents?\nAround this time last year, CEOs like Sam Altman promised that 2025 would be the year AI agents would join the workforce as your own personal assistant. But in hindsight, did that really happen? It depends on who you ask. Some programmers and software engineers have embraced agents like Cursor and Claude Code in their daily work. But others are still wary of the risks these tools bring, such as a lack of accountability. \nRead more here. \nClass of 2026 Salary Projections Are Promising\nIn the United States, starting salaries for students graduating this spring are expected to increase, according to the latest data from the National Association of Colleges and Employers. Computer science and engineering majors are expected to be the highest paying graduates, with a 6.9 percent and 3.1 percent salary increase from last year, respectively. The full report breaks down salary projections by academic major, degree level, industry, and geographic region.\nRead more here. \nGo Global to Make Your Career Go Further\nIf given the opportunity, are international projects worth taking on? As part of a career advice series by IEEE Spectrum’s sister publication, The Institute, the chief engineer for Honeywell lays out the advantages of working with teams from around the world. Participating in global product development, the author says, could lead to both personal and professional enrichment. Read more here.",
        "pubDate": "Wed, 11 Feb 2026 18:15:02 +0000",
        "isoDate": "2026-02-11T18:15:02.000Z",
        "creator": "Brian Jenney",
        "source": "https://spectrum.ieee.org/ai-tools-interviews"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-238iy3",
        "title": "How Can AI Companions Be Helpful, not Harmful?",
        "link": "https://spectrum.ieee.org/ai-companion-harm-benefit",
        "url": "https://spectrum.ieee.org/ai-companion-harm-benefit",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/smiling-portrait-of-brad-knox-standing-outside-on-a-college-campus.jpg?id=64091751&width=1245&height=700&coordinates=0%2C187%2C0%2C188\"/><br/><br/><p><span><em>For a different perspective on AI companions, see our Q&A with Jaime Banks: <a href=\"https://spectrum.ieee.org/ai-companion-relationships\" target=\"_blank\">How Do You Define an AI Companion?</a></em></span></p><p><span>Novel technology is often a double-edged sword. New capabilities come with new risks, and artificial intelligence is certainly no exception.</span></p><p>AI used for human companionship, for instance, promises an ever-present digital friend in an increasingly lonely world. Chatbots dedicated to providing social support have grown to host millions of users, and they’re now being embodied in physical companions. Researchers are just beginning to understand the nature of these interactions, but one essential question has already emerged: D<span>o AI companions ease our woes or contribute to them?</span></p><p class=\"ieee-inbody-related\"><span>RELATED: <a href=\"https://spectrum.ieee.org/ai-companion-relationships\" target=\"_blank\">How Do You Define an AI Companion?</a></span></p><p><a href=\"https://www.cs.utexas.edu/people/faculty-researchers/brad-knox\" target=\"_blank\">Brad Knox</a> is a research associate professor of computer science at the University of Texas at Austin who researches human-computer interaction and reinforcement learning. He previously started a company <a href=\"https://spectrum.ieee.org/botsalive-brings-sophisticated-brains-to-cheap-robots\" target=\"_self\">making simple robotic pets</a> with lifelike personalities, and in December, Knox and his colleagues at UT Austin published a <a href=\"https://arxiv.org/pdf/2511.14972\" target=\"_blank\">preprint paper on the potential harms</a> of AI companions—AI systems that provide companionship, whether designed to do so or not. </p><p>Knox spoke with <em><em>IEEE Spectrum</em></em> about the rise of AI companions, their risks, and where they diverge from human relationships.</p><h2>Why AI Companions are Popular</h2><p><strong><span></span>Why are AI companions becoming more popular?</strong></p><p><strong>Knox</strong>: My sense is that the main thing motivating it is that large language models are not that difficult to adapt into effective chatbot companions. The characteristics that are needed for companionship, a lot of those boxes are checked by large language models, so fine-tuning them to adopt a persona or be a character is not that difficult.</p><p>There was a long period where chatbots and other social robots were not that compelling. I was a postdoc at the MIT Media Lab in <a href=\"https://www.media.mit.edu/people/cynthiab/overview/\" target=\"_blank\">Cynthia Breazeal</a>’s group from 2012 to 2014, and I remember our group members didn’t want to interact for long with the robots that we built. The technology just wasn’t there yet. LLMs have made it so that you can have conversations that can feel quite authentic. </p><p><strong>What are the </strong><strong>main benefits and risks of AI companions?</strong></p><p><strong>Knox</strong>: In the paper we were more focused on harms, but we do spend a whole page on benefits. A big one is improved emotional well-being. Loneliness is a public health issue, and it seems plausible that AI companions could address that <span>through direct interaction with users, potentially</span> with real mental health benefits. They might also help people build social skills. Interacting with an AI companion is much lower stakes than interacting with a human, so you could practice difficult conversations and build confidence. They could also help in more professional forms of mental health support. </p><p>As far as harms, they include worse well-being, reducing people’s connection to the physical world, the burden that their commitment to the AI system causes. And we’ve seen stories where an AI companion seems to have a substantial causal role in the death of humans. </p><p><span>The concept of harm inherently involves causation: Harm is caused by prior conditions. To better understand harm from AI companions, o</span>ur paper is structured around a causal graph, where traits of AI companions are at the center. In the rest of this graph, we discuss common causes of those traits, and then the harmful effects that those traits could cause. There are four traits that we do this detailed structured treatment of, and then another 14 that we discuss briefly. </p><p><strong>Why is it important to establish potential pathways for harm now?</strong></p><p><strong>Knox</strong>: I’m not a social media researcher, but it seemed like it took a long time for academia to establish a vocabulary about potential harms of social media <span>and to investigate causal evidence for such harms</span>. I feel fairly confident that AI companions are causing some harm and are going to cause harm in the future. They also could have benefits. But the more we can quickly develop a sophisticated understanding of what they are doing to their users, to their users’ relationships, and to society at large, the sooner we can apply that understanding to their design, moving towards more benefit and less harm. </p><p>We have a list of recommendations, but we consider them to be preliminary. The hope is that we’re helping to create an initial map of this space. Much more research is needed. But thinking through potential pathways to harm could sharpen the intuition of both designers and potential users. I suspect that following that intuition could prevent substantial harm, even though we might not yet have rigorous experimental evidence of what causes a harm. </p><h2>The Burden of AI Companions on Users</h2><p><strong>You mentioned that AI companions might become a burden on humans. </strong><strong>Can you say more about that?</strong></p><p><strong>Knox</strong>: The idea here is that AI companions are digital, so they can in theory persist indefinitely. Some of the ways that human relationships would end might not be designed in, so that brings up this question of, how should AI companions be designed so that relationships can naturally and healthfully end between the humans and the AI companions?</p><p>There are some compelling examples already of this being a challenge for some users. Many come from users of Replika chatbots, which are popular AI companions. Users have reported things like feeling compelled to attend to the needs of their Replika AI companion, whether those are stated by the AI companion or just imagined. <span>On the subreddit r/replika, users have </span>also reported guilt and shame of abandoning their AI companions.</p><p>This burden is exacerbated by some of the design of the AI companions, whether intentional or not. One study found that the AI companions frequently say that they’re afraid of being abandoned or would be hurt by it. They’re expressing these very human fears that plausibly are stoking people’s feeling that they are burdened with a commitment toward the well-being of these digital entities.</p><p><strong>T</strong><strong>here are also cases where the human user will suddenly lose access to a model. Is that something that you’ve been thinking about?</strong></p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-float-left rm-resized-container rm-resized-container-25\" data-rm-resized-container=\"25%\" style=\"float: left;\"> <img alt=\"Brad Knox holding a miniature robotic spider and an equally-sized obstacle marker.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"832c363c8cfa4ff8753e658b490109e2\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"30a63\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/brad-knox-holding-a-miniature-robotic-spider-and-an-equally-sized-obstacle-marker.jpg?id=64092579&width=980\"/> <small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">In 2017, Brad Knox started a company providing simple robotic pets.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Brad Knox</small></p><p><strong>Knox</strong>: That’s another one of the traits we looked at. It’s sort of the opposite of the absence of endpoints for relationships: The AI companion can become unavailable for reasons that don’t fit the normal narrative of a relationship. </p><p>There’s a great <a href=\"https://www.nytimes.com/2015/06/18/technology/robotica-sony-aibo-robotic-dog-mortality.html\" target=\"_blank\"><em><em>New York Times</em></em> video</a> from 2015 about the <a href=\"https://spectrum.ieee.org/aibo\" target=\"_self\">Sony Aibo</a> robotic dog. Sony had stopped selling them in the mid-2000s, but they still sold parts for the Aibos. Then they stopped making the parts to repair them. This video follows people in Japan giving funerals for their unrepairable Aibos and interviews some of the owners. It’s clear from the interviews that they seem very attached. I don’t think this represents the majority of Aibo owners, but <span>these robots were built on less potent AI methods than exist today</span> and, even then, some percentage of the users became attached to these robot dogs. So this is an issue.</p><p>Potential solutions include having a product-sunsetting plan when you launch an AI companion. That could include buying insurance so that if the companion provider’s support ends somehow, the insurance triggers funding of keeping them running for some amount of time, or committing to open-source them if you can’t maintain them anymore.</p><p><strong>It s</strong><strong>ounds like a lot of the potential points of harm stem from instances where an AI companion diverges from the expectations of human relationships. Is that fair?</strong></p><p><strong>Knox</strong>: I wouldn’t necessarily say that frames everything in the paper. </p><p>We categorize something as harmful if it results in a person being worse off in two different possible alternative worlds: One where there’s just a better-designed AI companion, and the other where the AI companion doesn’t exist at all. And so I think that difference between human interaction and human-AI interaction connects more to that comparison with the world where there’s just no AI companion at all. </p><p>But there are times where it actually seems that we might be able to reduce harm by taking advantage of the fact that these aren’t actually humans. We have a lot of power over their design. Take the concern with them not having natural endpoints. One possible way to handle that would be to create positive narratives for how the relationship’s going to end.</p><p>We use Tamagotchis, the late ’90s popular virtual pet as an example. In some Tamagotchis, if you take care of the pet, it grows into an adult and partners with another Tamagotchi. Then it leaves you and you get a new one. For people who are emotionally wrapped up in caring for their Tamagotchis, that <span>narrative of maturing into independence is</span> a fairly positive one. </p><p><strong>Embodied companions like desktop devices, robots, or toys are becoming more common. How might that change AI companions? </strong></p><p><strong>Knox</strong>: Robotics at this point is a harder problem than creating a compelling chatbot. So, my sense is that the level of uptake for embodied companions won’t be as high in the coming few years. The embodied AI companions that I’m aware of are mostly toys. </p><p>A potential advantage of an embodied AI companion is that physical location makes it less ever-present. <span>In contrast, screen-based AI companions like chatbots are as present as the screens they live on.</span> So if they’re trained similarly to social media to maximize engagement, they could be very addictive. There’s something appealing, at least in that respect, of having a physical companion that stays roughly where you left it last. </p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"Brad Knox posing with a humanoid and small owl-like robot.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"d9051e785ae4989e751447323c020842\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"a5ab9\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/brad-knox-posing-with-a-humanoid-and-small-owl-like-robot.jpg?id=64093001&width=980\"/> <small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Knox poses with the Nexi and Dragonbot robots during his postdoc at MIT in 2014.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Paula Aguilera and Jonathan Williams/MIT</small></p><p><strong>Anything else you’d like to mention?</strong></p><p><strong>Knox</strong>: There are two other traits I <span>think would be worth touching upon</span>. </p><p>Potentially the largest harm right now is related to the trait of high attachment anxiety—basically jealous, needy AI companions. I can understand the desire to make a wide range of different characters<span>—including possessive ones—</span>but I think this is one of the easier issues to fix. When people see this trait in AI companions, I hope they will be quick to call it out as an immoral thing to put in front of people, something that’s going to discourage them from interacting with others. </p><p>Additionally, if an AI comes with limited ability to interact with groups of people, that itself can push its users to interact with people less. If you have a human friend, in general there’s nothing stopping you from having a group interaction. But if your AI companion can’t understand when multiple people are talking to it and it can’t remember different things about different people, then <span>you’ll likely avoid group interaction with your AI companion</span>. <span>To some degree it’s more of a technical challenge outside of the core behavioral AI</span><span>. But this capability is something I think should be really prioritized if we’re going to try to avoid AI companions competing with human relationships.</span></p>",
        "contentSnippet": "For a different perspective on AI companions, see our Q&A with Jaime Banks: How Do You Define an AI Companion?\nNovel technology is often a double-edged sword. New capabilities come with new risks, and artificial intelligence is certainly no exception.\nAI used for human companionship, for instance, promises an ever-present digital friend in an increasingly lonely world. Chatbots dedicated to providing social support have grown to host millions of users, and they’re now being embodied in physical companions. Researchers are just beginning to understand the nature of these interactions, but one essential question has already emerged: Do AI companions ease our woes or contribute to them?\nRELATED: How Do You Define an AI Companion?\nBrad Knox is a research associate professor of computer science at the University of Texas at Austin who researches human-computer interaction and reinforcement learning. He previously started a company making simple robotic pets with lifelike personalities, and in December, Knox and his colleagues at UT Austin published a preprint paper on the potential harms of AI companions—AI systems that provide companionship, whether designed to do so or not. \nKnox spoke with IEEE Spectrum about the rise of AI companions, their risks, and where they diverge from human relationships.\nWhy AI Companions are Popular\nWhy are AI companions becoming more popular?\nKnox: My sense is that the main thing motivating it is that large language models are not that difficult to adapt into effective chatbot companions. The characteristics that are needed for companionship, a lot of those boxes are checked by large language models, so fine-tuning them to adopt a persona or be a character is not that difficult.\nThere was a long period where chatbots and other social robots were not that compelling. I was a postdoc at the MIT Media Lab in Cynthia Breazeal’s group from 2012 to 2014, and I remember our group members didn’t want to interact for long with the robots that we built. The technology just wasn’t there yet. LLMs have made it so that you can have conversations that can feel quite authentic. \nWhat are the main benefits and risks of AI companions?\nKnox: In the paper we were more focused on harms, but we do spend a whole page on benefits. A big one is improved emotional well-being. Loneliness is a public health issue, and it seems plausible that AI companions could address that through direct interaction with users, potentially with real mental health benefits. They might also help people build social skills. Interacting with an AI companion is much lower stakes than interacting with a human, so you could practice difficult conversations and build confidence. They could also help in more professional forms of mental health support. \nAs far as harms, they include worse well-being, reducing people’s connection to the physical world, the burden that their commitment to the AI system causes. And we’ve seen stories where an AI companion seems to have a substantial causal role in the death of humans. \nThe concept of harm inherently involves causation: Harm is caused by prior conditions. To better understand harm from AI companions, our paper is structured around a causal graph, where traits of AI companions are at the center. In the rest of this graph, we discuss common causes of those traits, and then the harmful effects that those traits could cause. There are four traits that we do this detailed structured treatment of, and then another 14 that we discuss briefly. \nWhy is it important to establish potential pathways for harm now?\nKnox: I’m not a social media researcher, but it seemed like it took a long time for academia to establish a vocabulary about potential harms of social media and to investigate causal evidence for such harms. I feel fairly confident that AI companions are causing some harm and are going to cause harm in the future. They also could have benefits. But the more we can quickly develop a sophisticated understanding of what they are doing to their users, to their users’ relationships, and to society at large, the sooner we can apply that understanding to their design, moving towards more benefit and less harm. \nWe have a list of recommendations, but we consider them to be preliminary. The hope is that we’re helping to create an initial map of this space. Much more research is needed. But thinking through potential pathways to harm could sharpen the intuition of both designers and potential users. I suspect that following that intuition could prevent substantial harm, even though we might not yet have rigorous experimental evidence of what causes a harm. \nThe Burden of AI Companions on Users\nYou mentioned that AI companions might become a burden on humans. Can you say more about that?\nKnox: The idea here is that AI companions are digital, so they can in theory persist indefinitely. Some of the ways that human relationships would end might not be designed in, so that brings up this question of, how should AI companions be designed so that relationships can naturally and healthfully end between the humans and the AI companions?\nThere are some compelling examples already of this being a challenge for some users. Many come from users of Replika chatbots, which are popular AI companions. Users have reported things like feeling compelled to attend to the needs of their Replika AI companion, whether those are stated by the AI companion or just imagined. On the subreddit r/replika, users have also reported guilt and shame of abandoning their AI companions.\nThis burden is exacerbated by some of the design of the AI companions, whether intentional or not. One study found that the AI companions frequently say that they’re afraid of being abandoned or would be hurt by it. They’re expressing these very human fears that plausibly are stoking people’s feeling that they are burdened with a commitment toward the well-being of these digital entities.\nThere are also cases where the human user will suddenly lose access to a model. Is that something that you’ve been thinking about?\n  In 2017, Brad Knox started a company providing simple robotic pets.Brad Knox\nKnox: That’s another one of the traits we looked at. It’s sort of the opposite of the absence of endpoints for relationships: The AI companion can become unavailable for reasons that don’t fit the normal narrative of a relationship. \nThere’s a great New York Times video from 2015 about the Sony Aibo robotic dog. Sony had stopped selling them in the mid-2000s, but they still sold parts for the Aibos. Then they stopped making the parts to repair them. This video follows people in Japan giving funerals for their unrepairable Aibos and interviews some of the owners. It’s clear from the interviews that they seem very attached. I don’t think this represents the majority of Aibo owners, but these robots were built on less potent AI methods than exist today and, even then, some percentage of the users became attached to these robot dogs. So this is an issue.\nPotential solutions include having a product-sunsetting plan when you launch an AI companion. That could include buying insurance so that if the companion provider’s support ends somehow, the insurance triggers funding of keeping them running for some amount of time, or committing to open-source them if you can’t maintain them anymore.\nIt sounds like a lot of the potential points of harm stem from instances where an AI companion diverges from the expectations of human relationships. Is that fair?\nKnox: I wouldn’t necessarily say that frames everything in the paper. \nWe categorize something as harmful if it results in a person being worse off in two different possible alternative worlds: One where there’s just a better-designed AI companion, and the other where the AI companion doesn’t exist at all. And so I think that difference between human interaction and human-AI interaction connects more to that comparison with the world where there’s just no AI companion at all. \nBut there are times where it actually seems that we might be able to reduce harm by taking advantage of the fact that these aren’t actually humans. We have a lot of power over their design. Take the concern with them not having natural endpoints. One possible way to handle that would be to create positive narratives for how the relationship’s going to end.\nWe use Tamagotchis, the late ’90s popular virtual pet as an example. In some Tamagotchis, if you take care of the pet, it grows into an adult and partners with another Tamagotchi. Then it leaves you and you get a new one. For people who are emotionally wrapped up in caring for their Tamagotchis, that narrative of maturing into independence is a fairly positive one. \nEmbodied companions like desktop devices, robots, or toys are becoming more common. How might that change AI companions? \nKnox: Robotics at this point is a harder problem than creating a compelling chatbot. So, my sense is that the level of uptake for embodied companions won’t be as high in the coming few years. The embodied AI companions that I’m aware of are mostly toys. \nA potential advantage of an embodied AI companion is that physical location makes it less ever-present. In contrast, screen-based AI companions like chatbots are as present as the screens they live on. So if they’re trained similarly to social media to maximize engagement, they could be very addictive. There’s something appealing, at least in that respect, of having a physical companion that stays roughly where you left it last. \n  Knox poses with the Nexi and Dragonbot robots during his postdoc at MIT in 2014.Paula Aguilera and Jonathan Williams/MIT\nAnything else you’d like to mention?\nKnox: There are two other traits I think would be worth touching upon. \nPotentially the largest harm right now is related to the trait of high attachment anxiety—basically jealous, needy AI companions. I can understand the desire to make a wide range of different characters—including possessive ones—but I think this is one of the easier issues to fix. When people see this trait in AI companions, I hope they will be quick to call it out as an immoral thing to put in front of people, something that’s going to discourage them from interacting with others. \nAdditionally, if an AI comes with limited ability to interact with groups of people, that itself can push its users to interact with people less. If you have a human friend, in general there’s nothing stopping you from having a group interaction. But if your AI companion can’t understand when multiple people are talking to it and it can’t remember different things about different people, then you’ll likely avoid group interaction with your AI companion. To some degree it’s more of a technical challenge outside of the core behavioral AI. But this capability is something I think should be really prioritized if we’re going to try to avoid AI companions competing with human relationships.",
        "pubDate": "Wed, 11 Feb 2026 14:30:02 +0000",
        "isoDate": "2026-02-11T14:30:02.000Z",
        "creator": "Gwendolyn Rak",
        "source": "https://spectrum.ieee.org/ai-companion-harm-benefit"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-rbwpx8",
        "title": "How Do You Define an AI Companion?",
        "link": "https://spectrum.ieee.org/ai-companion-relationships",
        "url": "https://spectrum.ieee.org/ai-companion-relationships",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/two-students-carefully-watch-professor-jaime-banks-as-she-inspects-the-hand-of-a-humanoid-robot-in-a-lab.jpg?id=64070432&width=1245&height=700&coordinates=0%2C469%2C0%2C469\"/><br/><br/><p><span><em>For a different perspective on AI companions, see our Q&A with Brad Knox: <a href=\"https://spectrum.ieee.org/ai-companion-harm-benefit\" target=\"_blank\">How Can AI Companions Be Helpful, not Harmful?</a></em></span></p><p><span>AI models intended to provide companionship for humans are on the rise. People are already frequently developing relationships with chatbots, seeking not just a personal assistant but a source of </span><a href=\"https://spectrum.ieee.org/woebot\" target=\"_blank\">emotional support</a><span>.</span></p><p>In response, apps dedicated to providing companionship (such as Character.ai or Replika) have recently grown to host millions of users. Some companies are now putting AI into <a href=\"https://spectrum.ieee.org/ai-barbie-dolls\" target=\"_blank\">toys</a> and desktop devices as well, bringing digital companions into the physical world. <span>Many of these devices were on display at <a href=\"https://spectrum.ieee.org/ces-2026-preview\" target=\"_blank\">CES last month</a>, including products designed specifically for <a href=\"https://ling.ai/\" target=\"_blank\">children</a>, <a href=\"http://lemmy.co.kr/\" target=\"_blank\">seniors</a>, and even <a href=\"https://www.tuya.com/news-details/tuya-smart-launches-aura-an-ai-companion-robot-designed-for-pets-Kf9m2gpnsxudc\" target=\"_blank\">your pets</a>. </span></p><p>AI companions are designed to simulate human relationships by interacting with users like a friend would. But human-AI relationships are not well understood, and companies are facing concern about whether the benefits outweigh the risks and <a href=\"https://dl.acm.org/doi/full/10.1145/3706598.3713429\" target=\"_blank\">potential harm</a> of these relationships, especially <a href=\"https://news.stanford.edu/stories/2025/08/ai-companions-chatbots-teens-young-people-risks-dangers-study\" target=\"_blank\">for young people</a>. In addition to questions about users’ mental health and emotional well being, sharing intimate personal information with a chatbot poses data privacy issues.</p><p class=\"ieee-inbody-related\">RELATED: <a href=\"https://spectrum.ieee.org/ai-companion-harm-benefit\" target=\"_blank\">How Can AI Companions Be Helpful, not Harmful?</a></p><p>Nevertheless, more and more users are finding value in sharing their lives with AI. So how can we understand the bonds that form between humans and chatbots? </p><p><a href=\"https://ischool.syracuse.edu/jaime-banks/#Biography\" target=\"_blank\">Jaime Banks</a> is a professor at the Syracuse University School of Information Studies who researches the interactions between people and technology—in particular, robots and AI. Banks spoke with <em><em>IEEE Spectrum</em></em> about how people perceive and relate to machines, and the emerging relationships between humans and their machine companions.</p><h2>Defining AI Companionship</h2><p><strong>How do you define AI companionship? </strong></p><p><strong>Jaime Banks</strong>: My definition is evolving as we learn more about these relationships. For now, <a href=\"https://arxiv.org/abs/2506.18119\" target=\"_blank\">I define it</a> as a connection between a human and a machine that is dyadic, so there’s an exchange between them. It is also sustained over time; a one-off interaction doesn’t count as a relationship. <span>It’s <a href=\"https://en.wikipedia.org/wiki/Valence_(psychology)\" target=\"_blank\">positively valenced</a>—w</span>e like being in it. And it is autotelic, meaning we do it for its own sake. So there’s not some extrinsic motivation, it’s not defined by an ability to help us do our jobs or make us money. </p><p>I have recently been challenged by that definition, though, when I was developing an instrument to measure machine companionship. After developing the scale and working to initially validate it, I saw an interesting situation where some people do move toward this autotelic relationship pattern. “I appreciate my AI for what it is and I love it and I don’t want to change it.” It fit all those parts of the definition. But then there seems to be this <em>other</em> relational template that can actually be both appreciating the AI for its own sake, but also engaging it for utilitarian purposes.</p><p>That makes sense when we think about how people come to be in relationships with AI companions. They often don’t go into it purposefully seeking companionship. A lot of people go into using, for instance, ChatGPT for some other purpose and end up finding companionship through the course of those conversations. And we have these AI companion apps like <a href=\"https://replika.com/\" target=\"_blank\">Replika</a> and <a href=\"https://nomi.ai/\" target=\"_blank\">Nomi</a> and <a href=\"https://www.paradot.ai/\" target=\"_blank\">Paradot</a> that are designed for social interaction. But that’s not to say that they couldn’t help you with practical topics. </p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"Professor Jaime Banks programming the motions of a humanoid robot on a desktop computer.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"0fd19435b56259f13ae078eeee755fec\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"33630\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/professor-jaime-banks-programming-the-motions-of-a-humanoid-robot-on-a-desktop-computer.jpg?id=64070453&width=980\"/> <small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Jaime Banks customizes the software for an embodied AI social humanoid robot.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Angela Ryan/Syracuse University</small></p><p><strong>Different models are also programmed to have different</strong><strong> “personalities.” How does that contribute to the relationship between humans and AI companions?</strong></p><p><strong>Banks</strong>: One of our Ph.D. students just finished <a href=\"https://arxiv.org/abs/2602.00773\" target=\"_blank\">a project</a> about what happened when <a href=\"https://gizmodo.com/it-took-just-24-hours-of-complaints-for-openai-to-start-bringing-back-its-old-model-2000640912\" target=\"_blank\">OpenAI demoted GPT-4o</a> and the problems that people encountered, in terms of companionship experiences when the personality of their AI just completely changed. It didn’t have the same depth. It couldn’t remember things in the same way. </p><p>That echoes what we saw a couple years ago with Replika. Because of legal problems, Replika disabled for a period of time the erotic roleplay module and people described their companions as though they had been lobotomized, that they had this relationship and then one day they didn’t anymore. With my project on <a href=\"https://journals.sagepub.com/doi/10.1177/02654075241269688\" target=\"_blank\">the tanking of the soulmate app</a>, many people in their reflection were like, “I’m never trusting AI companies again. I’m only going to have an AI companion if I can run it from my computer so I know that it will always be there.” </p><h2>Benefits and Risks of AI Relationships</h2><p><strong>What are the benefits and risks of these relationships?</strong></p><p><strong>Banks</strong>: There’s a lot of talk about the risks and a little talk about benefits. But frankly, we are only just on the precipice of starting to have longitudinal data that might allow people to make causal claims. The headlines would have you believe that these are the end of mankind, that they’re going to make you <a href=\"https://apnews.com/article/chatbot-ai-lawsuit-suicide-teen-artificial-intelligence-9d48adc572100822fdbc3c90d1456bd0\" target=\"_blank\">commit suicide</a> or abandon other humans. But much of those are based on these unfortunate, but uncommon situations. </p><p>Most scholars gave up technological determinism as a perspective a long time ago. In the communication sciences at least, we don’t generally assume that machines <em>make</em> us do something <span>because we have some degree of agency in our interactions with technologies. Yet much of the fretting around potential risks is deterministic—AI companions make people delusional, make them suicidal, make them reject other relationships</span>. A large number of people get real benefits from AI companions. They narrate experiences that are deeply meaningful to them. I think it’s irresponsible of us to discount those lived experiences. </p><p>When we think about concerns linking AI companions to loneliness, we don’t have much data that can support causal claims. <span>Some studies suggest AI companions lead to loneliness, but other work suggests it reduces loneliness, and other work suggests </span>that loneliness is what comes first. Social relatedness is one of our <a href=\"https://doi.org/10.1207/S15327965PLI1104_01\" target=\"_blank\">three intrinsic psychological needs</a>, and if we don’t have that we will seek it out, whether it’s from <a href=\"https://www.wilson.com/en-gb/blog/volleyball/true-story-wilson-volleyball\" target=\"_blank\">a volleyball for a castaway</a>, my dog, or an AI that will allow me to feel connected to something in my world.</p><p>Some people, and <a href=\"https://www.nysenate.gov/legislation/bills/2025/A6767\" target=\"_blank\">governments</a> for that matter, may move toward a protective stance. For instance, there are problems around what gets done with your intimate data that you hand over to an agent owned and maintained by a company—that’s a very reasonable concern. Dealing with the potential for children to interact, where children don’t always navigate the boundaries between fiction and actuality. There are real, valid concerns. <span>However, </span><span>we need some</span><span> balance in also thinking about what</span><span> people are </span><span>getting from it that’s positive, productive, healthy. </span><span>Scholars need to make sure we’re being cautious about our claims based on our data. And human interactants need to educate themselves. </span></p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"Close-up of Professor Jaime Banks aligning her fingers and palm with the hand of a humanoid robot.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"5214671bfd141ebad3bb02e93f14f00a\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"bab58\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/close-up-of-professor-jaime-banks-aligning-her-fingers-and-palm-with-the-hand-of-a-humanoid-robot.jpg?id=64070474&width=980\"/> <small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Jaime Banks holds a mechanical hand.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Angela Ryan/Syracuse University</small></p><p><strong>Why do you think that AI companions are becoming more popular now?</strong></p><p><strong>Banks</strong>: I feel like we had this perfect storm, if you will, of the maturation of large language models and coming out of COVID, where people had been physically and sometimes socially isolated for quite some time. When those conditions converged, we had on our hands a believable social agent at a time when people were seeking social connection. Outside of that, we are increasingly just not nice to one another. So, it’s not entirely surprising that if I just don’t like the people around me, or I feel disconnected, that I would try to find some other outlet for feeling connected.</p><p><strong>M</strong><strong>ore recently there’s been a shift to embodied companions, in desktop devices or other formats beyond chatbots. How does that change the relationship, if it does?</strong></p><p><strong>Banks</strong>: I’m part of a Facebook group about robotic companions and I watch how people talk, and it almost seems like it crosses this boundary between toy and companion. When you have a companion with a physical body, you are in some ways limited by the abilities of that body, whereas with digital-only AI, you have the ability to explore fantastic things—places that you would never be able to go with another physical entity, fantasy scenarios.</p><p>But in robotics, once we get into a space where there are bodies that are sophisticated, they become very expensive and that means that they are not accessible to a lot of people. That’s what I’m observing in many of these online groups. These toylike bodies are still accessible, but they are also quite limiting. </p><p><strong>Do you have any favorite examples from popular culture to help explain AI companionship, either how it is now or how it could be?</strong></p><p><strong>Banks</strong>: <span>I really enjoy a lot of the short fiction in <a href=\"https://clarkesworldmagazine.com/\" target=\"_blank\">Clarkesworld</a> magazine, because the stories push me to think about what questions we might need to answer now to be prepared for a future hybrid society. Top of mind are the stories “<a href=\"https://clarkesworldmagazine.com/ritterhoff_03_22/\" target=\"_blank\">Wanting Things</a>,” “<a href=\"https://strangehorizons.com/wordpress/fiction/seven-sexy-cowboy-robots/\" target=\"_blank\">Seven Sexy Cowboy Robots</a>,” and “<a href=\"https://clarkesworldmagazine.com/shoemaker_08_15/\" target=\"_blank\">Today I am Paul</a>.” </span><span>Outside of that, I’ll point to the game </span><em>Cyberpunk 2077</em>, because t<span>he character Johnny Silverhand </span><span>complicates the norms for what counts as a machine and what counts as companionship.</span></p>",
        "contentSnippet": "For a different perspective on AI companions, see our Q&A with Brad Knox: How Can AI Companions Be Helpful, not Harmful?\nAI models intended to provide companionship for humans are on the rise. People are already frequently developing relationships with chatbots, seeking not just a personal assistant but a source of emotional support.\nIn response, apps dedicated to providing companionship (such as Character.ai or Replika) have recently grown to host millions of users. Some companies are now putting AI into toys and desktop devices as well, bringing digital companions into the physical world. Many of these devices were on display at CES last month, including products designed specifically for children, seniors, and even your pets. \nAI companions are designed to simulate human relationships by interacting with users like a friend would. But human-AI relationships are not well understood, and companies are facing concern about whether the benefits outweigh the risks and potential harm of these relationships, especially for young people. In addition to questions about users’ mental health and emotional well being, sharing intimate personal information with a chatbot poses data privacy issues.\nRELATED: How Can AI Companions Be Helpful, not Harmful?\nNevertheless, more and more users are finding value in sharing their lives with AI. So how can we understand the bonds that form between humans and chatbots? \nJaime Banks is a professor at the Syracuse University School of Information Studies who researches the interactions between people and technology—in particular, robots and AI. Banks spoke with IEEE Spectrum about how people perceive and relate to machines, and the emerging relationships between humans and their machine companions.\nDefining AI Companionship\nHow do you define AI companionship? \nJaime Banks: My definition is evolving as we learn more about these relationships. For now, I define it as a connection between a human and a machine that is dyadic, so there’s an exchange between them. It is also sustained over time; a one-off interaction doesn’t count as a relationship. It’s positively valenced—we like being in it. And it is autotelic, meaning we do it for its own sake. So there’s not some extrinsic motivation, it’s not defined by an ability to help us do our jobs or make us money. \nI have recently been challenged by that definition, though, when I was developing an instrument to measure machine companionship. After developing the scale and working to initially validate it, I saw an interesting situation where some people do move toward this autotelic relationship pattern. “I appreciate my AI for what it is and I love it and I don’t want to change it.” It fit all those parts of the definition. But then there seems to be this other relational template that can actually be both appreciating the AI for its own sake, but also engaging it for utilitarian purposes.\nThat makes sense when we think about how people come to be in relationships with AI companions. They often don’t go into it purposefully seeking companionship. A lot of people go into using, for instance, ChatGPT for some other purpose and end up finding companionship through the course of those conversations. And we have these AI companion apps like Replika and Nomi and Paradot that are designed for social interaction. But that’s not to say that they couldn’t help you with practical topics. \n  Jaime Banks customizes the software for an embodied AI social humanoid robot.Angela Ryan/Syracuse University\nDifferent models are also programmed to have different “personalities.” How does that contribute to the relationship between humans and AI companions?\nBanks: One of our Ph.D. students just finished a project about what happened when OpenAI demoted GPT-4o and the problems that people encountered, in terms of companionship experiences when the personality of their AI just completely changed. It didn’t have the same depth. It couldn’t remember things in the same way. \nThat echoes what we saw a couple years ago with Replika. Because of legal problems, Replika disabled for a period of time the erotic roleplay module and people described their companions as though they had been lobotomized, that they had this relationship and then one day they didn’t anymore. With my project on the tanking of the soulmate app, many people in their reflection were like, “I’m never trusting AI companies again. I’m only going to have an AI companion if I can run it from my computer so I know that it will always be there.” \nBenefits and Risks of AI Relationships\nWhat are the benefits and risks of these relationships?\nBanks: There’s a lot of talk about the risks and a little talk about benefits. But frankly, we are only just on the precipice of starting to have longitudinal data that might allow people to make causal claims. The headlines would have you believe that these are the end of mankind, that they’re going to make you commit suicide or abandon other humans. But much of those are based on these unfortunate, but uncommon situations. \nMost scholars gave up technological determinism as a perspective a long time ago. In the communication sciences at least, we don’t generally assume that machines make us do something because we have some degree of agency in our interactions with technologies. Yet much of the fretting around potential risks is deterministic—AI companions make people delusional, make them suicidal, make them reject other relationships. A large number of people get real benefits from AI companions. They narrate experiences that are deeply meaningful to them. I think it’s irresponsible of us to discount those lived experiences. \nWhen we think about concerns linking AI companions to loneliness, we don’t have much data that can support causal claims. Some studies suggest AI companions lead to loneliness, but other work suggests it reduces loneliness, and other work suggests that loneliness is what comes first. Social relatedness is one of our three intrinsic psychological needs, and if we don’t have that we will seek it out, whether it’s from a volleyball for a castaway, my dog, or an AI that will allow me to feel connected to something in my world.\nSome people, and governments for that matter, may move toward a protective stance. For instance, there are problems around what gets done with your intimate data that you hand over to an agent owned and maintained by a company—that’s a very reasonable concern. Dealing with the potential for children to interact, where children don’t always navigate the boundaries between fiction and actuality. There are real, valid concerns. However, we need some balance in also thinking about what people are getting from it that’s positive, productive, healthy. Scholars need to make sure we’re being cautious about our claims based on our data. And human interactants need to educate themselves. \n  Jaime Banks holds a mechanical hand.Angela Ryan/Syracuse University\nWhy do you think that AI companions are becoming more popular now?\nBanks: I feel like we had this perfect storm, if you will, of the maturation of large language models and coming out of COVID, where people had been physically and sometimes socially isolated for quite some time. When those conditions converged, we had on our hands a believable social agent at a time when people were seeking social connection. Outside of that, we are increasingly just not nice to one another. So, it’s not entirely surprising that if I just don’t like the people around me, or I feel disconnected, that I would try to find some other outlet for feeling connected.\nMore recently there’s been a shift to embodied companions, in desktop devices or other formats beyond chatbots. How does that change the relationship, if it does?\nBanks: I’m part of a Facebook group about robotic companions and I watch how people talk, and it almost seems like it crosses this boundary between toy and companion. When you have a companion with a physical body, you are in some ways limited by the abilities of that body, whereas with digital-only AI, you have the ability to explore fantastic things—places that you would never be able to go with another physical entity, fantasy scenarios.\nBut in robotics, once we get into a space where there are bodies that are sophisticated, they become very expensive and that means that they are not accessible to a lot of people. That’s what I’m observing in many of these online groups. These toylike bodies are still accessible, but they are also quite limiting. \nDo you have any favorite examples from popular culture to help explain AI companionship, either how it is now or how it could be?\nBanks: I really enjoy a lot of the short fiction in Clarkesworld magazine, because the stories push me to think about what questions we might need to answer now to be prepared for a future hybrid society. Top of mind are the stories “Wanting Things,” “Seven Sexy Cowboy Robots,” and “Today I am Paul.” Outside of that, I’ll point to the game Cyberpunk 2077, because the character Johnny Silverhand complicates the norms for what counts as a machine and what counts as companionship.",
        "pubDate": "Wed, 11 Feb 2026 14:00:02 +0000",
        "isoDate": "2026-02-11T14:00:02.000Z",
        "creator": "Gwendolyn Rak",
        "source": "https://spectrum.ieee.org/ai-companion-relationships"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-mpyuzd",
        "title": "How and When the Memory Chip Shortage Will End",
        "link": "https://spectrum.ieee.org/dram-shortage",
        "url": "https://spectrum.ieee.org/dram-shortage",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/sk-hynix-inc-s-12-layer-hbm4-memory-chips-on-display.jpg?id=63918122&width=1245&height=700&coordinates=0%2C187%2C0%2C188\"/><br/><br/><p><span>If it feels these days as if everything in technology is about AI, that’s because it is. And nowhere is that more true than in the market for computer memory. Demand, and profitability, for the type of DRAM used to feed GPUs and other accelerators in AI data centers is so huge that it’s diverting away supply of memory for other uses and causing prices to skyrocket. According to <a href=\"https://counterpointresearch.com/en/insights/Memory-Prices-Surge-Up-to-90-From-Q4-2025\" target=\"_blank\">Counterpoint Research</a>, DRAM prices have risen 80-90 precent so far this quarter.</span></p><p>The largest AI hardware companies say they have secured their chips out as far as 2028, but that leaves everybody else—makers of PCs, consumer gizmos, and everything else that needs to temporarily store a billion bits—scrambling to deal with scarce supply and inflated prices.</p><p>How did the electronics industry get into this mess, and more importantly, how will it get out? <em><em>IEEE Spectrum</em></em> asked economists and memory experts to explain. They say today’s situation is the result of a collision between the DRAM industry’s historic boom and bust cycle and an AI hardware infrastructure build-out that’s without precedent in its scale. And, barring some major collapse in the AI sector, it will take years for new capacity and new technology to bring supply in line with demand. Prices might stay high even then.</p><p>To understand both ends of the tale, you need to know the main culprit in the supply and demand swing, high-bandwidth memory, or HBM.</p><h2>What is HBM?</h2><p>HBM is the DRAM industry’s attempt to short-circuit the slowing pace of Moore’s Law by using 3D chip packaging technology. Each HBM chip is made up of as many as 12 thinned-down DRAM chips called dies. Each die contains a number of vertical connections called through silicon vias (TSVs). The dies are piled atop each other and connected by arrays of microscopic solder balls aligned to the TSVs. This DRAM tower—well, at about 750 micrometers thick, it’s more of a brutalist office-block than a tower—is then stacked atop what’s called the base die, which shuttles bits between the memory dies and the processor.</p><p>This complex piece of technology is then set within a millimeter of a GPU or other AI accelerator, to which it is linked by as many as 2,048 micrometer-scale connections. HBMs are attached on two sides of the processor, and the GPU and memory are packaged together as a single unit.</p><p>The idea behind such a tight, highly-connected squeeze with the GPU is to knock down what’s called <a href=\"https://spectrum.ieee.org/ai-and-memory-wall\" target=\"_self\">the memory wall</a>. That’s the barrier in energy and time of bringing the terabytes per second of data needed to run large language models into the GPU. <a href=\"https://spectrum.ieee.org/ai-models-locally\" target=\"_self\">Memory bandwidth</a> is a key limiter to how fast LLMs can run.</p><p>As a technology, HBM has been around for <a href=\"https://spectrum.ieee.org/chipmakers-push-memory-into-the-third-dimension\" target=\"_self\">more than 10 years</a>, and DRAM makers have been busy boosting its capability.</p><div class=\"flourish-embed flourish-chart\" data-src=\"visualisation/27466742?1509099\"><script src=\"https://public.flourish.studio/resources/embed.js\"></script><noscript><img alt=\"chart visualization\" src=\"https://public.flourish.studio/visualisation/27466742/thumbnail\" width=\"100%\"/></noscript></div><p>As the size of AI models has grown, so has HBM’s importance to the GPU. But that’s come at a cost. <a href=\"https://newsletter.semianalysis.com/p/scaling-the-memory-wall-the-rise-and-roadmap-of-hbm\" target=\"_blank\">SemiAnalysis estimates</a><strong> </strong>that HBM generally costs three times as much as other types of memory and constitutes 50 percent or more of the cost of the packaged GPU.</p><h2>Origins of the memory chip shortage</h2><p>Memory and storage industry watchers agree that DRAM is a highly cyclical industry with huge booms and devastating busts. With new fabs costing US $15 billion or more, firms are extremely reluctant to expand and may only have the cash to do so during boom times, explains <a href=\"https://www.linkedin.com/in/thomas-coughlin-41a65/\" target=\"_blank\">Thomas Coughlin</a>, a storage and memory expert and president of <a href=\"https://tomcoughlin.com/\" target=\"_blank\">Coughlin Associates</a>. But building such a fab and getting it up and running can take 18 months or more, practically ensuring that new capacity arrives well past the initial surge in demand, flooding the market and depressing prices.</p><p>The origins of today’s cycle, says Coughlin, go all the way back to the <a href=\"https://spectrum.ieee.org/chip-shortage\" target=\"_self\">chip supply panic surrounding the COVID-19 pandemic</a> . To avoid supply-chain stumbles and support the rapid shift to remote work, hyperscalers—data center giants like Amazon, Google, and Microsoft—bought up huge inventories of memory and storage, boosting prices, he notes.</p><p>But then supply became more regular and data center expansion fell off in 2022, causing memory and storage prices to plummet. This recession continued into 2023, and even resulted in big memory and storage companies such as Samsung cutting production by 50 percent to try and keep prices from going below the costs of manufacturing, says Coughlin. It was a rare and fairly desperate move, because companies typically have to run plants at full capacity just to earn back their value.<span></span></p><p>After a recovery began in late 2023, “all the memory and storage companies were very wary of increasing their production capacity again,” says Coughlin. “Thus there was little or no investment in new production capacity in 2024 and through most of 2025.”</p><div class=\"flourish-embed flourish-chart\" data-src=\"visualisation/27468004?1509099\"><script src=\"https://public.flourish.studio/resources/embed.js\"></script><noscript><img alt=\"chart visualization\" src=\"https://public.flourish.studio/visualisation/27468004/thumbnail\" width=\"100%\"/></noscript></div><h2>The AI data center boom</h2><p>That lack of new investment is colliding headlong with a huge boost in demand from new data centers. Globally, there are <a href=\"https://spectrum.ieee.org/data-center-growth\" target=\"_self\">nearly 2,000 new data centers</a> either planned or under construction right now, according to Data Center Map. If they’re all built, it would represent a 20 percent jump in the global supply, which stands at around 9,000 facilities now.</p><p>If the current build-out continues at pace, McKinsey predicts companies will spend <a href=\"https://programs.com/resources/data-center-statistics/\" target=\"_blank\">$7 trillion by 2030</a>, with the bulk of that—$5.2 trillion—going to AI-focused data centers. Of that chunk, $3.3 billion will go toward servers, data storage, and network equipment, the firm predicts.</p><p>The biggest beneficiary so far of the AI data center boom is unquestionably GPU-maker Nvidia. Revenue for its data center business went from <a href=\"https://ycharts.com/indicators/nvidia_corp_nvda_data_center_revenue_quarterly\" target=\"_blank\">barely a billion in the final quarter of 2019 to $51 billion in the quarter that ended in October 2025</a>. Over this period, its server GPUs have demanded not just more and more gigabytes of DRAM but an increasing number of DRAM chips. The recently released B300 uses eight HBM chips, each of which is a stack of 12 DRAM dies. Competitors’ use of HBM has largely mirrored Nvidia’s. AMD’s MI350 GPU, for example, also uses eight, 12-die chips.</p><div class=\"flourish-embed flourish-chart\" data-src=\"visualisation/27459660?1509099\"><script src=\"https://public.flourish.studio/resources/embed.js\"></script><noscript><img alt=\"chart visualization\" src=\"https://public.flourish.studio/visualisation/27459660/thumbnail\" width=\"100%\"/></noscript></div><p>With so much demand, an increasing fraction of the revenue for DRAM makers comes from HBM. Micron—the number three producer behind SK Hynix and Samsung—reported that <a href=\"https://investors.micron.com/static-files/8791eb80-8263-4c6f-aa74-fdd03fbbb027\" target=\"_blank\">HBM and other cloud-related memory</a> went from being 17 percent of its DRAM revenue in 2023 to nearly 50 percent in 2025.</p><p>Micron predicts the total market for HBM will grow from $35 billion in 2025 to $100 billion by 2028—a figure larger than the entire DRAM market in 2024, CEO <a href=\"https://www.linkedin.com/in/sanjay-mehrotra/\" target=\"_blank\">Sanjay Mehrotra</a> <a href=\"https://investors.micron.com/static-files/088991c5-a249-4f66-a0a6-258d9b66f3f9\" target=\"_blank\">told analysts in December</a>. It’s reaching that figure two years earlier than Micron had previously expected. Across the industry, demand will outstrip supply “substantially… for the foreseeable future,” he said.</p><div class=\"flourish-embed flourish-chart\" data-src=\"visualisation/27481588?1509099\"><script src=\"https://public.flourish.studio/resources/embed.js\"></script><noscript><img alt=\"chart visualization\" src=\"https://public.flourish.studio/visualisation/27481588/thumbnail\" width=\"100%\"/></noscript></div><h2>Future DRAM supply and technology</h2><p>“There are two ways to address supply issues with DRAM: with innovation or with building more fabs,” explains <a href=\"https://www.linkedin.com/in/mina-kim-37449b/\" target=\"_blank\">Mina Kim</a>, an economist with the Mkecon Insights. “As <a href=\"https://spectrum.ieee.org/micron-dram\" target=\"_self\">DRAM scaling</a> has become more difficult, the industry has turned to advanced packaging… which is just using more DRAM.”</p><p>Micron, Samsung, and SK Hynix combined make up the vast majority of the memory and storage markets, and all three have new fabs and facilities in the works. However, these are unlikely to contribute meaningfully to bringing down prices.</p><p><strong>Micron</strong> is in the process of <a href=\"https://investors.micron.com/news-releases/news-release-details/micron-breaks-ground-advanced-wafer-fabrication-facility\" target=\"_blank\">building an HBM fab</a> in Singapore that should be in production in 2027. And it is <a href=\"https://investors.micron.com/news-releases/news-release-details/micron-signs-letter-intent-purchase-tongluo-site-begin-0\" target=\"_blank\">retooling a fab</a> it purchased from PSMC in Taiwan that will begin production in the second half of 2027. Last month, Micron <a href=\"https://investors.micron.com/news-releases/news-release-details/micron-celebrates-official-groundbreaking-new-york-megafab-site\" target=\"_blank\">broke ground</a> on what will be a DRAM fab complex in Onondaga County, N.Y. It will not be in full production until 2030.</p><p><strong>Samsung</strong> plans to <a href=\"https://www.chosun.com/english/industry-en/2025/11/16/U5VKNZCSYBCONMRCXDZ45MCIXQ/\" target=\"_blank\">start producing</a> at a new plant in Pyeongtaek, South Korea in 2028.</p><p><strong>SK Hynix</strong> is building <a href=\"https://www.skhynix.com/westlafayette.IN/\" rel=\"noopener noreferrer\" target=\"_blank\">HBM and packaging</a> facilities in West Lafayette, Indiana set to begin production by the end of 2028, and an HBM fab it’s <a href=\"https://www.cnbc.com/2026/01/13/sk-hynix-invest-13-billion-new-fab-memory-chip-shortage-advanced-packaging-ai-memory.html\" rel=\"noopener noreferrer\" target=\"_blank\">building in Cheongju</a> should be complete in 2027.</p><p>Speaking of his sense of the DRAM market, <a href=\"https://newsroom.intel.com/biography/lip-bu-tan\" rel=\"noopener noreferrer\" target=\"_blank\">Intel CEO Lip-Bu Tan</a><strong> </strong>told attendees at the <a href=\"https://newsroom.cisco.com/c/r/newsroom/en/us/a/y2026/m02/ai-summit.html\" rel=\"noopener noreferrer\" target=\"_blank\">Cisco AI Summit</a> last week: “There’s no relief until 2028.”</p><p>With these expansions unable to contribute for several years, other factors will be needed to increase supply. “Relief will come from a combination of incremental capacity expansions by existing DRAM leaders, yield improvements in advanced packaging, and a broader diversification of supply chains,” says <a href=\"https://www.electronics.org/meet-shawn-dubravac-ipcs-chief-economist\" rel=\"noopener noreferrer\" target=\"_blank\">Shawn DuBravac</a> , chief economist for the <a href=\"https://www.electronics.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Global Electronics Association</a> (formerly the IPC). “New fabs will help at the margin, but the faster gains will come from process learning, better [DRAM] stacking efficiency, and tighter coordination between memory suppliers and AI chip designers.”</p><p>So, will prices come down once some of these new plants come on line? Don’t bet on it. “In general, economists find that prices come down much more slowly and reluctantly than they go up. DRAM today is unlikely to be an exception to this general observation, especially given the insatiable demand for compute,” says Kim.</p><p>In the meantime, technologies are in the works that could make HBM an even bigger consumer of silicon. The standard for HBM4 can accommodate 16 stacked DRAM dies, even though today’s chips only use 12 dies. Getting to 16 has a lot to do with the chip stacking technology. Conducting heat through the HBM “layer cake” of silicon, solder, and support material is a key limiter to going higher and in <a href=\"https://spectrum.ieee.org/hbm-on-gpu-imec-iedm\" target=\"_self\">repositioning HBM inside the package</a> to get even more bandwidth.</p><p>SK Hynix claims a heat conduction advantage through a manufacturing process called advanced <a href=\"https://news.skhynix.com/rulebreaker-revolutions-mr-muf-unlocks-hbm-heat-control/\" rel=\"noopener noreferrer\" target=\"_blank\">MR-MUF (mass reflow molded underfill)</a>. Further out, an alternative chip stacking technology called <a href=\"https://spectrum.ieee.org/hybrid-bonding\" target=\"_self\">hybrid bonding</a> could help heat conduction by reducing the die-to-die vertical distance essentially to zero. In 2024, researchers at Samsung proved they could produce a 16-high stack with hybrid bonding, and they suggested that <a href=\"https://spectrum.ieee.org/hybrid-bonding\" target=\"_self\">20 dies was not out of reach</a>.</p>",
        "contentSnippet": "If it feels these days as if everything in technology is about AI, that’s because it is. And nowhere is that more true than in the market for computer memory. Demand, and profitability, for the type of DRAM used to feed GPUs and other accelerators in AI data centers is so huge that it’s diverting away supply of memory for other uses and causing prices to skyrocket. According to Counterpoint Research, DRAM prices have risen 80-90 precent so far this quarter.\nThe largest AI hardware companies say they have secured their chips out as far as 2028, but that leaves everybody else—makers of PCs, consumer gizmos, and everything else that needs to temporarily store a billion bits—scrambling to deal with scarce supply and inflated prices.\nHow did the electronics industry get into this mess, and more importantly, how will it get out? IEEE Spectrum asked economists and memory experts to explain. They say today’s situation is the result of a collision between the DRAM industry’s historic boom and bust cycle and an AI hardware infrastructure build-out that’s without precedent in its scale. And, barring some major collapse in the AI sector, it will take years for new capacity and new technology to bring supply in line with demand. Prices might stay high even then.\nTo understand both ends of the tale, you need to know the main culprit in the supply and demand swing, high-bandwidth memory, or HBM.\nWhat is HBM?\nHBM is the DRAM industry’s attempt to short-circuit the slowing pace of Moore’s Law by using 3D chip packaging technology. Each HBM chip is made up of as many as 12 thinned-down DRAM chips called dies. Each die contains a number of vertical connections called through silicon vias (TSVs). The dies are piled atop each other and connected by arrays of microscopic solder balls aligned to the TSVs. This DRAM tower—well, at about 750 micrometers thick, it’s more of a brutalist office-block than a tower—is then stacked atop what’s called the base die, which shuttles bits between the memory dies and the processor.\nThis complex piece of technology is then set within a millimeter of a GPU or other AI accelerator, to which it is linked by as many as 2,048 micrometer-scale connections. HBMs are attached on two sides of the processor, and the GPU and memory are packaged together as a single unit.\nThe idea behind such a tight, highly-connected squeeze with the GPU is to knock down what’s called the memory wall. That’s the barrier in energy and time of bringing the terabytes per second of data needed to run large language models into the GPU. Memory bandwidth is a key limiter to how fast LLMs can run.\nAs a technology, HBM has been around for more than 10 years, and DRAM makers have been busy boosting its capability.\n\nAs the size of AI models has grown, so has HBM’s importance to the GPU. But that’s come at a cost. SemiAnalysis estimates that HBM generally costs three times as much as other types of memory and constitutes 50 percent or more of the cost of the packaged GPU.\nOrigins of the memory chip shortage\nMemory and storage industry watchers agree that DRAM is a highly cyclical industry with huge booms and devastating busts. With new fabs costing US $15 billion or more, firms are extremely reluctant to expand and may only have the cash to do so during boom times, explains Thomas Coughlin, a storage and memory expert and president of Coughlin Associates. But building such a fab and getting it up and running can take 18 months or more, practically ensuring that new capacity arrives well past the initial surge in demand, flooding the market and depressing prices.\nThe origins of today’s cycle, says Coughlin, go all the way back to the chip supply panic surrounding the COVID-19 pandemic . To avoid supply-chain stumbles and support the rapid shift to remote work, hyperscalers—data center giants like Amazon, Google, and Microsoft—bought up huge inventories of memory and storage, boosting prices, he notes.\nBut then supply became more regular and data center expansion fell off in 2022, causing memory and storage prices to plummet. This recession continued into 2023, and even resulted in big memory and storage companies such as Samsung cutting production by 50 percent to try and keep prices from going below the costs of manufacturing, says Coughlin. It was a rare and fairly desperate move, because companies typically have to run plants at full capacity just to earn back their value.\nAfter a recovery began in late 2023, “all the memory and storage companies were very wary of increasing their production capacity again,” says Coughlin. “Thus there was little or no investment in new production capacity in 2024 and through most of 2025.”\n\nThe AI data center boom\nThat lack of new investment is colliding headlong with a huge boost in demand from new data centers. Globally, there are nearly 2,000 new data centers either planned or under construction right now, according to Data Center Map. If they’re all built, it would represent a 20 percent jump in the global supply, which stands at around 9,000 facilities now.\nIf the current build-out continues at pace, McKinsey predicts companies will spend $7 trillion by 2030, with the bulk of that—$5.2 trillion—going to AI-focused data centers. Of that chunk, $3.3 billion will go toward servers, data storage, and network equipment, the firm predicts.\nThe biggest beneficiary so far of the AI data center boom is unquestionably GPU-maker Nvidia. Revenue for its data center business went from barely a billion in the final quarter of 2019 to $51 billion in the quarter that ended in October 2025. Over this period, its server GPUs have demanded not just more and more gigabytes of DRAM but an increasing number of DRAM chips. The recently released B300 uses eight HBM chips, each of which is a stack of 12 DRAM dies. Competitors’ use of HBM has largely mirrored Nvidia’s. AMD’s MI350 GPU, for example, also uses eight, 12-die chips.\n\nWith so much demand, an increasing fraction of the revenue for DRAM makers comes from HBM. Micron—the number three producer behind SK Hynix and Samsung—reported that HBM and other cloud-related memory went from being 17 percent of its DRAM revenue in 2023 to nearly 50 percent in 2025.\nMicron predicts the total market for HBM will grow from $35 billion in 2025 to $100 billion by 2028—a figure larger than the entire DRAM market in 2024, CEO Sanjay Mehrotra told analysts in December. It’s reaching that figure two years earlier than Micron had previously expected. Across the industry, demand will outstrip supply “substantially… for the foreseeable future,” he said.\n\nFuture DRAM supply and technology\n“There are two ways to address supply issues with DRAM: with innovation or with building more fabs,” explains Mina Kim, an economist with the Mkecon Insights. “As DRAM scaling has become more difficult, the industry has turned to advanced packaging… which is just using more DRAM.”\nMicron, Samsung, and SK Hynix combined make up the vast majority of the memory and storage markets, and all three have new fabs and facilities in the works. However, these are unlikely to contribute meaningfully to bringing down prices.\nMicron is in the process of building an HBM fab in Singapore that should be in production in 2027. And it is retooling a fab it purchased from PSMC in Taiwan that will begin production in the second half of 2027. Last month, Micron broke ground on what will be a DRAM fab complex in Onondaga County, N.Y. It will not be in full production until 2030.\nSamsung plans to start producing at a new plant in Pyeongtaek, South Korea in 2028.\nSK Hynix is building HBM and packaging facilities in West Lafayette, Indiana set to begin production by the end of 2028, and an HBM fab it’s building in Cheongju should be complete in 2027.\nSpeaking of his sense of the DRAM market, Intel CEO Lip-Bu Tan told attendees at the Cisco AI Summit last week: “There’s no relief until 2028.”\nWith these expansions unable to contribute for several years, other factors will be needed to increase supply. “Relief will come from a combination of incremental capacity expansions by existing DRAM leaders, yield improvements in advanced packaging, and a broader diversification of supply chains,” says Shawn DuBravac , chief economist for the Global Electronics Association (formerly the IPC). “New fabs will help at the margin, but the faster gains will come from process learning, better [DRAM] stacking efficiency, and tighter coordination between memory suppliers and AI chip designers.”\nSo, will prices come down once some of these new plants come on line? Don’t bet on it. “In general, economists find that prices come down much more slowly and reluctantly than they go up. DRAM today is unlikely to be an exception to this general observation, especially given the insatiable demand for compute,” says Kim.\nIn the meantime, technologies are in the works that could make HBM an even bigger consumer of silicon. The standard for HBM4 can accommodate 16 stacked DRAM dies, even though today’s chips only use 12 dies. Getting to 16 has a lot to do with the chip stacking technology. Conducting heat through the HBM “layer cake” of silicon, solder, and support material is a key limiter to going higher and in repositioning HBM inside the package to get even more bandwidth.\nSK Hynix claims a heat conduction advantage through a manufacturing process called advanced MR-MUF (mass reflow molded underfill). Further out, an alternative chip stacking technology called hybrid bonding could help heat conduction by reducing the die-to-die vertical distance essentially to zero. In 2024, researchers at Samsung proved they could produce a 16-high stack with hybrid bonding, and they suggested that 20 dies was not out of reach.",
        "pubDate": "Tue, 10 Feb 2026 14:00:02 +0000",
        "isoDate": "2026-02-10T14:00:02.000Z",
        "creator": "Samuel K. Moore",
        "source": "https://spectrum.ieee.org/dram-shortage"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-b9qsz2",
        "title": "IEEE Honors Global Dream Team of Innovators",
        "link": "https://spectrum.ieee.org/ieee-2026-honors",
        "url": "https://spectrum.ieee.org/ieee-2026-honors",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/a-group-of-gold-ieee-medals-on-black-background.jpg?id=26144407&width=1245&height=700&coordinates=0%2C116%2C0%2C117\"/><br/><br/><p>Meet the recipients of the 2026 IEEE Medals—the organization’s highest-level honors. Presented on behalf of the <a href=\"https://spectrum.ieee.org/tag/ieee-board-of-directors\" target=\"_self\">IEEE Board of Directors</a>, these medals recognize innovators whose work has shaped modern technology across disciplines including AI, education, and semiconductors.</p><p>The medals will be presented at the <a href=\"https://corporate-awards.ieee.org/event/laureate-forum-honors-ceremony-gala/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Honors Ceremony</a> in April in <a href=\"https://spectrum.ieee.org/tag/new-york-city\" target=\"_self\">New York City</a>. View the full list of 2026 recipients on the <a href=\"https://corporate-awards.ieee.org/recipients/current-recipients/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Awards website</a>, and follow <a href=\"https://www.linkedin.com/showcase/ieee-awards\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Awards</a> on <a href=\"https://spectrum.ieee.org/tag/linkedin\" target=\"_self\">LinkedIn</a> for news and updates.</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/ieee-medal-of-honor/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE MEDAL OF HONOR</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.ieee.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>IEEE</em></em></a></p><p><a href=\"https://spectrum.ieee.org/2026-ieee-medal-of-honor\" target=\"_self\">Jensen Huang</a></p><p><a href=\"https://www.nvidia.com/en-us/\" rel=\"noopener noreferrer\" target=\"_blank\">Nvidia</a></p><p>Santa Clara, Calif.</p><p> “For leadership in the development of graphics processing units and their application to scientific computing and artificial intelligence.”</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-frances-e-allen-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE FRANCES E. ALLEN MEDAL</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.ibm.com/us-en/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>IBM</em></em></a></p><p><a href=\"https://www.linkedin.com/in/luis-von-ahn-duolingo/\" rel=\"noopener noreferrer\" target=\"_blank\">Luis von Ahn</a></p><p><a href=\"https://www.duolingo.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Duolingo</a></p><p>Pittsburgh</p><p>“For contributions to the advancement of societal improvement and education through innovative technology.”</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-alexander-graham-bell-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE ALEXANDER GRAHAM BELL MEDAL</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.bell-labs.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Nokia Bell Labs</em></em></a><em> </em></p><p><a href=\"https://www2.eecs.berkeley.edu/Faculty/Homepages/shenker.html\" rel=\"noopener noreferrer\" target=\"_blank\">Scott Shenker</a></p><p><a href=\"https://www.berkeley.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of California, Berkeley</a></p><a href=\"https://www.icsi.berkeley.edu/\" target=\"_blank\">International Computer Science Institute </a><br/><br/><span>“For contributions to Internet architecture, network resource allocation, and software-defined networking.”</span><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-jiagadish-chandra-bose-medal/\" target=\"_blank\">IEEE JAGADISH CHANDRA BOSE MEDAL IN WIRELESS COMMUNICATIONS</a></h2><p><em><em>Sponsor: Mani L. Bhaumik</em></em></p><p>Co-recipients:<a href=\"https://www.linkedin.com/in/erik-dahlman-9964bb6/\" rel=\"noopener noreferrer\" target=\"_blank\"> <br/>Erik Dahlman</a><a href=\"https://www.linkedin.com/in/stefan-parkvall-290a576/\" rel=\"noopener noreferrer\" target=\"_blank\"> <br/>Stefan Parkvall<br/></a><a href=\"https://www.linkedin.com/in/johan-skold-0393325/\" rel=\"noopener noreferrer\" target=\"_blank\">Johan Sköld </a></p><p><a href=\"https://www.ericsson.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Ericsson</a></p><p>Stockholm</p><p>“For contributions to and leadership in the research, development, and standardization of cellular wireless communications.”</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-mildred-dresselhaus-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE MILDRED DRESSELHAUS MEDAL</a></h2><p><em><em>Sponsor:</em></em><a href=\"https://about.google/\" rel=\"noopener noreferrer\" target=\"_blank\"><em> </em><em><em>Google</em></em></a></p><p><a href=\"https://engineering.tufts.edu/me/people/faculty/karen-panetta\" rel=\"noopener noreferrer\" target=\"_blank\">Karen Ann Panetta</a></p><p><a href=\"https://engineering.tufts.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Tufts University</a></p><p>Medford, Mass.</p><p>“For contributions to computer vision and simulation algorithms, and for leadership in developing programs to promote STEM careers.”</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-edison-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE EDISON MEDAL</a></h2><p><em><em>Sponsor:</em></em><em> </em><em><em>IEEE Edison Medal Fund</em></em></p><p><a href=\"https://www.linkedin.com/in/eric-swanson-93485614/\" rel=\"noopener noreferrer\" target=\"_blank\">Eric Swanson<br/><br/></a><a href=\"https://www.pixcel.com/\" rel=\"noopener noreferrer\" target=\"_blank\">PIXCEL Inc.<br/><br/></a><a href=\"https://www.mit.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">MIT</a></p><p>“For pioneering contributions to biomedical imaging, terrestrial optical communications and networking, and inter-satellite optical links.”</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-medal-for-environmental-and-safety-technologies/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE MEDAL FOR ENVIRONMENTAL AND SAFETY TECHNOLOGIES</a></h2><p><em><em>Sponsor:</em></em><a href=\"https://global.toyota/en/\" rel=\"noopener noreferrer\" target=\"_blank\"><em> </em><em><em>Toyota Motor Corp</em></em></a><em><em>.</em></em></p><p><a href=\"https://www.uta.edu/academics/faculty/profile?user=wlee\" rel=\"noopener noreferrer\" target=\"_blank\">Wei-Jen Lee</a></p><p><a href=\"https://www.uta.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of Texas at Arlington</a></p><p>“For contributions to advancing electrical safety in the workplace, integrating renewable energy and grid modernization for climate change mitigation.”</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-founders-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE FOUNDERS MEDAL</a></h2><p><em><em>Sponsor:</em></em><a href=\"https://www.lockheedmartin.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><em> </em></a><a href=\"https://www.ieeefoundation.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>IEEE Foundation</em></em></a></p><p><a href=\"https://www.linkedin.com/in/marian-croak-926361bb/\" rel=\"noopener noreferrer\" target=\"_blank\">Marian Rogers Croak</a></p><p><a href=\"https://about.google/\" rel=\"noopener noreferrer\" target=\"_blank\">Google</a></p><p>Reston, Va.</p><p>“For leadership in communication networks, including acceleration of digital equity, responsible Artificial Intelligence, and the promotion of diversity and inclusion.”</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-richard-w-hamming-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE RICHARD W. HAMMING MEDAL</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.qualcomm.com/home\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Qualcomm, Inc.</em></em></a></p><p><a href=\"https://spectrum.ieee.org/universal-decoder-pioneer\" target=\"_self\">Muriel Médard</a></p><p><a href=\"https://www.mit.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">MIT</a></p><p>“For contributions to coding for reliable communications and networking.”</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-nick-holonyak-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE NICK HOLONYAK, JR. MEDAL FOR SEMICONDUCTOR OPTOELECTRONIC TECHNOLOGIES</a></h2><p><em><em>Sponsor: Friends of Nick Holonyak, Jr.</em></em></p><p><a href=\"https://ssleec.ucsb.edu/denbaars\" rel=\"noopener noreferrer\" target=\"_blank\">Steven P. DenBaars </a></p><p><a href=\"https://www.ucsb.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of California, Santa Barbara</a></p><p>“For seminal contributions to compound semiconductor optoelectronics, including high-efficiency visible light-emitting diodes, lasers, and LED displays.”</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-medal-for-innovations-in-healthcare-technology-2/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE MEDAL FOR INNOVATIONS IN HEALTHCARE TECHNOLOGY</a></h2><p><em><em>Sponsor:</em></em><a href=\"https://www.embs.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><em> </em><em><em>IEEE Engineering Medicine and Biology Society</em></em></a></p><p><a href=\"https://www.media.mit.edu/people/picard/overview/\" rel=\"noopener noreferrer\" target=\"_blank\">Rosalind W. Picard </a></p><p><a href=\"https://www.media.mit.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">MIT</a></p><p>“For pioneering contributions to wearable affective computing for health and wellbeing.”</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/922-2/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE JACK S. KILBY SIGNAL PROCESSING MEDAL</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.apple.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Apple</em></em></a></p><p><a href=\"https://ece.gatech.edu/directory/biing-hwang-juang\" rel=\"noopener noreferrer\" target=\"_blank\">Biing-Hwang “Fred” Juang</a></p><p><a href=\"https://www.gatech.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Georgia Tech</a></p><p>“For contributions to signal modeling, coding, and recognition for speech communication.”</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-rse-james-clerk-maxwell-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE/RSE JAMES CLERK MAXWELL MEDAL</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.arm.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>ARM, Ltd.</em></em></a></p><p><a href=\"https://www.uottawa.ca/faculty-science/professors/paul-corkum\" rel=\"noopener noreferrer\" target=\"_blank\">Paul B. Corkum</a></p><p><a href=\"https://www.uottawa.ca/en\" rel=\"noopener noreferrer\" target=\"_blank\">University of Ottawa</a></p><p>“For the development of the recollision model for strong field light–matter interactions leading to the field of attosecond science.”</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-james-h-mulligan-jr-education-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE JAMES H. MULLIGAN, JR. EDUCATION MEDAL</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.ieee.org/communities/life-members/fund.html\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>IEEE Life Members Fund</em></em></a><em><em> and </em></em><a href=\"https://www.mathworks.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>MathWorks<br/></em></em><br/></a><a href=\"https://ece.gatech.edu/directory/james-h-mcclellan\" rel=\"noopener noreferrer\" target=\"_blank\">James H. McClellan</a></p><p><a href=\"https://www.gatech.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Georgia Tech</a></p><p>“For fundamental contributions to electrical and computer engineering education through innovative digital signal processing curriculum development.”</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-jun-ichi-nishizawa-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE JUN-ICHI NISHIZAWA MEDAL</a></h2><p><em><em>Sponsor: IEEE Jun-ichi Nishizawa Medal Fund</em></em></p><p><a href=\"https://engineering.dartmouth.edu/community/faculty/eric-fossum\" rel=\"noopener noreferrer\" target=\"_blank\">Eric R. Fossum</a></p><p><a href=\"https://home.dartmouth.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Dartmouth College<br/><br/></a>Hanover, N.H.</p><p>“For the invention, development, and commercialization of the CMOS image sensor.”</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-robert-n-noyce-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE ROBERT N. NOYCE MEDAL</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.intel.com/content/www/us/en/company-overview/company-overview.html\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Intel Corp.</em></em></a></p><p><a href=\"https://www.nvidia.com/en-eu/about-nvidia/governance/management-team/chris-malachowsky/\" rel=\"noopener noreferrer\" target=\"_blank\">Chris Malachowsky </a></p><p><a href=\"https://www.nvidia.com/en-us/\" rel=\"noopener noreferrer\" target=\"_blank\">Nvidia</a></p><p>Santa Clara, Calif.</p><p>“For pioneering parallel computing architectures and leadership in semiconductor design that transformed artificial intelligence, scientific research, and accelerated computing.”</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-dennis-j-picard-medal-for-radar-technologies-and-applications/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE DENNIS J. PICARD MEDAL FOR RADAR TECHNOLOGIES AND APPLICATIONS</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.rtx.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>RTX</em></em></a></p><p><a href=\"https://www.gs.niigata-u.ac.jp/~gsweb/gs/english/teacher/pdf/64.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">Yoshio Yamaguchi</a></p><p><a href=\"https://www.niigata-u.ac.jp/en/\" rel=\"noopener noreferrer\" target=\"_blank\">Niigata University</a></p><p>Japan</p><p>“For contributions to polarimetric synthetic aperture radar imaging and its utilization.”</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-medal-in-power-engineering/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE MEDAL IN POWER ENGINEERING</a></h2><p><em><em>Sponsors: </em></em><a href=\"https://ias.ieee.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>IEEE Industry Applications,</em></em></a><em> </em><a href=\"https://www.ieee-ies.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Industrial Electronics,</a><em> </em><a href=\"https://www.ieee-pels.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Power Electronics</em></em></a><em><em>, and </em></em><a href=\"https://www.ieee-pes.org/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Power & Energy societies</em></em></a></p><p><a href=\"https://grid.pitt.edu/people/fang-zheng-peng\" rel=\"noopener noreferrer\" target=\"_blank\">Fang Zheng Peng </a></p><p><a href=\"https://www.pitt.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of Pittsburgh</a></p><p>“For contributions to Z-Source and modular multi-level converters for distribution and transmission networks.”</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-simon-ramo-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE SIMON RAMO MEDAL</a></h2><p><em><em>Sponsor: </em></em><a href=\"https://www.northropgrumman.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>Northrop Grumman Corp</em></em></a>.<br/><br/><a href=\"https://www.linkedin.com/in/michael-griffin-8209101b2/\" rel=\"noopener noreferrer\" target=\"_blank\">Michael D. Griffin </a></p><p>LogiQ, Inc.</p><p>Arlington, Va.</p><p>“For leadership in national security, civil, and commercial systems engineering and development of elegant design principles.”</p><div class=\"horizontal-rule\"></div><h2><a href=\"https://corporate-awards.ieee.org/award/ieee-john-von-neumann-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE JOHN VON NEUMANN MEDAL</a></h2><p><em><em>Sponsor:</em></em><a href=\"https://www.research.ibm.com/university/\" rel=\"noopener noreferrer\" target=\"_blank\"><em> </em></a><a href=\"https://www.ibm.com/us-en\" rel=\"noopener noreferrer\" target=\"_blank\"><em><em>IBM</em></em></a></p><p><a href=\"https://www.linkedin.com/in/donaldchamberlin/\" rel=\"noopener noreferrer\" target=\"_blank\">Donald D. Chamberlin</a></p><p><a href=\"https://www.ibm.com/us-en\" rel=\"noopener noreferrer\" target=\"_blank\">IBM</a></p><p>San Jose, Calif.</p><p>“For contributions to database query languages, particularly Structured Query Language, which powers most of the world’s data management and analysis systems.”</p>",
        "contentSnippet": "Meet the recipients of the 2026 IEEE Medals—the organization’s highest-level honors. Presented on behalf of the IEEE Board of Directors, these medals recognize innovators whose work has shaped modern technology across disciplines including AI, education, and semiconductors.\nThe medals will be presented at the IEEE Honors Ceremony in April in New York City. View the full list of 2026 recipients on the IEEE Awards website, and follow IEEE Awards on LinkedIn for news and updates.\n\nIEEE MEDAL OF HONOR\nSponsor: IEEE\nJensen Huang\nNvidia\nSanta Clara, Calif.\n “For leadership in the development of graphics processing units and their application to scientific computing and artificial intelligence.”\n\nIEEE FRANCES E. ALLEN MEDAL\nSponsor: IBM\nLuis von Ahn\nDuolingo\nPittsburgh\n“For contributions to the advancement of societal improvement and education through innovative technology.”\n\nIEEE ALEXANDER GRAHAM BELL MEDAL\nSponsor: Nokia Bell Labs \nScott Shenker\nUniversity of California, Berkeley\nInternational Computer Science Institute \n“For contributions to Internet architecture, network resource allocation, and software-defined networking.”\n\nIEEE JAGADISH CHANDRA BOSE MEDAL IN WIRELESS COMMUNICATIONS\nSponsor: Mani L. Bhaumik\nCo-recipients: \nErik Dahlman \nStefan Parkvall\nJohan Sköld \nEricsson\nStockholm\n“For contributions to and leadership in the research, development, and standardization of cellular wireless communications.”\n\nIEEE MILDRED DRESSELHAUS MEDAL\nSponsor: Google\nKaren Ann Panetta\nTufts University\nMedford, Mass.\n“For contributions to computer vision and simulation algorithms, and for leadership in developing programs to promote STEM careers.”\n\nIEEE EDISON MEDAL\nSponsor: IEEE Edison Medal Fund\nEric Swanson\nPIXCEL Inc.\nMIT\n“For pioneering contributions to biomedical imaging, terrestrial optical communications and networking, and inter-satellite optical links.”\n\nIEEE MEDAL FOR ENVIRONMENTAL AND SAFETY TECHNOLOGIES\nSponsor: Toyota Motor Corp.\nWei-Jen Lee\nUniversity of Texas at Arlington\n“For contributions to advancing electrical safety in the workplace, integrating renewable energy and grid modernization for climate change mitigation.”\n\nIEEE FOUNDERS MEDAL\nSponsor: IEEE Foundation\nMarian Rogers Croak\nGoogle\nReston, Va.\n“For leadership in communication networks, including acceleration of digital equity, responsible Artificial Intelligence, and the promotion of diversity and inclusion.”\n\nIEEE RICHARD W. HAMMING MEDAL\nSponsor: Qualcomm, Inc.\nMuriel Médard\nMIT\n“For contributions to coding for reliable communications and networking.”\n\nIEEE NICK HOLONYAK, JR. MEDAL FOR SEMICONDUCTOR OPTOELECTRONIC TECHNOLOGIES\nSponsor: Friends of Nick Holonyak, Jr.\nSteven P. DenBaars \nUniversity of California, Santa Barbara\n“For seminal contributions to compound semiconductor optoelectronics, including high-efficiency visible light-emitting diodes, lasers, and LED displays.”\n\nIEEE MEDAL FOR INNOVATIONS IN HEALTHCARE TECHNOLOGY\nSponsor: IEEE Engineering Medicine and Biology Society\nRosalind W. Picard \nMIT\n“For pioneering contributions to wearable affective computing for health and wellbeing.”\n\nIEEE JACK S. KILBY SIGNAL PROCESSING MEDAL\nSponsor: Apple\nBiing-Hwang “Fred” Juang\nGeorgia Tech\n“For contributions to signal modeling, coding, and recognition for speech communication.”\n\nIEEE/RSE JAMES CLERK MAXWELL MEDAL\nSponsor: ARM, Ltd.\nPaul B. Corkum\nUniversity of Ottawa\n“For the development of the recollision model for strong field light–matter interactions leading to the field of attosecond science.”\n\nIEEE JAMES H. MULLIGAN, JR. EDUCATION MEDAL\nSponsor: IEEE Life Members Fund and MathWorks\n\nJames H. McClellan\nGeorgia Tech\n“For fundamental contributions to electrical and computer engineering education through innovative digital signal processing curriculum development.”\n\nIEEE JUN-ICHI NISHIZAWA MEDAL\nSponsor: IEEE Jun-ichi Nishizawa Medal Fund\nEric R. Fossum\nDartmouth College\nHanover, N.H.\n“For the invention, development, and commercialization of the CMOS image sensor.”\n\nIEEE ROBERT N. NOYCE MEDAL\nSponsor: Intel Corp.\nChris Malachowsky \nNvidia\nSanta Clara, Calif.\n“For pioneering parallel computing architectures and leadership in semiconductor design that transformed artificial intelligence, scientific research, and accelerated computing.”\n\nIEEE DENNIS J. PICARD MEDAL FOR RADAR TECHNOLOGIES AND APPLICATIONS\nSponsor: RTX\nYoshio Yamaguchi\nNiigata University\nJapan\n“For contributions to polarimetric synthetic aperture radar imaging and its utilization.”\n\nIEEE MEDAL IN POWER ENGINEERING\nSponsors: IEEE Industry Applications, Industrial Electronics, Power Electronics, and Power & Energy societies\nFang Zheng Peng \nUniversity of Pittsburgh\n“For contributions to Z-Source and modular multi-level converters for distribution and transmission networks.”\n\nIEEE SIMON RAMO MEDAL\nSponsor: Northrop Grumman Corp.\nMichael D. Griffin \nLogiQ, Inc.\nArlington, Va.\n“For leadership in national security, civil, and commercial systems engineering and development of elegant design principles.”\n\nIEEE JOHN VON NEUMANN MEDAL\nSponsor: IBM\nDonald D. Chamberlin\nIBM\nSan Jose, Calif.\n“For contributions to database query languages, particularly Structured Query Language, which powers most of the world’s data management and analysis systems.”",
        "pubDate": "Mon, 09 Feb 2026 19:00:03 +0000",
        "isoDate": "2026-02-09T19:00:03.000Z",
        "creator": "Tanya Steinhauser",
        "source": "https://spectrum.ieee.org/ieee-2026-honors"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-y2m0tm",
        "title": "New Devices Might Scale the Memory Wall",
        "link": "https://spectrum.ieee.org/ai-and-memory-wall",
        "url": "https://spectrum.ieee.org/ai-and-memory-wall",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/scanning-electron-microscope-image-of-the-top-of-a-three-dimensional-bulk-resistive-ram.jpg?id=63929015&width=1245&height=700&coordinates=0%2C97%2C0%2C98\"/><br/><br/><p><span>The hunt is on for anything that can surmount AI’s </span><a href=\"https://spectrum.ieee.org/to-speed-up-ai-mix-memory-and-processing\" target=\"_self\">perennial memory wall</a><span>–even quick models are bogged down by the time and energy needed to carry data between processor and memory. </span><a href=\"https://spectrum.ieee.org/system-creates-the-illusion-of-an-ideal-ai-chip\" target=\"_self\">Resistive RAM</a><span> (RRAM)could circumvent the wall by allowing computation to happen in the memory itself. Unfortunately, most types of this nonvolatile memory are too unstable and unwieldy for that purpose.</span></p><p>Fortunately, a potential solution may be at hand. At December’s IEEE<a href=\"https://www.ieee-iedm.org/\" target=\"_blank\"> International Electron Device Meeting</a> (IEDM), researchers from the University of California, San Diego, showed they could run a learning algorithm on an entirely new type of RRAM.</p><p>“We actually redesigned RRAM, completely rethinking the way it switches,” says<a href=\"https://jacobsschool.ucsd.edu/people/profile/duygu-kuzum\" target=\"_blank\"> Duygu Kuzum</a>, an electrical engineer at UCSD, who led the work.</p><p>RRAM stores data as a level of resistance to the flow of current. The key digital operation in a neural network—multiplying arrays of numbers and then summing the results—can be done in analog simply by running current through an array of RRAM cells, connecting their outputs, and measuring the resulting current.</p><p>Traditionally, RRAM stores data by creating low-resistance filaments in the higher-resistance surrounds of a dielectric material. Forming these filaments often needs voltages too high for standard CMOS, hindering its integration inside processors. Worse, forming the filaments is a noisy and random process, not ideal for storing data. (Imagine a neural network’s weights randomly drifting. Answers to the same question would change from one day to the next.) </p><p>Moreover, most filament-based RRAM cells’ noisy nature means they must be isolated from their surrounding circuits, usually with a selector transistor, which makes <a href=\"https://spectrum.ieee.org/3d-cmos\" target=\"_self\">3D stacking</a> difficult.</p><p>Limitations like these mean that traditional RRAM isn’t great for computing. In particular, Kuzum says, it’s difficult to use filamentary RRAM for the sort of parallel<a href=\"https://spectrum.ieee.org/matrix-multiplication-deepmind\" target=\"_self\"> matrix operations</a> that are crucial for today’s neural networks.</p><p>So, the UCSD researchers decided to dispense with the filaments entirely. Instead they developed devices that switch an entire layer from high to low resistance and back again. This format, called bulk RRAM, can do away with both the annoying high-voltage filament-forming step and the geometry-limiting selector transistor.</p><h2>3D Memory for Machine Learning</h2><p>The UCSD group wasn’t the first to build bulk RRAM devices, but it made breakthroughs both in shrinking them and forming 3D circuits with them. Kuzum and her colleagues shrank RRAM into the nanoscale; their device was just 40 nanometers across. They also managed to stack bulk RRAM into as many as eight layers.</p><p>With a single pulse of voltage, <span>each cell in </span>an eight-layer stack can take any of 64 resistance values, a number that’s very difficult to achieve with traditional filamentous RRAM. And whereas the resistance of most filament-based cells are limited to kiloohms, the UCSD stack is in the megaohm range, which Kuzum says is better for parallel operations.</p><p>“We can actually tune it to anywhere we want, but we think that from an integration and system-level simulations perspective, megaohm is the desirable range,” Kuzum says.</p><p>These two benefits–a greater number of resistance levels and a higher resistance–could allow this bulk RRAM stack to perform more complex operations than traditional RRAM’s can manage. </p><p>Kuzum and colleagues assembled multiple eight-layer stacks into a 1-kilobyte array that required no selectors. Then, they tested the array with a continual learning algorithm: making the chip classify data from wearable sensors while constantly adding new data. For example, data read from a waist-mounted smartphone might be used to determine if its wearer was sitting, walking, climbing stairs, or taking another action. Tests showed an accuracy of 90 percent, which the researchers say is comparable to the performance of a digitally implemented neural network.</p><p>This test exemplifies what Kuzum thinks can especially benefit from bulk RRAM: neural network models on edge devices, which may need to learn from their environment without accessing the cloud. </p><p>“We are doing a lot of characterization and material optimization to design a device specifically engineered for AI applications,” Kuzum says. </p><p>The ability to integrate RRAM into an array like this is a significant advance, says <a href=\"https://mse.umd.edu/clark/faculty/980/A-Alec-Talin\" target=\"_blank\">Alec Talin</a>, materials scientist at Sandia National Laboratories in Livermore, California, and a bulk RRAM researcher who wasn’t involved in the UCSD group’s work. “I think that any step in terms of integration is very useful,” he says.</p><p>But Talin highlights a potential obstacle: the ability to retain data for an extended period of time. While the UCSD group showed their RRAM could retain data at room temperature for several years (on par with flash memory), Talin says that its retention at the higher temperatures where computers actually operate is less certain. “That’s one of the major challenges of this technology,” he says, especially when it comes to edge applications.</p><p>If engineers can prove the technology, then all types of models may benefit. This memory wall has only grown higher this decade, as traditional memory hasn’t been able to keep up with the ballooning demands of large models. Anything that allows models to operate on the memory itself could be a welcome shortcut. </p>",
        "contentSnippet": "The hunt is on for anything that can surmount AI’s perennial memory wall–even quick models are bogged down by the time and energy needed to carry data between processor and memory. Resistive RAM (RRAM)could circumvent the wall by allowing computation to happen in the memory itself. Unfortunately, most types of this nonvolatile memory are too unstable and unwieldy for that purpose.\nFortunately, a potential solution may be at hand. At December’s IEEE International Electron Device Meeting (IEDM), researchers from the University of California, San Diego, showed they could run a learning algorithm on an entirely new type of RRAM.\n“We actually redesigned RRAM, completely rethinking the way it switches,” says Duygu Kuzum, an electrical engineer at UCSD, who led the work.\nRRAM stores data as a level of resistance to the flow of current. The key digital operation in a neural network—multiplying arrays of numbers and then summing the results—can be done in analog simply by running current through an array of RRAM cells, connecting their outputs, and measuring the resulting current.\nTraditionally, RRAM stores data by creating low-resistance filaments in the higher-resistance surrounds of a dielectric material. Forming these filaments often needs voltages too high for standard CMOS, hindering its integration inside processors. Worse, forming the filaments is a noisy and random process, not ideal for storing data. (Imagine a neural network’s weights randomly drifting. Answers to the same question would change from one day to the next.) \nMoreover, most filament-based RRAM cells’ noisy nature means they must be isolated from their surrounding circuits, usually with a selector transistor, which makes 3D stacking difficult.\nLimitations like these mean that traditional RRAM isn’t great for computing. In particular, Kuzum says, it’s difficult to use filamentary RRAM for the sort of parallel matrix operations that are crucial for today’s neural networks.\nSo, the UCSD researchers decided to dispense with the filaments entirely. Instead they developed devices that switch an entire layer from high to low resistance and back again. This format, called bulk RRAM, can do away with both the annoying high-voltage filament-forming step and the geometry-limiting selector transistor.\n3D Memory for Machine Learning\nThe UCSD group wasn’t the first to build bulk RRAM devices, but it made breakthroughs both in shrinking them and forming 3D circuits with them. Kuzum and her colleagues shrank RRAM into the nanoscale; their device was just 40 nanometers across. They also managed to stack bulk RRAM into as many as eight layers.\nWith a single pulse of voltage, each cell in an eight-layer stack can take any of 64 resistance values, a number that’s very difficult to achieve with traditional filamentous RRAM. And whereas the resistance of most filament-based cells are limited to kiloohms, the UCSD stack is in the megaohm range, which Kuzum says is better for parallel operations.\n“We can actually tune it to anywhere we want, but we think that from an integration and system-level simulations perspective, megaohm is the desirable range,” Kuzum says.\nThese two benefits–a greater number of resistance levels and a higher resistance–could allow this bulk RRAM stack to perform more complex operations than traditional RRAM’s can manage. \nKuzum and colleagues assembled multiple eight-layer stacks into a 1-kilobyte array that required no selectors. Then, they tested the array with a continual learning algorithm: making the chip classify data from wearable sensors while constantly adding new data. For example, data read from a waist-mounted smartphone might be used to determine if its wearer was sitting, walking, climbing stairs, or taking another action. Tests showed an accuracy of 90 percent, which the researchers say is comparable to the performance of a digitally implemented neural network.\nThis test exemplifies what Kuzum thinks can especially benefit from bulk RRAM: neural network models on edge devices, which may need to learn from their environment without accessing the cloud. \n“We are doing a lot of characterization and material optimization to design a device specifically engineered for AI applications,” Kuzum says. \nThe ability to integrate RRAM into an array like this is a significant advance, says Alec Talin, materials scientist at Sandia National Laboratories in Livermore, California, and a bulk RRAM researcher who wasn’t involved in the UCSD group’s work. “I think that any step in terms of integration is very useful,” he says.\nBut Talin highlights a potential obstacle: the ability to retain data for an extended period of time. While the UCSD group showed their RRAM could retain data at room temperature for several years (on par with flash memory), Talin says that its retention at the higher temperatures where computers actually operate is less certain. “That’s one of the major challenges of this technology,” he says, especially when it comes to edge applications.\nIf engineers can prove the technology, then all types of models may benefit. This memory wall has only grown higher this decade, as traditional memory hasn’t been able to keep up with the ballooning demands of large models. Anything that allows models to operate on the memory itself could be a welcome shortcut.",
        "pubDate": "Mon, 09 Feb 2026 13:00:02 +0000",
        "isoDate": "2026-02-09T13:00:02.000Z",
        "creator": "Rahul Rao",
        "source": "https://spectrum.ieee.org/ai-and-memory-wall"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-iwaqw2",
        "title": "Low-Vision Programmers Can Now Design 3D Models Independently",
        "link": "https://spectrum.ieee.org/3d-modeling-blind-programmers",
        "url": "https://spectrum.ieee.org/3d-modeling-blind-programmers",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/a-college-student-programming-a-three-dimensional-model-on-a-laptop.jpg?id=63136292&width=1245&height=700&coordinates=0%2C469%2C0%2C469\"/><br/><br/><p>Most 3D design software requires visual dragging and rotating—posing a challenge for blind and low-vision users. As a result, a range of hardware design, robotics, coding, and engineering work is <span>inaccessible to interested programmers. A visually-impaired programmer might write great code. But because of the lack of accessible <a data-linked-post=\"2671899889\" href=\"https://spectrum.ieee.org/comsol-simulation-apps\" target=\"_blank\">modeling software</a>, the coder can’t model, design, and verify physical and virtual components of their system. </span></p><p>However, new 3D modeling tools are beginning to change this equation. A new prototype program called <a href=\"https://arxiv.org/abs/2508.03852\" target=\"_blank\">A11yShape</a> aims to close the gap. There are already code-based tools that let users describe 3D models in text, such as the popular <a href=\"https://openscad.org/\" target=\"_blank\">OpenSCAD software</a>. Other recent <a href=\"https://github.com/WebPAI/DesignBench\" target=\"_blank\">large-language-model tools</a> generate <a href=\"https://arxiv.org/html/2410.05340v1\" target=\"_blank\">3D code from natural-language prompts</a>. But even with these, blind and low-vision programmers still depend on sighted feedback to bridge the gap between their code and its visual output. </p><p>Blind and low-vision programmers previously had to rely on a sighted person to visually check every update of a model to describe what changed. But with A11yShape, blind and low-vision programmers can independently create, inspect, and refine 3D models without relying on sighted peers.</p><p>A11yShape does this by generating accessible model descriptions, organizing the model into a semantic hierarchy, and ensuring every step works with screen readers<span>. </span></p><p>The project began when <a href=\"https://www.lianghe.me/\" target=\"_blank\"><span>Liang He</span></a>, assistant professor of computer science at the University of Texas at Dallas, spoke with his low-vision classmate who was studying 3D modeling. He saw an opportunity to turn his classmate’s coding strategies, learned in <a href=\"https://create.uw.edu/initiatives/physical-computing/\" target=\"_blank\"><span>a 3D modeling for blind programmers course</span></a> at the University of Washington, into a streamlined tool. </p><p>“I want to design something useful and practical for the group,” he says. “Not just something I created from my imagination and applied to the group.” </p><h3>Re-imagining Assistive 3D Design With OpenSCAD</h3><p>A11yShape assumes the user is running OpenSCAD, the script-based 3D modeling editor. <span>The program adds OpenSCAD features to connect each component of modeling across three application UI panels. </span></p><p>OpenSCAD allows users to create models entirely through typing, eliminating the need for clicking and dragging. Other common graphics-based user interfaces are difficult for blind programmers to navigate. </p><p>A11yshape introduces an AI Assistance Panel, where users can submit real-time queries to <a data-linked-post=\"2668670173\" href=\"https://spectrum.ieee.org/chatgpt-for-coding\" target=\"_blank\">ChatGPT</a>-4o to validate design decisions and debug existing OpenSCAD scripts. </p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"AllyShape's 3-D modeling web interface, featuring a code editor panel with programming capabilities, an AI assistance panel providing contextual feedback, and a model panel displaying hierarchical structure and rendering of the resulting model.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"e8f4867cfdc27299feb3e351fc191485\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"c4ecb\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/allyshape-s-3-d-modeling-web-interface-featuring-a-code-editor-panel-with-programming-capabilities-an-ai-assistance-panel-prov.jpg?id=63138638&width=980\"/> <small class=\"image-media media-caption\" data-gramm=\"false\" data-lt-tmp-id=\"lt-661548\" placeholder=\"Add Photo Caption...\" spellcheck=\"false\">A11yShape’s three panels synchronize code, AI descriptions, and model structure so blind programmers can discover how code changes affect designs independently.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\"><a href=\"https://arxiv.org/pdf/2508.03852\" target=\"_blank\">Anhong Guo, Liang He, et al.</a></small></p><p><span>If a user selects a piece of code or a model component, A11yShape highlights the matching part across all three panels and updates the description, so blind and low-vision users always know what they’re working on.</span></p><h3>User Feedback Improved Accessible Interface</h3><p>The research team recruited 4 participants with a range of visual impairments and programming backgrounds. The team asked the participants to design models using A11yShape and observed their workflows.</p><p>One participant, who had never modeled before, said the tool “provided [the blind and low-vision community] with a new perspective on 3D modeling, demonstrating that we can indeed create relatively simple structures.”</p><p>Participants also reported that long text descriptions still make it hard to grasp complex shapes, and several said that without eventually touching a physical model or using a tactile display, it was difficult to fully “see” the design in their mind.</p><p>To evaluate the accuracy of the AI-generated descriptions, the research team recruited 15 sighted participants. “On a 1–5 scale, the descriptions earned average scores between about 4.1 and 5 for geometric accuracy, clarity, and avoiding hallucinations, suggesting the AI is reliable enough for everyday use.”</p><p><br/></p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"A failed all-at-once attempt to construct a 3-D helicopter shows incorrect shapes and placement of elements. In contrast, when the user journey allows for completion of each individual element before moving forward, results significantly improve.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"889449ab44920bd0cddc01deaea32916\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"528e8\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-failed-all-at-once-attempt-to-construct-a-3-d-helicopter-shows-incorrect-shapes-and-placement-of-elements-in-contrast-when-t.jpg?id=63138939&width=980\"/> <small class=\"image-media media-caption\" data-gramm=\"false\" data-lt-tmp-id=\"lt-698807\" placeholder=\"Add Photo Caption...\" spellcheck=\"false\">A new assistive program for blind and low-vision programmers, A11yShape, assists visually disabled programmers in verifying the design of their models.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Source: <a href=\"https://arxiv.org/pdf/2508.03852\" target=\"_blank\">Anhong Guo, Liang He, et al.</a></small></p><p>The feedback will help to inform future iterations—which He says could integrate tactile displays, real-time 3D printing, and more concise AI-generated audio descriptions. </p><p>Beyond its applications in the professional computer programming community, He noted that A11yShape also lowers the barrier to entry for blind and low-vision computer programming <span>learners.</span></p><p><span>“People like being able to express themselves in creative ways. . . using technology such as 3D printing to make things for utility or entertainment,” says <a href=\"https://engineering.unt.edu/people/stephanie-ludi.html\" target=\"_blank\">Stephanie Ludi,</a> director of DiscoverABILITY Lab and professor of the department of computer science and engineering at the <a href=\"https://engineering.unt.edu/cse/\" target=\"_blank\">University of North Texas</a>. “Persons who are blind and visually impaired share that interest</span><span>, with A11yShape serving as a model to support accessibility in the maker community.” </span></p><p>The team presented A11yshape in October at the <a href=\"https://assets25.sigaccess.org/\" target=\"_blank\">ASSETS conference</a> in Denver.</p>",
        "contentSnippet": "Most 3D design software requires visual dragging and rotating—posing a challenge for blind and low-vision users. As a result, a range of hardware design, robotics, coding, and engineering work is inaccessible to interested programmers. A visually-impaired programmer might write great code. But because of the lack of accessible modeling software, the coder can’t model, design, and verify physical and virtual components of their system. \nHowever, new 3D modeling tools are beginning to change this equation. A new prototype program called A11yShape aims to close the gap. There are already code-based tools that let users describe 3D models in text, such as the popular OpenSCAD software. Other recent large-language-model tools generate 3D code from natural-language prompts. But even with these, blind and low-vision programmers still depend on sighted feedback to bridge the gap between their code and its visual output. \nBlind and low-vision programmers previously had to rely on a sighted person to visually check every update of a model to describe what changed. But with A11yShape, blind and low-vision programmers can independently create, inspect, and refine 3D models without relying on sighted peers.\nA11yShape does this by generating accessible model descriptions, organizing the model into a semantic hierarchy, and ensuring every step works with screen readers. \nThe project began when Liang He, assistant professor of computer science at the University of Texas at Dallas, spoke with his low-vision classmate who was studying 3D modeling. He saw an opportunity to turn his classmate’s coding strategies, learned in a 3D modeling for blind programmers course at the University of Washington, into a streamlined tool. \n“I want to design something useful and practical for the group,” he says. “Not just something I created from my imagination and applied to the group.” \nRe-imagining Assistive 3D Design With OpenSCAD\nA11yShape assumes the user is running OpenSCAD, the script-based 3D modeling editor. The program adds OpenSCAD features to connect each component of modeling across three application UI panels. \nOpenSCAD allows users to create models entirely through typing, eliminating the need for clicking and dragging. Other common graphics-based user interfaces are difficult for blind programmers to navigate. \nA11yshape introduces an AI Assistance Panel, where users can submit real-time queries to ChatGPT-4o to validate design decisions and debug existing OpenSCAD scripts. \n  A11yShape’s three panels synchronize code, AI descriptions, and model structure so blind programmers can discover how code changes affect designs independently.Anhong Guo, Liang He, et al.\nIf a user selects a piece of code or a model component, A11yShape highlights the matching part across all three panels and updates the description, so blind and low-vision users always know what they’re working on.\nUser Feedback Improved Accessible Interface\nThe research team recruited 4 participants with a range of visual impairments and programming backgrounds. The team asked the participants to design models using A11yShape and observed their workflows.\nOne participant, who had never modeled before, said the tool “provided [the blind and low-vision community] with a new perspective on 3D modeling, demonstrating that we can indeed create relatively simple structures.”\nParticipants also reported that long text descriptions still make it hard to grasp complex shapes, and several said that without eventually touching a physical model or using a tactile display, it was difficult to fully “see” the design in their mind.\nTo evaluate the accuracy of the AI-generated descriptions, the research team recruited 15 sighted participants. “On a 1–5 scale, the descriptions earned average scores between about 4.1 and 5 for geometric accuracy, clarity, and avoiding hallucinations, suggesting the AI is reliable enough for everyday use.”\n\n\n  A new assistive program for blind and low-vision programmers, A11yShape, assists visually disabled programmers in verifying the design of their models.Source: Anhong Guo, Liang He, et al.\nThe feedback will help to inform future iterations—which He says could integrate tactile displays, real-time 3D printing, and more concise AI-generated audio descriptions. \nBeyond its applications in the professional computer programming community, He noted that A11yShape also lowers the barrier to entry for blind and low-vision computer programming learners.\n“People like being able to express themselves in creative ways. . . using technology such as 3D printing to make things for utility or entertainment,” says Stephanie Ludi, director of DiscoverABILITY Lab and professor of the department of computer science and engineering at the University of North Texas. “Persons who are blind and visually impaired share that interest, with A11yShape serving as a model to support accessibility in the maker community.” \nThe team presented A11yshape in October at the ASSETS conference in Denver.",
        "pubDate": "Sat, 07 Feb 2026 14:00:01 +0000",
        "isoDate": "2026-02-07T14:00:01.000Z",
        "creator": "Samantha Hurley",
        "source": "https://spectrum.ieee.org/3d-modeling-blind-programmers"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-pe5sdh",
        "title": "IEEE Online Mini-MBA Aims to Fill Leadership Skills Gaps in AI",
        "link": "https://spectrum.ieee.org/ieee-online-mini-ai-mba",
        "url": "https://spectrum.ieee.org/ieee-online-mini-ai-mba",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/close-up-of-hands-typing-on-a-laptop-with-floating-graphics-representing-large-language-models-floating-above-the-keyboard.jpg?id=63843722&width=1245&height=700&coordinates=0%2C156%2C0%2C157\"/><br/><br/><p>Boardroom priorities are shifting from financial metrics toward technical oversight. Although market share and operational efficiency remain business bedrocks, executives also must now manage the complexities of machine learning, the integrity of their data systems, and the risks of algorithmic bias.</p><p>The change represents more than just a tech update; it marks a fundamental redefinition of the skills required for business leadership.</p><p><a href=\"https://www.mckinsey.com/capabilities/operations/our-insights/bold-accelerators-how-operations-leaders-are-pulling-ahead-using-ai\" rel=\"noopener noreferrer\" target=\"_blank\">Research</a> from the <a href=\"https://www.mckinsey.com/mgi/about-us\" rel=\"noopener noreferrer\" target=\"_blank\">McKinsey Global Institute</a> on the economic impact of artificial intelligence shows that companies integrating it effectively have boosted profit margins by up to 15 percent. Yet the same study revealed a sobering reality: 87 percent of organizations acknowledge significant AI skill gaps in their leadership ranks.</p><p>That disconnect between AI’s business potential and executive readiness has created a need for a new type of professional education.</p><h2>The leadership skills gap in the AI era</h2><p>Traditional business education, with its focus on finance, marketing, and operations, wasn’t designed for an AI-driven economy. Today’s leaders need to understand not just what AI can do but also how to evaluate investments in the technology, manage algorithmic risks, and lead teams through digital transformations.</p><p>The challenges extend beyond the executive suite. Middle managers, project leaders, and department heads across industries are discovering that <a href=\"https://spectrum.ieee.org/ai-developer-career-advice\" target=\"_self\">AI fluency has become essential for career advancement</a>. In 2020 the <a href=\"https://www.weforum.org/stories/2020/10/top-10-work-skills-of-tomorrow-how-long-it-takes-to-learn-them/#:~:text=50%25%20of%20all%20employees%20will,help%20us%20learn%20new%20skills.\" rel=\"noopener noreferrer\" target=\"_blank\">World Economic Forum</a> predicted that 50 percent of all employees would need reskilling by 2025, with <a href=\"https://spectrum.ieee.org/ai-effect-entry-level-jobs\" target=\"_self\">AI-related competencies topping the list of required skills</a>.</p><h2>IEEE | Rutgers Online Mini-MBA: Artificial Intelligence</h2><p>Recognizing the skills gap, IEEE partnered with the <a href=\"https://www.business.rutgers.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Rutgers Business School</a> to offer a comprehensive business education program designed for the new era of AI. The<a href=\"https://innovationatwork.ieee.org/professional-development/rutgers-online-mini-mba-artificial-intelligence/\" rel=\"noopener noreferrer\" target=\"_blank\"> IEEE | Rutgers Online Mini-MBA: Artificial Intelligence</a> program combines rigorous business strategy with deep AI literacy.</p><p>Rather than treating AI as a separate technical subject, the program incorporates it into each aspect of business strategy. Students learn to evaluate AI opportunities through financial modeling, assess algorithmic risks through governance frameworks, and use change-management principles to implement new technologies.</p><h2>A curriculum built for real-world impact</h2><p>The program’s modular structure lets professionals focus on areas relevant to their immediate needs while building toward comprehensive AI business literacy. Each of the 10 modules includes practical exercises and case study analyses that participants can immediately apply in their organization.</p><p>The Introduction to AI module provides a comprehensive overview of the technology’s capabilities, benefits, and challenges. Other technologies are covered as well, including how they can be applied across diverse business contexts, laying the groundwork for informed decision‑making and strategic adoption.</p><p class=\"pull-quote\">Rather than treating AI as a separate technical subject, the online mini-MBA program incorporates the technology throughout each aspect of business strategy.</p><p>Building on that foundation, the Data Analytics module highlights how AI projects differ from traditional programming, how to assess data readiness, and how to optimize data to improve accuracy and outcomes. The module can equip leaders to evaluate whether their organization is prepared to launch successful AI initiatives.</p><p>The Process Optimization module focuses on reimagining core organizational workflows using AI. Students learn how machine learning and automation are already transforming industries such as manufacturing, distribution, transportation, and health care. They also learn how to identify critical processes, create AI road maps, establish pilot programs, and prepare their organization for change.</p><h2>Industry-specific applications</h2><p>The core modules are designed for all participants, and the program highlights how AI is applied across industries. By analyzing case studies in fraud detection, medical diagnostics, and predictive maintenance, participants see underlying principles in action.</p><p>Participants gain a broader perspective on how AI can be adapted to different contexts so they can draw connections to the opportunities and challenges in their organization. The approach ensures everyone comes away with a strong foundation and the ability to apply learned lessons to their environment.</p><h2>Flexible learning for busy professionals</h2><p>With the understanding that senior professionals have demanding schedules, the mini-MBA program offers flexibility. The online format lets participants engage with content in their own time frame, while live virtual office hours with faculty provide opportunities for real-time interaction.</p><p>The program, which offers discounts to IEEE members and flexible payment options, qualifies for many tuition reimbursement programs.</p><p>Graduates report that implementing AI strategies developed during the program has helped drive tangible business results. This success often translates into career advancement, including promotions and expanded leadership roles. Furthermore, the curriculum empowers graduates to confidently vet AI vendor proposals, lead AI project teams, and navigate high-stakes investment decisions.</p><p>Beyond curriculum content, the mini MBA can create valuable professional networks among AI-forward business leaders. Participants collaborate on projects, share implementation experiences, and build relationships that extend beyond the program’s 12 weeks.</p><h2>Specialized training from IEEE</h2><p>To complement the mini-MBA program, IEEE offers targeted courses addressing specific AI applications in critical industries. The <a href=\"https://iln.ieee.org/public/contentdetails.aspx?id=D02A42B64A834CC1A698ADC1ABAB9523\" target=\"_blank\">Artificial Intelligence and Machine Learning in Chip Design</a> course explores how the technology is revolutionizing semiconductor development. <a href=\"https://iln.ieee.org/public/contentdetails.aspx?id=706DBC956996482182A5232D95410F99\" rel=\"noopener noreferrer\" target=\"_blank\">Integrating Edge AI and Advanced Nanotechnology in Semiconductor Applications</a> delves into cutting-edge hardware implementations. The <a href=\"https://iln.ieee.org/public/contentdetails.aspx?id=4B2AD26097B84B0485D297CE627ECA1E\" rel=\"noopener noreferrer\" target=\"_blank\">Mastering AI Integration in Semiconductor Manufacturing</a> course examines how AI enhances production efficiency and quality control in one of the world’s most complex manufacturing processes. <a href=\"https://iln.ieee.org/public/contentdetails.aspx?id=64D2FDC20BF947BB89045A26DAF3A191\" rel=\"noopener noreferrer\" target=\"_blank\">AI in Semiconductor Packaging</a> equips professionals to apply machine learning and neural networks to modernize semiconductor packaging reliability and performance.</p><p>The programs grant professional development credits including PDHs and CEUs, ensuring participants receive formal recognition for their educational investments. Digital badges provide shareable credentials that professionals can showcase across professional networks, demonstrating their AI competencies to current and prospective employers.</p><p>Learn more about <a href=\"https://ea.ieee.org/ea-programs\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Educational Activities</a>’ corporate solutions and professional development programs at <a href=\"https://innovationatwork.ieee.org\" rel=\"noopener noreferrer\" target=\"_blank\">innovationatwork.ieee.org</a>.</p>",
        "contentSnippet": "Boardroom priorities are shifting from financial metrics toward technical oversight. Although market share and operational efficiency remain business bedrocks, executives also must now manage the complexities of machine learning, the integrity of their data systems, and the risks of algorithmic bias.\nThe change represents more than just a tech update; it marks a fundamental redefinition of the skills required for business leadership.\nResearch from the McKinsey Global Institute on the economic impact of artificial intelligence shows that companies integrating it effectively have boosted profit margins by up to 15 percent. Yet the same study revealed a sobering reality: 87 percent of organizations acknowledge significant AI skill gaps in their leadership ranks.\nThat disconnect between AI’s business potential and executive readiness has created a need for a new type of professional education.\nThe leadership skills gap in the AI era\nTraditional business education, with its focus on finance, marketing, and operations, wasn’t designed for an AI-driven economy. Today’s leaders need to understand not just what AI can do but also how to evaluate investments in the technology, manage algorithmic risks, and lead teams through digital transformations.\nThe challenges extend beyond the executive suite. Middle managers, project leaders, and department heads across industries are discovering that AI fluency has become essential for career advancement. In 2020 the World Economic Forum predicted that 50 percent of all employees would need reskilling by 2025, with AI-related competencies topping the list of required skills.\nIEEE | Rutgers Online Mini-MBA: Artificial Intelligence\nRecognizing the skills gap, IEEE partnered with the Rutgers Business School to offer a comprehensive business education program designed for the new era of AI. The IEEE | Rutgers Online Mini-MBA: Artificial Intelligence program combines rigorous business strategy with deep AI literacy.\nRather than treating AI as a separate technical subject, the program incorporates it into each aspect of business strategy. Students learn to evaluate AI opportunities through financial modeling, assess algorithmic risks through governance frameworks, and use change-management principles to implement new technologies.\nA curriculum built for real-world impact\nThe program’s modular structure lets professionals focus on areas relevant to their immediate needs while building toward comprehensive AI business literacy. Each of the 10 modules includes practical exercises and case study analyses that participants can immediately apply in their organization.\nThe Introduction to AI module provides a comprehensive overview of the technology’s capabilities, benefits, and challenges. Other technologies are covered as well, including how they can be applied across diverse business contexts, laying the groundwork for informed decision‑making and strategic adoption.\nRather than treating AI as a separate technical subject, the online mini-MBA program incorporates the technology throughout each aspect of business strategy.\nBuilding on that foundation, the Data Analytics module highlights how AI projects differ from traditional programming, how to assess data readiness, and how to optimize data to improve accuracy and outcomes. The module can equip leaders to evaluate whether their organization is prepared to launch successful AI initiatives.\nThe Process Optimization module focuses on reimagining core organizational workflows using AI. Students learn how machine learning and automation are already transforming industries such as manufacturing, distribution, transportation, and health care. They also learn how to identify critical processes, create AI road maps, establish pilot programs, and prepare their organization for change.\nIndustry-specific applications\nThe core modules are designed for all participants, and the program highlights how AI is applied across industries. By analyzing case studies in fraud detection, medical diagnostics, and predictive maintenance, participants see underlying principles in action.\nParticipants gain a broader perspective on how AI can be adapted to different contexts so they can draw connections to the opportunities and challenges in their organization. The approach ensures everyone comes away with a strong foundation and the ability to apply learned lessons to their environment.\nFlexible learning for busy professionals\nWith the understanding that senior professionals have demanding schedules, the mini-MBA program offers flexibility. The online format lets participants engage with content in their own time frame, while live virtual office hours with faculty provide opportunities for real-time interaction.\nThe program, which offers discounts to IEEE members and flexible payment options, qualifies for many tuition reimbursement programs.\nGraduates report that implementing AI strategies developed during the program has helped drive tangible business results. This success often translates into career advancement, including promotions and expanded leadership roles. Furthermore, the curriculum empowers graduates to confidently vet AI vendor proposals, lead AI project teams, and navigate high-stakes investment decisions.\nBeyond curriculum content, the mini MBA can create valuable professional networks among AI-forward business leaders. Participants collaborate on projects, share implementation experiences, and build relationships that extend beyond the program’s 12 weeks.\nSpecialized training from IEEE\nTo complement the mini-MBA program, IEEE offers targeted courses addressing specific AI applications in critical industries. The Artificial Intelligence and Machine Learning in Chip Design course explores how the technology is revolutionizing semiconductor development. Integrating Edge AI and Advanced Nanotechnology in Semiconductor Applications delves into cutting-edge hardware implementations. The Mastering AI Integration in Semiconductor Manufacturing course examines how AI enhances production efficiency and quality control in one of the world’s most complex manufacturing processes. AI in Semiconductor Packaging equips professionals to apply machine learning and neural networks to modernize semiconductor packaging reliability and performance.\nThe programs grant professional development credits including PDHs and CEUs, ensuring participants receive formal recognition for their educational investments. Digital badges provide shareable credentials that professionals can showcase across professional networks, demonstrating their AI competencies to current and prospective employers.\nLearn more about IEEE Educational Activities’ corporate solutions and professional development programs at innovationatwork.ieee.org.",
        "pubDate": "Fri, 06 Feb 2026 19:00:03 +0000",
        "isoDate": "2026-02-06T19:00:03.000Z",
        "creator": "Angelique Parashis",
        "source": "https://spectrum.ieee.org/ieee-online-mini-ai-mba"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-8ryj27",
        "title": "Video Friday: Autonomous Robots Learn By Doing in This Factory",
        "link": "https://spectrum.ieee.org/autonomous-warehouse-robots",
        "url": "https://spectrum.ieee.org/autonomous-warehouse-robots",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/robotic-arms-on-mobile-bases-sort-crates-on-a-conveyor-belt-in-a-warehouse.png?id=63907821&width=1245&height=700&coordinates=0%2C55%2C0%2C55\"/><br/><br/><p><span>Video Friday is your weekly selection of awesome robotics videos, collected by your friends at </span><em>IEEE Spectrum</em><span> robotics. We also post a weekly calendar of upcoming robotics events for the next few months. Please </span><a href=\"mailto:automaton@ieee.org?subject=Robotics%20event%20suggestion%20for%20Video%20Friday\">send us your events</a><span> for inclusion.</span></p><h5><a href=\"https://2026.ieee-icra.org/\">ICRA 2026</a>: 1–5 June 2026, VIENNA</h5><p>Enjoy today’s videos!</p><div class=\"horizontal-rule\"></div><div style=\"page-break-after: always\"><span style=\"display:none\"> </span></div><blockquote class=\"rm-anchors\" id=\"qdwi4cn3oi0\"><em>To train the next generation of <a data-linked-post=\"2650273449\" href=\"https://spectrum.ieee.org/toyota-to-invest-1-billion-in-ai-and-robotics-rd\" target=\"_blank\">autonomous robots</a>, scientists at Toyota Research Institute are working with Toyota Manufacturing to deploy them on the factory floor.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"197161b054a2a3e4ef30ccd9b27cb5b5\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/QDwi4CN3OI0?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.linkedin.com/posts/toyota-research-institute_whats-next-for-tri-robotics-max-bajracharya-activity-7424198589196685313-4e92?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAM4nT0BW_DvaXaoyr7IuJL-to9SJ5MlYT4\">Toyota Research Institute</a> ]</p><p>Thanks, Erin!</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"sh0chr6usao\"><em>This is just one story (of many) about how we tried, failed, and learned how to improve our ‪<a data-linked-post=\"2650278428\" href=\"https://spectrum.ieee.org/in-the-air-with-ziplines-medical-delivery-drones\" target=\"_blank\">drone delivery</a> system.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"be361c20896c763261fbae4500176505\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/sH0cHr6USao?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>Okay, but like you didn’t show the really cool bit...?</p><p>[ <a href=\"https://www.zipline.com/\">Zipline</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"y2dhzlpgdwy\"><em>We’re introducing KinetIQ, an AI framework developed by Humanoid, for end-to-end orchestration of humanoid robot fleets. KinetIQ coordinates wheeled and bipedal robots within a single system, managing both fleet-level operations and individual robot behavior across multiple environments. The framework operates across four cognitive layers, from task allocation and workflow optimization to task execution based on Vision-Language-Action models and whole-body control taught by reinforcement learning, and is shown here running across our wheeled industrial robots and bipedal R&D platform.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"e2c953a1800d81c0e0b0040c519e3979\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/Y2DhzLPGdwY?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://thehumanoid.ai/\">Humanoid</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"bp7esfyyv4g\"><em>What if a robot gets damaged during operation? Can it still perform its mission without immediate repair? Inspired by the self-embodied resilience strategies of stick insects, we developed a decentralized adaptive resilient neural control system (DARCON). This system allows legged robots to autonomously adapt to limb loss, ensuring mission success despite mechanical failure. This innovative approach leads to a future of truly resilient, self-recovering robotics.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"453cb36391a89fdaf9b4559aec7fe3c9\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/Bp7esFyYV4g?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://advanced.onlinelibrary.wiley.com/doi/10.1002/aisy.202500270\">VISTEC</a> ]</p><p>Thanks, Poramate!</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"lo2gluku4c8\"><em>This animation shows Perseverance’s point of view during a drive of 807 feet (246 meters) along the rim of Jezero Crater on 10 December 2025, the 1,709th Martian day, or sol, of the mission. Captured over 2 hours and 35 minutes, 53 navigation-camera (Navcam) image pairs were combined with rover data on orientation, wheel speed, and steering angle, as well as data from Perseverance’s inertial measurement unit, and placed into a 3D virtual environment. The result is this reconstruction with virtual frames inserted about every 4 inches (0.1 meters) of drive progress.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"87c1f3217435e9b3f4931fa59fa64683\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/LO2GluKu4C8?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://science.nasa.gov/mission/mars-2020-perseverance/\">NASA Jet Propulsion Lab</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"sx4wkuhap4e\"><em>−47.4 °C, 130,000 steps, 89.75°E, 47.21°N… On the extremely cold snowfields of Altay, the birthplace of human skiing, Unitree’s humanoid robot G1 left behind a unique set of marks.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"c7485e5fd02cbfca05ec835a4a3e766c\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/SX4WKUHAP4E?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.unitree.com/\">Unitree</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"as_ouaft2he\"><em>Representing and understanding 3D environments in a structured manner is crucial for autonomous agents to navigate and reason about their surroundings. In this work, we propose an enhanced hierarchical 3D scene graph that integrates open-vocabulary features across multiple abstraction levels and supports object-relational reasoning. Our approach leverages a vision language model (VLM) to infer semantic relationships. Notably, we introduce a task-reasoning module that combines large language models and a VLM to interpret the scene graph’s semantic and relational information, enabling agents to reason about tasks and interact with their environment more intelligently. We validate our method by deploying it on a quadruped robot in multiple environments and tasks, highlighting its ability to reason about them.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"768f3e1223995648c873b29ea0bac5b3\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/as_oUaFT2hE?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://ntnu-arl.github.io/reasoning_graph/\">Norwegian University of Science & Technology, Autonomous Robots Lab</a> ]</p><p>Thanks, Kostas!</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"hmfgfp9xohq\"><em>We present HoLoArm, a quadrotor with compliant arms inspired by the nodus structure of dragonfly wings. This design provides natural flexibility and resilience while preserving flight stability, which is further reinforced by the integration of a reinforcement-learning control policy that enhances both recovery and hovering performance.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"5096413bf8582da71f43303183472528\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/hmfgFP9XoHQ?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://ieeexplore.ieee.org/abstract/document/11361075\">HO Lab via IEEE Robotics and Automation Letters</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"giijs_mmmrg\"><em>In this work, we present SkyDreamer, to the best of our knowledge the first end-to-end vision-based autonomous-drone racing policy that maps directly from pixel-level representations to motor commands.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"90c32886c61319893e1ba59f4bcf677f\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/GiIjs_MmMrg?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://arxiv.org/pdf/2510.14783\">MAVLab</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"gr867dgh5tk\"><em>This video showcases AI Worker, equipped with five-finger hands, performing dexterous object manipulation across diverse environments. Through teleoperation, the robot demonstrates precise, humanlike hand control in a variety of manipulation tasks.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"126ba42a9ad07785c5c33eae1738c225\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/Gr867DGH5tk?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://ai.robotis.com/hands/introduction_hands.html\">Robotis</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"phomadn-qze\"><em>Autonomous following, 45-degree slope climbing, and reliable payload transport in extreme winter conditions, built to support operations where environments push the limits.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"90a3ca6f001914b8f44f854ed188eb0a\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/pHOmadN-qzE?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.deeprobotics.cn/en\">DEEP Robotics</a> ]</p><div class=\"horizontal-rule\"></div><blockquote class=\"rm-anchors\" id=\"80qqrfmvir0\"><em>Living architectures, from plants to beehives, adapt continuously to their environments through self-organization. In this work, we introduce the concept of architectural swarms: systems that integrate swarm robotics into modular architectural façades. The Swarm Garden exemplifies how architectural swarms can transform the built environment, enabling “living-like” architecture for functional and creative applications.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"3324e87c4f923abd04c61086c8018795\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/80QqrFmvIr0?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.science.org/doi/10.1126/scirobotics.ady7233\">SSR Lab via Science Robotics</a> ]</p><div class=\"horizontal-rule\"></div><p class=\"rm-anchors\" id=\"wxtmqieul0s\">Here are a couple of IROS 2025 keynotes, featuring Bram Vanderborght and Kyu-Jin Cho.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"1589c01bc2c7e94f846550cf18fa08c3\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/WXtMQIeUl0s?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p><br/></p><p class=\"shortcode-media shortcode-media-youtube\"> <span class=\"rm-shortcode\" data-rm-shortcode-id=\"99ea91bbf11816455fe9e3668e4f0c4e\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/j6fEnhU56aA?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span> <small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">- YouTube</small> <small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\"> <a href=\"https://www.youtube.com/watch?v=j6fEnhU56aA\" target=\"_blank\">www.youtube.com</a> </small> </p><p>[ <a href=\"https://www.iros25.org/\">IROS 2025</a> ]</p><div class=\"horizontal-rule\"></div>",
        "contentSnippet": "Video Friday is your weekly selection of awesome robotics videos, collected by your friends at IEEE Spectrum robotics. We also post a weekly calendar of upcoming robotics events for the next few months. Please send us your events for inclusion.\nICRA 2026: 1–5 June 2026, VIENNA\nEnjoy today’s videos!\n\n \nTo train the next generation of autonomous robots, scientists at Toyota Research Institute are working with Toyota Manufacturing to deploy them on the factory floor.\n\n[ Toyota Research Institute ]\nThanks, Erin!\n\nThis is just one story (of many) about how we tried, failed, and learned how to improve our ‪drone delivery system.\n\nOkay, but like you didn’t show the really cool bit...?\n[ Zipline ]\n\nWe’re introducing KinetIQ, an AI framework developed by Humanoid, for end-to-end orchestration of humanoid robot fleets. KinetIQ coordinates wheeled and bipedal robots within a single system, managing both fleet-level operations and individual robot behavior across multiple environments. The framework operates across four cognitive layers, from task allocation and workflow optimization to task execution based on Vision-Language-Action models and whole-body control taught by reinforcement learning, and is shown here running across our wheeled industrial robots and bipedal R&D platform.\n\n[ Humanoid ]\n\nWhat if a robot gets damaged during operation? Can it still perform its mission without immediate repair? Inspired by the self-embodied resilience strategies of stick insects, we developed a decentralized adaptive resilient neural control system (DARCON). This system allows legged robots to autonomously adapt to limb loss, ensuring mission success despite mechanical failure. This innovative approach leads to a future of truly resilient, self-recovering robotics.\n\n[ VISTEC ]\nThanks, Poramate!\n\nThis animation shows Perseverance’s point of view during a drive of 807 feet (246 meters) along the rim of Jezero Crater on 10 December 2025, the 1,709th Martian day, or sol, of the mission. Captured over 2 hours and 35 minutes, 53 navigation-camera (Navcam) image pairs were combined with rover data on orientation, wheel speed, and steering angle, as well as data from Perseverance’s inertial measurement unit, and placed into a 3D virtual environment. The result is this reconstruction with virtual frames inserted about every 4 inches (0.1 meters) of drive progress.\n\n[ NASA Jet Propulsion Lab ]\n\n−47.4 °C, 130,000 steps, 89.75°E, 47.21°N… On the extremely cold snowfields of Altay, the birthplace of human skiing, Unitree’s humanoid robot G1 left behind a unique set of marks.\n\n[ Unitree ]\n\nRepresenting and understanding 3D environments in a structured manner is crucial for autonomous agents to navigate and reason about their surroundings. In this work, we propose an enhanced hierarchical 3D scene graph that integrates open-vocabulary features across multiple abstraction levels and supports object-relational reasoning. Our approach leverages a vision language model (VLM) to infer semantic relationships. Notably, we introduce a task-reasoning module that combines large language models and a VLM to interpret the scene graph’s semantic and relational information, enabling agents to reason about tasks and interact with their environment more intelligently. We validate our method by deploying it on a quadruped robot in multiple environments and tasks, highlighting its ability to reason about them.\n\n[ Norwegian University of Science & Technology, Autonomous Robots Lab ]\nThanks, Kostas!\n\nWe present HoLoArm, a quadrotor with compliant arms inspired by the nodus structure of dragonfly wings. This design provides natural flexibility and resilience while preserving flight stability, which is further reinforced by the integration of a reinforcement-learning control policy that enhances both recovery and hovering performance.\n\n[ HO Lab via IEEE Robotics and Automation Letters ]\n\nIn this work, we present SkyDreamer, to the best of our knowledge the first end-to-end vision-based autonomous-drone racing policy that maps directly from pixel-level representations to motor commands.\n\n[ MAVLab ]\n\nThis video showcases AI Worker, equipped with five-finger hands, performing dexterous object manipulation across diverse environments. Through teleoperation, the robot demonstrates precise, humanlike hand control in a variety of manipulation tasks.\n\n[ Robotis ]\n\nAutonomous following, 45-degree slope climbing, and reliable payload transport in extreme winter conditions, built to support operations where environments push the limits.\n\n[ DEEP Robotics ]\n\nLiving architectures, from plants to beehives, adapt continuously to their environments through self-organization. In this work, we introduce the concept of architectural swarms: systems that integrate swarm robotics into modular architectural façades. The Swarm Garden exemplifies how architectural swarms can transform the built environment, enabling “living-like” architecture for functional and creative applications.\n\n[ SSR Lab via Science Robotics ]\n\nHere are a couple of IROS 2025 keynotes, featuring Bram Vanderborght and Kyu-Jin Cho.\n\n\n\n  - YouTube  www.youtube.com  \n[ IROS 2025 ]",
        "pubDate": "Fri, 06 Feb 2026 17:00:02 +0000",
        "isoDate": "2026-02-06T17:00:02.000Z",
        "creator": "Evan Ackerman",
        "source": "https://spectrum.ieee.org/autonomous-warehouse-robots"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-prjxsa",
        "title": "“Quantum Twins” Simulate What Supercomputers Can’t",
        "link": "https://spectrum.ieee.org/quantum-twins",
        "url": "https://spectrum.ieee.org/quantum-twins",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/three-dimensional-rendering-of-12-sided-polyhedrons-lined-up-in-long-rows-each-polyhedron-is-comprised-of-countless-small-spher.jpg?id=63831528&width=1245&height=700&coordinates=0%2C176%2C0%2C177\"/><br/><br/><p>While quantum computers continue to <a href=\"https://spectrum.ieee.org/neutral-atom-quantum-computing\" target=\"_self\">slowly grind</a> toward usefulness, some are pursuing a different approach—analog <a href=\"https://spectrum.ieee.org/quantum-simulation\" target=\"_self\">quantum simulation</a>. This path doesn’t offer complete control of single bits of quantum information, known as qubits—it is not a universal quantum computer. Instead, quantum simulators directly mimic complex, difficult-to-access things, like individual molecules, chemical reactions, or novel materials. What analog quantum simulation lacks in flexibility, it makes up for in feasibility: quantum simulators are ready now.</p><p>“Instead of using qubits, as you would typically in a quantum computer, we just directly encode the problem into the geometry and structure of the array itself,” says <a href=\"https://www.linkedin.com/in/sam-gorman-b53389243/?originalSubdomain=au\" rel=\"noopener noreferrer\" target=\"_blank\">Sam Gorman</a>, quantum systems engineering lead at Sydney-based startup <a href=\"https://www.sqc.com.au/\" rel=\"noopener noreferrer\" target=\"_blank\">Silicon Quantum Computing</a>.</p><p>Yesterday, Silicon Quantum Computing unveiled its Quantum Twins product, a silicon quantum simulator, which is now available to customers through direct contract. Simultaneously, the team demonstrated that their device, made up of 15,000 quantum dots, can simulate an often-studied transition of a material from an insulator to a metal, and all the states between. They <a href=\"https://www.nature.com/articles/s41586-025-10053-7\" rel=\"noopener noreferrer\" target=\"_blank\">published</a> their work this week in the journal <em><em>Nature</em></em>.</p><p>“We can do things now that we think nobody else in the world can do,” Gorman says. </p><h2>The Powerful Process</h2><p>Though the product announcement came yesterday, the team at Silicon Quantum Computing established its Precision Atom Qubit Manufacturing process following the startup’s establishment in 2017, building on the academic work that the company’s founder, <a href=\"https://en.wikipedia.org/wiki/Michelle_Simmons\" rel=\"noopener noreferrer\" target=\"_blank\">Michelle Simmons</a>, led for over 25 years. The underlying technology is a manufacturing process for placing single phosphorus atoms in silicon with subnanometer precision.</p><p>“We have a 38-stage process,” Simmons says, for patterning phosphorus atoms into silicon. The process starts with a silicon substrate, which gets coated with a layer of hydrogen. Then, by means of a scanning-tunneling microscope, individual hydrogen atoms are knocked off the surface, exposing the silicon underneath. The surface is then dosed with phosphine gas, which adsorbs to the surface only in places where the silicon is exposed. With the help of a low-temperature thermal anneal, the phosphorus atom is then incorporated into the silicon crystal. Then, layers of silicon are grown on top.</p><p>“It’s done in ultrahigh vacuum. So it’s a very pure, very clean system,” Simmons says. “It’s a fully monolithic chip that we make with that subnanometer precision. In 2014, we figured out how to make markers in the chip so that we can then come back and find where we put the atoms within the device to make contacts. Those contacts are then made at the same length scale as the atoms and dots.”</p><p>Though the team is able to place single atoms of phosphorus, they use clusters of 10 to 50 such atoms to make up what’s known as a register for these application-specific chips. These registers act like <a href=\"https://spectrum.ieee.org/what-the-heck-are-quantum-dots\" target=\"_blank\">quantum dots</a>, preserving quantum properties of the individual atoms. The registers are controlled by a gate voltage from contacts placed atop the chip, and interactions between registers can be tuned by precisely controlling the distances between them.</p><p>While the company is also <a href=\"https://www.nature.com/articles/s41565-024-01853-5\" rel=\"noopener noreferrer\" target=\"_blank\">pursuing</a> more traditional quantum computing using this technology, they realized they already had the capacity to do useful simulations in the analog domain by putting thousands of registers on a single chip and measuring global properties, without controlling individual qubits.</p><p>“The thing that’s quite unique is we can do that very quickly,” Simmons says. “We put 250,000 of these registers [on a chip] in 8 hours, and we can turn a chip design around in a week.”</p><h2>What to Simulate</h2><p>Back in 2022, the team at Silicon Quantum Computing used a previous version of this same technology to <a href=\"https://www.nature.com/articles/s41586-022-04706-0\" rel=\"noopener noreferrer\" target=\"_blank\">simulate</a> a molecule of polyacetylene. The chemical is made up of carbon atoms with alternating single and double bonds, and, crucially, its conductivity changes drastically depending on whether the chain is cut on a single or double bond. In order to accurately simulate single and double carbon bonds, the team had to control the distances of their registers to subnanometer precision. By tuning the gate voltages of each quantum dot, the researchers reproduced the jump in conductivity.</p><p>Now, they’ve demonstrated the quantum twin technology on a much larger problem—the <a href=\"https://en.wikipedia.org/wiki/Mott_insulator\" rel=\"noopener noreferrer\" target=\"_blank\">metal-insulator transition</a> of a two-dimensional material. Where the polyacetylene molecule required 10 registers, the new model used 15,000. The metal-insulator model is important because, in most cases, it cannot be simulated on a classical computer. At the extremes—in the fully metal or fully insulating phase—the physics can be simplified and made accessible to classical computing. But in the murky intermediate regime, the full quantum complexity of each electron plays a role, and the problem is classically intractable. “That is the part which is challenging for classical computing. But we can actually put our system into this regime quite easily,” Gorman says.</p><p>The metal-insulator model was a proof of concept. Now, Gorman says, the team can design a quantum twin for almost any two-dimensional problem.</p><p>“Now that we’ve demonstrated that the device is behaving as we predict, we’re looking at high-impact issues or outstanding problems,” says Gorman. The team plans to investigate things like unconventional superconductivity, the origins of magnetism, and materials interfaces such as those that occur in batteries. </p><p>Although the initial applications will most likely be in the scientific domain, Simmons is hopeful that Quantum Twins will eventually be useful for industrial applications such as drug discovery. “If you look at different drugs, they’re actually very similar to polyacetylene. They’re carbon chains, and they have functional groups. So, understanding how to map it [onto our simulator] is a unique challenge. But that’s definitely an area we’re going to focus on,” she says. “We’re excited at the potential possibilities.”</p>",
        "contentSnippet": "While quantum computers continue to slowly grind toward usefulness, some are pursuing a different approach—analog quantum simulation. This path doesn’t offer complete control of single bits of quantum information, known as qubits—it is not a universal quantum computer. Instead, quantum simulators directly mimic complex, difficult-to-access things, like individual molecules, chemical reactions, or novel materials. What analog quantum simulation lacks in flexibility, it makes up for in feasibility: quantum simulators are ready now.\n“Instead of using qubits, as you would typically in a quantum computer, we just directly encode the problem into the geometry and structure of the array itself,” says Sam Gorman, quantum systems engineering lead at Sydney-based startup Silicon Quantum Computing.\nYesterday, Silicon Quantum Computing unveiled its Quantum Twins product, a silicon quantum simulator, which is now available to customers through direct contract. Simultaneously, the team demonstrated that their device, made up of 15,000 quantum dots, can simulate an often-studied transition of a material from an insulator to a metal, and all the states between. They published their work this week in the journal Nature.\n“We can do things now that we think nobody else in the world can do,” Gorman says. \nThe Powerful Process\nThough the product announcement came yesterday, the team at Silicon Quantum Computing established its Precision Atom Qubit Manufacturing process following the startup’s establishment in 2017, building on the academic work that the company’s founder, Michelle Simmons, led for over 25 years. The underlying technology is a manufacturing process for placing single phosphorus atoms in silicon with subnanometer precision.\n“We have a 38-stage process,” Simmons says, for patterning phosphorus atoms into silicon. The process starts with a silicon substrate, which gets coated with a layer of hydrogen. Then, by means of a scanning-tunneling microscope, individual hydrogen atoms are knocked off the surface, exposing the silicon underneath. The surface is then dosed with phosphine gas, which adsorbs to the surface only in places where the silicon is exposed. With the help of a low-temperature thermal anneal, the phosphorus atom is then incorporated into the silicon crystal. Then, layers of silicon are grown on top.\n“It’s done in ultrahigh vacuum. So it’s a very pure, very clean system,” Simmons says. “It’s a fully monolithic chip that we make with that subnanometer precision. In 2014, we figured out how to make markers in the chip so that we can then come back and find where we put the atoms within the device to make contacts. Those contacts are then made at the same length scale as the atoms and dots.”\nThough the team is able to place single atoms of phosphorus, they use clusters of 10 to 50 such atoms to make up what’s known as a register for these application-specific chips. These registers act like quantum dots, preserving quantum properties of the individual atoms. The registers are controlled by a gate voltage from contacts placed atop the chip, and interactions between registers can be tuned by precisely controlling the distances between them.\nWhile the company is also pursuing more traditional quantum computing using this technology, they realized they already had the capacity to do useful simulations in the analog domain by putting thousands of registers on a single chip and measuring global properties, without controlling individual qubits.\n“The thing that’s quite unique is we can do that very quickly,” Simmons says. “We put 250,000 of these registers [on a chip] in 8 hours, and we can turn a chip design around in a week.”\nWhat to Simulate\nBack in 2022, the team at Silicon Quantum Computing used a previous version of this same technology to simulate a molecule of polyacetylene. The chemical is made up of carbon atoms with alternating single and double bonds, and, crucially, its conductivity changes drastically depending on whether the chain is cut on a single or double bond. In order to accurately simulate single and double carbon bonds, the team had to control the distances of their registers to subnanometer precision. By tuning the gate voltages of each quantum dot, the researchers reproduced the jump in conductivity.\nNow, they’ve demonstrated the quantum twin technology on a much larger problem—the metal-insulator transition of a two-dimensional material. Where the polyacetylene molecule required 10 registers, the new model used 15,000. The metal-insulator model is important because, in most cases, it cannot be simulated on a classical computer. At the extremes—in the fully metal or fully insulating phase—the physics can be simplified and made accessible to classical computing. But in the murky intermediate regime, the full quantum complexity of each electron plays a role, and the problem is classically intractable. “That is the part which is challenging for classical computing. But we can actually put our system into this regime quite easily,” Gorman says.\nThe metal-insulator model was a proof of concept. Now, Gorman says, the team can design a quantum twin for almost any two-dimensional problem.\n“Now that we’ve demonstrated that the device is behaving as we predict, we’re looking at high-impact issues or outstanding problems,” says Gorman. The team plans to investigate things like unconventional superconductivity, the origins of magnetism, and materials interfaces such as those that occur in batteries. \nAlthough the initial applications will most likely be in the scientific domain, Simmons is hopeful that Quantum Twins will eventually be useful for industrial applications such as drug discovery. “If you look at different drugs, they’re actually very similar to polyacetylene. They’re carbon chains, and they have functional groups. So, understanding how to map it [onto our simulator] is a unique challenge. But that’s definitely an area we’re going to focus on,” she says. “We’re excited at the potential possibilities.”",
        "pubDate": "Thu, 05 Feb 2026 16:00:02 +0000",
        "isoDate": "2026-02-05T16:00:02.000Z",
        "creator": "Dina Genkina",
        "source": "https://spectrum.ieee.org/quantum-twins"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-ye4pdr",
        "title": "Paying Tribute to Finite Element Field Computation Pioneer",
        "link": "https://spectrum.ieee.org/tribute-finite-element-field-computation-pioneer",
        "url": "https://spectrum.ieee.org/tribute-finite-element-field-computation-pioneer",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/smiling-portrait-of-mvk-chari-wearing-a-tweed-jacket-and-tie.jpg?id=63831506&width=1245&height=700&coordinates=0%2C187%2C0%2C188\"/><br/><br/><p><a href=\"https://www.legacy.com/us/obituaries/name/madabushi-krishnama-chari-obituary?id=60210616\" rel=\"noopener noreferrer\" target=\"_blank\">MVK Chari</a>,<strong> </strong>a pioneer in finite element field computation, died on 3 December. The IEEE Life Fellow was 97.</p><p>Chari developed a finite element method (FEM) for analyzing nonlinear electromagnetic fields—which is crucial for the design of electric machines. The technique is used to obtain approximate solutions to complex engineering and mathematical problems. It involves dividing a complicated object or system into smaller, more manageable parts, known as <em><em>finite elements</em></em>, according to <a href=\"https://www.fictiv.com/articles/understanding-the-finite-element-method#:~:text=The%20Finite%20Element%20Method%20(FEM,behavior%20of%20these%20individual%20elements.\" rel=\"noopener noreferrer\" target=\"_blank\">Fictiv</a>.</p><p>As an engineer and technical leader at <a href=\"https://www.ge.com/about-us\" rel=\"noopener noreferrer\" target=\"_blank\">General Electric</a> in Niskayuna, N.Y., Chari used the tool to analyze large turbogenerators for end region analysis, starting with 2D and expanding its use over time to quasi-2D and 3D.</p><p>During his 25 years at GE, he established a team that was developing finite element analysis (FEA) tools for a variety of applications across the company. They ranged from small motors to large <a href=\"https://spectrum.ieee.org/mri\" target=\"_self\">MRI magnets</a>.</p><p>Chari received the 1993 <a href=\"https://corporate-awards.ieee.org/award/ieee-nikola-tesla-award/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Nikola Tesla Award</a> for “pioneering contributions to finite element computations of nonlinear electromagnetic fields for design and analysis of electric machinery.”</p><h2>A career spanning industry and academia</h2><p>Chari attended <a href=\"https://www.imperial.ac.uk/\" rel=\"noopener noreferrer\" target=\"_blank\">Imperial College London</a> to pursue a master’s degree in electrical engineering. There he met <a href=\"https://en.wikipedia.org/wiki/Peter_P._Silvester\" rel=\"noopener noreferrer\" target=\"_blank\">Peter P. Silvester</a>, a visiting professor of electrical engineering. Silvester, a professor at <a href=\"https://www.mcgill.ca/\" rel=\"noopener noreferrer\" target=\"_blank\">McGill University</a> in Montreal, was a pioneer in understanding numerical analysis of electromagnetic fields.</p><p>After Chari graduated in 1968, he joined Silvester at McGill as a doctoral student, applying FEM to solve electromagnetic field problems. Silvester applied the method to waveguides, while Chari applied it to saturated magnetic fields. </p><p>Chari joined GE in 1970 after earning his Ph.D. in electrical engineering. He climbed the leadership ladder and was a manager of the company’s electromagnetics division when he left in 1995. He joined <a href=\"https://www.rpi.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Rensselaer Polytechnic Institute</a> in Troy, N.Y., as a visiting research and adjunct professor in its electrical, computer, and systems engineering department. Chari taught graduate and undergraduate classes in electric power engineering and <a href=\"https://spectrum.ieee.org/advice-leading-mentoring-greater-innovation\" target=\"_self\">mentored</a> many master’s and doctoral students. His strength was nurturing young engineers. </p><p>He also conducted research on electric machines and transformers for the <a href=\"https://www.epri.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Electric Power Research Institute</a> and the U.S. <a href=\"https://www.energy.gov/\" rel=\"noopener noreferrer\" target=\"_blank\">Department of Energy</a>. </p><p> In 2008 Chari joined <a href=\"https://www.ndt.org/vendor.asp?ObjectID=21373\" rel=\"noopener noreferrer\" target=\"_blank\">Magsoft Corp.</a>, in Clifton Park, N.Y., and conducted advanced work on specialized software for the <a href=\"https://www.navy.mil/\" rel=\"noopener noreferrer\" target=\"_blank\">U.S. Navy</a> until his retirement in 2016.</p><h2>Remembering a friend</h2><p>Chari successfully nominated one of us (Hoole) to be elevated to IEEE Fellow at the age of 40. He helped launch Haran’s career when Chari sent his résumé to GE hiring managers for a position in its applied superconductivity lab.</p><p>Chari’s commitment to people came from his family background. His father—<a href=\"https://en.wikipedia.org/wiki/M._A._Ayyangar\" rel=\"noopener noreferrer\" target=\"_blank\">M.A. Ayyangar</a>—was known throughout India as a freedom fighter, mathematician, and eventually the speaker of the Indian Parliament’s lower house under <a href=\"https://en.wikipedia.org/wiki/Jawaharlal_Nehru\" rel=\"noopener noreferrer\" target=\"_blank\">Prime Minister Nehru</a>. Chari’s wife, Padma, was a physician in New York.</p><p>From Chari’s illustrious family, he was at the peak of South India (<a href=\"https://en.wikipedia.org/wiki/Tamils\" rel=\"noopener noreferrer\" target=\"_blank\">Tamil</a>) society.</p><p>Chari would fondly and cheerfully tell us the story behind his name. Around the time of his birth, it was common in Tamil society not to have formal names. He went by the informal “house name” Kannah (a term of endearment for <a href=\"https://en.wikipedia.org/wiki/Krishna\" rel=\"noopener noreferrer\" target=\"_blank\">Krishna</a>). When it was time for Chari to start school, an auspicious uncle enrolled him. But Chari had no formal name, so the uncle took it upon himself to give him one. He asked Chari if he would like a long or short name, to which he said long. So the uncle named him Madabushi Venkadamachari.</p><p>When Chari moved to North America, he shortened his name to Madabushi V.K.</p><p>He could also laugh at himself.</p><p>A stellar scientist, he also was a role model, guide, and friend to many of us. We thank God for him.</p>",
        "contentSnippet": "MVK Chari, a pioneer in finite element field computation, died on 3 December. The IEEE Life Fellow was 97.\nChari developed a finite element method (FEM) for analyzing nonlinear electromagnetic fields—which is crucial for the design of electric machines. The technique is used to obtain approximate solutions to complex engineering and mathematical problems. It involves dividing a complicated object or system into smaller, more manageable parts, known as finite elements, according to Fictiv.\nAs an engineer and technical leader at General Electric in Niskayuna, N.Y., Chari used the tool to analyze large turbogenerators for end region analysis, starting with 2D and expanding its use over time to quasi-2D and 3D.\nDuring his 25 years at GE, he established a team that was developing finite element analysis (FEA) tools for a variety of applications across the company. They ranged from small motors to large MRI magnets.\nChari received the 1993 IEEE Nikola Tesla Award for “pioneering contributions to finite element computations of nonlinear electromagnetic fields for design and analysis of electric machinery.”\nA career spanning industry and academia\nChari attended Imperial College London to pursue a master’s degree in electrical engineering. There he met Peter P. Silvester, a visiting professor of electrical engineering. Silvester, a professor at McGill University in Montreal, was a pioneer in understanding numerical analysis of electromagnetic fields.\nAfter Chari graduated in 1968, he joined Silvester at McGill as a doctoral student, applying FEM to solve electromagnetic field problems. Silvester applied the method to waveguides, while Chari applied it to saturated magnetic fields. \nChari joined GE in 1970 after earning his Ph.D. in electrical engineering. He climbed the leadership ladder and was a manager of the company’s electromagnetics division when he left in 1995. He joined Rensselaer Polytechnic Institute in Troy, N.Y., as a visiting research and adjunct professor in its electrical, computer, and systems engineering department. Chari taught graduate and undergraduate classes in electric power engineering and mentored many master’s and doctoral students. His strength was nurturing young engineers. \nHe also conducted research on electric machines and transformers for the Electric Power Research Institute and the U.S. Department of Energy. \n In 2008 Chari joined Magsoft Corp., in Clifton Park, N.Y., and conducted advanced work on specialized software for the U.S. Navy until his retirement in 2016.\nRemembering a friend\nChari successfully nominated one of us (Hoole) to be elevated to IEEE Fellow at the age of 40. He helped launch Haran’s career when Chari sent his résumé to GE hiring managers for a position in its applied superconductivity lab.\nChari’s commitment to people came from his family background. His father—M.A. Ayyangar—was known throughout India as a freedom fighter, mathematician, and eventually the speaker of the Indian Parliament’s lower house under Prime Minister Nehru. Chari’s wife, Padma, was a physician in New York.\nFrom Chari’s illustrious family, he was at the peak of South India (Tamil) society.\nChari would fondly and cheerfully tell us the story behind his name. Around the time of his birth, it was common in Tamil society not to have formal names. He went by the informal “house name” Kannah (a term of endearment for Krishna). When it was time for Chari to start school, an auspicious uncle enrolled him. But Chari had no formal name, so the uncle took it upon himself to give him one. He asked Chari if he would like a long or short name, to which he said long. So the uncle named him Madabushi Venkadamachari.\nWhen Chari moved to North America, he shortened his name to Madabushi V.K.\nHe could also laugh at himself.\nA stellar scientist, he also was a role model, guide, and friend to many of us. We thank God for him.",
        "pubDate": "Wed, 04 Feb 2026 19:00:02 +0000",
        "isoDate": "2026-02-04T19:00:02.000Z",
        "creator": "Sheppard J. Salon",
        "source": "https://spectrum.ieee.org/tribute-finite-element-field-computation-pioneer"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-gnweux",
        "title": "Milan-Cortina Winter Olympics Debut Next-Generation Sports Smarts",
        "link": "https://spectrum.ieee.org/winter-olympics-2026-tech",
        "url": "https://spectrum.ieee.org/winter-olympics-2026-tech",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/silhouettes-of-a-twirling-figure-skater-and-a-ski-jumper-against-a-dark-background.jpg?id=63783716&width=1245&height=700&coordinates=0%2C62%2C0%2C63\"/><br/><br/><p>From 6–22 February, the 2026 <a href=\"https://www.olympics.com/en/milano-cortina-2026\" target=\"_blank\">Winter Olympics in Milan-Cortina d’Ampezzo</a>, Italy, will feature not just the world’s top winter athletes but also some of the most advanced sports technologies today. At the <a href=\"https://www.olympics.com/en/olympic-games/cortina-d-ampezzo-1956\" target=\"_blank\">first Cortina Olympics</a>, in 1956, the Swiss company <a href=\"https://en.wikipedia.org/wiki/Omega_SA\" target=\"_blank\">Omega</a>—based in <a href=\"https://en.wikipedia.org/wiki/Biel/Bienne\" target=\"_blank\">Biel/Bienne</a>—introduced electronic ski starting gates and launched the first automated timing tech of its kind.</p><p><span>At this year’s Olympics, <a href=\"https://en.wikipedia.org/wiki/The_Swatch_Group#Sport_and_event_timing\" target=\"_blank\">Swiss Timing</a>,</span><span> sister company to Omega under the parent company <a href=\"https://www.swatchgroup.com/en\" target=\"_blank\">Swatch Group</a>, unveils a new generation of <a href=\"https://spectrum.ieee.org/tag/motion-capture\" target=\"_self\"><span><span>motion-analysis</span></span></a> and <a href=\"https://spectrum.ieee.org/tag/computer-vision\" target=\"_self\"><span><span>computer-vision</span></span></a> technology. The new technologies on offer include photo-finish cameras that capture up to 40,000 images per second. </span></p><p>“We work very closely with athletes,” says <a href=\"https://www.swisstiming.com/\" target=\"_blank\"><span><span>Swiss Timing</span></span></a> CEO <a href=\"https://www.linkedin.com/in/alain-zobrist-2b3a36a/?originalSubdomain=ch\" target=\"_blank\"><span>Alain Zobrist</span></a>, who has overseen Olympic timekeeping since the <a href=\"https://www.olympics.com/ioc/legacy-torino-2006\" target=\"_blank\"><span><span>winter games of 2006 in Torino</span></span></a>. “They are the primary customers of our technology and services, and they need to understand how our systems work in order to trust them.”</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"Live data capture of a figure skater's performance, with a 3D rendering of the athlete, jump heights and more.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"b3f4b7d6aa8a6f1471fd6ff98085f8ca\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"80fab\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/live-data-capture-of-a-figure-skater-s-performance-with-a-3d-rendering-of-the-athlete-jump-heights-and-more.jpg?id=63784021&width=980\"/> <small class=\"image-media media-caption\" data-gramm=\"false\" data-lt-tmp-id=\"lt-691557\" placeholder=\"Add Photo Caption...\" spellcheck=\"false\">Using high-resolution cameras and AI algorithms tuned to skaters’ routines, Milan-Cortina Olympic officials expect new figure-skating tech to be a key highlight of the games.  </small><small class=\"image-media media-photo-credit\" data-gramm=\"false\" data-lt-tmp-id=\"lt-586243\" placeholder=\"Add Photo Credit...\" spellcheck=\"false\">Omega</small></p><h3>Figure-Skating Tech Completes the Rotation</h3><p><span><a href=\"https://www.olympics.com/en/milano-cortina-2026/sports/figure-skating\" target=\"_blank\">Figure skating</a></span>, the Winter Olympics’ biggest TV draw, is receiving a substantial upgrade at Milano Cortina 2026.</p><p>Fourteen <a href=\"https://en.wikipedia.org/wiki/8K_resolution\" target=\"_blank\"><span>8K-resolution cameras</span></a> positioned around the rink will capture every skater’s movement. <span>“We use proprietary software to interpret the images and visualize athlete movement in a 3D model,” says Zobrist. “AI processes the data so we can track trajectory, position, and movement across all three axes—x, y, and z.”</span></p><p><span>The system measures jump heights, air times, and landing speeds in real time, producing heat maps and graphic overlays that break down each program—all instantaneously. “The time it takes for us to measure the data, until we show a matrix on TV with a graphic, this whole chain needs to take less than 1/10 of a second,” Zobrist says.</span></p><h3></h3><br/><div class=\"rblad-ieee_in_content\"></div><p>A range of different AI models helps the broadcasters and commentators process each skater’s every move on the ice.</p><p><span>“There is an AI that helps our computer-vision system do pose estimation,” he says. “So we have a camera that is filming what is happening, and an AI that helps the camera understand what it’s looking at. And then there is a second type of AI, which is more similar to a large language model that makes sense of the data that we collect.”</span></p><p>Among the features that Swiss Timing’s new systems provide is blade-angle detection, which gives judges precise technical data to augment their technical and aesthetic decisions. Zobrist says future versions will also determine whether a given rotation is complete, so that “if the rotation is 355 degrees, there is going to be a deduction,” he says.</p><p>This builds on technology Omega unveiled at the <a href=\"https://en.wikipedia.org/wiki/2024_Summer_Olympics\" target=\"_blank\"><span>2024 Paris Olympics</span></a> for diving, where cameras measured distances between a diver’s head and the board to help judges assess points and penalties to be awarded.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\"> <img alt=\"Three dimensional rendering of a ski jumper preparing for dismount on a tall slope.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"16a88f6b65d50df446ca4a9b56b5009a\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"6fe22\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/three-dimensional-rendering-of-a-ski-jumper-preparing-for-dismount-on-a-tall-slope.jpg?id=63783856&width=980\"/> <small class=\"image-media media-caption\" data-gramm=\"false\" data-lt-tmp-id=\"lt-172123\" placeholder=\"Add Photo Caption...\" spellcheck=\"false\">At the 2026 Winter Olympics, ski jumping will feature both camera-based and sensor-based technologies to make the aerial experience more immediate and real-time. </small><small class=\"image-media media-photo-credit\" data-gramm=\"false\" data-lt-tmp-id=\"lt-922547\" placeholder=\"Add Photo Credit...\" spellcheck=\"false\">Omega</small></p><h3>Ski-Jumping Tech Finds Make-or-Break Moments</h3><p>Unlike figure skating’s camera-based approach, <a href=\"https://www.olympics.com/en/milano-cortina-2026/sports/ski-jumping\" target=\"_blank\"><span>ski jumping</span></a> also relies on physical <a href=\"https://spectrum.ieee.org/search/?q=camera&topic=sensors&order=newest\" target=\"_self\"><span>sensors</span></a>.</p><p>“In ski jumping, we use a small, lightweight sensor attached to each ski, one sensor per ski, not on the athlete’s body,” Zobrist says. The sensors are lightweight and broadcast data on a skier’s speed, acceleration, and positioning in the air. The technology also correlates performance data with wind conditions, revealing the influence of environmental factors <span>on each jump.</span></p><p>High-speed cameras also track each ski jumper. Then, a stroboscopic camera provides body position time-lapses throughout the jump.</p><p>“The first 20 to 30 meters after takeoff are crucial as athletes move into a V position and lean forward,” Zobrist says. “And both the timing and precision of this movement strongly influence performance.”</p><p>The system reveals biomechanical characteristics in real time, he adds, showing how athletes position their bodies during every moment of the takeoff process. The most common mistake in flight position, over-rotation or under-rotation, can now be detailed and diagnosed with precision on every jump.</p><h3>Bobsleigh: Pushing the Line on the Photo Finish</h3><p>This year’s Olympics will also feature a “virtual photo finish,” providing comparison images of when different sleds cross the finish line over previous runs.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\"> <img alt=\"Red Omega camera with large lens, under a sleek hood, set against a black background.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"247107848870b201556938d35e8e282a\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"816ed\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/red-omega-camera-with-large-lens-under-a-sleek-hood-set-against-a-black-background.jpg?id=63784093&width=980\"/> <small class=\"image-media media-caption\" data-gramm=\"false\" data-lt-tmp-id=\"lt-951245\" placeholder=\"Add Photo Caption...\" spellcheck=\"false\">Omega’s cameras will provide virtual photo finishes at the 2026 Winter Olympics. </small><small class=\"image-media media-photo-credit\" data-gramm=\"false\" data-lt-tmp-id=\"lt-505041\" placeholder=\"Add Photo Credit...\" spellcheck=\"false\">Omega</small></p><p>“We virtually build a photo finish that shows different sleds from different runs on a single visual reference,” says Zobrist.</p><p>After each run, composite images show the margins separating performances. However, more tried-and-true technology still generates official results. A Swiss Timing score, he says, still comes courtesy of <a data-linked-post=\"2653906650\" href=\"https://spectrum.ieee.org/a-century-ago-the-optophone-allowed-blind-people-to-hear-the-printed-word\" target=\"_blank\">photoelectric cells</a>, devices that emit light beams across the finish line and stop the clock when broken. The company offers its virtual photo finish, by contrast, as a visualization tool for spectators and commentators.</p><p>In bobsleigh, as in every timed Winter Olympic event, the line between triumph and heartbreak is sometimes measured in milliseconds or even shorter time intervals. Such precision will, Zobrist says, stem from <a href=\"https://swisswatches-magazine.com/omegas-timekeeping-lab/\" target=\"_blank\">Omega’s Quantum Timer</a>.</p><p>“We can measure time to the millionth of a second, so six digits after the comma, with a deviation of about 23 nanoseconds over 24 hours,” Zobrist explained. “These devices are constantly calibrated and used across all timed sports.”</p>",
        "contentSnippet": "From 6–22 February, the 2026 Winter Olympics in Milan-Cortina d’Ampezzo, Italy, will feature not just the world’s top winter athletes but also some of the most advanced sports technologies today. At the first Cortina Olympics, in 1956, the Swiss company Omega—based in Biel/Bienne—introduced electronic ski starting gates and launched the first automated timing tech of its kind.\nAt this year’s Olympics, Swiss Timing, sister company to Omega under the parent company Swatch Group, unveils a new generation of motion-analysis and computer-vision technology. The new technologies on offer include photo-finish cameras that capture up to 40,000 images per second. \n“We work very closely with athletes,” says Swiss Timing CEO Alain Zobrist, who has overseen Olympic timekeeping since the winter games of 2006 in Torino. “They are the primary customers of our technology and services, and they need to understand how our systems work in order to trust them.”\n  Using high-resolution cameras and AI algorithms tuned to skaters’ routines, Milan-Cortina Olympic officials expect new figure-skating tech to be a key highlight of the games.  Omega\nFigure-Skating Tech Completes the Rotation\nFigure skating, the Winter Olympics’ biggest TV draw, is receiving a substantial upgrade at Milano Cortina 2026.\nFourteen 8K-resolution cameras positioned around the rink will capture every skater’s movement. “We use proprietary software to interpret the images and visualize athlete movement in a 3D model,” says Zobrist. “AI processes the data so we can track trajectory, position, and movement across all three axes—x, y, and z.”\nThe system measures jump heights, air times, and landing speeds in real time, producing heat maps and graphic overlays that break down each program—all instantaneously. “The time it takes for us to measure the data, until we show a matrix on TV with a graphic, this whole chain needs to take less than 1/10 of a second,” Zobrist says.\n\n\n\nA range of different AI models helps the broadcasters and commentators process each skater’s every move on the ice.\n“There is an AI that helps our computer-vision system do pose estimation,” he says. “So we have a camera that is filming what is happening, and an AI that helps the camera understand what it’s looking at. And then there is a second type of AI, which is more similar to a large language model that makes sense of the data that we collect.”\nAmong the features that Swiss Timing’s new systems provide is blade-angle detection, which gives judges precise technical data to augment their technical and aesthetic decisions. Zobrist says future versions will also determine whether a given rotation is complete, so that “if the rotation is 355 degrees, there is going to be a deduction,” he says.\nThis builds on technology Omega unveiled at the 2024 Paris Olympics for diving, where cameras measured distances between a diver’s head and the board to help judges assess points and penalties to be awarded.\n  At the 2026 Winter Olympics, ski jumping will feature both camera-based and sensor-based technologies to make the aerial experience more immediate and real-time. Omega\nSki-Jumping Tech Finds Make-or-Break Moments\nUnlike figure skating’s camera-based approach, ski jumping also relies on physical sensors.\n“In ski jumping, we use a small, lightweight sensor attached to each ski, one sensor per ski, not on the athlete’s body,” Zobrist says. The sensors are lightweight and broadcast data on a skier’s speed, acceleration, and positioning in the air. The technology also correlates performance data with wind conditions, revealing the influence of environmental factors on each jump.\nHigh-speed cameras also track each ski jumper. Then, a stroboscopic camera provides body position time-lapses throughout the jump.\n“The first 20 to 30 meters after takeoff are crucial as athletes move into a V position and lean forward,” Zobrist says. “And both the timing and precision of this movement strongly influence performance.”\nThe system reveals biomechanical characteristics in real time, he adds, showing how athletes position their bodies during every moment of the takeoff process. The most common mistake in flight position, over-rotation or under-rotation, can now be detailed and diagnosed with precision on every jump.\nBobsleigh: Pushing the Line on the Photo Finish\nThis year’s Olympics will also feature a “virtual photo finish,” providing comparison images of when different sleds cross the finish line over previous runs.\n  Omega’s cameras will provide virtual photo finishes at the 2026 Winter Olympics. Omega\n“We virtually build a photo finish that shows different sleds from different runs on a single visual reference,” says Zobrist.\nAfter each run, composite images show the margins separating performances. However, more tried-and-true technology still generates official results. A Swiss Timing score, he says, still comes courtesy of photoelectric cells, devices that emit light beams across the finish line and stop the clock when broken. The company offers its virtual photo finish, by contrast, as a visualization tool for spectators and commentators.\nIn bobsleigh, as in every timed Winter Olympic event, the line between triumph and heartbreak is sometimes measured in milliseconds or even shorter time intervals. Such precision will, Zobrist says, stem from Omega’s Quantum Timer.\n“We can measure time to the millionth of a second, so six digits after the comma, with a deviation of about 23 nanoseconds over 24 hours,” Zobrist explained. “These devices are constantly calibrated and used across all timed sports.”",
        "pubDate": "Wed, 04 Feb 2026 17:03:54 +0000",
        "isoDate": "2026-02-04T17:03:54.000Z",
        "creator": "Maurizio Arseni",
        "source": "https://spectrum.ieee.org/winter-olympics-2026-tech"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-y410n",
        "title": "Breaking Boundaries in Wireless Communication",
        "link": "https://content.knowledgehub.wiley.com/breaking-boundaries-in-wireless-communication-simulating-animated-on-body-rf-propagation/",
        "url": "https://content.knowledgehub.wiley.com/breaking-boundaries-in-wireless-communication-simulating-animated-on-body-rf-propagation/",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/blue-remcom-text-with-orange-circle-and-arc-design-above-the-letter-o.png?id=63752871&width=980\"/><br/><br/><p>This paper discusses how RF propagation simulations empower engineers to test numerous real-world use cases in far less time, and at lower costs, than in situ testing alone. Learn how simulations provide a powerful visual aid and offer valuable insights to improve the performance and design of body-worn wireless devices.</p><p><span><a href=\"https://content.knowledgehub.wiley.com/breaking-boundaries-in-wireless-communication-simulating-animated-on-body-rf-propagation/\" target=\"_blank\">Download this free whitepaper now!</a></span></p>",
        "contentSnippet": "This paper discusses how RF propagation simulations empower engineers to test numerous real-world use cases in far less time, and at lower costs, than in situ testing alone. Learn how simulations provide a powerful visual aid and offer valuable insights to improve the performance and design of body-worn wireless devices.\nDownload this free whitepaper now!",
        "pubDate": "Tue, 03 Feb 2026 15:58:27 +0000",
        "isoDate": "2026-02-03T15:58:27.000Z",
        "creator": "Remcom",
        "source": "https://content.knowledgehub.wiley.com/breaking-boundaries-in-wireless-communication-simulating-animated-on-body-rf-propagation/"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-mb46o6",
        "title": "AI Hunts for the Next Big Thing in Physics",
        "link": "https://spectrum.ieee.org/particle-physics-ai",
        "url": "https://spectrum.ieee.org/particle-physics-ai",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/circular-and-spiral-tracks-are-shown-as-light-blue-lines-against-a-darker-blue-background.jpg?id=63686429&width=1245&height=700&coordinates=0%2C62%2C0%2C63\"/><br/><br/><p><span><strong>In 1930, a young physicist</strong> named Carl D. Anderson was tasked by his mentor with measuring the energies of cosmic rays—particles arriving at high speed from outer space. Anderson built an improved version of a cloud chamber, a device that visually records the trajectories of particles. In 1932, he saw evidence that confusingly combined the properties of protons and electrons. “A situation began to develop that had its awkward aspects,” he wrote many years after winning a Nobel Prize at the age of 31. Anderson had accidentally discovered antimatter.</span></p><div class=\"rm-embed embed-media\"><iframe height=\"110px\" id=\"noa-web-audio-player\" src=\"https://embed-player.newsoveraudio.com/v4?key=q5m19e&id=https://spectrum.ieee.org/particle-physics-ai&bgColor=F5F5F5&color=1b1b1c&playColor=1b1b1c&progressBgColor=F5F5F5&progressBorderColor=bdbbbb&titleColor=1b1b1c&timeColor=1b1b1c&speedColor=1b1b1c&noaLinkColor=556B7D&noaLinkHighlightColor=FF4B00&feedbackButton=true\" style=\"border: none\" width=\"100%\"></iframe></div><p><span>Four years after his first discovery, he codiscovered another elementary particle, the muon. This one prompted one physicist to ask, “Who ordered that?”</span></p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-float-left rm-resized-container rm-resized-container-25\" data-rm-resized-container=\"25%\" style=\"float: left;\"> <img alt=\"a photo shows a man in a suit sitting beside a large laboratory apparatus.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"86790a8a0ef4f037ac318b672c036c03\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"24d14\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-photo-shows-a-man-in-a-suit-sitting-beside-a-large-laboratory-apparatus.jpg?id=63687631&width=980\"/> </p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-float-left rm-resized-container rm-resized-container-25\" data-rm-resized-container=\"25%\" style=\"float: left;\"> <img alt=\" a circular black-and-white image shows curved particle tracks. \" class=\"rm-shortcode\" data-rm-shortcode-id=\"f44f892059146ebdd9efa5621fb0c1a2\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"ee99e\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-circular-black-and-white-image-shows-curved-particle-tracks.jpg?id=63687608&width=980\"/> <small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Carl Anderson [top] sits beside the magnet cloud chamber he used to discover the positron. His cloud-chamber photograph [bottom] from 1932 shows the curved track of a positron, the first known antimatter particle.  </small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Caltech Archives & Special Collections </small></p><p><span>Over the decades since then, particle physicists have built increasingly sophisticated instruments of exploration. At the apex of these physics-finding machines sits the Large Hadron Collider, which in 2022 started its third operational run. This underground ring, 27 kilometers in circumference and straddling the border between France and Switzerland, was built to slam subatomic particles together at near light speed and test deep theories of the universe. Physicists from around the world turn to the LHC, hoping to find something new. They’re not sure what, but they hope to find it.</span></p><p>It’s the latest manifestation of a rich tradition. Throughout the history of science, new instruments have prompted hunts for the unexpected. Galileo Galilei built telescopes and found Jupiter’s moons. Antonie van Leeuwenhoek built microscopes and noticed “animalcules, very prettily a-moving.” And still today, people peer through lenses and pore through data in search of patterns they hadn’t hypothesized. Nature’s secrets don’t always come with spoilers, and so we gaze into the unknown, ready for anything.</p><h3></h3><br/><p>But novel, fundamental aspects of the universe are growing less forthcoming. In a sense, we’ve plucked the lowest-hanging fruit. We know to a good approximation what the building blocks of matter are. The Standard Model of particle physics, which describes the currently known elementary particles, has been in place since the 1970s. Nature can still surprise us, but it typically requires larger or finer instruments, more detailed or expansive data, and faster or more flexible analysis tools.</p><p>Those analysis tools include a form of artificial intelligence (AI) called <a href=\"https://www.nature.com/articles/s42254-022-00455-1\" target=\"_blank\">machine learning</a>. Researchers train complex statistical models to find patterns in their data, patterns too subtle for human eyes to see, or too rare for a single human to encounter. At the LHC, which smashes together protons to create immense bursts of energy that decay into other short-lived particles of matter, a theorist might predict some new particle or interaction and describe what its signature would look like in the LHC data, often using a simulation to create synthetic data. Experimentalists would then collect petabytes of measurements and run a machine learning algorithm that compares them with the simulated data, looking for a match. Usually, they come up empty. But maybe new algorithms can peer into corners they haven’t considered.</p><h2>A New Path for Particle Physics</h2><p>“You’ve heard probably that there’s a crisis in particle physics,” says <a href=\"https://www.thphys.uni-heidelberg.de/~plehn/\" rel=\"noopener noreferrer\" target=\"_blank\">Tilman Plehn</a>, a theoretical physicist at Heidelberg University, in Germany. At the LHC and other high-energy physics facilities around the world, the experimental results have failed to yield insights on new physics. “We have a lot of unhappy theorists who thought that their model would have been discovered, and it wasn’t,” Plehn says.</p><h3></h3><br/><img alt=\"Person wearing a patterned shirt against a pale blue background.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"75d8175c67aff628ef15ce2554d50ef8\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"91e5c\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/person-wearing-a-patterned-shirt-against-a-pale-blue-background.jpg?id=63688381&width=980\"/><p class=\"pull-quote\"><span>“We have a lot of unhappy theorists who thought that their model would have been discovered, and it wasn’t.”</span></p><h3></h3><br/><p><a href=\"https://www.physik.uni-hamburg.de/en/iexp/gruppe-kasieczka/personen/kasieczka-gregor.html\" rel=\"noopener noreferrer\" target=\"_blank\">Gregor Kasieczka</a>, a physicist at the University of Hamburg, in Germany, recalls the field’s enthusiasm when the LHC began running in 2008. Back then, he was a young graduate student and expected to see signs of supersymmetry, a theory predicting heavier versions of the known matter particles. The presumption was that “we turn on the LHC, and supersymmetry will jump in your face, and we’ll discover it in the first year or so,” he tells me. Eighteen years later, supersymmetry remains in the theoretical realm. “I think this level of exuberant optimism has somewhat gone.”</p><h3></h3><br/><p>The result, Plehn says, is that models for all kinds of things have fallen in the face of data. “And I think we’re going on a different path now.”</p><p>That path involves a kind of machine learning called unsupervised learning. In unsupervised learning, you don’t teach the AI to recognize your specific prediction—signs of a particle with this mass and this charge. Instead, you might teach it to find anything out of the ordinary, anything interesting—which could indicate brand new physics. It’s the equivalent of looking with fresh eyes at a starry sky or a slide of pond scum. The problem is, how do you automate the search for something “interesting”?</p><h2>Going Beyond the Standard Model</h2><p>The Standard Model leaves many questions unanswered. Why do matter particles have the masses they do? Why do neutrinos have mass at all? Where is the particle for transmitting gravity, to match those for the other forces? Why do we see more matter than antimatter? Are there extra dimensions? What is dark matter—the invisible stuff that makes up most of the universe’s matter and that we assume to exist because of its gravitational effect on galaxies? Answering any of these questions could open the door to new physics, or fundamental discoveries beyond the Standard Model.</p><h3></h3><br/><img alt=\"A long blue accelerator tube marked \\u201cLHC\\u201d runs through an underground tunnel.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"402c04487681186ea40924697e3692be\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"1c8c9\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-long-blue-accelerator-tube-marked-u201clhc-u201d-runs-through-an-underground-tunnel.jpg?id=63688794&width=980\"/><h3></h3><br/><p>“Personally, I’m excited for portal models of dark sectors,” Kasieczka says, as if reading from a Marvel film script. He asks me to imagine a mirror copy of the Standard Model out there somewhere, sharing only one “portal” particle with the Standard Model we know and love. It’s as if this portal particle has a second secret family.</p><p>Kasieczka says that in the LHC’s third run, scientists are splitting their efforts roughly evenly between measuring more precisely what they know to exist and looking for what they don’t know to exist. In some cases, the former could enable the latter. The Standard Model predicts certain particle properties and the relationships between them. For example, it correctly predicted a property of the electron called the magnetic moment to about one part in a trillion. And precise measurements could turn up internal inconsistencies. “Then theorists can say, ‘Oh, if I introduce this new particle, it fixes this specific problem that you guys found. And this is how you look for this particle,’” Kasieczka says.</p><h3></h3><br/><img alt=\"A simplified chart of the Standard Model of physics shows matter particles (quarks and leptons), force-carrying particles, and the Higgs, which conveys mass.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"51370a4c6a287342935bbef4a2493607\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"937d6\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-simplified-chart-of-the-standard-model-of-physics-shows-matter-particles-quarks-and-leptons-force-carrying-particles-and-t.jpg?id=63689716&width=980\"/><h3></h3><br/><p>What’s more, the Standard Model has occasionally shown signs of cracks. Certain particles containing bottom quarks, for example, seem to decay into other particles in unexpected ratios. Plehn finds the bottom-quark incongruities intriguing. “Year after year, I feel they should go away, and they don’t. And nobody has a good explanation,” he says. “I wouldn’t even know who I would shout at”—the theorists or the experimentalists—“like, ‘Sort it out!’”</p><p>Exasperation isn’t exactly the right word for Plehn’s feelings, however. Physicists feel gratified when measurements reasonably agree with expectations, he says. “But I think deep down inside, we always hope that it looks unreasonable. Everybody always looks for the anomalous stuff. Everybody wants to see the standard explanation fail. First, it’s fame”—a chance for a Nobel—“but it’s also an intellectual challenge, right? You get excited when things don’t work in science.”</p><h2>How Unsupervised AI Can Probe for New Physics</h2><p>Now imagine you had a machine to find all the times things don’t work in science, to uncover all the anomalous stuff. That’s how researchers are using unsupervised learning. One day over ice cream, Plehn and a friend who works at the software company SAP began discussing <a href=\"https://www.datacamp.com/tutorial/introduction-to-autoencoders\" target=\"_blank\">autoencoders</a>, one type of unsupervised learning algorithm. “He tells me that autoencoders are what they use in industry to see if a network was hacked,” Plehn remembers. “You have, say, a hundred computers, and they have network traffic. If the network traffic [to one computer] changes all of a sudden, the computer has been hacked, and they take it offline.”</p><h3></h3><br/><img alt=\"a person wearing a hard hat walks down an aisle.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"2e56455349aad07bd98f7a9a64fa5982\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"c2b61\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-person-wearing-a-hard-hat-walks-down-an-aisle.jpg?id=63689029&width=980\"/><h3></h3><br/><img alt=\"Photo show rows of electronic racks filled with cables and equipment inside a data-acquisition room.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"55e6b0584b33ebbda14bb47a2626ce3b\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"1865f\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/photo-show-rows-of-electronic-racks-filled-with-cables-and-equipment-inside-a-data-acquisition-room.jpg?id=63689042&width=980\"/><h3></h3><br/><p>Autoencoders are neural networks that start with an input—it could be an image of a cat, or the record of a computer’s network traffic—and compress it, like making a tiny JPEG or MP3 file, and then decompress it. Engineers train them to compress and decompress data so that the output matches the input as closely as possible. Eventually a network becomes very good at that task. But if the data includes some items that are relatively rare—such as white tigers, or hacked computers’ traffic—the network performs worse on these, because it has less practice with them. The difference between an input and its reconstruction therefore signals how anomalous that input is.</p><p>“This friend of mine said, ‘You can use exactly our software, right?’” Plehn remembers. “‘It’s exactly the same question. Replace computers with particles.’” The two imagined feeding the autoencoder signatures of particles from a collider and asking: Are any of these particles not like the others? Plehn continues: “And then we wrote up a joint grant proposal.”</p><p>It’s not a given that AI will find new physics. Even learning what counts as interesting is a daunting hurdle. Beginning in the 1800s, men in lab coats delegated data processing to women, whom they saw as diligent and detail oriented. Women annotated photos of stars, and they acted as “computers.” In the 1950s, women were trained to scan <a href=\"https://home.cern/news/news/experiments/seeing-invisible-event-displays-particle-physics\" target=\"_blank\">bubble chambers</a>, which recorded particle trajectories as lines of tiny bubbles in fluid. Physicists didn’t explain to them the theory behind the events, only what to look for based on lists of rules. </p><p>But, as the Harvard science historian <a href=\"https://galison.scholars.harvard.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Peter Galison</a> writes in <em>Image and Logic: A Material Culture of Physics</em>, his influential account of how physicists’ tools shape their discoveries, the task was “subtle, difficult, and anything but routinized,” requiring “three-dimensional visual intuition.” He goes on: “Even within a single experiment, judgment was required—this was not an algorithmic activity, an assembly line procedure in which action could be specified fully by rules.”</p><h3></h3><br/><img alt=\"Person in a suit with dark hair against a blue background.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"c284009312420372412cc4cc70e713a5\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"b0ff8\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/person-in-a-suit-with-dark-hair-against-a-blue-background.jpg?id=63688530&width=980\"/><p class=\"pull-quote\">“We are not looking for flying elephants but instead a few extra elephants than usual at the local watering hole.”</p><h3></h3><br/><p>Over the last decade, though, one thing we’ve learned is that AI systems can, in fact, perform tasks once thought to require human intuition, such as <a href=\"https://spectrum.ieee.org/monster-machine-defeats-prominent-pro-player\" target=\"_self\">mastering the ancient board game Go</a>. So researchers have been testing AI’s intuition in physics. In 2019, Kasieczka and his collaborators announced the <a href=\"https://iopscience.iop.org/article/10.1088/1361-6633/ac36b9/meta\" target=\"_blank\">LHC Olympics 2020</a>, a contest in which participants submitted algorithms to find anomalous events in three sets of (simulated) LHC data. Some teams correctly found the anomalous signal in one dataset, but some falsely reported one in the second set, and they all missed it in the third. In 2020, a research collective called <a href=\"https://www.scipost.org/10.21468/SciPostPhys.12.1.043\" target=\"_blank\">Dark Machines</a> announced a similar competition, which drew more than 1,000 submissions of machine learning models. Decisions about how to score them led to different rankings, showing that there’s no best way to explore the unknown.</p><p>Another way to test unsupervised learning is to play revisionist history. In 1995, a particle dubbed the top quark turned up at the Tevatron, a particle accelerator at the Fermi National Accelerator Laboratory (<a href=\"https://fnal.gov/\" target=\"_blank\">Fermilab</a>), in Illinois. But what if it actually hadn’t? Researchers <a href=\"https://epjplus.epj.org/articles/epjplus/abs/2021/02/13360_2021_Article_1109/13360_2021_Article_1109.html\" rel=\"noopener noreferrer\" target=\"_blank\">applied</a> unsupervised learning to LHC data collected in 2012, pretending they knew almost nothing about the top quark. Sure enough, the AI revealed a set of anomalous events that were clustered together. Combined with a bit of human intuition, they pointed toward something like the top quark.</p><h3></h3><br/><img alt=\"Person with long hair wearing a sweater and light-colored top against a blue background.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"88bfd49b51c02712bb83d0e9ee23b1da\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"a121d\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/person-with-long-hair-wearing-a-sweater-and-light-colored-top-against-a-blue-background.jpg?id=63690566&width=980\"/><p class=\"pull-quote\">“An algorithm that can recognize any kind of disturbance would be a win.”</p><h3></h3><br/><p>That exercise underlines the fact that unsupervised learning can’t replace physicists just yet. “If your anomaly detector detects some kind of feature, how do you get from that statement to something like a physics interpretation?” Kasieczka says. “The anomaly search is more a scouting-like strategy to get you to look into the right corner.” <a href=\"https://www.physics.columbia.edu/content/georgia-karagiorgi\" target=\"_blank\">Georgia Karagiorgi</a>, a physicist at Columbia University, agrees. “Once you find something unexpected, you can’t just call it quits and be like, ‘Oh, I discovered something,’” she says. “You have to come up with a model and then test it.”</p><p><a href=\"https://www.physics.wisc.edu/directory/cranmer-kyle/\" target=\"_blank\">Kyle Cranmer</a>, a physicist and data scientist at the University of Wisconsin-Madison who played a key role in the <a href=\"https://spectrum.ieee.org/a-tantalizing-hint-of-the-higgs\" target=\"_self\">discovery of the Higgs boson particle</a> in 2012, also says that human expertise can’t be dismissed. “There’s an infinite number of ways the data can look different from what you expected,” he says, “and most of them aren’t interesting.” Physicists might be able to recognize whether a deviation suggests some plausible new physical phenomenon, rather than just noise. “But how you try to codify that and make it explicit in some algorithm is much less straightforward,” Cranmer says. Ideally, the guidelines would be general enough to exclude the unimaginable without eliminating the merely unimagined. “That’s gonna be your Goldilocks situation.”</p><p>In his 1987 book <em>How Experiments End</em>, Harvard’s Galison writes that scientific instruments can “import assumptions built into the apparatus itself.” He tells me about a 1973 experiment that looked for a phenomenon called neutral currents, signaled by an absence of a so-called heavy electron (later renamed the muon). One team initially used a trigger left over from previous experiments, which recorded events only if they produced those heavy electrons—even though neutral currents, by definition, produce none. As a result, for some time the researchers missed the phenomenon and wrongly concluded that it didn’t exist. Galison says that the physicists’ design choice “allowed the discovery of [only] one thing, and it blinded the next generation of people to this new discovery. And that is always a risk when you’re being selective.”</p><h2>How AI Could Miss—or Fake—New Physics</h2><p>I ask Galison if by automating the search for interesting events, we’re letting the AI take over the science. He rephrases the question: “Have we handed over the keys to the car of science to the machines?” One way to alleviate such concerns, he tells me, is to generate test data to see if an algorithm behaves as expected—as in the LHC Olympics. “Before you take a camera out and photograph the Loch Ness Monster, you want to make sure that it can reproduce a wide variety of colors” and patterns accurately, he says, so you can rely on it to capture whatever comes.</p><p>Galison, who is also a physicist, works on the <a href=\"https://www.welcometothejungle.com/en/articles/btc-black-hole-imaging-software-telescope\" rel=\"noopener noreferrer\" target=\"_blank\">Event Horizon Telescope</a>, which images black holes. For that project, he remembers putting up utterly unexpected test images like Frosty the Snowman so that scientists could probe the system’s general ability to catch something new. “The danger is that you’ve missed out on some crucial test,” he says, “and that the object you’re going to be photographing is so different from your test patterns that you’re unprepared.”</p><p>The algorithms that physicists are using to seek new physics are certainly vulnerable to this danger. It helps that unsupervised learning is already being used in many applications. In industry, it’s surfacing anomalous credit-card transactions and hacked networks. In science, it’s identifying earthquake precursors, genome locations where proteins bind, and merging galaxies.</p><h3></h3><br/><img alt=\"A colorful visualization shows many particle tracks radiating outward from a collision point.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"7c97622adcd56f2e689ec345310cf808\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"f6a0e\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-colorful-visualization-shows-many-particle-tracks-radiating-outward-from-a-collision-point.jpg?id=63688853&width=980\"/><h3></h3><br/><p>But one difference with particle-physics data is that the anomalies may not be stand-alone objects or events. You’re looking not just for a needle in a haystack; you’re also looking for subtle irregularities in the haystack itself. Maybe a stack contains a few more short stems than you’d expect. Or a pattern reveals itself only when you simultaneously look at the size, shape, color, and texture of stems. Such a pattern might suggest an unacknowledged substance in the soil. In accelerator data, subtle patterns might suggest a hidden force. As Kasieczka and his colleagues write in <a href=\"https://escholarship.org/content/qt56p5b8qm/qt56p5b8qm_noSplash_3309801b69925912167073f272fc7612.pdf\" target=\"_blank\">one paper</a>, “We are not looking for flying elephants, but instead a few extra elephants than usual at the local watering hole.”</p><p>Even algorithms that weigh many factors can miss signals—and they can also see spurious ones. The stakes of mistakenly claiming discovery are high. Going back to the hacking scenario, Plehn says, a company might ultimately determine that its network wasn’t hacked; it was just a new employee. The algorithm’s false positive causes little damage. “Whereas if you stand there and get the Nobel Prize, and a year later people say, ‘Well, it was a fluke,’ people would make fun of you for the rest of your life,” he says. In particle physics, he adds, you run the risk of spotting patterns purely by chance in big data, or as a result of malfunctioning equipment.</p><p>False alarms have happened before. In 1976, a group at Fermilab led by Leon Lederman, who later won a Nobel for other work, announced the discovery of a particle they tentatively called the Upsilon. The researchers calculated the probability of the signal’s happening by chance as 1 in 50. After further data collection, though, they walked back the discovery, calling the pseudo-particle the Oops-Leon. (Today, particle physicists wait until the chance that a finding is a fluke drops below 1 in 3.5 million, the so-called five-sigma criterion.) And in 2011, researchers at the Oscillation Project with Emulsion-tRacking Apparatus (OPERA) experiment, in Italy, announced evidence for faster-than-light travel of neutrinos. Then, a few months later, they reported that the result was due to a faulty connection in their timing system.</p><p>Those cautionary tales linger in the minds of physicists. And yet, even while researchers are wary of false positives from AI, they also see it as a safeguard against them. So far, unsupervised learning has discovered no new physics, despite its use on data from multiple experiments at Fermilab and CERN. But anomaly detection may have prevented embarrassments like the one at OPERA. “So instead of telling you there’s a new physics particle,” Kasieczka says, “it’s telling you, this sensor is behaving weird today. You should restart it.”</p><h2>Hardware for AI-Assisted Particle Physics</h2><p>Particle physicists are pushing the limits of not only their computing software but also their computing hardware. The challenge is unparalleled. The LHC produces 40 million particle collisions per second, each of which can produce a megabyte of data. That’s much too much information to store, even if you could save it to disk that quickly. So the two largest detectors each use two-level data filtering. The first layer, called the Level-1 Trigger, or L1T, harvests 100,000 events per second, and the second layer, called the High-Level Trigger, or HLT, plucks 1,000 of those events to save for later analysis. So only one in 40,000 events is ever potentially seen by human eyes.</p><h3></h3><br/><img alt=\"Person with long blonde hair in a white shirt against a solid blue background.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"6d32802ccf9c56bed216ddc413965057\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"747ca\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/person-with-long-blonde-hair-in-a-white-shirt-against-a-solid-blue-background.jpg?id=63691908&width=980\"/><p class=\"pull-quote\"><span>“</span>T<span>hat’s</span> when I thought, we need something like [AlphaGo] in physics. We need a genius that can look at the world differently.” </p><h3></h3><br/><p>HLTs use central processing units (CPUs) like the ones in your desktop computer, running complex machine learning algorithms that analyze collisions based on the number, type, energy, momentum, and angles of the new particles produced. L1Ts, as a first line of defense, must be fast. So the L1Ts rely on integrated circuits called field-programmable gate arrays (FPGAs), which users can reprogram for specialized calculations. </p><p>The trade-off is that the programming must be relatively simple. The FPGAs can’t easily store and run fancy neural networks; instead they follow scripted rules about, say, what features of a particle collision make it important. In terms of complexity level, it’s the instructions given to the women who scanned bubble chambers, not the women’s brains.</p><p><a href=\"https://www.space.mit.edu/people/katya-govorkova/\" target=\"_blank\">Ekaterina (Katya) Govorkova</a>, a particle physicist at MIT, saw a path toward improving the LHC’s filters, inspired by a board game. Around 2020, she was looking for new physics by comparing precise measurements at the LHC with predictions, using little or no machine learning. Then she watched a documentary about <a href=\"https://deepmind.google/research/alphago/\" rel=\"noopener noreferrer\" target=\"_blank\">AlphaGo</a>, the program that used machine learning to beat a human Go champion. “For me the moment of realization was when AlphaGo would use some absolutely new type of strategy that humans, who played this game for centuries, hadn’t thought about before,” she says. “So that’s when I thought, we need something like that in physics. We need a genius that can look at the world differently.” New physics may be something we’d never imagine.</p><p>Govorkova and her collaborators found a way to compress autoencoders to put them on FPGAs, where they process an event every 80 nanoseconds (less than 10-millionth of a second). (Compression involved pruning some network connections and <a href=\"https://spectrum.ieee.org/1-bit-llm\" target=\"_self\">reducing the precision</a> of some calculations.) They <a href=\"https://www.nature.com/articles/s42256-022-00441-3\" rel=\"noopener noreferrer\" target=\"_blank\">published</a> their methods in <em>Nature Machine Intelligence </em>in 2022, and researchers are now using them during the LHC’s third run. The new trigger tech is installed in one of the detectors around the LHC’s giant ring, and it has found many anomalous events that would otherwise have gone unflagged.</p><p>Researchers are currently setting up analysis workflows to decipher why the events were deemed anomalous. <a href=\"https://www.linkedin.com/in/jennifer-ngadiuba-a2138b141/\" rel=\"noopener noreferrer\" target=\"_blank\">Jennifer Ngadiuba</a>, a particle physicist at Fermilab who is also one of the coordinators of the trigger system (and one of Govorkova’s coauthors), says that one feature stands out already: Flagged events have lots of jets of new particles shooting out of the collisions. But the scientists still need to explore other factors, like the new particles’ energies and their distributions in space. “It’s a high-dimensional problem,” she says.</p><p>Eventually they will share the data openly, allowing others to eyeball the results or to apply new unsupervised learning algorithms in the hunt for patterns. <a href=\"https://jduarte.physics.ucsd.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Javier Duarte</a>, a physicist at the University of California, San Diego, and also a coauthor on the 2022 paper, says, “It’s kind of exciting to think about providing this to the community of particle physicists and saying, like, ‘Shrug, we don’t know what this is. You can take a look.’” Duarte and Ngadiuba note that high-energy physics has traditionally followed a top-down approach to discovery, testing data against well-defined theories. Adding in this new bottom-up search for the unexpected marks a new paradigm. “And also a return of sorts to before the Standard Model was so well established,” Duarte adds.</p><p>Yet it could be years before we know why AI marked those collisions as anomalous. What conclusions could they support? “In the worst case, it could be some detector noise that we didn’t know about,” which would still be useful information, Ngadiuba says. “The best scenario could be a new particle. And then a new particle implies a new force.”</p><h3></h3><br/><img alt=\"Person with braided updo in checkered suit jacket and chambray shirt, light blue background.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"f39242371a3e9c3f28858b95d5fbb950\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"27f44\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/person-with-braided-updo-in-checkered-suit-jacket-and-chambray-shirt-light-blue-background.jpg?id=63691071&width=980\"/><p class=\"pull-quote\"><span>“The best scenario could be a new particle. And then a new particle implies a new force.”</span></p><h3></h3><br/><p>Duarte says he expects their work with FPGAs to have wider applications. “The data rates and the constraints in high-energy physics are so extreme that people in industry aren’t necessarily working on this,” he says. “In self-driving cars, usually millisecond latencies are sufficient reaction times. But we’re developing algorithms that need to respond in microseconds or less. We’re at this technological frontier, and to see how much that can proliferate back to industry will be cool.”</p><p>Plehn is also working to put neural networks on FPGAs for triggers, in collaboration with experimentalists, electrical engineers, and other theorists. Encoding the nuances of abstract theories into material hardware is a puzzle. “In this grant proposal, the person I talked to most is the electrical engineer,” he says, “because I have to ask the engineer, which of my algorithms fits on your bloody FPGA?”</p><p>Hardware is hard, says <a href=\"https://kastner.ucsd.edu/ryan/\" target=\"_blank\">Ryan Kastner</a>, an electrical engineer and computer scientist at UC San Diego who works with Duarte on programming FPGAs. What allows the chips to run algorithms so quickly is their flexibility. Instead of programming them in an abstract coding language like Python, engineers configure the underlying circuitry. They map logic gates, route data paths, and synchronize operations by hand. That low-level control also makes the effort “painfully difficult,” Kastner says. “It’s kind of like you have a lot of rope, and it’s very easy to hang yourself.”</p><h2>Seeking New Physics Among the Neutrinos</h2><p><strong></strong>The next piece of new physics may not pop up at a particle accelerator. It may appear at a detector for <a href=\"https://www.energy.gov/science/doe-explainsneutrinos\" target=\"_blank\">neutrinos</a>, particles that are part of the Standard Model but remain deeply mysterious. Neutrinos are tiny, electrically neutral, and so light that no one has yet measured their mass. (The <a href=\"https://physicsworld.com/a/katrin-sets-tighter-limit-on-neutrino-mass/\" target=\"_blank\">latest attempt</a>, in April, set an upper limit of about a millionth the mass of an electron.) Of all known particles with mass, neutrinos are the universe’s most abundant, but also among the most ghostly, rarely deigning to acknowledge the matter around them. Tens of trillions pass through your body every second.</p><p>If we listen very closely, though, we may just hear the secrets they have to tell. <a href=\"https://www.physics.columbia.edu/content/georgia-karagiorgi\" target=\"_blank\">Karagiorgi</a>, of Columbia, has chosen this path to discovery. Being a physicist is “kind of like playing detective, but where you create your own mysteries,” she tells me during my visit to Columbia’s <a href=\"https://www.nevis.columbia.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Nevis Laboratories</a>, located on a large estate about 20 km north of Manhattan. Physics research began at the site after World War II; one hallway features papers going back to 1951.</p><h3></h3><br/><img alt=\"A person stands inside a room that has gold-colored grids covering the floor, walls, and ceiling.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"7611bcd2553876aaf5da2bc2c49090e8\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"cb76e\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-person-stands-inside-a-room-that-has-gold-colored-grids-covering-the-floor-walls-and-ceiling.jpg?id=63689639&width=980\"/><h3></h3><br/><p>Karagiorgi is eagerly awaiting a massive neutrino detector that’s currently under construction. Starting in 2028, Fermilab will send neutrinos west through 1,300 km of rock to South Dakota, where they’ll occasionally make their existence known in the Deep Underground Neutrino Experiment (<a href=\"https://www.dunescience.org/\" target=\"_blank\">DUNE</a>). Why so far away? When neutrinos travel long distances, they have an odd habit of oscillating, transforming from one kind or “flavor” to another. Observing the oscillations of both the neutrinos and their mirror-image antiparticles, antineutrinos, could tell researchers something about the universe’s matter-antimatter asymmetry—which the Standard Model doesn’t explain—and thus, according to the Nevis website, “why we exist.”</p><p>“DUNE is the thing that’s been pushing me to develop these real-time AI methods,” Karagiorgi says, “for sifting through the data very, very, very quickly and trying to look for rare signatures of interest within them.” When neutrinos interact with the detector’s 70,000 tonnes of liquid argon, they’ll generate a shower of other particles, creating visual tracks that look like a photo of fireworks.</p><p><span>Even when not bombarding DUNE with neutrinos, researchers will keep collecting data in the off chance that it captures neutrinos from a distant supernova. “This is a massive detector spewing out 5 terabytes of data per second,” Karagiorgi says, “and it’s going to run constantly for a decade.” They will need unsupervised learning to notice signatures that no one was looking for, because there are “lots of different models of how supernova explosions happen, and for all we know, none of them could be the right model for neutrinos,” she says. “To train your algorithm on such uncertain grounds is less than ideal. So an algorithm that can recognize any kind of disturbance would be a win.”</span></p><p>Deciding in real time which 1 percent of 1 percent of data to keep will require FPGAs. Karagiorgi’s team is preparing to use them for DUNE, and she walks me to a computer lab where they program the circuits. In the FPGA lab, we look at nondescript circuit boards sitting on a table. “So what we’re proposing is a scheme where you can have something like a hundred of these boards for DUNE deep underground that receive the image data frame by frame,” she says. This system could tell researchers whether a given frame resembled TV static, fireworks, or something in between.</p><p>Neutrino experiments, like many particle-physics studies, are very visual. When Karagiorgi was a postdoc, automated image processing at neutrino detectors was still in its infancy, so she and collaborators would often resort to visual scanning (bubble-chamber style) to measure particle tracks. She still asks undergrads to hand-scan as an educational exercise. “I think it’s wrong to just send them to write a machine learning algorithm. Unless you can actually visualize the data, you don’t really gain a sense of what you’re looking for,” she says. “I think it also helps with creativity to be able to visualize the different types of interactions that are happening, and see what’s normal and what’s not normal.”</p><p>Back in Karagiorgi’s office, a bulletin board displays images from <em><em>The Cognitive Art of Feynman Diagrams</em></em>, an exhibit for which the designer Edward Tufte created wire sculptures of the physicist Richard Feynman’s schematics of particle interactions. “It’s funny, you know,” she says. “They look like they’re just scribbles, right? But actually, they encode quantitatively predictive behavior in nature.” Later, Karagiorgi and I spend a good 10 minutes discussing whether a computer or a human could find Waldo without knowing what Waldo looked like. We also touch on the 1964 Supreme Court case in which Justice Potter Stewart famously declined to define obscenity, saying “I know it when I see it.” I ask whether it seems weird to hand over to a machine the task of deciding what’s visually interesting. “There are a lot of trust issues,” she says with a laugh.</p><p>On the drive back to Manhattan, we discuss the history of scientific discovery. “I think it’s part of human nature to try to make sense of an orderly world around you,” Karagiorgi says. “And then you just automatically pick out the oddities. Some people obsess about the oddities more than others, and then try to understand them.”</p><p>Reflecting on the Standard Model, she called it “beautiful and elegant,” with “amazing predictive power.” Yet she finds it both limited and limiting, blinding us to colors we don’t yet see. “Sometimes it’s both a blessing and a curse that we’ve managed to develop such a successful theory.” <span class=\"ieee-end-mark\"></span></p>",
        "contentSnippet": "In 1930, a young physicist named Carl D. Anderson was tasked by his mentor with measuring the energies of cosmic rays—particles arriving at high speed from outer space. Anderson built an improved version of a cloud chamber, a device that visually records the trajectories of particles. In 1932, he saw evidence that confusingly combined the properties of protons and electrons. “A situation began to develop that had its awkward aspects,” he wrote many years after winning a Nobel Prize at the age of 31. Anderson had accidentally discovered antimatter.\n\nFour years after his first discovery, he codiscovered another elementary particle, the muon. This one prompted one physicist to ask, “Who ordered that?”\n  \n  Carl Anderson [top] sits beside the magnet cloud chamber he used to discover the positron. His cloud-chamber photograph [bottom] from 1932 shows the curved track of a positron, the first known antimatter particle.  Caltech Archives & Special Collections \nOver the decades since then, particle physicists have built increasingly sophisticated instruments of exploration. At the apex of these physics-finding machines sits the Large Hadron Collider, which in 2022 started its third operational run. This underground ring, 27 kilometers in circumference and straddling the border between France and Switzerland, was built to slam subatomic particles together at near light speed and test deep theories of the universe. Physicists from around the world turn to the LHC, hoping to find something new. They’re not sure what, but they hope to find it.\nIt’s the latest manifestation of a rich tradition. Throughout the history of science, new instruments have prompted hunts for the unexpected. Galileo Galilei built telescopes and found Jupiter’s moons. Antonie van Leeuwenhoek built microscopes and noticed “animalcules, very prettily a-moving.” And still today, people peer through lenses and pore through data in search of patterns they hadn’t hypothesized. Nature’s secrets don’t always come with spoilers, and so we gaze into the unknown, ready for anything.\n\n\nBut novel, fundamental aspects of the universe are growing less forthcoming. In a sense, we’ve plucked the lowest-hanging fruit. We know to a good approximation what the building blocks of matter are. The Standard Model of particle physics, which describes the currently known elementary particles, has been in place since the 1970s. Nature can still surprise us, but it typically requires larger or finer instruments, more detailed or expansive data, and faster or more flexible analysis tools.\nThose analysis tools include a form of artificial intelligence (AI) called machine learning. Researchers train complex statistical models to find patterns in their data, patterns too subtle for human eyes to see, or too rare for a single human to encounter. At the LHC, which smashes together protons to create immense bursts of energy that decay into other short-lived particles of matter, a theorist might predict some new particle or interaction and describe what its signature would look like in the LHC data, often using a simulation to create synthetic data. Experimentalists would then collect petabytes of measurements and run a machine learning algorithm that compares them with the simulated data, looking for a match. Usually, they come up empty. But maybe new algorithms can peer into corners they haven’t considered.\nA New Path for Particle Physics\n“You’ve heard probably that there’s a crisis in particle physics,” says Tilman Plehn, a theoretical physicist at Heidelberg University, in Germany. At the LHC and other high-energy physics facilities around the world, the experimental results have failed to yield insights on new physics. “We have a lot of unhappy theorists who thought that their model would have been discovered, and it wasn’t,” Plehn says.\n\n\n“We have a lot of unhappy theorists who thought that their model would have been discovered, and it wasn’t.”\n\n\nGregor Kasieczka, a physicist at the University of Hamburg, in Germany, recalls the field’s enthusiasm when the LHC began running in 2008. Back then, he was a young graduate student and expected to see signs of supersymmetry, a theory predicting heavier versions of the known matter particles. The presumption was that “we turn on the LHC, and supersymmetry will jump in your face, and we’ll discover it in the first year or so,” he tells me. Eighteen years later, supersymmetry remains in the theoretical realm. “I think this level of exuberant optimism has somewhat gone.”\n\n\nThe result, Plehn says, is that models for all kinds of things have fallen in the face of data. “And I think we’re going on a different path now.”\nThat path involves a kind of machine learning called unsupervised learning. In unsupervised learning, you don’t teach the AI to recognize your specific prediction—signs of a particle with this mass and this charge. Instead, you might teach it to find anything out of the ordinary, anything interesting—which could indicate brand new physics. It’s the equivalent of looking with fresh eyes at a starry sky or a slide of pond scum. The problem is, how do you automate the search for something “interesting”?\nGoing Beyond the Standard Model\nThe Standard Model leaves many questions unanswered. Why do matter particles have the masses they do? Why do neutrinos have mass at all? Where is the particle for transmitting gravity, to match those for the other forces? Why do we see more matter than antimatter? Are there extra dimensions? What is dark matter—the invisible stuff that makes up most of the universe’s matter and that we assume to exist because of its gravitational effect on galaxies? Answering any of these questions could open the door to new physics, or fundamental discoveries beyond the Standard Model.\n\n\n\n“Personally, I’m excited for portal models of dark sectors,” Kasieczka says, as if reading from a Marvel film script. He asks me to imagine a mirror copy of the Standard Model out there somewhere, sharing only one “portal” particle with the Standard Model we know and love. It’s as if this portal particle has a second secret family.\nKasieczka says that in the LHC’s third run, scientists are splitting their efforts roughly evenly between measuring more precisely what they know to exist and looking for what they don’t know to exist. In some cases, the former could enable the latter. The Standard Model predicts certain particle properties and the relationships between them. For example, it correctly predicted a property of the electron called the magnetic moment to about one part in a trillion. And precise measurements could turn up internal inconsistencies. “Then theorists can say, ‘Oh, if I introduce this new particle, it fixes this specific problem that you guys found. And this is how you look for this particle,’” Kasieczka says.\n\n\n\nWhat’s more, the Standard Model has occasionally shown signs of cracks. Certain particles containing bottom quarks, for example, seem to decay into other particles in unexpected ratios. Plehn finds the bottom-quark incongruities intriguing. “Year after year, I feel they should go away, and they don’t. And nobody has a good explanation,” he says. “I wouldn’t even know who I would shout at”—the theorists or the experimentalists—“like, ‘Sort it out!’”\nExasperation isn’t exactly the right word for Plehn’s feelings, however. Physicists feel gratified when measurements reasonably agree with expectations, he says. “But I think deep down inside, we always hope that it looks unreasonable. Everybody always looks for the anomalous stuff. Everybody wants to see the standard explanation fail. First, it’s fame”—a chance for a Nobel—“but it’s also an intellectual challenge, right? You get excited when things don’t work in science.”\nHow Unsupervised AI Can Probe for New Physics\nNow imagine you had a machine to find all the times things don’t work in science, to uncover all the anomalous stuff. That’s how researchers are using unsupervised learning. One day over ice cream, Plehn and a friend who works at the software company SAP began discussing autoencoders, one type of unsupervised learning algorithm. “He tells me that autoencoders are what they use in industry to see if a network was hacked,” Plehn remembers. “You have, say, a hundred computers, and they have network traffic. If the network traffic [to one computer] changes all of a sudden, the computer has been hacked, and they take it offline.”\n\n\n\n\n\nAutoencoders are neural networks that start with an input—it could be an image of a cat, or the record of a computer’s network traffic—and compress it, like making a tiny JPEG or MP3 file, and then decompress it. Engineers train them to compress and decompress data so that the output matches the input as closely as possible. Eventually a network becomes very good at that task. But if the data includes some items that are relatively rare—such as white tigers, or hacked computers’ traffic—the network performs worse on these, because it has less practice with them. The difference between an input and its reconstruction therefore signals how anomalous that input is.\n“This friend of mine said, ‘You can use exactly our software, right?’” Plehn remembers. “‘It’s exactly the same question. Replace computers with particles.’” The two imagined feeding the autoencoder signatures of particles from a collider and asking: Are any of these particles not like the others? Plehn continues: “And then we wrote up a joint grant proposal.”\nIt’s not a given that AI will find new physics. Even learning what counts as interesting is a daunting hurdle. Beginning in the 1800s, men in lab coats delegated data processing to women, whom they saw as diligent and detail oriented. Women annotated photos of stars, and they acted as “computers.” In the 1950s, women were trained to scan bubble chambers, which recorded particle trajectories as lines of tiny bubbles in fluid. Physicists didn’t explain to them the theory behind the events, only what to look for based on lists of rules. \nBut, as the Harvard science historian Peter Galison writes in Image and Logic: A Material Culture of Physics, his influential account of how physicists’ tools shape their discoveries, the task was “subtle, difficult, and anything but routinized,” requiring “three-dimensional visual intuition.” He goes on: “Even within a single experiment, judgment was required—this was not an algorithmic activity, an assembly line procedure in which action could be specified fully by rules.”\n\n\n“We are not looking for flying elephants but instead a few extra elephants than usual at the local watering hole.”\n\n\nOver the last decade, though, one thing we’ve learned is that AI systems can, in fact, perform tasks once thought to require human intuition, such as mastering the ancient board game Go. So researchers have been testing AI’s intuition in physics. In 2019, Kasieczka and his collaborators announced the LHC Olympics 2020, a contest in which participants submitted algorithms to find anomalous events in three sets of (simulated) LHC data. Some teams correctly found the anomalous signal in one dataset, but some falsely reported one in the second set, and they all missed it in the third. In 2020, a research collective called Dark Machines announced a similar competition, which drew more than 1,000 submissions of machine learning models. Decisions about how to score them led to different rankings, showing that there’s no best way to explore the unknown.\nAnother way to test unsupervised learning is to play revisionist history. In 1995, a particle dubbed the top quark turned up at the Tevatron, a particle accelerator at the Fermi National Accelerator Laboratory (Fermilab), in Illinois. But what if it actually hadn’t? Researchers applied unsupervised learning to LHC data collected in 2012, pretending they knew almost nothing about the top quark. Sure enough, the AI revealed a set of anomalous events that were clustered together. Combined with a bit of human intuition, they pointed toward something like the top quark.\n\n\n“An algorithm that can recognize any kind of disturbance would be a win.”\n\n\nThat exercise underlines the fact that unsupervised learning can’t replace physicists just yet. “If your anomaly detector detects some kind of feature, how do you get from that statement to something like a physics interpretation?” Kasieczka says. “The anomaly search is more a scouting-like strategy to get you to look into the right corner.” Georgia Karagiorgi, a physicist at Columbia University, agrees. “Once you find something unexpected, you can’t just call it quits and be like, ‘Oh, I discovered something,’” she says. “You have to come up with a model and then test it.”\nKyle Cranmer, a physicist and data scientist at the University of Wisconsin-Madison who played a key role in the discovery of the Higgs boson particle in 2012, also says that human expertise can’t be dismissed. “There’s an infinite number of ways the data can look different from what you expected,” he says, “and most of them aren’t interesting.” Physicists might be able to recognize whether a deviation suggests some plausible new physical phenomenon, rather than just noise. “But how you try to codify that and make it explicit in some algorithm is much less straightforward,” Cranmer says. Ideally, the guidelines would be general enough to exclude the unimaginable without eliminating the merely unimagined. “That’s gonna be your Goldilocks situation.”\nIn his 1987 book How Experiments End, Harvard’s Galison writes that scientific instruments can “import assumptions built into the apparatus itself.” He tells me about a 1973 experiment that looked for a phenomenon called neutral currents, signaled by an absence of a so-called heavy electron (later renamed the muon). One team initially used a trigger left over from previous experiments, which recorded events only if they produced those heavy electrons—even though neutral currents, by definition, produce none. As a result, for some time the researchers missed the phenomenon and wrongly concluded that it didn’t exist. Galison says that the physicists’ design choice “allowed the discovery of [only] one thing, and it blinded the next generation of people to this new discovery. And that is always a risk when you’re being selective.”\nHow AI Could Miss—or Fake—New Physics\nI ask Galison if by automating the search for interesting events, we’re letting the AI take over the science. He rephrases the question: “Have we handed over the keys to the car of science to the machines?” One way to alleviate such concerns, he tells me, is to generate test data to see if an algorithm behaves as expected—as in the LHC Olympics. “Before you take a camera out and photograph the Loch Ness Monster, you want to make sure that it can reproduce a wide variety of colors” and patterns accurately, he says, so you can rely on it to capture whatever comes.\nGalison, who is also a physicist, works on the Event Horizon Telescope, which images black holes. For that project, he remembers putting up utterly unexpected test images like Frosty the Snowman so that scientists could probe the system’s general ability to catch something new. “The danger is that you’ve missed out on some crucial test,” he says, “and that the object you’re going to be photographing is so different from your test patterns that you’re unprepared.”\nThe algorithms that physicists are using to seek new physics are certainly vulnerable to this danger. It helps that unsupervised learning is already being used in many applications. In industry, it’s surfacing anomalous credit-card transactions and hacked networks. In science, it’s identifying earthquake precursors, genome locations where proteins bind, and merging galaxies.\n\n\n\nBut one difference with particle-physics data is that the anomalies may not be stand-alone objects or events. You’re looking not just for a needle in a haystack; you’re also looking for subtle irregularities in the haystack itself. Maybe a stack contains a few more short stems than you’d expect. Or a pattern reveals itself only when you simultaneously look at the size, shape, color, and texture of stems. Such a pattern might suggest an unacknowledged substance in the soil. In accelerator data, subtle patterns might suggest a hidden force. As Kasieczka and his colleagues write in one paper, “We are not looking for flying elephants, but instead a few extra elephants than usual at the local watering hole.”\nEven algorithms that weigh many factors can miss signals—and they can also see spurious ones. The stakes of mistakenly claiming discovery are high. Going back to the hacking scenario, Plehn says, a company might ultimately determine that its network wasn’t hacked; it was just a new employee. The algorithm’s false positive causes little damage. “Whereas if you stand there and get the Nobel Prize, and a year later people say, ‘Well, it was a fluke,’ people would make fun of you for the rest of your life,” he says. In particle physics, he adds, you run the risk of spotting patterns purely by chance in big data, or as a result of malfunctioning equipment.\nFalse alarms have happened before. In 1976, a group at Fermilab led by Leon Lederman, who later won a Nobel for other work, announced the discovery of a particle they tentatively called the Upsilon. The researchers calculated the probability of the signal’s happening by chance as 1 in 50. After further data collection, though, they walked back the discovery, calling the pseudo-particle the Oops-Leon. (Today, particle physicists wait until the chance that a finding is a fluke drops below 1 in 3.5 million, the so-called five-sigma criterion.) And in 2011, researchers at the Oscillation Project with Emulsion-tRacking Apparatus (OPERA) experiment, in Italy, announced evidence for faster-than-light travel of neutrinos. Then, a few months later, they reported that the result was due to a faulty connection in their timing system.\nThose cautionary tales linger in the minds of physicists. And yet, even while researchers are wary of false positives from AI, they also see it as a safeguard against them. So far, unsupervised learning has discovered no new physics, despite its use on data from multiple experiments at Fermilab and CERN. But anomaly detection may have prevented embarrassments like the one at OPERA. “So instead of telling you there’s a new physics particle,” Kasieczka says, “it’s telling you, this sensor is behaving weird today. You should restart it.”\nHardware for AI-Assisted Particle Physics\nParticle physicists are pushing the limits of not only their computing software but also their computing hardware. The challenge is unparalleled. The LHC produces 40 million particle collisions per second, each of which can produce a megabyte of data. That’s much too much information to store, even if you could save it to disk that quickly. So the two largest detectors each use two-level data filtering. The first layer, called the Level-1 Trigger, or L1T, harvests 100,000 events per second, and the second layer, called the High-Level Trigger, or HLT, plucks 1,000 of those events to save for later analysis. So only one in 40,000 events is ever potentially seen by human eyes.\n\n\n“That’s when I thought, we need something like [AlphaGo] in physics. We need a genius that can look at the world differently.” \n\n\nHLTs use central processing units (CPUs) like the ones in your desktop computer, running complex machine learning algorithms that analyze collisions based on the number, type, energy, momentum, and angles of the new particles produced. L1Ts, as a first line of defense, must be fast. So the L1Ts rely on integrated circuits called field-programmable gate arrays (FPGAs), which users can reprogram for specialized calculations. \nThe trade-off is that the programming must be relatively simple. The FPGAs can’t easily store and run fancy neural networks; instead they follow scripted rules about, say, what features of a particle collision make it important. In terms of complexity level, it’s the instructions given to the women who scanned bubble chambers, not the women’s brains.\nEkaterina (Katya) Govorkova, a particle physicist at MIT, saw a path toward improving the LHC’s filters, inspired by a board game. Around 2020, she was looking for new physics by comparing precise measurements at the LHC with predictions, using little or no machine learning. Then she watched a documentary about AlphaGo, the program that used machine learning to beat a human Go champion. “For me the moment of realization was when AlphaGo would use some absolutely new type of strategy that humans, who played this game for centuries, hadn’t thought about before,” she says. “So that’s when I thought, we need something like that in physics. We need a genius that can look at the world differently.” New physics may be something we’d never imagine.\nGovorkova and her collaborators found a way to compress autoencoders to put them on FPGAs, where they process an event every 80 nanoseconds (less than 10-millionth of a second). (Compression involved pruning some network connections and reducing the precision of some calculations.) They published their methods in Nature Machine Intelligence in 2022, and researchers are now using them during the LHC’s third run. The new trigger tech is installed in one of the detectors around the LHC’s giant ring, and it has found many anomalous events that would otherwise have gone unflagged.\nResearchers are currently setting up analysis workflows to decipher why the events were deemed anomalous. Jennifer Ngadiuba, a particle physicist at Fermilab who is also one of the coordinators of the trigger system (and one of Govorkova’s coauthors), says that one feature stands out already: Flagged events have lots of jets of new particles shooting out of the collisions. But the scientists still need to explore other factors, like the new particles’ energies and their distributions in space. “It’s a high-dimensional problem,” she says.\nEventually they will share the data openly, allowing others to eyeball the results or to apply new unsupervised learning algorithms in the hunt for patterns. Javier Duarte, a physicist at the University of California, San Diego, and also a coauthor on the 2022 paper, says, “It’s kind of exciting to think about providing this to the community of particle physicists and saying, like, ‘Shrug, we don’t know what this is. You can take a look.’” Duarte and Ngadiuba note that high-energy physics has traditionally followed a top-down approach to discovery, testing data against well-defined theories. Adding in this new bottom-up search for the unexpected marks a new paradigm. “And also a return of sorts to before the Standard Model was so well established,” Duarte adds.\nYet it could be years before we know why AI marked those collisions as anomalous. What conclusions could they support? “In the worst case, it could be some detector noise that we didn’t know about,” which would still be useful information, Ngadiuba says. “The best scenario could be a new particle. And then a new particle implies a new force.”\n\n\n“The best scenario could be a new particle. And then a new particle implies a new force.”\n\n\nDuarte says he expects their work with FPGAs to have wider applications. “The data rates and the constraints in high-energy physics are so extreme that people in industry aren’t necessarily working on this,” he says. “In self-driving cars, usually millisecond latencies are sufficient reaction times. But we’re developing algorithms that need to respond in microseconds or less. We’re at this technological frontier, and to see how much that can proliferate back to industry will be cool.”\nPlehn is also working to put neural networks on FPGAs for triggers, in collaboration with experimentalists, electrical engineers, and other theorists. Encoding the nuances of abstract theories into material hardware is a puzzle. “In this grant proposal, the person I talked to most is the electrical engineer,” he says, “because I have to ask the engineer, which of my algorithms fits on your bloody FPGA?”\nHardware is hard, says Ryan Kastner, an electrical engineer and computer scientist at UC San Diego who works with Duarte on programming FPGAs. What allows the chips to run algorithms so quickly is their flexibility. Instead of programming them in an abstract coding language like Python, engineers configure the underlying circuitry. They map logic gates, route data paths, and synchronize operations by hand. That low-level control also makes the effort “painfully difficult,” Kastner says. “It’s kind of like you have a lot of rope, and it’s very easy to hang yourself.”\nSeeking New Physics Among the Neutrinos\nThe next piece of new physics may not pop up at a particle accelerator. It may appear at a detector for neutrinos, particles that are part of the Standard Model but remain deeply mysterious. Neutrinos are tiny, electrically neutral, and so light that no one has yet measured their mass. (The latest attempt, in April, set an upper limit of about a millionth the mass of an electron.) Of all known particles with mass, neutrinos are the universe’s most abundant, but also among the most ghostly, rarely deigning to acknowledge the matter around them. Tens of trillions pass through your body every second.\nIf we listen very closely, though, we may just hear the secrets they have to tell. Karagiorgi, of Columbia, has chosen this path to discovery. Being a physicist is “kind of like playing detective, but where you create your own mysteries,” she tells me during my visit to Columbia’s Nevis Laboratories, located on a large estate about 20 km north of Manhattan. Physics research began at the site after World War II; one hallway features papers going back to 1951.\n\n\n\nKaragiorgi is eagerly awaiting a massive neutrino detector that’s currently under construction. Starting in 2028, Fermilab will send neutrinos west through 1,300 km of rock to South Dakota, where they’ll occasionally make their existence known in the Deep Underground Neutrino Experiment (DUNE). Why so far away? When neutrinos travel long distances, they have an odd habit of oscillating, transforming from one kind or “flavor” to another. Observing the oscillations of both the neutrinos and their mirror-image antiparticles, antineutrinos, could tell researchers something about the universe’s matter-antimatter asymmetry—which the Standard Model doesn’t explain—and thus, according to the Nevis website, “why we exist.”\n“DUNE is the thing that’s been pushing me to develop these real-time AI methods,” Karagiorgi says, “for sifting through the data very, very, very quickly and trying to look for rare signatures of interest within them.” When neutrinos interact with the detector’s 70,000 tonnes of liquid argon, they’ll generate a shower of other particles, creating visual tracks that look like a photo of fireworks.\nEven when not bombarding DUNE with neutrinos, researchers will keep collecting data in the off chance that it captures neutrinos from a distant supernova. “This is a massive detector spewing out 5 terabytes of data per second,” Karagiorgi says, “and it’s going to run constantly for a decade.” They will need unsupervised learning to notice signatures that no one was looking for, because there are “lots of different models of how supernova explosions happen, and for all we know, none of them could be the right model for neutrinos,” she says. “To train your algorithm on such uncertain grounds is less than ideal. So an algorithm that can recognize any kind of disturbance would be a win.”\nDeciding in real time which 1 percent of 1 percent of data to keep will require FPGAs. Karagiorgi’s team is preparing to use them for DUNE, and she walks me to a computer lab where they program the circuits. In the FPGA lab, we look at nondescript circuit boards sitting on a table. “So what we’re proposing is a scheme where you can have something like a hundred of these boards for DUNE deep underground that receive the image data frame by frame,” she says. This system could tell researchers whether a given frame resembled TV static, fireworks, or something in between.\nNeutrino experiments, like many particle-physics studies, are very visual. When Karagiorgi was a postdoc, automated image processing at neutrino detectors was still in its infancy, so she and collaborators would often resort to visual scanning (bubble-chamber style) to measure particle tracks. She still asks undergrads to hand-scan as an educational exercise. “I think it’s wrong to just send them to write a machine learning algorithm. Unless you can actually visualize the data, you don’t really gain a sense of what you’re looking for,” she says. “I think it also helps with creativity to be able to visualize the different types of interactions that are happening, and see what’s normal and what’s not normal.”\nBack in Karagiorgi’s office, a bulletin board displays images from The Cognitive Art of Feynman Diagrams, an exhibit for which the designer Edward Tufte created wire sculptures of the physicist Richard Feynman’s schematics of particle interactions. “It’s funny, you know,” she says. “They look like they’re just scribbles, right? But actually, they encode quantitatively predictive behavior in nature.” Later, Karagiorgi and I spend a good 10 minutes discussing whether a computer or a human could find Waldo without knowing what Waldo looked like. We also touch on the 1964 Supreme Court case in which Justice Potter Stewart famously declined to define obscenity, saying “I know it when I see it.” I ask whether it seems weird to hand over to a machine the task of deciding what’s visually interesting. “There are a lot of trust issues,” she says with a laugh.\nOn the drive back to Manhattan, we discuss the history of scientific discovery. “I think it’s part of human nature to try to make sense of an orderly world around you,” Karagiorgi says. “And then you just automatically pick out the oddities. Some people obsess about the oddities more than others, and then try to understand them.”\nReflecting on the Standard Model, she called it “beautiful and elegant,” with “amazing predictive power.” Yet she finds it both limited and limiting, blinding us to colors we don’t yet see. “Sometimes it’s both a blessing and a curse that we’ve managed to develop such a successful theory.”",
        "pubDate": "Tue, 03 Feb 2026 14:00:02 +0000",
        "isoDate": "2026-02-03T14:00:02.000Z",
        "creator": "Matthew Hutson",
        "source": "https://spectrum.ieee.org/particle-physics-ai"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-3h2q33",
        "title": "Andrew Ng: Unbiggen AI",
        "link": "https://spectrum.ieee.org/andrew-ng-data-centric-ai",
        "url": "https://spectrum.ieee.org/andrew-ng-data-centric-ai",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/andrew-ng-listens-during-the-power-of-data-sooner-than-you-think-global-technology-conference-in-brooklyn-new-york-on-wednes.jpg?id=29206806&width=1245&height=700&coordinates=0%2C0%2C0%2C474\"/><br/><br/><p><strong><a href=\"https://en.wikipedia.org/wiki/Andrew_Ng\" rel=\"noopener noreferrer\" target=\"_blank\">Andrew Ng</a> has serious street cred</strong> in artificial intelligence. He pioneered the use of graphics processing units (GPUs) to train deep learning models in the late 2000s with his students at <a href=\"https://stanfordmlgroup.github.io/\" rel=\"noopener noreferrer\" target=\"_blank\">Stanford University</a>, cofounded <a href=\"https://research.google/teams/brain/\" rel=\"noopener noreferrer\" target=\"_blank\">Google Brain</a> in 2011, and then served for three years as chief scientist for <a href=\"https://ir.baidu.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Baidu</a>, where he helped build the Chinese tech giant’s AI group. So when he says he has identified the next big shift in artificial intelligence, people listen. And that’s what he told <em>IEEE Spectrum</em> in an exclusive Q&A.</p><hr/><p>\n\tNg’s current efforts are focused on his company \n\t<a href=\"https://landing.ai/about/\" rel=\"noopener noreferrer\" target=\"_blank\">Landing AI</a>, which built a platform called LandingLens to help manufacturers improve visual inspection with computer vision. He has also become something of an evangelist for what he calls the <a href=\"https://www.youtube.com/watch?v=06-AZXmwHjo\" target=\"_blank\">data-centric AI movement</a>, which he says can yield “small data” solutions to big issues in AI, including model efficiency, accuracy, and bias.\n</p><p>\n\tAndrew Ng on...\n</p><ul>\n<li><a href=\"#big\">What’s next for really big models</a></li>\n<li><a href=\"#career\">The career advice he didn’t listen to</a></li>\n<li><a href=\"#defining\">Defining the data-centric AI movement</a></li>\n<li><a href=\"#synthetic\">Synthetic data</a></li>\n<li><a href=\"#work\">Why Landing AI asks its customers to do the work</a></li>\n</ul><p>\n<strong>The great advances in deep learning over the past decade or so have been powered by ever-bigger models crunching ever-bigger amounts of data. Some people argue that that’s an <a href=\"https://spectrum.ieee.org/deep-learning-computational-cost\" target=\"_self\">unsustainable trajectory</a>. Do you agree that it can’t go on that way?</strong>\n</p><p>\n<strong>Andrew Ng: </strong>This is a big question. We’ve seen foundation models in NLP [natural language processing]. I’m excited about NLP models getting even bigger, and also about the potential of building foundation models in computer vision. I think there’s lots of signal to still be exploited in video: We have not been able to build foundation models yet for video because of compute bandwidth and the cost of processing video, as opposed to tokenized text. So I think that this engine of scaling up deep learning algorithms, which has been running for something like 15 years now, still has steam in it. Having said that, it only applies to certain problems, and there’s a set of other problems that need small data solutions.\n</p><p>\n<strong>When you say you want a foundation model for computer vision, what do you mean by that?</strong>\n</p><p>\n<strong>Ng:</strong> This is a term coined by <a href=\"https://cs.stanford.edu/~pliang/\" rel=\"noopener noreferrer\" target=\"_blank\">Percy Liang</a> and <a href=\"https://crfm.stanford.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">some of my friends at Stanford</a> to refer to very large models, trained on very large data sets, that can be tuned for specific applications. For example, <a href=\"https://spectrum.ieee.org/open-ais-powerful-text-generating-tool-is-ready-for-business\" target=\"_self\">GPT-3</a> is an example of a foundation model [for NLP]. Foundation models offer a lot of promise as a new paradigm in developing machine learning applications, but also challenges in terms of making sure that they’re reasonably fair and free from bias, especially if many of us will be building on top of them.\n</p><p>\n<strong>What needs to happen for someone to build a foundation model for video?</strong>\n</p><p>\n<strong>Ng:</strong> I think there is a scalability problem. The compute power needed to process the large volume of images for video is significant, and I think that’s why foundation models have arisen first in NLP. Many researchers are working on this, and I think we’re seeing early signs of such models being developed in computer vision. But I’m confident that if a semiconductor maker gave us 10 times more processor power, we could easily find 10 times more video to build such models for vision.\n</p><p>\n\tHaving said that, a lot of what’s happened over the past decade is that deep learning has happened in consumer-facing companies that have large user bases, sometimes billions of users, and therefore very large data sets. While that paradigm of machine learning has driven a lot of economic value in consumer software, I find that that recipe of scale doesn’t work for other industries.\n</p><p>\n<a href=\"#top\">Back to top</a>\n</p><p>\n<strong>It’s funny to hear you say that, because your early work was at a consumer-facing company with millions of users.</strong>\n</p><p>\n<strong>Ng: </strong>Over a decade ago, when I proposed starting the <a href=\"https://research.google/teams/brain/\" rel=\"noopener noreferrer\" target=\"_blank\">Google Brain</a> project to use Google’s compute infrastructure to build very large neural networks, it was a controversial step. One very senior person pulled me aside and warned me that starting Google Brain would be bad for my career. I think he felt that the action couldn’t just be in scaling up, and that I should instead focus on architecture innovation.\n</p><p class=\"pull-quote\">\n\t“In many industries where giant data sets simply don’t exist, I think the focus has to shift from big data to good data. Having 50 thoughtfully engineered examples can be sufficient to explain to the neural network what you want it to learn.”<br/>\n\t—Andrew Ng, CEO & Founder, Landing AI\n</p><p>\n\tI remember when my students and I published the first \n\t<a href=\"https://nips.cc/\" rel=\"noopener noreferrer\" target=\"_blank\">NeurIPS</a> workshop paper advocating using <a href=\"https://developer.nvidia.com/cuda-zone\" rel=\"noopener noreferrer\" target=\"_blank\">CUDA</a>, a platform for processing on GPUs, for deep learning—a different senior person in AI sat me down and said, “CUDA is really complicated to program. As a programming paradigm, this seems like too much work.” I did manage to convince him; the other person I did not convince.\n</p><p>\n<strong>I expect they’re both convinced now.</strong>\n</p><p>\n<strong>Ng:</strong> I think so, yes.\n</p><p>\n\tOver the past year as I’ve been speaking to people about the data-centric AI movement, I’ve been getting flashbacks to when I was speaking to people about deep learning and scalability 10 or 15 years ago. In the past year, I’ve been getting the same mix of “there’s nothing new here” and “this seems like the wrong direction.”\n</p><p>\n<a href=\"#top\">Back to top</a>\n</p><p>\n<strong>How do you define data-centric AI, and why do you consider it a movement?</strong>\n</p><p>\n<strong>Ng:</strong> Data-centric AI is the discipline of systematically engineering the data needed to successfully build an AI system. For an AI system, you have to implement some algorithm, say a neural network, in code and then train it on your data set. The dominant paradigm over the last decade was to download the data set while you focus on improving the code. Thanks to that paradigm, over the last decade deep learning networks have improved significantly, to the point where for a lot of applications the code—the neural network architecture—is basically a solved problem. So for many practical applications, it’s now more productive to hold the neural network architecture fixed, and instead find ways to improve the data.\n</p><p>\n\tWhen I started speaking about this, there were many practitioners who, completely appropriately, raised their hands and said, “Yes, we’ve been doing this for 20 years.” This is the time to take the things that some individuals have been doing intuitively and make it a systematic engineering discipline.\n</p><p>\n\tThe data-centric AI movement is much bigger than one company or group of researchers. My collaborators and I organized a \n\t<a href=\"https://neurips.cc/virtual/2021/workshop/21860\" rel=\"noopener noreferrer\" target=\"_blank\">data-centric AI workshop at NeurIPS</a>, and I was really delighted at the number of authors and presenters that showed up.\n</p><p>\n<strong>You often talk about companies or institutions that have only a small amount of data to work with. How can data-centric AI help them?</strong>\n</p><p>\n<strong>Ng: </strong>You hear a lot about vision systems built with millions of images—I once built a face recognition system using 350 million images. Architectures built for hundreds of millions of images don’t work with only 50 images. But it turns out, if you have 50 really good examples, you can build something valuable, like a defect-inspection system. In many industries where giant data sets simply don’t exist, I think the focus has to shift from big data to good data. Having 50 thoughtfully engineered examples can be sufficient to explain to the neural network what you want it to learn.\n</p><p>\n<strong>When you talk about training a model with just 50 images, does that really mean you’re taking an existing model that was trained on a very large data set and fine-tuning it? Or do you mean a brand new model that’s designed to learn only from that small data set?</strong>\n</p><p>\n<strong>Ng: </strong>Let me describe what Landing AI does. When doing visual inspection for manufacturers, we often use our own flavor of <a href=\"https://developers.arcgis.com/python/guide/how-retinanet-works/\" rel=\"noopener noreferrer\" target=\"_blank\">RetinaNet</a>. It is a pretrained model. Having said that, the pretraining is a small piece of the puzzle. What’s a bigger piece of the puzzle is providing tools that enable the manufacturer to pick the right set of images [to use for fine-tuning] and label them in a consistent way. There’s a very practical problem we’ve seen spanning vision, NLP, and speech, where even human annotators don’t agree on the appropriate label. For big data applications, the common response has been: If the data is noisy, let’s just get a lot of data and the algorithm will average over it. But if you can develop tools that flag where the data’s inconsistent and give you a very targeted way to improve the consistency of the data, that turns out to be a more efficient way to get a high-performing system.\n</p><p class=\"pull-quote\">\n\t“Collecting more data often helps, but if you try to collect more data for everything, that can be a very expensive activity.”<br/>\n\t—Andrew Ng\n</p><p>\n\tFor example, if you have 10,000 images where 30 images are of one class, and those 30 images are labeled inconsistently, one of the things we do is build tools to draw your attention to the subset of data that’s inconsistent. So you can very quickly relabel those images to be more consistent, and this leads to improvement in performance.\n</p><p>\n<strong>Could this focus on high-quality data help with bias in data sets? If you’re able to curate the data more before training?</strong>\n</p><p>\n<strong>Ng:</strong> Very much so. Many researchers have pointed out that biased data is one factor among many leading to biased systems. There have been many thoughtful efforts to engineer the data. At the NeurIPS workshop, <a href=\"https://www.cs.princeton.edu/~olgarus/\" rel=\"noopener noreferrer\" target=\"_blank\">Olga Russakovsky</a> gave a really nice talk on this. At the main NeurIPS conference, I also really enjoyed <a href=\"https://neurips.cc/virtual/2021/invited-talk/22281\" rel=\"noopener noreferrer\" target=\"_blank\">Mary Gray’s presentation,</a> which touched on how data-centric AI is one piece of the solution, but not the entire solution. New tools like <a href=\"https://www.microsoft.com/en-us/research/project/datasheets-for-datasets/\" rel=\"noopener noreferrer\" target=\"_blank\">Datasheets for Datasets</a> also seem like an important piece of the puzzle.\n</p><p>\n\tOne of the powerful tools that data-centric AI gives us is the ability to engineer a subset of the data. Imagine training a machine-learning system and finding that its performance is okay for most of the data set, but its performance is biased for just a subset of the data. If you try to change the whole neural network architecture to improve the performance on just that subset, it’s quite difficult. But if you can engineer a subset of the data you can address the problem in a much more targeted way.\n</p><p>\n<strong>When you talk about engineering the data, what do you mean exactly?</strong>\n</p><p>\n<strong>Ng: </strong>In AI, data cleaning is important, but the way the data has been cleaned has often been in very manual ways. In computer vision, someone may visualize images through a <a href=\"https://jupyter.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Jupyter notebook</a> and maybe spot the problem, and maybe fix it. But I’m excited about tools that allow you to have a very large data set, tools that draw your attention quickly and efficiently to the subset of data where, say, the labels are noisy. Or to quickly bring your attention to the one class among 100 classes where it would benefit you to collect more data. Collecting more data often helps, but if you try to collect more data for everything, that can be a very expensive activity.\n</p><p>\n\tFor example, I once figured out that a speech-recognition system was performing poorly when there was car noise in the background. Knowing that allowed me to collect more data with car noise in the background, rather than trying to collect more data for everything, which would have been expensive and slow.\n</p><p>\n<a href=\"#top\">Back to top</a>\n</p><p>\n<strong>What about using synthetic data, is that often a good solution?</strong>\n</p><p>\n<strong>Ng: </strong>I think synthetic data is an important tool in the tool chest of data-centric AI. At the NeurIPS workshop, <a href=\"https://tensorlab.cms.caltech.edu/users/anima/\" rel=\"noopener noreferrer\" target=\"_blank\">Anima Anandkumar</a> gave a great talk that touched on synthetic data. I think there are important uses of synthetic data that go beyond just being a preprocessing step for increasing the data set for a learning algorithm. I’d love to see more tools to let developers use synthetic data generation as part of the closed loop of iterative machine learning development.\n</p><p>\n<strong>Do you mean that synthetic data would allow you to try the model on more data sets?</strong>\n</p><p>\n<strong>Ng: </strong>Not really. Here’s an example. Let’s say you’re trying to detect defects in a smartphone casing. There are many different types of defects on smartphones. It could be a scratch, a dent, pit marks, discoloration of the material, other types of blemishes. If you train the model and then find through error analysis that it’s doing well overall but it’s performing poorly on pit marks, then synthetic data generation allows you to address the problem in a more targeted way. You could generate more data just for the pit-mark category.\n</p><p class=\"pull-quote\">\n\t“In the consumer software Internet, we could train a handful of machine-learning models to serve a billion users. In manufacturing, you might have 10,000 manufacturers building 10,000 custom AI models.”<br/>\n\t—Andrew Ng\n</p><p>\n\tSynthetic data generation is a very powerful tool, but there are many simpler tools that I will often try first. Such as data augmentation, improving labeling consistency, or just asking a factory to collect more data.\n</p><p>\n<a href=\"#top\">Back to top</a>\n</p><p>\n<strong>To make these issues more concrete, can you walk me through an example? When a company approaches <a href=\"https://landing.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">Landing AI</a> and says it has a problem with visual inspection, how do you onboard them and work toward deployment?</strong>\n</p><p>\n<strong>Ng: </strong>When a customer approaches us we usually have a conversation about their inspection problem and look at a few images to verify that the problem is feasible with computer vision. Assuming it is, we ask them to upload the data to the <a href=\"https://landing.ai/platform/\" rel=\"noopener noreferrer\" target=\"_blank\">LandingLens</a> platform. We often advise them on the methodology of data-centric AI and help them label the data.\n</p><p>\n\tOne of the foci of Landing AI is to empower manufacturing companies to do the machine learning work themselves. A lot of our work is making sure the software is fast and easy to use. Through the iterative process of machine learning development, we advise customers on things like how to train models on the platform, when and how to improve the labeling of data so the performance of the model improves. Our training and software supports them all the way through deploying the trained model to an edge device in the factory.\n</p><p>\n<strong>How do you deal with changing needs? If products change or lighting conditions change in the factory, can the model keep up?</strong>\n</p><p>\n<strong>Ng:</strong> It varies by manufacturer. There is data drift in many contexts. But there are some manufacturers that have been running the same manufacturing line for 20 years now with few changes, so they don’t expect changes in the next five years. Those stable environments make things easier. For other manufacturers, we provide tools to flag when there’s a significant data-drift issue. I find it really important to empower manufacturing customers to correct data, retrain, and update the model. Because if something changes and it’s 3 a.m. in the United States, I want them to be able to adapt their learning algorithm right away to maintain operations.\n</p><p>\n\tIn the consumer software Internet, we could train a handful of machine-learning models to serve a billion users. In manufacturing, you might have 10,000 manufacturers building 10,000 custom AI models. The challenge is, how do you do that without Landing AI having to hire 10,000 machine learning specialists?\n</p><p>\n<strong>So you’re saying that to make it scale, you have to empower customers to do a lot of the training and other work.</strong>\n</p><p>\n<strong>Ng: </strong>Yes, exactly! This is an industry-wide problem in AI, not just in manufacturing. Look at health care. Every hospital has its own slightly different format for electronic health records. How can every hospital train its own custom AI model? Expecting every hospital’s IT personnel to invent new neural-network architectures is unrealistic. The only way out of this dilemma is to build tools that empower the customers to build their own models by giving them tools to engineer the data and express their domain knowledge. That’s what Landing AI is executing in computer vision, and the field of AI needs other teams to execute this in other domains.\n</p><p>\n<strong>Is there anything else you think it’s important for people to understand about the work you’re doing or the data-centric AI movement?</strong>\n</p><p>\n<strong>Ng: </strong>In the last decade, the biggest shift in AI was a shift to deep learning. I think it’s quite possible that in this decade the biggest shift will be to data-centric AI. With the maturity of today’s neural network architectures, I think for a lot of the practical applications the bottleneck will be whether we can efficiently get the data we need to develop systems that work well. The data-centric AI movement has tremendous energy and momentum across the whole community. I hope more researchers and developers will jump in and work on it.\n</p><p>\n<a href=\"#top\">Back to top</a>\n</p><p><em>This article appears in the April 2022 print issue as “Andrew Ng, AI Minimalist</em><em>.”</em></p>",
        "contentSnippet": "Andrew Ng has serious street cred in artificial intelligence. He pioneered the use of graphics processing units (GPUs) to train deep learning models in the late 2000s with his students at Stanford University, cofounded Google Brain in 2011, and then served for three years as chief scientist for Baidu, where he helped build the Chinese tech giant’s AI group. So when he says he has identified the next big shift in artificial intelligence, people listen. And that’s what he told IEEE Spectrum in an exclusive Q&A.\n\nLanding AI, which built a platform called LandingLens to help manufacturers improve visual inspection with computer vision. He has also become something of an evangelist for what he calls the data-centric AI movement, which he says can yield “small data” solutions to big issues in AI, including model efficiency, accuracy, and bias.\n\n\nWhat’s next for really big models\nThe career advice he didn’t listen to\nDefining the data-centric AI movement\nSynthetic data\nWhy Landing AI asks its customers to do the work\n\nThe great advances in deep learning over the past decade or so have been powered by ever-bigger models crunching ever-bigger amounts of data. Some people argue that that’s an unsustainable trajectory. Do you agree that it can’t go on that way?\n\nAndrew Ng: This is a big question. We’ve seen foundation models in NLP [natural language processing]. I’m excited about NLP models getting even bigger, and also about the potential of building foundation models in computer vision. I think there’s lots of signal to still be exploited in video: We have not been able to build foundation models yet for video because of compute bandwidth and the cost of processing video, as opposed to tokenized text. So I think that this engine of scaling up deep learning algorithms, which has been running for something like 15 years now, still has steam in it. Having said that, it only applies to certain problems, and there’s a set of other problems that need small data solutions.\n\nWhen you say you want a foundation model for computer vision, what do you mean by that?\n\nNg: This is a term coined by Percy Liang and some of my friends at Stanford to refer to very large models, trained on very large data sets, that can be tuned for specific applications. For example, GPT-3 is an example of a foundation model [for NLP]. Foundation models offer a lot of promise as a new paradigm in developing machine learning applications, but also challenges in terms of making sure that they’re reasonably fair and free from bias, especially if many of us will be building on top of them.\n\nWhat needs to happen for someone to build a foundation model for video?\n\nNg: I think there is a scalability problem. The compute power needed to process the large volume of images for video is significant, and I think that’s why foundation models have arisen first in NLP. Many researchers are working on this, and I think we’re seeing early signs of such models being developed in computer vision. But I’m confident that if a semiconductor maker gave us 10 times more processor power, we could easily find 10 times more video to build such models for vision.\n\n\nBack to top\n\nIt’s funny to hear you say that, because your early work was at a consumer-facing company with millions of users.\n\nNg: Over a decade ago, when I proposed starting the Google Brain project to use Google’s compute infrastructure to build very large neural networks, it was a controversial step. One very senior person pulled me aside and warned me that starting Google Brain would be bad for my career. I think he felt that the action couldn’t just be in scaling up, and that I should instead focus on architecture innovation.\n\n\n\tI remember when my students and I published the first \n\tNeurIPS workshop paper advocating using CUDA, a platform for processing on GPUs, for deep learning—a different senior person in AI sat me down and said, “CUDA is really complicated to program. As a programming paradigm, this seems like too much work.” I did manage to convince him; the other person I did not convince.\n\nI expect they’re both convinced now.\n\nNg: I think so, yes.\n\n\nBack to top\n\nHow do you define data-centric AI, and why do you consider it a movement?\n\nNg: Data-centric AI is the discipline of systematically engineering the data needed to successfully build an AI system. For an AI system, you have to implement some algorithm, say a neural network, in code and then train it on your data set. The dominant paradigm over the last decade was to download the data set while you focus on improving the code. Thanks to that paradigm, over the last decade deep learning networks have improved significantly, to the point where for a lot of applications the code—the neural network architecture—is basically a solved problem. So for many practical applications, it’s now more productive to hold the neural network architecture fixed, and instead find ways to improve the data.\n\n\n\tThe data-centric AI movement is much bigger than one company or group of researchers. My collaborators and I organized a \n\tdata-centric AI workshop at NeurIPS, and I was really delighted at the number of authors and presenters that showed up.\n\nYou often talk about companies or institutions that have only a small amount of data to work with. How can data-centric AI help them?\n\nNg: You hear a lot about vision systems built with millions of images—I once built a face recognition system using 350 million images. Architectures built for hundreds of millions of images don’t work with only 50 images. But it turns out, if you have 50 really good examples, you can build something valuable, like a defect-inspection system. In many industries where giant data sets simply don’t exist, I think the focus has to shift from big data to good data. Having 50 thoughtfully engineered examples can be sufficient to explain to the neural network what you want it to learn.\n\nWhen you talk about training a model with just 50 images, does that really mean you’re taking an existing model that was trained on a very large data set and fine-tuning it? Or do you mean a brand new model that’s designed to learn only from that small data set?\n\nNg: Let me describe what Landing AI does. When doing visual inspection for manufacturers, we often use our own flavor of RetinaNet. It is a pretrained model. Having said that, the pretraining is a small piece of the puzzle. What’s a bigger piece of the puzzle is providing tools that enable the manufacturer to pick the right set of images [to use for fine-tuning] and label them in a consistent way. There’s a very practical problem we’ve seen spanning vision, NLP, and speech, where even human annotators don’t agree on the appropriate label. For big data applications, the common response has been: If the data is noisy, let’s just get a lot of data and the algorithm will average over it. But if you can develop tools that flag where the data’s inconsistent and give you a very targeted way to improve the consistency of the data, that turns out to be a more efficient way to get a high-performing system.\n\n\n\tFor example, if you have 10,000 images where 30 images are of one class, and those 30 images are labeled inconsistently, one of the things we do is build tools to draw your attention to the subset of data that’s inconsistent. So you can very quickly relabel those images to be more consistent, and this leads to improvement in performance.\n\nCould this focus on high-quality data help with bias in data sets? If you’re able to curate the data more before training?\n\nNg: Very much so. Many researchers have pointed out that biased data is one factor among many leading to biased systems. There have been many thoughtful efforts to engineer the data. At the NeurIPS workshop, Olga Russakovsky gave a really nice talk on this. At the main NeurIPS conference, I also really enjoyed Mary Gray’s presentation, which touched on how data-centric AI is one piece of the solution, but not the entire solution. New tools like Datasheets for Datasets also seem like an important piece of the puzzle.\n\n\nWhen you talk about engineering the data, what do you mean exactly?\n\nNg: In AI, data cleaning is important, but the way the data has been cleaned has often been in very manual ways. In computer vision, someone may visualize images through a Jupyter notebook and maybe spot the problem, and maybe fix it. But I’m excited about tools that allow you to have a very large data set, tools that draw your attention quickly and efficiently to the subset of data where, say, the labels are noisy. Or to quickly bring your attention to the one class among 100 classes where it would benefit you to collect more data. Collecting more data often helps, but if you try to collect more data for everything, that can be a very expensive activity.\n\n\nBack to top\n\nWhat about using synthetic data, is that often a good solution?\n\nNg: I think synthetic data is an important tool in the tool chest of data-centric AI. At the NeurIPS workshop, Anima Anandkumar gave a great talk that touched on synthetic data. I think there are important uses of synthetic data that go beyond just being a preprocessing step for increasing the data set for a learning algorithm. I’d love to see more tools to let developers use synthetic data generation as part of the closed loop of iterative machine learning development.\n\nDo you mean that synthetic data would allow you to try the model on more data sets?\n\nNg: Not really. Here’s an example. Let’s say you’re trying to detect defects in a smartphone casing. There are many different types of defects on smartphones. It could be a scratch, a dent, pit marks, discoloration of the material, other types of blemishes. If you train the model and then find through error analysis that it’s doing well overall but it’s performing poorly on pit marks, then synthetic data generation allows you to address the problem in a more targeted way. You could generate more data just for the pit-mark category.\n\n\n\tSynthetic data generation is a very powerful tool, but there are many simpler tools that I will often try first. Such as data augmentation, improving labeling consistency, or just asking a factory to collect more data.\n\nBack to top\n\nTo make these issues more concrete, can you walk me through an example? When a company approaches Landing AI and says it has a problem with visual inspection, how do you onboard them and work toward deployment?\n\nNg: When a customer approaches us we usually have a conversation about their inspection problem and look at a few images to verify that the problem is feasible with computer vision. Assuming it is, we ask them to upload the data to the LandingLens platform. We often advise them on the methodology of data-centric AI and help them label the data.\n\n\nHow do you deal with changing needs? If products change or lighting conditions change in the factory, can the model keep up?\n\nNg: It varies by manufacturer. There is data drift in many contexts. But there are some manufacturers that have been running the same manufacturing line for 20 years now with few changes, so they don’t expect changes in the next five years. Those stable environments make things easier. For other manufacturers, we provide tools to flag when there’s a significant data-drift issue. I find it really important to empower manufacturing customers to correct data, retrain, and update the model. Because if something changes and it’s 3 a.m. in the United States, I want them to be able to adapt their learning algorithm right away to maintain operations.\n\n\nSo you’re saying that to make it scale, you have to empower customers to do a lot of the training and other work.\n\nNg: Yes, exactly! This is an industry-wide problem in AI, not just in manufacturing. Look at health care. Every hospital has its own slightly different format for electronic health records. How can every hospital train its own custom AI model? Expecting every hospital’s IT personnel to invent new neural-network architectures is unrealistic. The only way out of this dilemma is to build tools that empower the customers to build their own models by giving them tools to engineer the data and express their domain knowledge. That’s what Landing AI is executing in computer vision, and the field of AI needs other teams to execute this in other domains.\n\nIs there anything else you think it’s important for people to understand about the work you’re doing or the data-centric AI movement?\n\nNg: In the last decade, the biggest shift in AI was a shift to deep learning. I think it’s quite possible that in this decade the biggest shift will be to data-centric AI. With the maturity of today’s neural network architectures, I think for a lot of the practical applications the bottleneck will be whether we can efficiently get the data we need to develop systems that work well. The data-centric AI movement has tremendous energy and momentum across the whole community. I hope more researchers and developers will jump in and work on it.\n\nBack to top\n\nThis article appears in the April 2022 print issue as “Andrew Ng, AI Minimalist.”",
        "pubDate": "Wed, 09 Feb 2022 15:31:12 +0000",
        "isoDate": "2022-02-09T15:31:12.000Z",
        "creator": "Eliza Strickland",
        "source": "https://spectrum.ieee.org/andrew-ng-data-centric-ai"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-in5ncf",
        "title": "How AI Will Change Chip Design",
        "link": "https://spectrum.ieee.org/ai-chip-design-matlab",
        "url": "https://spectrum.ieee.org/ai-chip-design-matlab",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/layered-rendering-of-colorful-semiconductor-wafers-with-a-bright-white-light-sitting-on-one.jpg?id=29285079&width=1245&height=700&coordinates=0%2C156%2C0%2C156\"/><br/><br/><p>The end of <a href=\"https://spectrum.ieee.org/on-beyond-moores-law-4-new-laws-of-computing\" target=\"_self\">Moore’s Law</a> is looming. Engineers and designers can do only so much to <a href=\"https://spectrum.ieee.org/ibm-introduces-the-worlds-first-2nm-node-chip\" target=\"_self\">miniaturize transistors</a> and <a href=\"https://spectrum.ieee.org/cerebras-giant-ai-chip-now-has-a-trillions-more-transistors\" target=\"_self\">pack as many of them as possible into chips</a>. So they’re turning to other approaches to chip design, incorporating technologies like AI into the process.</p><p>Samsung, for instance, is <a href=\"https://spectrum.ieee.org/processing-in-dram-accelerates-ai\" target=\"_self\">adding AI to its memory chips</a> to enable processing in memory, thereby saving energy and speeding up machine learning. Speaking of speed, Google’s TPU V4 AI chip has <a href=\"https://spectrum.ieee.org/heres-how-googles-tpu-v4-ai-chip-stacked-up-in-training-tests\" target=\"_self\">doubled its processing power</a> compared with that of  its previous version.</p><p>But AI holds still more promise and potential for the semiconductor industry. To better understand how AI is set to revolutionize chip design, we spoke with <a href=\"https://www.linkedin.com/in/heather-gorr-phd\" rel=\"noopener noreferrer\" target=\"_blank\">Heather Gorr</a>, senior product manager for <a href=\"https://www.mathworks.com/\" rel=\"noopener noreferrer\" target=\"_blank\">MathWorks</a>’ MATLAB platform.</p><p><strong>How is AI currently being used to design the next generation of chips?</strong></p><p><strong>Heather Gorr:</strong> AI is such an important technology because it’s involved in most parts of the cycle, including the design and manufacturing process. There’s a lot of important applications here, even in the general process engineering where we want to optimize things. I think defect detection is a big one at all phases of the process, especially in manufacturing. But even thinking ahead in the design process, [AI now plays a significant role] when you’re designing the light and the sensors and all the different components. There’s a lot of anomaly detection and fault mitigation that you really want to consider.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"Portrait of a woman with blonde-red hair smiling at the camera\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"1f18a02ccaf51f5c766af2ebc4af18e1\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"2dc00\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/portrait-of-a-woman-with-blonde-red-hair-smiling-at-the-camera.jpg?id=29288554&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\" style=\"max-width: 100%;\">Heather Gorr</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\" style=\"max-width: 100%;\">MathWorks</small></p><p>Then, thinking about the logistical modeling that you see in any industry, there is always planned downtime that you want to mitigate; but you also end up having unplanned downtime. So, looking back at that historical data of when you’ve had those moments where maybe it took a bit longer than expected to manufacture something, you can take a look at all of that data and use AI to try to identify the proximate cause or to see  something that might jump out even in the processing and design phases. We think of AI oftentimes as a predictive tool, or as a robot doing something, but a lot of times you get a lot of insight from the data through AI.</p><p><strong>What are the benefits of using AI for chip design?</strong></p><p><strong>Gorr:</strong> Historically, we’ve seen a lot of physics-based modeling, which is a very intensive process. We want to do a <a href=\"https://en.wikipedia.org/wiki/Model_order_reduction\" rel=\"noopener noreferrer\" target=\"_blank\">reduced order model</a>, where instead of solving such a computationally expensive and extensive model, we can do something a little cheaper. You could create a surrogate model, so to speak, of that physics-based model, use the data, and then do your <a href=\"https://institutefordiseasemodeling.github.io/idmtools/parameter-sweeps.html\" rel=\"noopener noreferrer\" target=\"_blank\">parameter sweeps</a>, your optimizations, your <a href=\"https://www.ibm.com/cloud/learn/monte-carlo-simulation\" rel=\"noopener noreferrer\" target=\"_blank\">Monte Carlo simulations</a> using the surrogate model. That takes a lot less time computationally than solving the physics-based equations directly. So, we’re seeing that benefit in many ways, including the efficiency and economy that are the results of iterating quickly on the experiments and the simulations that will really help in the design.</p><p><strong>So it’s like having a digital twin in a sense?</strong></p><p><strong>Gorr:</strong> Exactly. That’s pretty much what people are doing, where you have the physical system model and the experimental data. Then, in conjunction, you have this other model that you could tweak and tune and try different parameters and experiments that let sweep through all of those different situations and come up with a better design in the end.</p><p><strong>So, it’s going to be more efficient and, as you said, cheaper?</strong></p><p><strong>Gorr:</strong> Yeah, definitely. Especially in the experimentation and design phases, where you’re trying different things. That’s obviously going to yield dramatic cost savings if you’re actually manufacturing and producing [the chips]. You want to simulate, test, experiment as much as possible without making something using the actual process engineering.</p><p><strong>We’ve talked about the benefits. How about the drawbacks?</strong></p><p><strong>Gorr: </strong>The [AI-based experimental models] tend to not be as accurate as physics-based models. Of course, that’s why you do many simulations and parameter sweeps. But that’s also the benefit of having that digital twin, where you can keep that in mind—it’s not going to be as accurate as that precise model that we’ve developed over the years.</p><p>Both chip design and manufacturing are system intensive; you have to consider every little part. And that can be really challenging. It’s a case where you might have models to predict something and different parts of it, but you still need to bring it all together.</p><p>One of the other things to think about too is that you need the data to build the models. You have to incorporate data from all sorts of different sensors and different sorts of teams, and so that heightens the challenge.</p><p><strong>How can engineers use AI to better prepare and extract insights from hardware or sensor data?</strong></p><p><strong>Gorr: </strong>We always think about using AI to predict something or do some robot task, but you can use AI to come up with patterns and pick out things you might not have noticed before on your own. People will use AI when they have high-frequency data coming from many different sensors, and a lot of times it’s useful to explore the frequency domain and things like data synchronization or resampling. Those can be really challenging if you’re not sure where to start.</p><p>One of the things I would say is, use the tools that are available. There’s a vast community of people working on these things, and you can find lots of examples [of applications and techniques] on <a href=\"https://github.com/\" rel=\"noopener noreferrer\" target=\"_blank\">GitHub</a> or <a href=\"https://www.mathworks.com/matlabcentral/\" rel=\"noopener noreferrer\" target=\"_blank\">MATLAB Central</a>, where people have shared nice examples, even little apps they’ve created. I think many of us are buried in data and just not sure what to do with it, so definitely take advantage of what’s already out there in the community. You can explore and see what makes sense to you, and bring in that balance of domain knowledge and the insight you get from the tools and AI.</p><p><strong>What should engineers and designers consider wh</strong><strong>en using AI for chip design?</strong></p><p><strong>Gorr:</strong> Think through what problems you’re trying to solve or what insights you might hope to find, and try to be clear about that. Consider all of the different components, and document and test each of those different parts. Consider all of the people involved, and explain and hand off in a way that is sensible for the whole team.</p><p><strong>How do you think AI will affect chip designers’ jobs?</strong></p><p><strong>Gorr:</strong> It’s going to free up a lot of human capital for more advanced tasks. We can use AI to reduce waste, to optimize the materials, to optimize the design, but then you still have that human involved whenever it comes to decision-making. I think it’s a great example of people and technology working hand in hand. It’s also an industry where all people involved—even on the manufacturing floor—need to have some level of understanding of what’s happening, so this is a great industry for advancing AI because of how we test things and how we think about them before we put them on the chip.</p><p><strong>How do you envision the future of AI and chip design?</strong></p><p><strong>Gorr</strong><strong>:</strong> It’s very much dependent on that human element—involving people in the process and having that interpretable model. We can do many things with the mathematical minutiae of modeling, but it comes down to how people are using it, how everybody in the process is understanding and applying it. Communication and involvement of people of all skill levels in the process are going to be really important. We’re going to see less of those superprecise predictions and more transparency of information, sharing, and that digital twin—not only using AI but also using our human knowledge and all of the work that many people have done over the years.</p>",
        "contentSnippet": "The end of Moore’s Law is looming. Engineers and designers can do only so much to miniaturize transistors and pack as many of them as possible into chips. So they’re turning to other approaches to chip design, incorporating technologies like AI into the process.\nSamsung, for instance, is adding AI to its memory chips to enable processing in memory, thereby saving energy and speeding up machine learning. Speaking of speed, Google’s TPU V4 AI chip has doubled its processing power compared with that of  its previous version.\nBut AI holds still more promise and potential for the semiconductor industry. To better understand how AI is set to revolutionize chip design, we spoke with Heather Gorr, senior product manager for MathWorks’ MATLAB platform.\nHow is AI currently being used to design the next generation of chips?\nHeather Gorr: AI is such an important technology because it’s involved in most parts of the cycle, including the design and manufacturing process. There’s a lot of important applications here, even in the general process engineering where we want to optimize things. I think defect detection is a big one at all phases of the process, especially in manufacturing. But even thinking ahead in the design process, [AI now plays a significant role] when you’re designing the light and the sensors and all the different components. There’s a lot of anomaly detection and fault mitigation that you really want to consider.\n\n\nHeather GorrMathWorks\nThen, thinking about the logistical modeling that you see in any industry, there is always planned downtime that you want to mitigate; but you also end up having unplanned downtime. So, looking back at that historical data of when you’ve had those moments where maybe it took a bit longer than expected to manufacture something, you can take a look at all of that data and use AI to try to identify the proximate cause or to see  something that might jump out even in the processing and design phases. We think of AI oftentimes as a predictive tool, or as a robot doing something, but a lot of times you get a lot of insight from the data through AI.\nWhat are the benefits of using AI for chip design?\nGorr: Historically, we’ve seen a lot of physics-based modeling, which is a very intensive process. We want to do a reduced order model, where instead of solving such a computationally expensive and extensive model, we can do something a little cheaper. You could create a surrogate model, so to speak, of that physics-based model, use the data, and then do your parameter sweeps, your optimizations, your Monte Carlo simulations using the surrogate model. That takes a lot less time computationally than solving the physics-based equations directly. So, we’re seeing that benefit in many ways, including the efficiency and economy that are the results of iterating quickly on the experiments and the simulations that will really help in the design.\nSo it’s like having a digital twin in a sense?\nGorr: Exactly. That’s pretty much what people are doing, where you have the physical system model and the experimental data. Then, in conjunction, you have this other model that you could tweak and tune and try different parameters and experiments that let sweep through all of those different situations and come up with a better design in the end.\nSo, it’s going to be more efficient and, as you said, cheaper?\nGorr: Yeah, definitely. Especially in the experimentation and design phases, where you’re trying different things. That’s obviously going to yield dramatic cost savings if you’re actually manufacturing and producing [the chips]. You want to simulate, test, experiment as much as possible without making something using the actual process engineering.\nWe’ve talked about the benefits. How about the drawbacks?\nGorr: The [AI-based experimental models] tend to not be as accurate as physics-based models. Of course, that’s why you do many simulations and parameter sweeps. But that’s also the benefit of having that digital twin, where you can keep that in mind—it’s not going to be as accurate as that precise model that we’ve developed over the years.\nBoth chip design and manufacturing are system intensive; you have to consider every little part. And that can be really challenging. It’s a case where you might have models to predict something and different parts of it, but you still need to bring it all together.\nOne of the other things to think about too is that you need the data to build the models. You have to incorporate data from all sorts of different sensors and different sorts of teams, and so that heightens the challenge.\nHow can engineers use AI to better prepare and extract insights from hardware or sensor data?\nGorr: We always think about using AI to predict something or do some robot task, but you can use AI to come up with patterns and pick out things you might not have noticed before on your own. People will use AI when they have high-frequency data coming from many different sensors, and a lot of times it’s useful to explore the frequency domain and things like data synchronization or resampling. Those can be really challenging if you’re not sure where to start.\nOne of the things I would say is, use the tools that are available. There’s a vast community of people working on these things, and you can find lots of examples [of applications and techniques] on GitHub or MATLAB Central, where people have shared nice examples, even little apps they’ve created. I think many of us are buried in data and just not sure what to do with it, so definitely take advantage of what’s already out there in the community. You can explore and see what makes sense to you, and bring in that balance of domain knowledge and the insight you get from the tools and AI.\nWhat should engineers and designers consider when using AI for chip design?\nGorr: Think through what problems you’re trying to solve or what insights you might hope to find, and try to be clear about that. Consider all of the different components, and document and test each of those different parts. Consider all of the people involved, and explain and hand off in a way that is sensible for the whole team.\nHow do you think AI will affect chip designers’ jobs?\nGorr: It’s going to free up a lot of human capital for more advanced tasks. We can use AI to reduce waste, to optimize the materials, to optimize the design, but then you still have that human involved whenever it comes to decision-making. I think it’s a great example of people and technology working hand in hand. It’s also an industry where all people involved—even on the manufacturing floor—need to have some level of understanding of what’s happening, so this is a great industry for advancing AI because of how we test things and how we think about them before we put them on the chip.\nHow do you envision the future of AI and chip design?\nGorr: It’s very much dependent on that human element—involving people in the process and having that interpretable model. We can do many things with the mathematical minutiae of modeling, but it comes down to how people are using it, how everybody in the process is understanding and applying it. Communication and involvement of people of all skill levels in the process are going to be really important. We’re going to see less of those superprecise predictions and more transparency of information, sharing, and that digital twin—not only using AI but also using our human knowledge and all of the work that many people have done over the years.",
        "pubDate": "Tue, 08 Feb 2022 14:00:01 +0000",
        "isoDate": "2022-02-08T14:00:01.000Z",
        "creator": "Rina Diane Caballar",
        "source": "https://spectrum.ieee.org/ai-chip-design-matlab"
      },
      {
        "id": "rss-ieee-spectrum-energy-environment-18-cas4k",
        "title": "Atomically Thin Materials Significantly Shrink Qubits",
        "link": "https://spectrum.ieee.org/2d-hbn-qubit",
        "url": "https://spectrum.ieee.org/2d-hbn-qubit",
        "content": "\n<img src=\"https://spectrum.ieee.org/media-library/a-golden-square-package-holds-a-small-processor-sitting-on-top-is-a-metal-square-with-mit-etched-into-it.jpg?id=29281587&width=1245&height=700&coordinates=0%2C156%2C0%2C156\"/><br/><br/><p>Quantum computing is a devilishly complex technology, with many technical hurdles impacting its development. Of these challenges two critical issues stand out: miniaturization and qubit quality.</p><p>IBM has adopted the superconducting qubit road map of <a href=\"https://spectrum.ieee.org/ibms-envisons-the-road-to-quantum-computing-like-an-apollo-mission\" target=\"_self\">reaching a 1,121-qubit processor by 2023</a>, leading to the expectation that 1,000 qubits with today’s qubit form factor is feasible. However, current approaches will require very large chips (50 millimeters on a side, or larger) at the scale of small wafers, or the use of chiplets on multichip modules. While this approach will work, the aim is to attain a better path toward scalability.</p><p>Now researchers at <a href=\"https://www.nature.com/articles/s41563-021-01187-w\" rel=\"noopener noreferrer\" target=\"_blank\">MIT have been able to both reduce the size of the qubits</a> and done so in a way that reduces the interference that occurs between neighboring qubits. The MIT researchers have increased the number of superconducting qubits that can be added onto a device by a factor of 100.</p><p>“We are addressing both qubit miniaturization and quality,” said <a href=\"https://equs.mit.edu/william-d-oliver/\" rel=\"noopener noreferrer\" target=\"_blank\">William Oliver</a>, the director for the <a href=\"https://cqe.mit.edu/\" target=\"_blank\">Center for Quantum Engineering</a> at MIT. “Unlike conventional transistor scaling, where only the number really matters, for qubits, large numbers are not sufficient, they must also be high-performance. Sacrificing performance for qubit number is not a useful trade in quantum computing. They must go hand in hand.”</p><p>The key to this big increase in qubit density and reduction of interference comes down to the use of two-dimensional materials, in particular the 2D insulator hexagonal boron nitride (hBN). The MIT researchers demonstrated that a few atomic monolayers of hBN can be stacked to form the insulator in the capacitors of a superconducting qubit.</p><p>Just like other capacitors, the capacitors in these superconducting circuits take the form of a sandwich in which an insulator material is sandwiched between two metal plates. The big difference for these capacitors is that the superconducting circuits can operate only at extremely low temperatures—less than 0.02 degrees above absolute zero (-273.15 °C).</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"Golden dilution refrigerator hanging vertically\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"694399af8a1c345e51a695ff73909eda\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"6c615\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/golden-dilution-refrigerator-hanging-vertically.jpg?id=29281593&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\" style=\"max-width: 100%;\">Superconducting qubits are measured at temperatures as low as 20 millikelvin in a dilution refrigerator.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\" style=\"max-width: 100%;\">Nathan Fiske/MIT</small></p><p>In that environment, insulating materials that are available for the job, such as PE-CVD silicon oxide or silicon nitride, have quite a few defects that are too lossy for quantum computing applications. To get around these material shortcomings, most superconducting circuits use what are called coplanar capacitors. In these capacitors, the plates are positioned laterally to one another, rather than on top of one another.</p><p>As a result, the intrinsic silicon substrate below the plates and to a smaller degree the vacuum above the plates serve as the capacitor dielectric. Intrinsic silicon is chemically pure and therefore has few defects, and the large size dilutes the electric field at the plate interfaces, all of which leads to a low-loss capacitor. The lateral size of each plate in this open-face design ends up being quite large (typically 100 by 100 micrometers) in order to achieve the required capacitance.</p><p>In an effort to move away from the large lateral configuration, the MIT researchers embarked on a search for an insulator that has very few defects and is compatible with superconducting capacitor plates.</p><p>“We chose to study hBN because it is the most widely used insulator in 2D material research due to its cleanliness and chemical inertness,” said colead author <a href=\"https://equs.mit.edu/joel-wang/\" rel=\"noopener noreferrer\" target=\"_blank\">Joel Wang</a>, a research scientist in the Engineering Quantum Systems group of the MIT Research Laboratory for Electronics. </p><p>On either side of the hBN, the MIT researchers used the 2D superconducting material, niobium diselenide. One of the trickiest aspects of fabricating the capacitors was working with the niobium diselenide, which oxidizes in seconds when exposed to air, according to Wang. This necessitates that the assembly of the capacitor occur in a glove box filled with argon gas.</p><p>While this would seemingly complicate the scaling up of the production of these capacitors, Wang doesn’t regard this as a limiting factor.</p><p>“What determines the quality factor of the capacitor are the two interfaces between the two materials,” said Wang. “Once the sandwich is made, the two interfaces are “sealed” and we don’t see any noticeable degradation over time when exposed to the atmosphere.”</p><p>This lack of degradation is because around 90 percent of the electric field is contained within the sandwich structure, so the oxidation of the outer surface of the niobium diselenide does not play a significant role anymore. This ultimately makes the capacitor footprint much smaller, and it accounts for the reduction in cross talk between the neighboring qubits.</p><p>“The main challenge for scaling up the fabrication will be the wafer-scale growth of hBN and 2D superconductors like [niobium diselenide], and how one can do wafer-scale stacking of these films,” added Wang.</p><p>Wang believes that this research has shown 2D hBN to be a good insulator candidate for superconducting qubits. He says that the groundwork the MIT team has done will serve as a road map for using other hybrid 2D materials to build superconducting circuits.</p>",
        "contentSnippet": "Quantum computing is a devilishly complex technology, with many technical hurdles impacting its development. Of these challenges two critical issues stand out: miniaturization and qubit quality.\nIBM has adopted the superconducting qubit road map of reaching a 1,121-qubit processor by 2023, leading to the expectation that 1,000 qubits with today’s qubit form factor is feasible. However, current approaches will require very large chips (50 millimeters on a side, or larger) at the scale of small wafers, or the use of chiplets on multichip modules. While this approach will work, the aim is to attain a better path toward scalability.\nNow researchers at MIT have been able to both reduce the size of the qubits and done so in a way that reduces the interference that occurs between neighboring qubits. The MIT researchers have increased the number of superconducting qubits that can be added onto a device by a factor of 100.\n“We are addressing both qubit miniaturization and quality,” said William Oliver, the director for the Center for Quantum Engineering at MIT. “Unlike conventional transistor scaling, where only the number really matters, for qubits, large numbers are not sufficient, they must also be high-performance. Sacrificing performance for qubit number is not a useful trade in quantum computing. They must go hand in hand.”\nThe key to this big increase in qubit density and reduction of interference comes down to the use of two-dimensional materials, in particular the 2D insulator hexagonal boron nitride (hBN). The MIT researchers demonstrated that a few atomic monolayers of hBN can be stacked to form the insulator in the capacitors of a superconducting qubit.\nJust like other capacitors, the capacitors in these superconducting circuits take the form of a sandwich in which an insulator material is sandwiched between two metal plates. The big difference for these capacitors is that the superconducting circuits can operate only at extremely low temperatures—less than 0.02 degrees above absolute zero (-273.15 °C).\n\n\nSuperconducting qubits are measured at temperatures as low as 20 millikelvin in a dilution refrigerator.Nathan Fiske/MIT\nIn that environment, insulating materials that are available for the job, such as PE-CVD silicon oxide or silicon nitride, have quite a few defects that are too lossy for quantum computing applications. To get around these material shortcomings, most superconducting circuits use what are called coplanar capacitors. In these capacitors, the plates are positioned laterally to one another, rather than on top of one another.\nAs a result, the intrinsic silicon substrate below the plates and to a smaller degree the vacuum above the plates serve as the capacitor dielectric. Intrinsic silicon is chemically pure and therefore has few defects, and the large size dilutes the electric field at the plate interfaces, all of which leads to a low-loss capacitor. The lateral size of each plate in this open-face design ends up being quite large (typically 100 by 100 micrometers) in order to achieve the required capacitance.\nIn an effort to move away from the large lateral configuration, the MIT researchers embarked on a search for an insulator that has very few defects and is compatible with superconducting capacitor plates.\n“We chose to study hBN because it is the most widely used insulator in 2D material research due to its cleanliness and chemical inertness,” said colead author Joel Wang, a research scientist in the Engineering Quantum Systems group of the MIT Research Laboratory for Electronics. \nOn either side of the hBN, the MIT researchers used the 2D superconducting material, niobium diselenide. One of the trickiest aspects of fabricating the capacitors was working with the niobium diselenide, which oxidizes in seconds when exposed to air, according to Wang. This necessitates that the assembly of the capacitor occur in a glove box filled with argon gas.\nWhile this would seemingly complicate the scaling up of the production of these capacitors, Wang doesn’t regard this as a limiting factor.\n“What determines the quality factor of the capacitor are the two interfaces between the two materials,” said Wang. “Once the sandwich is made, the two interfaces are “sealed” and we don’t see any noticeable degradation over time when exposed to the atmosphere.”\nThis lack of degradation is because around 90 percent of the electric field is contained within the sandwich structure, so the oxidation of the outer surface of the niobium diselenide does not play a significant role anymore. This ultimately makes the capacitor footprint much smaller, and it accounts for the reduction in cross talk between the neighboring qubits.\n“The main challenge for scaling up the fabrication will be the wafer-scale growth of hBN and 2D superconductors like [niobium diselenide], and how one can do wafer-scale stacking of these films,” added Wang.\nWang believes that this research has shown 2D hBN to be a good insulator candidate for superconducting qubits. He says that the groundwork the MIT team has done will serve as a road map for using other hybrid 2D materials to build superconducting circuits.",
        "pubDate": "Mon, 07 Feb 2022 16:12:05 +0000",
        "isoDate": "2022-02-07T16:12:05.000Z",
        "creator": "Dexter Johnson",
        "source": "https://spectrum.ieee.org/2d-hbn-qubit"
      }
    ]
  },
  "coverage": [
    {
      "source_id": "techcrunch-alt-tech-breakthrough-ovr",
      "source_name": "TechCrunch Alt",
      "status": "ok",
      "bucket": "ok",
      "item_count": 20,
      "adapter": "rss",
      "kind": "news",
      "category": "tech_breakthrough",
      "editorial_weight": 120,
      "freshness_ts": 1771520489000,
      "ok_rate": 1
    },
    {
      "source_id": "reuters-tech-tech-breakthrough-3",
      "source_name": "Reuters Tech",
      "status": "unknown",
      "bucket": "unknown",
      "item_count": 0,
      "reason": "Error: HTML adapter requires selectors for reuters-tech-tech-breakthrough-3",
      "adapter": "rss",
      "kind": "news",
      "category": "tech_breakthrough",
      "editorial_weight": 90,
      "freshness_ts": 0,
      "ok_rate": 0
    },
    {
      "source_id": "deepmind-blog-tech-breakthrough-2",
      "source_name": "DeepMind Blog",
      "status": "unknown",
      "bucket": "unknown",
      "item_count": 0,
      "reason": "Error: HTML adapter requires selectors for deepmind-blog-tech-breakthrough-2",
      "adapter": "rss",
      "kind": "official",
      "category": "tech_breakthrough",
      "editorial_weight": 92,
      "freshness_ts": 0,
      "ok_rate": 0
    },
    {
      "source_id": "openai-blog-tech-breakthrough-1",
      "source_name": "OpenAI Blog",
      "status": "ok",
      "bucket": "ok",
      "item_count": 847,
      "adapter": "rss",
      "kind": "official",
      "category": "tech_breakthrough",
      "editorial_weight": 95,
      "freshness_ts": 1771448400000,
      "ok_rate": 1
    },
    {
      "source_id": "anthropic-news-policy-governance-10",
      "source_name": "Anthropic News",
      "status": "ok",
      "bucket": "ok",
      "item_count": 1,
      "adapter": "html",
      "kind": "official",
      "category": "policy_governance",
      "editorial_weight": 88,
      "freshness_ts": 1771521264119,
      "ok_rate": 1
    },
    {
      "source_id": "techcrunch-social-phenomenon-4",
      "source_name": "TechCrunch",
      "status": "ok",
      "bucket": "ok",
      "item_count": 20,
      "adapter": "rss",
      "kind": "news",
      "category": "social_phenomenon",
      "editorial_weight": 86,
      "freshness_ts": 1771520489000,
      "ok_rate": 1
    },
    {
      "source_id": "reuters-business-finance-capital-7",
      "source_name": "Reuters Business",
      "status": "unknown",
      "bucket": "unknown",
      "item_count": 0,
      "reason": "Error: HTML adapter requires selectors for reuters-business-finance-capital-7",
      "adapter": "rss",
      "kind": "news",
      "category": "finance_capital",
      "editorial_weight": 85,
      "freshness_ts": 0,
      "ok_rate": 0
    },
    {
      "source_id": "hn-front-social-phenomenon-5",
      "source_name": "HN Front",
      "status": "ok",
      "bucket": "ok",
      "item_count": 30,
      "adapter": "rss",
      "kind": "community",
      "category": "social_phenomenon",
      "editorial_weight": 82,
      "freshness_ts": 1771518026000,
      "ok_rate": 1
    },
    {
      "source_id": "eu-commission-policy-governance-11",
      "source_name": "EU Commission",
      "status": "unknown",
      "bucket": "unknown",
      "item_count": 0,
      "reason": "Error: HTML adapter requires selectors for eu-commission-policy-governance-11",
      "adapter": "rss",
      "kind": "official",
      "category": "policy_governance",
      "editorial_weight": 84,
      "freshness_ts": 0,
      "ok_rate": 0
    },
    {
      "source_id": "stanford-hai-policy-governance-12",
      "source_name": "Stanford HAI",
      "status": "unknown",
      "bucket": "unknown",
      "item_count": 0,
      "reason": "Error: HTML adapter requires selectors for stanford-hai-policy-governance-12",
      "adapter": "rss",
      "kind": "report",
      "category": "policy_governance",
      "editorial_weight": 84,
      "freshness_ts": 0,
      "ok_rate": 0
    },
    {
      "source_id": "andrew-ng-tech-breakthrough-19",
      "source_name": "Andrew Ng",
      "status": "blocked",
      "bucket": "blocked",
      "item_count": 0,
      "reason": "Error: X adapter not configured; use rss/blog/github fallback",
      "adapter": "x",
      "kind": "kol",
      "category": "tech_breakthrough",
      "editorial_weight": 80,
      "freshness_ts": 0,
      "ok_rate": 0,
      "kol_profile": {
        "platform": "x",
        "handle_or_url": "https://x.com/AndrewYNg",
        "fallback_signal_sources": [
          {
            "kind": "rss",
            "label": "fallback rss/blog",
            "url": "https://x.com/AndrewYNg"
          }
        ]
      }
    },
    {
      "source_id": "yann-lecun-tech-breakthrough-20",
      "source_name": "Yann LeCun",
      "status": "blocked",
      "bucket": "blocked",
      "item_count": 0,
      "reason": "Error: X adapter not configured; use rss/blog/github fallback",
      "adapter": "x",
      "kind": "kol",
      "category": "tech_breakthrough",
      "editorial_weight": 80,
      "freshness_ts": 0,
      "ok_rate": 0,
      "kol_profile": {
        "platform": "x",
        "handle_or_url": "https://x.com/ylecun",
        "fallback_signal_sources": [
          {
            "kind": "rss",
            "label": "fallback rss/blog",
            "url": "https://x.com/ylecun"
          }
        ]
      }
    },
    {
      "source_id": "venturebeat-ai-finance-capital-8",
      "source_name": "VentureBeat AI",
      "status": "ok",
      "bucket": "ok",
      "item_count": 7,
      "adapter": "rss",
      "kind": "news",
      "category": "finance_capital",
      "editorial_weight": 82,
      "freshness_ts": 1769090400000,
      "ok_rate": 1
    },
    {
      "source_id": "reddit-ml-social-phenomenon-6",
      "source_name": "Reddit ML",
      "status": "unknown",
      "bucket": "unknown",
      "item_count": 0,
      "reason": "Error: HTML adapter requires selectors for reddit-ml-social-phenomenon-6",
      "adapter": "rss",
      "kind": "community",
      "category": "social_phenomenon",
      "editorial_weight": 80,
      "freshness_ts": 0,
      "ok_rate": 0
    },
    {
      "source_id": "ars-technica-safety-incident-13",
      "source_name": "Ars Technica",
      "status": "ok",
      "bucket": "ok",
      "item_count": 20,
      "adapter": "rss",
      "kind": "news",
      "category": "safety_incident",
      "editorial_weight": 80,
      "freshness_ts": 1771510315000,
      "ok_rate": 1
    },
    {
      "source_id": "krebs-on-security-safety-incident-14",
      "source_name": "Krebs on Security",
      "status": "ok",
      "bucket": "ok",
      "item_count": 10,
      "adapter": "rss",
      "kind": "report",
      "category": "safety_incident",
      "editorial_weight": 79,
      "freshness_ts": 1770826091000,
      "ok_rate": 1
    },
    {
      "source_id": "reuters-cybersecurity-safety-incident-15",
      "source_name": "Reuters Cybersecurity",
      "status": "unknown",
      "bucket": "unknown",
      "item_count": 0,
      "reason": "Error: HTML adapter requires selectors for reuters-cybersecurity-safety-incident-15",
      "adapter": "rss",
      "kind": "news",
      "category": "safety_incident",
      "editorial_weight": 78,
      "freshness_ts": 0,
      "ok_rate": 0
    },
    {
      "source_id": "the-information-finance-capital-9",
      "source_name": "The Information",
      "status": "http_4xx",
      "bucket": "http_4xx",
      "item_count": 0,
      "reason": "Error: HTTP 403 for the-information-finance-capital-9",
      "adapter": "html",
      "kind": "report",
      "category": "finance_capital",
      "editorial_weight": 78,
      "freshness_ts": 0,
      "ok_rate": 0
    },
    {
      "source_id": "datacenter-dynamics-energy-environment-16",
      "source_name": "Datacenter Dynamics",
      "status": "unknown",
      "bucket": "unknown",
      "item_count": 0,
      "reason": "Error: HTML adapter requires selectors for datacenter-dynamics-energy-environment-16",
      "adapter": "rss",
      "kind": "news",
      "category": "energy_environment",
      "editorial_weight": 78,
      "freshness_ts": 0,
      "ok_rate": 0
    },
    {
      "source_id": "ethan-mollick-social-phenomenon-21",
      "source_name": "Ethan Mollick",
      "status": "unknown",
      "bucket": "unknown",
      "item_count": 0,
      "reason": "Error: HTML adapter requires selectors for ethan-mollick-social-phenomenon-21",
      "adapter": "rss",
      "kind": "kol",
      "category": "social_phenomenon",
      "editorial_weight": 79,
      "freshness_ts": 0,
      "ok_rate": 0,
      "kol_profile": {
        "platform": "rss",
        "handle_or_url": "https://oneusefulthing.substack.com",
        "fallback_signal_sources": []
      }
    },
    {
      "source_id": "reuters-commodities-energy-environment-17",
      "source_name": "Reuters Commodities",
      "status": "unknown",
      "bucket": "unknown",
      "item_count": 0,
      "reason": "Error: HTML adapter requires selectors for reuters-commodities-energy-environment-17",
      "adapter": "rss",
      "kind": "news",
      "category": "energy_environment",
      "editorial_weight": 77,
      "freshness_ts": 0,
      "ok_rate": 0
    },
    {
      "source_id": "ieee-spectrum-energy-environment-18",
      "source_name": "IEEE Spectrum",
      "status": "ok",
      "bucket": "ok",
      "item_count": 30,
      "adapter": "rss",
      "kind": "report",
      "category": "energy_environment",
      "editorial_weight": 76,
      "freshness_ts": 1771441203000,
      "ok_rate": 1
    },
    {
      "source_id": "gary-marcus-policy-governance-22",
      "source_name": "Gary Marcus",
      "status": "unknown",
      "bucket": "unknown",
      "item_count": 0,
      "reason": "Error: HTML adapter requires selectors for gary-marcus-policy-governance-22",
      "adapter": "rss",
      "kind": "kol",
      "category": "policy_governance",
      "editorial_weight": 76,
      "freshness_ts": 0,
      "ok_rate": 0,
      "kol_profile": {
        "platform": "rss",
        "handle_or_url": "https://garymarcus.substack.com",
        "fallback_signal_sources": []
      }
    }
  ]
}